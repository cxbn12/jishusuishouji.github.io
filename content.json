[{"title":"Java的类加载机制","date":"2017-05-09T16:52:35.000Z","path":"2017/05/10/Java的类加载机制.md/Java的类加载机制/","text":"","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"}]},{"title":"Java虚拟机：Java类加载机制","date":"2017-05-09T14:57:56.000Z","path":"2017/05/09/java/Java虚拟机：Java类加载机制/","text":"源代码(.java)会被编译为class文件(.class文件)，.class文件描述了类的各种信息，.class文件需要加载到虚拟机之后才能运行和使用。 类加载使用的7个阶段类从加载到虚拟机到到卸载出内存，整个生命周期包括：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initiallization）、使用（Using）和卸载（Unloading）这7个阶段。其中验证、准备、解析这个三个阶段统称为连接（Linking）加载、验证、准备、初始化、卸载这五个阶段的顺序是确定的，而解析阶段不一定：它在某些情况下可以初始化阶段之后再开始，这是为了支持Java语言的运行时绑定（也称为动态绑定）。加载、验证、准备、解析、初始化五个阶段组成了一个完整的类加载过程。卸载属于GC的工作。 加载（Loading）有两种时机会触发类加载：1、预加载。虚拟机启动时加载，加载的是JAVA_HOME/lib/下的rt.jar中的.class文件，由于rt.jar包中的类经常被使用，因此随着虚拟机启动一起被加载。 验证rt.java包中的类是否在虚拟器启动的时候被加载123public class Test &#123; public static void main(String[] args) &#123;&#125;&#125; 编译运行该类:123456789101112131415&gt;javac Test.java&gt;java -XX:+TraceClassLoading Test[Opened C:\\Program Files\\Java\\jdk1.8.0_111\\jre\\lib\\rt.jar][Loaded java.lang.Object from C:\\Program Files\\Java\\jdk1.8.0_111\\jre\\lib\\rt.jar][Loaded java.io.Serializable from C:\\Program Files\\Java\\jdk1.8.0_111\\jre\\lib\\rt.jar][Loaded java.lang.Comparable from C:\\Program Files\\Java\\jdk1.8.0_111\\jre\\lib\\rt.jar][Loaded java.lang.CharSequence from C:\\Program Files\\Java\\jdk1.8.0_111\\jre\\lib\\rt.jar][Loaded java.lang.String from C:\\Program Files\\Java\\jdk1.8.0_111\\jre\\lib\\rt.jar][Loaded java.lang.reflect.AnnotatedElement from C:\\Program Files\\Java\\jdk1.8.0_111\\jre\\lib\\rt.jar][Loaded java.lang.reflect.GenericDeclaration from C:\\Program Files\\Java\\jdk1.8.0_111\\jre\\lib\\rt.jar][Loaded java.lang.reflect.Type from C:\\Program Files\\Java\\jdk1.8.0_111\\jre\\lib\\rt.jar][Loaded java.lang.Class from C:\\Program Files\\Java\\jdk1.8.0_111\\jre\\lib\\rt.jar][Loaded java.lang.Cloneable from C:\\Program Files\\Java\\jdk1.8.0_111\\jre\\lib\\rt.jar][Loaded java.lang.ClassLoader from C:\\Program Files\\Java\\jdk1.8.0_111\\jre\\lib\\rt.jar]... 2、运行时加载。虚拟机在用到一个.class文件的时会先去内存中查看一下这个.class文件有没有被加载，如果没有就会按照类的全限定名来加载这个类。 加载阶段做的事情1、获取.class文件的二进制流2、将.class文件中包含的类信息、静态变量、字节码、常量等内容放入方法区中3、在内存中生成一个代表这个.class文件的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。一般这个Class是在堆里的，不过HotSpot虚拟机是放在方法区中的。 虚拟机规范对这三点并没有做详细的规定，因此虚拟机实现的灵活度是相当大的。加载阶段对于开发者来说是可控性最强的一个阶段。 验证连接阶段的第一步，主要是为了确保.class文件的字节流包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 .class文件不一定要从Java源码编译而来，可以使用任何途径产生，甚至包括用十六进制编辑器直接编写来产生.class文件。虚拟机如果不检查输入的字节流，对其完全信任的话，很可能会因为载入了有害的字节流而导致系统崩溃，所以验证是虚拟机对自身保护的一项重要工作。 验证阶段主要包含以下几个工作：1、文件格式验证.class文件的第5~第8个字节表示的是该.class文件的主次版本号，验证的时候会对这4个字节做一个验证，高版本的JDK能向下兼容以前版本的.class文件，但不能运行以后的class文件，即使文件格式未发生任何变化，虚拟机也必须拒绝执行超过其版本号的.class文件。例如有一段java代码是JDK1.6编译的，那么JDK1.6、JDK1.7能运行编译出来.class文件，而JDK1.5、JDK1.4以及更低的JDK版本是无法运行这个.class文件的。如果运行，会抛出java.lang.UnsupportedClassVersionError。 2、元数据验证 3、字节码验证 4、符号引用验证 准备准备阶段是正式为类变量分配内存并设置其初始值的阶段，这些变量所使用的内存都将在方法区中分配。1、这时候进行内存分配的仅仅是类变量（被static修饰的变量），而不是实例变量，实例变量将会在对象实例化的时候随着对象一起分配在Java堆中2、这个阶段赋初始值的变量指的是那些不被final修饰的static变量，比如public static int value = 123;，value在准备阶段过后是0而不是123，给value赋值为123的动作是在初始化阶段才进行的；而public static final int value = 123;,在准备阶段，虚拟机就会给value赋值为123。 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 初始化初始化阶段是类加载过程的最后一步，初始化阶段是真正执行类中定义的Java字节码的过程。初始化过程是一个执行类构造器&lt;clinit&gt;()方法的过程，根据程序员通过程序制定的主观计划去初始化类变量和其它资源。初始化阶段做的事就是给static变量赋予用户指定的值以及执行静态代码块。 注意一下，虚拟机会保证类的初始化在多线程环境中被正确地加锁、同步，即如果多个线程同时去初始化一个类，那么只会有一个类去执行这个类的&lt;clinit&gt;()方法，其他线程都要阻塞等待，直至活动线程执行&lt;clinit&gt;()方法完毕。因此如果在一个类的&lt;clinit&gt;()方法中有耗时很长的操作，就可能造成多个进程阻塞。不过其他线程虽然会阻塞，但是执行&lt;clinit&gt;()方法的那条线程退出&lt;clinit&gt;()方法后，其他线程不会再次进入&lt;clinit&gt;()方法了，因为同一个类加载器下，一个类只会初始化一次。实际应用中这种阻塞往往是比较隐蔽的，要小心。 Java虚拟机规范严格规定了有且只有5种场景必须立即对类进行初始化，这4种场景也称为对一个类进行主动引用： 1、使用new关键字实例化对象、读取或者设置一个类的静态字段（被final修饰的静态字段除外）、调用一个类的静态方法的时候2、使用java.lang.reflect包中的方法对类进行反射调用的时候3、初始化一个类，发现其父类还没有初始化过的时候4、虚拟机启动的时候，虚拟机会先初始化用户指定的包含main()方法的那个类 除了上面4种场景外，所有引用类的方式都不会触发类的初始化，称为被动引用： 1、子类引用父类静态字段，不会导致子类初始化。 123456public class SuperClass &#123; public static String value = &quot;value&quot;; static &#123; System.out.println(&quot;SuperClass init&quot;); &#125;&#125; 12345public class SubClass extends SuperClass &#123; static &#123; System.out.println(&quot;SubClass init&quot;); &#125;&#125; 12345public class TestMain &#123; public static void main(String[] args) &#123; System.out.println(SubClass.value); &#125;&#125; 运行结果为：12SuperClass initvalue 2、通过数组定义引用类，不会触发此类的初始化12345public class TestMain &#123; public static void main(String[] args) &#123; SuperClass[] scs = new SuperClass[10]; &#125;&#125; 运行之后没有任何输出 3、引用静态常量时，常量在编译阶段会存入类的常量池中，本质上并没有直接引用到定义常量的类1234567public class Constant &#123; public static final String CONSTANT = &quot;CONSTANT&quot;; static &#123; System.out.println(&quot;Constant init&quot;); &#125;&#125; 12345public class TestMain &#123; public static void main(String[] args) &#123; System.out.println(Constant.CONSTANT); &#125;&#125; 运行结果为：1CONSTANT","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"}]},{"title":"如何配置Policy文件进行Java安全策略的设置","date":"2017-05-08T19:08:09.000Z","path":"2017/05/09/如何配置Policy文件进行Java安全策略的设置.md/如何配置Policy文件进行Java安全策略的设置/","text":"Java语言具有完善的安全框架，从编程语言、编译器、解释程序到Java虚拟机，都能确保Java系统不被恶意的代码或敌对的编译器暗中破坏，它们能够保证Java代码按预定的规则运作。但是如果需要逾越这些限制时，比如读写文件，监听和读写Socket，退出Java系统，就必须使用数字签名或安全策略文件（*.Policy）。 在企业内部网中，推荐使用安全策略文件来设置java程序权限。企业内部网中各台计算机的位置、用途和安全性明确，更适于使用安全策略文件来设置java的权限，软件的安装、设置、升级和迁移都非常的方便，并且还可以和数字签名配合使用，更重要的是可以细分每个java程序的权限，使用起来灵活方便。 Java中安全策略的概念 Java安全策略详细说明了不同的代码所拥有的不同资源的许可，由一个Policy对象来表达。比如为了让applet（或者运行在SecurityManager下的应用程序）能够执行受保护的行为，例如读写文件，applet（或Java应用程序）必须获得那项操作的许可,安全策略文件可以配置这些许可。在程序中可以通过调用getPolicy方法得到当前安装的Policy对象，也可以通过调用setPolicy方法改变。Policy对象评估整个策略，返回一个适当的Permissions对象，详细说明那些代码可以访问那些资源。 策略文件可以储存在无格式的ASCII文件，或Policy类的二进制文件，或数据库中。本文仅讨论无格式的ASCII文件的形式。 Policy文件的格式\\jdk1.8.0_111\\jre\\lib\\security\\java.policy\\jdk1.8.0_111\\jre\\lib\\security\\java.security Policy文件的语法格式与说明Policy文件实质上是一个记录列表，它可能含有一个“keystore”记录，以及含有零个或多个“grant”记录。123456keystore &quot;some_keystore_url&quot;, &quot;keystore_type&quot;;grant [SignedBy &quot;signer_names&quot;] [, CodeBase &quot;URL&quot;] &#123; Permission permission_class_name [ &quot;target_name&quot; ] [, &quot;action&quot;] [, SignedBy &quot;signer_names&quot;]; Permission ...&#125;; keystore记录keystore是一个私有密钥（private keys）数据库和相应的数字签名，例如X.509证书。Policy文件中可能只有一条keystore记录（也可能不含有该记录），它可以出现在文件中grant记录以外的任何地方。Policy配置文件中指定的keystores用于寻找grant记录中指定的、签名者的公共密钥（public keys），如果任何grant记录指定签名者（signer_names），那么，keystore记录必须出现在policy配置文件中。 —- “some_keystore_url”是指keystore的URL位置，”keystore_type”是指keystore的类型。第二个选项是可选项，如果没有指定，该类型则假定由安全属性文件（java.security）中的”keystore.type”属性来确定。keystore类型定义了keystore信息的存储和数据格式，用于保护keystore中的私有密钥和keystore完整性的算法。Sun Microsystems支持的缺省类型为“JKS”。 grant记录在`Policy文件中的每一个grant记录含有一个CodeSource（一个指定的代码）及其permission(许可)。 Policy文件中的每一条grant记录遵循下面的格式，以保留字“grant”开头，表示一条新的记录的开始，“Permission”是另一个保留字，在记录中用来标记一个新的许可的开始。每一个grant记录授予一个指定的代码（CodeBase）一套许可（Permissions）。 permission_class_name必须是一个合格并存在的类名，例如java.io.FilePermission，不能使用缩写（例如FilePermission）。target_name用来指定目标类的位置，action用于指定目标类拥有的权限。target_name可以直接指定类名（可以是绝对或相对路径），目录名，也可以是下面的通配符： directory/ 目录下的所有文件 当前目录的所有文件directory/-目录下的所有文件，包括子目录 当前目录下的所有文件，包括子目录《ALL FILES》文件系统中的所有文件对于java.io.FilePermission，action可以是：read, write, delete和execute。对于java.net.SocketPermission，action可以是：listen，accept，connect，read，write。 —- 1.3 Policy文件中的属性扩展（Property Expansion）—- 属性扩展与shell中使用的变量扩展类似，它的格式为： “${some.property}”实际使用的例子为：permission java.io.FilePermission“${user.home}”, “read”;“${user.home}”的值为”d:\\Project”，因此，下面的语句和上面的语句是一样的：permission java.io.FilePermission “d:\\Project “, “read”; 三. 实例—- 当初始化Policy时，首先装载系统Policy，然后再增加用户Policy，如果两者都不存在，则使用缺省的Policy，即原始的沙箱模型。—- 系统Policy文件的缺省位置为： {java.home}/lib/security/java.policy (Solaris){java.home}\\lib\\security\\java.policy (Windows)用户Policy文件的缺省位置为：{user.home}/.java.policy (Solaris){user.home}.java.policy (Windows) —- 其实，在实际使用中，我们可能不会象上面介绍的那么复杂，特别是在不使用数字签名时。这时，我们完全可以借鉴JDK 1.2提供给我们的现成的\\jdk1.2\\jre\\lib\\security\\java.policy文件，根据我们的需要作相应的修改，本文就针对不使用数字签名情况详细说明安全策略文件的用法。—- 下面，是一个完整的在Windows 95/98/NT下使用的.java.policy文件。在文件中，分别使用注释的形式说明了每个“permission”记录的用途。 // For LanServerTalk.java and LanClientTalk.java grant {//对系统和用户目录“读”的权限permission java.util.PropertyPermission“user.dir”, “read”;permission java.util.PropertyPermission“user.home”, “read”;permission java.util.PropertyPermission“java.home”, “read”;permission java.util.PropertyPermission“java.class.path”, “read”;permission java.util.PropertyPermission“user.name”, “read”; //对线程和线程组的操作权限permission java.lang.RuntimePermission“modifyThread”;permission java.lang.RuntimePermission“modifyThreadGroup”; //操作Socket端口的各种权限permission java.net.SocketPermission“-“, “listen”;permission java.net.SocketPermission“-“, “accept”;permission java.net.SocketPermission“-“, “connect”;permission java.net.SocketPermission “-“, “read”;permission java.net.SocketPermission “-“, “write”; //读写文件的权限permission java.io.FilePermission “-“, “read”;permission java.io.FilePermission “-“, “write”; //退出系统的权限，例如System.exit(0)permission java.lang.RuntimePermission “exitVM”;}; 四. java.policy文件的使用—- 对于windows 95/98/NT，使用.java.policy文件的方法主要有下面两种。—- 1． 使用缺省目录 —- 我们可以简单地将编辑好的.java.policy文件拷贝到windows 95/98/NT的HOME目录，这时，所有的applet(或Java应用程序)可能都拥有某些相同的权限，使用起来简单，但不灵活（例如：对于java.io.FilePermission ，其目标类的target_name必须使用绝对路径），如果不是在企业内部网中使用，还可能存在一定安全隐患。 —- 2． 在命令行中指定 —- 在命令行，如果我们希望传递一个Policy文件给appletviewer，还可以使用”-J-Djava.security.policy”参数来指定policy的位置： appletviewer -J-Djava.security.policy=pURL myApplet —- pURL为Policy文件的位置。下面，是一个实际的例子，以当前目录的.java.policy文件所指定的安全策略运行当前目录的LanServerTalk.html（文件中装载并运行LanServerTalk.java）：appletviewer -J-Djava.security.policy=.java.policy LanServerTalk.html —- 这种方法使用灵活，特别是作为一个软件包在企业内部网中发布时，安装、设置和迁移软件，基本无须修改Policy文件的内容，使用起来相当简单，而且，安全许可的范围控制较精细。 缺省策略实现和策略文件语法上次修改时间： 1998 年 10 月 30 日 Java 应用程序环境的策略（对不同来源的代码指定权限）由 Policy 对象来表示。更明确地说，就是由 Policy 类（包含在 java.security 包中）的实现抽象方法的 Policy 子类来表示。 Policy 对象所用策略信息的源位置由 Policy 实现决定。缺省 Policy 实现从静态策略配置文件获得自己的信息。本文档的其余部分叙述了缺省 Policy 实现及其所读取的策略文件中必须使用的语法。有关使用 Policy Tool 来创建策略文件（不必知道所需语法）的详细信息，请参阅《策略工具文档》 (for Solaris) (for Windows)。 以下是本文档其余部分的概要： 缺省 Policy 实现缺省策略文件位置更改 Policy 实现策略文件语法策略文件示例策略文件中的属性扩展相关文档 缺省 Policy 实现在缺省 Policy 实现中，可在一个或多个策略配置文件中指定策略。配置文件的作用是指定特定代码源的代码所能获得的权限。 可利用简单的文本编辑器或 Policy Tool 实用程序来编写策略文件。 缺省情况下，系统上只有单个全系统策略文件和唯一的（可选）用户策略文件。 首次调用缺省 Policy 对象的 getPermissions 方法或在任何时候调用 Policy 对象 refresh 方法时，即对其进行初始化。初始化包括分析策略配置文件（请参阅策略文件语法）及组装 Policy 对象。 缺省策略文件位置如前所述，系统在缺省情况下具有单个全系统策略文件和唯一的用户策略文件。 系统策略文件的缺省位置为： java.home/lib/security/java.policy (Solaris)java.home\\lib\\security\\java.policy (Windows)注意： java.home 指的是名为“java.home”的系统属性的值，它指定 JDK 的安装目录。 系统策略文件可用于授予全系统代码权限。与 JDK 一起安装的 java.policy 文件可向标准扩展 (Java standard extensions) 授予全部权限，允许任何用户在无特权要求的端口进行监听，同时允许任何代码读取某些对安全不敏感的“标准”属性（例如“os.name”和“file.separator”属性）。 用户策略文件的缺省位置为： user.home/.java.policy (Solaris)user.home.java.policy (Windows)注意： user.home 指的是名为“user.home”的系统属性的值，它指定用户的主目录。在 Windows 系统中，假定用户名是 uName，“user.home”属性的缺省值为： C:\\Winnt\\Profiles\\uName（多用户 Windows NT 系统中）C:\\Windows\\Profiles\\uName（多用户 Windows 95 系统中）C:\\Windows（单用户 Windows 95 系统中）初始化 Policy 时，将首先加载系统策略，然后在 Policy 中添加用户策略。如果两种策略均不存在，则采用内置策略。该内置策略与原始的沙箱策略相同。 策略文件的位置在安全属性文件中指定。安全属性文件的位置为： java.home/lib/security/java.security (Solaris)java.home\\lib\\security\\java.security (Windows)如上所述，java.home 指示 JDK 的安装目录。策略文件的位置被指定为其名称具有以下形式的属性的值： policy.url.n其中 n 为数字。应采用以下形式的语句行来指定每个属性值： policy.url.n=URL其中，URL 为 URL 规范。 例如，安全属性文件中将把缺省系统和用户策略文件定义为： policy.url.1=file:${java.home}/lib/security/java.policypolicy.url.2=file:${user.home}/.java.policy有关利用特殊语法（例如利用 ${java.home} 来指定 java.home 属性值）来指定属性值的详细信息，请参阅属性扩展。 实际上，用户可以指定多个 URL（包括“http://”形式的 URL）,从而加载所有指定的策略文件。也可注释掉或更改第二个 URL，从而禁止读取缺省用户策略文件。 该算法自 policy.url.1 开始，然后不断递增直到查不到 URL 为止。因此，如果有了 policy.url.1 和 policy.url.3，就不会读取 policy.url.3。 运行时指定其它策略文件 在执行应用程序时也可以指定附加的或不同的策略文件，方法是用“-Djava.security.policy”命令行参数来指定（该命令行参数设置 java.security.policy 属性值）。例如，如果使用 java -Djava.security.manager -Djava.security.policy=someURL SomeApp 这里 someURL 是指定策略文件位置的 URL，则除了加载安全属性文件中指定的所有策略文件外，还会加载本方法所指定的策略文件。 注意： URL 可以是任何标准 URL，也可以只是当前目录下策略文件的文件名，如下例所示： java -Djava.security.manager -Djava.security.policy=mypolicy WriteFile“-Djava.security.manager”参数可确保缺省安全管理器已被安装，这样就容易对应用程序进行策略检查。如果应用程序 SomeApp 安装有安全管理器，则不需要该参数。如果使用 java -Djava.security.manager -Djava.security.policy==someURL SomeApp （请注意双等号），就会仅使用指定的策略文件，而安全属性文件中指出的策略文件将被忽略。 如果要将策略文件传递给 appletviewer，就应使用参数“-J-Djava.security.policy”，如下所示： appletviewer -J-Djava.security.policy=someURL myApplet 请注意：如果将安全属性文件中的“policy.allowSystemProperty”属性设置为“false”，就会忽略“-Djava.security.policy”策略文件值（对于 java 和 appletviewer 命令）。缺省值为“true”。 更改 Policy 实现可以用其它 policy 类来代替缺省 Policy 实现类，前提是前者属于抽象 Policy 类的子类并可实现 getPermissions 方法（及其它必要的方法）。 缺省 Policy 实现的更改可通过编辑安全属性文件来完成，其中安全属性文件指 JDK lib/security 目录中的 java.security 文件。 下面给出一种可在 java.security 中设置的属性类型的形式： policy.provider=PolicyClassName PolicyClassName 必须指定所需 Policy 实现类的完整名称。该属性的缺省安全属性文件项如下所示： policy.provider=sun.security.provider.PolicyFile 要想自定义安全属性文件项，可通过更改属性值来指定另一个类，如下例所示： policy.provider=com.mycom.MyPolicy策略文件语法JDK 的策略配置文件可用于指定来自特定代码源的代码所能获得的权限（何种系统资源访问类型）。 为了使 applet（或在安全管理器下运行的应用程序）能够执行受保护的动作（例如读写文件），必须向 applet（或应用程序）授予进行该动作的权限。在缺省 Policy 实现中，必须由策略配置文件中的 grant 项授予该权限。有关详细信息，请参阅以下内容及 “Java 安全体系结构规范”（唯一的例外是：代码对位于与它自身同一 (URL) 位置并且对那一位置子目录下的文件总是自动拥有读权限，而无需授予明确的权限）。 策略配置文件主要包含授权项列表。其中可能包含“keystore”（密钥仓库）项及零个或多个“grant”（授权）项。 Keystore 项 keystore 是存放私钥及相关数字证书（例如验证对应的公钥的 X.509 证书链）的数据库。keytool 实用程序 (for Solaris) (for Windows) 用于创建和管理密钥仓库。策略配置文件中所指定的 keystore 用于查找在该文件的授权项中所指定的签名人公钥。如果某一授权项指定了签名人别名（请参阅以下内容），则在策略配置文件中必须含有 keystore 项。 目前，在策略文件中只能有一个 keystore 项（第一项后的其它 keystore 项将被忽略），且该项可位于文件授权项以外的任何位置。其语法如下所示： keystore &quot;some_keystore_url&quot;, &quot;keystore_type&quot;; 其中“some_keystore_url”指定密钥仓库的 URL 位置，而“keystore_type”指定密钥仓库的类型。 URL 是相对于策略文件位置而言。因此，如果在安全属性文件中按以下方式指定策略文件： policy.url.1=http://foo.bar.com/fum/some.policy 而且策略文件中含有以下项： keystore &quot;.keystore&quot;; 就会从下列位置加载密钥仓库： http://foo.bar.com/fum/.keystore URL 也可以是绝对 URL。 keystore type 定义密钥仓库信息的存储和数据格式，同时也定义用于保护密钥仓库中私钥及密钥仓库自身完整性的算法。Sun Microsystems 所支持的缺省类型是名为“JKS”的专用密钥仓库类型。因此，如果密钥仓库类型属于“JKS”，就无需在 keystore 项中加以指定。 授权项 通常认为执行代码来自于某“代码源”（由 CodeSource 类型的对象表示）。代码源不仅包含代码的源位置 (URL)，而且还包括对包含与签写代码的私钥相对应的公钥的证书之引用。代码源中的证书通过用户密钥仓库中的符号别名引用。 每个授权项包括一个或多个“权限项”，前面为可选 codeBase 和 signedBy 名字/值对，用于指定要授予权限的代码。授权项的基本格式如下所示： grant signedBy “signer_names”, codeBase “URL” { permission permission_class_name “target_name”, “action”, signedBy “signer_names”; …. permission permission_class_name “target_name”, “action”, signedBy “signer_names”; }; 以上所有非斜体的项必须按原样出现（尽管大小写无关紧要且部分为可选项，如下所示）。 斜体项代表变量值。 授权项必须以 grant 开头。 SignedBy 和 CodeBase 域 signedBy 和 codeBase 名字/值对为可选域，其间的顺序无关紧要。 signedBy 值表示存储在密钥仓库中的证书别名。该证书内的公钥用于验证代码上的数字签名；用户可以向由私钥（私钥对应于该别名所指定的 keystore 项中的公钥）签名的代码授予权限。 signedBy 的值可以是由逗号分隔的多个别名。 例如“Adam,Eve,Charles”，其含义为“Adam，Eve 和 Charles 签名”；它们之间的关系是 AND（与）而非 OR（或）。更确切地说，“Adam 签名的代码”语句的含义是“JAR 文件中有含类文件的代码，这个 JAR 文件已用密钥仓库中别名为 Adam 的项中与公钥所对应的私钥签名”。 signedBy 域可选，这是因为如果省略该域，则表示“任何签名人”。代码是否有签名或由谁签名都没有关系。 codeBase 值表示的是代码源位置；用户可向来自该位置的代码授权。空 codeBase 项表示“任何代码”；代码来源于何处没有关系。 注意： codeBase 值是 URL，因此应该始终用正斜杠（而不要用反斜杠）作为目录分隔符，即使代码源实际在 Windows 系统上。这样，如果 Windows 系统上代码的源位置实际上是 C:\\somepath\\api\\，则 codeBase 策略项的外观将如下所示： grant codeBase &quot;file:/C:/somepath/api/&quot; { ... } codeBase 值的准确含义要取决于最后的字符。后面跟着“/”的 codeBase 将匹配指定目录下的所有类文件（非 JAR 文件）。后面跟着“/*”的 codeBase 将匹配该目录下的所有文件（类文件和 JAR 文件）。后面跟着“/-”的 codeBase 将匹配该目录下的所有文件（类文件和 JAR 文件）及该目录下子目录中的所有文件。下表说明了各种不同的情况。下载代码的 Codebase URL 策略中的 Codebase URL 是否匹配?java.sun.com/people/gong/ java.sun.com/people/gong是 java.sun.com/people/gong/ java.sun.com/people/gong/是 java.sun.com/people/gong/ java.sun.com/people/gong/*是 java.sun.com/people/gong/ java.sun.com/people/gong/-是 java.sun.com/people/gong/appl.jar java.sun.com/people/gong/否 java.sun.com/people/gong/appl.jar java.sun.com/people/gong/-是 java.sun.com/people/gong/appl.jar java.sun.com/people/gong/*是 java.sun.com/people/gong/appl.jar java.sun.com/people/-是 java.sun.com/people/gong/appl.jar java.sun.com/people/*否 java.sun.com/people/gong/ java.sun.com/people/-是 java.sun.com/people/gong/ java.sun.com/people/*否 权限项 权限项必须以 permission 开头。上述模板中的字 permission_class_name 的实际值可以是特定的权限类型（例如 java.io.FilePermission 或 java.lang.RuntimePermission）。 “action” 对于许多权限类型而言都是必需的，例如 java.io.FilePermission（指定允许何种类型的文件访问权限）。 对于诸如 java.lang.RuntimePermission 等权限类型则为可选项：既可以在 permission_class_name 之后的 “target_name” 值中指定权限，也可以不指定权限。 权限项的 signedBy 名字/值对为可选项。如果有名字/值对，则表示为已签名权限。意即必须由给定的别名对权限类签名，方可授予权限。例如，假定有以下授权项： grant { permission Foo “foobar”, signedBy “FooSoft”; }如果将 Foo.class 权限放到 JAR 文件中，且该 JAR 文件已由与 “FooSoft” 别名所指定的证书中的公钥相对应的私钥签名，或在 Foo.class 是系统类（因为系统类不受策略限制）的情况下，即可授予 Foo 权限类型。 权限项中出现的项目必须按指定顺序出现（permission，permission_class_name，”target_name”，”action” 和 signedBy “signer_names”）。分号表示项终止。 大小写对于标识符（permission、signedBy、codeBase 等）来说并不重要，但对于 permission_class_name 或作为值传递过来的字符串而言就很重要了。 有关 Windows 系统上文件路径规范的注意事项 请注意：在指定 java.io.FilePermission 时，”target_name” 是文件路径。在 Windows 系统上，无论何时在字符串中（而不是在 codeBase URL 中）直接指定文件路径，路径中都需要两个反斜杠来代表一个实际的反斜杠，如下例所示： grant { permission java.io.FilePermission “C:\\users\\cathy\\foo.bat”, “read”; };原因在于：字符串是由符号处理器 (java.io.StreamTokenizer) 来处理的。符号处理器允许将“\\”用作转义字符串（例如，“\\n”表示换行），因此需要用两个反斜杠来表示一个反斜杠。符号处理器处理完以上文件路径字符串后，将把双反斜杠转换成单个反斜杠，其最终结果为： &quot;C:\\users\\cathy\\foo.bat&quot; 策略文件示例策略配置文件中两项的示例如下所示： // 如果代码由 “Duke” 签字，则向 /tmp 中的所有文件 // 授予读/写访问权限： grant signedBy “Duke” { permission java.io.FilePermission “/tmp/*”, “read,write”; };// 授予所有用户以下权限： grant { permission java.util.PropertyPermission “java.vendor”; }; 另一个示例策略配置文件如下所示。 grant signedBy “sysadmin”, codeBase “file:/home/sysadmin/“ { permission java.security.SecurityPermission “Security.insertProvider.“; permission java.security.SecurityPermission “Security.removeProvider.“; permission java.security.SecurityPermission “Security.setProperty.“; };本示例规定：只有满足以下条件的代码才能调用 Security 类中的方法以添加或删除提供者或者设置 Security 属性： 代码将从位于本地文件系统上“/home/sysadmin/”目录下的签名 JAR 文件中加载。可以用密钥仓库中别名“sysadmin”所引用的公钥来校验签名。可以忽略代码源中两个组件的任何一个（或两者）。下面是忽略 codeBase 的示例： grant signedBy “sysadmin” { permission java.security.SecurityPermission “Security.insertProvider.“; permission java.security.SecurityPermission “Security.removeProvider.“; };如果该策略生效，则来自 JAR 文件（由 “sysadmin” 签名）的代码可以添加/删除提供者，而不管 JAR 文件来源于何处。 下面是没有签名人的示例： grant codeBase “file:/home/sysadmin/-“ { permission java.security.SecurityPermission “Security.insertProvider.“; permission java.security.SecurityPermission “Security.removeProvider.“; };这里，来自本地文件系统“/home/sysadmin/”目录下任意位置的代码都可以添加/删除提供者。 该代码不必签名。 下面是既不含 codeBase 也不含 signedBy 的示例： grant { permission java.security.SecurityPermission “Security.insertProvider.“; permission java.security.SecurityPermission “Security.removeProvider.“; };此处，由于两个代码源组件均被忽略，因此任何代码（不管来自于何处，是否已签名或由何人签名）都可添加/删除提供者。 策略文件中的属性扩展策略文件和安全属性文件中可以进行属性扩展。 属性扩展类似于扩展 shell 中的变量。也就是说，当类似 ${some.property} 的字符串出现在策略文件或安全属性文件中时，它将被扩展为系统属性的值。 例如， permission java.io.FilePermission &quot;${user.home}&quot;, &quot;read&quot;; 将把 “${user.home}” 扩展为使用 “user.home” 系统属性的值。如果该属性的值是 “/home/cathy”，则以上示例等价于： permission java.io.FilePermission &quot;/home/cathy&quot;, &quot;read&quot;; 为了能在与平台无关的策略文件中使用，也可采用特殊记号 “${/}”。该记号是 “${file.separator}” 的简化表示。这种方式允许使用下列字符串： permission java.io.FilePermission &quot;${user.home}${/}*&quot;, &quot;read&quot;; 如果 “user.home” 属性的值是 /home/cathy，而且是在 Solaris 系统上，则以上字符串将转换为： permission java.io.FilePermission &quot;/home/cathy/*&quot;, &quot;read&quot;; 如果 “user.home” 值是 C:\\users\\cathy，而且是在 Windows 系统上，则以上字符串将转换为： permission java.io.FilePermission &quot;C:\\users\\cathy\\*&quot;, &quot;read&quot;; 同样，作为一种特例，如果扩展 codebase 中的属性，例如 grant codeBase &quot;file:${java.home}/lib/ext/&quot; 则任何文件分隔符都将自动转换为“/”。这样，在 Windows 系统上，以上字符串将转换为： grant codeBase &quot;file:C:/jdk1.2/lib/ext/&quot; 即使 “java.home” 被设置为 C:\\jdk1.2。因此，用户就不必也不应该在 codeBase 字符串中使用 ${/}。 策略文件中允许使用双引号字符串的地方都可进行属性扩展。其中包括 “signer_names”、”URL”、”target_name” 和 “action” 域。 是否允许属性扩展由安全属性文件中的“policy.expandProperties”属性控制。如果该属性为真（缺省值），则允许扩展。 请注意：不能使用嵌套属性；嵌套属性将无效。 例如， &quot;${user.${foo}}&quot; 是无效的，即使将“foo”属性设置为“home”。原因在于属性解析程序不能识别嵌套属性；解析程序只是简单地搜索第一个“${”，然后继续搜索直到找到第一个“}”为止，同时试图将搜索结果（这里是 “${user.$foo}”）解释为属性。如果没有这种属性，则解析程序就会发生解释失败。 也请注意：如果在 grant 项、permission 项或 keystore 项中无法扩展某个属性，则该项将被忽略。例如，如果在没有定义系统属性“foo”的情况下使用语句： grant codeBase &quot;${foo}&quot; { permission ...; permission ...; }; 则该 grant 项中的所有权限都将被忽略。如果使用语句： grant { permission Foo &quot;${foo}&quot;; permission Bar; }; 则将仅忽略“permission Foo…”项。最后，如果使用语句： keystore &quot;${foo}&quot;; 则将忽略 keystore 项。 Windows 系统、文件路径和属性的扩展 如上所述，在 Windows 系统上，当直接在字符串中（而不是在 codeBase URL 中）指定文件路径时，用户需要用两个反斜杠来代表文件路径中一个实际的反斜杠，如下例所示： grant { permission java.io.FilePermission &quot;C:\\\\users\\\\cathy\\\\foo.bat&quot;, &quot;read&quot;; }; 原因在于：字符串是由符号处理器 (java.io.StreamTokenizer) 来处理的。符号处理器允许将“\\”用作转义字符串（例如，“\\n”表示换行），因此需要用两个反斜杠来表示一个反斜杠。符号处理器处理完以上文件路径字符串后，将把双反斜杠转换成单个反斜杠，其最终结果为： &quot;C:\\users\\cathy\\foo.bat&quot; 符号处理器处理完字符串后，即进行字符串中的属性扩展。因此，如果使用字符串： &quot;${user.home}\\\\foo.bat&quot; 则符号处理器首先处理字符串，即将双反斜杠转换成单个反斜杠，其结果为： &quot;${user.home}\\foo.bat&quot; 随即扩展 ${user.home} 属性，其最终结果为： &quot;C:\\users\\cathy\\foo.bat&quot; 以上假定 “user.home” 的值是 C:\\users\\cathy。当然，为实现与平台无关，最好在开始指定字符串时不要显式带上斜杠，即可以用 ${/} 属性来代替，如下例所示： &quot;${user.home}${/}foo.bat&quot;","comments":true,"tags":[]},{"title":"java安全管理器SecurityManager","date":"2017-05-08T16:33:39.000Z","path":"2017/05/09/java安全管理器SecurityManager.md/java安全管理器SecurityManager/","text":"问题的提出阅读源码中关于SecurityManager的代码1234SecurityManager security = System.getSecurityManager();if (security != null) &#123; security.checkWrite(name);&#125; 在本机运行正常，在服务器运行报错权限错误：123456Exception in thread &quot;main&quot; java.security.AccessControlException: access denied (java.lang.RuntimePermission createSecurityManager) at java.security.AccessControlContext.checkPermission(AccessControlContext.java:374) at java.security.AccessController.checkPermission(AccessController.java:549) at java.lang.SecurityManager.checkPermission(SecurityManager.java:532) at java.lang.SecurityManager.&lt;init&gt;(SecurityManager.java:282) ... 为了彻底明白这些情况，需要研究一下SecurityManager。 SecurityManager应用场景当运行未知的Java程序(可能有恶意代码（删除系统文件、重启系统等）)时，为了防止恶意代码对系统产生影响，需要对运行的代码的权限进行控制，这时就需要启用Java安全管理器。 管理器配置文件默认配置文件默认的安全管理器配置文件位于$JAVA_HOME/jre/lib/security/java.policy，当未指定配置文件时，将会使用该默认配置。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// Standard extensions get all permissions by defaultgrant codeBase &quot;file:$&#123;&#123;java.ext.dirs&#125;&#125;/*&quot; &#123; permission java.security.AllPermission;&#125;;// default permissions granted to all domainsgrant &#123; // Allows any thread to stop itself using the java.lang.Thread.stop() // method that takes no argument. // Note that this permission is granted by default only to remain // backwards compatible. // It is strongly recommended that you either remove this permission // from this policy file or further restrict it to code sources // that you specify, because Thread.stop() is potentially unsafe. // See the API specification of java.lang.Thread.stop() for more // information. permission java.lang.RuntimePermission &quot;stopThread&quot;; // allows anyone to listen on dynamic ports permission java.net.SocketPermission &quot;localhost:0&quot;, &quot;listen&quot;; // &quot;standard&quot; properies that can be read by anyone permission java.util.PropertyPermission &quot;java.version&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;java.vendor&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;java.vendor.url&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;java.class.version&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;os.name&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;os.version&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;os.arch&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;file.separator&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;path.separator&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;line.separator&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;java.specification.version&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;java.specification.vendor&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;java.specification.name&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;java.vm.specification.version&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;java.vm.specification.vendor&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;java.vm.specification.name&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;java.vm.version&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;java.vm.vendor&quot;, &quot;read&quot;; permission java.util.PropertyPermission &quot;java.vm.name&quot;, &quot;read&quot;;&#125;; 启用安全管理器 有两种方式，建议采用参数启用方式。 参数启用方式运行程序的时候附加参数启用安全管理器：1-Djava.security.manager 指定配置文件的位置：1-Djava.security.manager -Djava.security.policy=&quot;E:/java.policy&quot; 编码方式启用1System.setSecurityManager(new SecurityManager()); 参数启用本质上也是通过编码启用，不过参数启用灵活（sun.misc.Launcher）： 12345678910111213141516171819String str = System.getProperty(&quot;java.security.manager&quot;);if (str != null)&#123; SecurityManager localSecurityManager = null; if ((&quot;&quot;.equals(str)) || (&quot;default&quot;.equals(str))) &#123; localSecurityManager = new SecurityManager(); &#125; else &#123; try &#123; localSecurityManager = (SecurityManager)this.loader.loadClass(str).newInstance(); &#125; catch (IllegalAccessException localIllegalAccessException) &#123;&#125;catch (InstantiationException localInstantiationException) &#123;&#125;catch (ClassNotFoundException localClassNotFoundException) &#123;&#125;catch (ClassCastException localClassCastException) &#123;&#125; &#125; if (localSecurityManager != null) &#123; System.setSecurityManager(localSecurityManager); &#125; else &#123; throw new InternalError(&quot;Could not create SecurityManager: &quot; + str); &#125;&#125; 会创建一个默认的SecurityManager 配置文件解析配置基本原则在启用安全管理器的时候，配置遵循以下基本原则： 没有配置的权限表示没有 只能配置有什么权限，不能配置禁止做什么 同一种权限可多次配置，取并集。 统一资源的多种权限可用逗号分割。 默认配置文件解释第一部分授权：123grant codeBase &quot;file:$&#123;&#123;java.ext.dirs&#125;&#125;/*&quot; &#123; permission java.security.AllPermission;&#125;; 授权位于”file:$/*”下的class和jar包所有权限。 第二部分授权：1234grant &#123; permission java.lang.RuntimePermission &quot;stopThread&quot;; …… &#125; 这是细粒度的授权，对某些资源进行授权。RuntimePermission的可授权操作(stopThread仅仅是其中的一个)如下(可查看javadoc)： 权限目标名称 权限所允许的操作 允许此权限所带来的风险 createClassLoader 创建类加载器 授予该权限极其危险。能够实例化自己的类加载器的恶意应用程序可能会在系统中装载自己的恶意类。这些新加载的类可能被类加载器置于任意保护域中，从而自动将该域的权限授予这些类。 getClassLoader 类加载器的获取（即调用类的类加载器） 这将授予攻击者得到具体类的加载器的权限。这很危险，由于攻击者能够访问类的类加载器，所以攻击者能够加载其他可用于该类加载器的类。通常攻击者不具备这些类的访问权限。 setContextClassLoader 线程使用的上下文类加载器的设置 在需要查找可能不存在于系统类加载器中的资源时，系统代码和扩展部分会使用上下文类加载器。授予 setContextClassLoader 权限将允许代码改变特定线程（包括系统线程）使用的上下文类加载器。 enableContextClassLoaderOverride 线程上下文类加载器方法的子类实现 在需要查找可能不存在于系统类加载器中的资源时，系统代码和扩展部分会使用上下文类加载器。授予enableContextClassLoaderOverride权限将允许线程的子类重写某些方法，这些方法用于得到或设置特定线程的上下文类加载器。 setSecurityManager 设置安全管理器（可能会替换现有的） 安全管理器是允许应用程序实现安全策略的类。授予setSecurityManager权限将通过安装一个不同的、可能限制更少的安全管理器，来允许代码改变所用的安全管理器，因此可跳过原有安全管理器所强制执行的某些检查。 createSecurityManager 创建新的安全管理器 授予代码对受保护的、敏感方法的访问权，可能会泄露有关其他类或执行堆栈的信息。 getenv.{variable name} 读取指定环境变量的值 此权限允许代码读取特定环境变量的值或确定它是否存在。如果该变量含有机密数据，则这项授权是很危险的。 exitVM.{exit status} 暂停带有指定退出状态的Java虚拟机 此权限允许攻击者通过自动强制暂停虚拟机来发起一次拒绝服务攻击。注意：自动为那些从应用程序类路径加载的全部代码授予 “exitVM.*“权限，从而使这些应用程序能够自行中止。此外，”exitVM“权限等于”exitVM.*”。 shutdownHooks 虚拟机关闭钩子 (hook) 的注册与取消 此权限允许攻击者注册一个妨碍虚拟机正常关闭的恶意关闭钩子 (hook)。 setFactory 设置由ServerSocket或Socket使用的套接字工厂，或URL使用的流处理程序工厂 此权限允许代码设置套接字、服务器套接字、流处理程序或 RMI套接字工厂的实际实现。攻击者可能设置错误的实现，从而破坏数据流。 setIO System.out、System.in和System.err的设置 此权限允许改变标准系统流的值。攻击者可以改变System.in来监视和窃取用户输入，或将System.err设置为”null“ OutputStream，从而隐藏发送到System.err的所有错误信息。 modifyThread 修改线程，例如通过调用线程的interrupt、stop、suspend、resume、setDaemon、setPriority、setName和setUncaughtExceptionHandler方法 此权限允许攻击者修改系统中任意线程的行为。 stopThread 通过调用线程的stop方法停止线程 如果系统已授予代码访问该线程的权限，则此权限允许代码停止系统中的任何线程。此权限会造成一定的危险，因为该代码可能通过中止现有的线程来破坏系统。 modifyThreadGroup 修改线程组，例如通过调用ThreadGroup的destroy、getParent、resume、setDaemon、setMaxPriority、stop和suspend方法 此权限允许攻击者创建线程组并设置它们的运行优先级。 getProtectionDomain 获取类的ProtectionDomain 此权限允许代码获得特定代码源的安全策略信息。虽然获得安全策略信息并不足以危及系统安全，但这确实会给攻击者提供了能够更好地定位攻击目标的其他信息，例如本地文件名称等。 getFileSystemAttributes 获取文件系统属性 此权限允许代码获得文件系统信息（如调用者可用的磁盘使用量或磁盘空间）。这存在潜在危险，因为它泄露了关于系统硬件配置的信息以及一些关于调用者写入文件特权的信息。 readFileDescriptor 读取文件描述符 此权限允许代码读取与文件描述符读取相关的特定文件。如果该文件包含机密数据，则此操作非常危险。 writeFileDescriptor 写入文件描述符 此权限允许代码写入与描述符相关的特定文件。此权限很危险，因为它可能允许恶意代码传播病毒，或者至少也会填满整个磁盘。 loadLibrary.{库名} 动态链接指定的库 允许applet具有加载本机代码库的权限是危险的，因为Java安全架构并未设计成可以防止恶意行为，并且也无法在本机代码的级别上防止恶意行为。 accessClassInPackage.{包名} 当类加载器调用SecurityManager的checkPackageAccess方法时，通过类加载器的loadClass方法访问指定的包 此权限允许代码访问它们通常无法访问的那些包中的类。恶意代码可能利用这些类帮助它们实现破坏系统安全的企图。 defineClassInPackage.{包名} 当类加载器调用SecurityManager的checkPackageDefinition方法时，通过类加载器的defineClass 方法定义指定的包中的类。 此权限允许代码在特定包中定义类。这样做很危险，因为具有此权限的恶意代码可能在受信任的包中定义恶意类，比如java.security或java.lang。 accessDeclaredMembers 访问类的已声明成员 此权限允许代码查询类的公共、受保护、默认（包）访问和私有的字段和或方法。尽管代码可以访问私有和受保护字段和方法名称，但它不能访问私有/受保护字段数据并且不能调用任何私有方法。此外，恶意代码可能使用该信息来更好地定位攻击目标。而且，它可以调用类中的任意公共方法和/或访问公共字段。如果代码不能用这些方法和字段将对象强制转换为类/接口，那么它通常无法调用这些方法和/或访问该字段，而这可能很危险。 queuePrintJob 打印作业请求的开始 这可能向打印机输出敏感信息，或者只是浪费纸张。 getStackTrace 获取另一个线程的堆栈追踪信息。 此权限允许获取另一个线程的堆栈追踪信息。此操作可能允许执行恶意代码监视线程并发现应用程序中的弱点。 setDefaultUncaughtExceptionHandler 在线程由于未捕获的异常而突然终止时，设置将要使用的默认处理程序 此权限允许攻击者注册恶意的未捕获异常处理程序，可能会妨碍线程的终止 Preferences 表示得到java.util.prefs.Preferences的访问权所需的权限。java.util.prefs.Preferences实现了用户或系统的根，这反过来又允许获取或更新Preferences 持久内部存储中的操作。 如果运行此代码的用户具有足够的读/写内部存储的OS特权，则此权限就允许用户读/写优先级内部存储。实际的内部存储可能位于传统的文件系统目录中或注册表中，这取决于平台 OS。 可配置项详解当批量配置的时候，有三种模式： directory/ 表示directory目录下的所有.class文件，不包括.jar文件directory/* 表示directory目录下的所有的.class及.jar文件directory/-`` 表示directory目录下的所有的.class及.jar`文件，包括子目录 可以通过${}来引用系统属性，如： &quot;file:$/*&quot; 问题解决 取消安全管理器 增加相应权限如果没有某项权限则报错信息会提示是请求什么权限： 1Exception in thread &quot;main&quot; java.security.AccessControlException: access denied (java.io.FilePermission c:\\test.txt write) 对c:\\test.txt没有写权限。 最简单的事开放所有权限（不推荐）：123grant &#123; permission java.security.AllPermission;&#125;;","comments":true,"tags":[]},{"title":"编写java的安全管理器","date":"2017-05-08T16:04:27.000Z","path":"2017/05/09/java的安全机制.md/java的安全机制/","text":"安全管理器SecurityManager核心方法checkPerssiom,而该方法又调用AccessController的checkPerssiom方法，访问控制器AccessController的栈检查机制会遍历整个PerssiomCollection来判断具体拥有什么权限,一旦发现栈中一个权限不允许会抛出异常，否则简单的返回。 编写java的安全管理器定义一个类继承自SecurityManger并重写checkRead方法12345678910111213package com.test.security.manager;public class MySecurityManager extends SecurityManager &#123; @Override public void checkRead(String fileFullPath) &#123; // super.checkRead(fileFullPath); if (fileFullPath.endsWith(&quot;test&quot;)) &#123; throw new SecurityException(&quot;你没有读取的本文件的权限&quot;); &#125; &#125;&#125; 测试123456789101112131415161718package com.test.security.manager;import java.io.FileInputStream;import java.io.IOException;import org.junit.Test;public class MySecurityManagerTest &#123; @Test public void testCheckReadString() &#123; System.setSecurityManager(new MySecurityManager()); try &#123; FileInputStream fis = new FileInputStream(&quot;test&quot;); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 测试结果12345678910111213141516171819202122232425262728java.lang.SecurityException: 你没有读取的本文件的权限 at com.test.security.manager.MySecurityManager.checkRead(MySecurityManager.java:9) at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:127) at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:93) at com.test.security.manager.MySecurityManagerTest.testCheckReadString(MySecurityManagerTest.java:13) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:86) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:678) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192) System.setSecurityManager(new MySecurityManager());这是安装安全管理器的一种方法，也可以用-Djava.security.manager安装默认的安全管理器。 解读进入FileInputStream的构造函数:1234567891011121314151617public FileInputStream(File file) throws FileNotFoundException &#123; String name = (file != null ? file.getPath() : null); SecurityManager security = System.getSecurityManager(); if (security != null) &#123; security.checkRead(name); &#125; if (name == null) &#123; throw new NullPointerException(); &#125; if (file.isInvalid()) &#123; throw new FileNotFoundException(&quot;Invalid file path&quot;); &#125; fd = new FileDescriptor(); fd.attach(this); path = name; open(name);&#125; 先会执行SecurityManager security = System.getSecurityManager();，然后再调用security的checkRead方法。 联想一下，在使用java的File时会new File(&quot;test&quot;).setWritable(Boolean.TRUE, Boolean.TRUE);，这可以指定创建文件的权限，这里就是使用了安全管理器来设置权限。12345678910public boolean setWritable(boolean writable, boolean ownerOnly) &#123; SecurityManager security = System.getSecurityManager(); if (security != null) &#123; security.checkWrite(path); &#125; if (isInvalid()) &#123; return false; &#125; return fs.setPermission(this, FileSystem.ACCESS_WRITE, writable, ownerOnly);&#125;","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"}]},{"title":"Reflections中的getDeclared**与get**的区别 ","date":"2017-05-02T11:16:18.000Z","path":"2017/05/02/Reflections中的getDeclared-与get-的区别.md/Reflections中的getDeclared__与get__的区别_/","text":"getDeclaredMethod(s)返回该类本身的所有方法(包括私有方法)，但不包括继承的方法。返回数组中的元素没有排序，也没有任何特定的顺序。如果该类或接口不声明任何方法，或此Class对象表示一个基本类型、数组类型或void，则此方法返回一个长度为0的数组。 类初始化方法不包含在返回数组中。 该方法返回所有重载的方法。 getMethod(s)返回某个类的所有public(包括继承来public方法)。 如果此Class对象表示基本类型或void，则此方法返回长度为0的数组。 总结getDeclaredMethods：自身，所有方法，不继承getMethods:public 继承 getDeclaredField（s）和getField（s）同上getDeclaredAnnotation（s）返回直接存在于此元素上的所有注释。该方法将忽略继承的注释。（如果没有注释直接存在于此元素上，则返回长度为零的一个数组。）该方法的调用者可以随意修改返回的数组；这不会对其他调用者返回的数组产生任何影响。getAnnotation（s）：返回此元素上存在的所有注释。（如果此元素没有注释，则返回长度为零的数组。）该方法的调用者可以随意修改返回的数组；这不会对其他调用者返回的数组产生任何影响。getDeclaredAnnotations得到的是当前成员所有的注释，不包括继承的。而getAnnotations得到的是包括继承的所有注释。 关键在于继承的问题上，getDeclaredAnnotations和getAnnotations是否相同，就在于父类的注解是否可继承，这可以用sun.reflect.annotation.AnnotationType antype3=AnnotationType.getInstance(Class.forName(annotationtype_class(example:”javax.ejb.Stateful”)).isInherited())来判定，如果为true，说明可以被继承则存在与getAnnotations之中而不在getDeclaredAnnotations之中，否则，也不存在与getannnotations中，因为不能被继承。","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"},{"name":"反射","slug":"反射","permalink":"http://jishusuishouji.github.io/tags/反射/"}]},{"title":"Spring 资源访问剖析和策略模式应用","date":"2017-04-24T14:45:24.000Z","path":"2017/04/24/spring/Spring_资源访问剖析和策略模式应用/","text":"","comments":true,"tags":[{"name":"spring","slug":"spring","permalink":"http://jishusuishouji.github.io/tags/spring/"}]},{"title":"java 类型信息 instanceof 和 isInstance区别","date":"2017-04-19T21:26:32.000Z","path":"2017/04/20/java/java_类型信息_instanceof_和_isInstance区别/","text":"123class A&#123; &#125; 123class B extends A &#123; &#125; 123class C extends B &#123; &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class T &#123; public static void main(String[] args) &#123; C c = new C(); B b = new B(); A a = new A(); B bc = new C(); A ac = new C(); System.out.println(c instanceof C); System.out.println(c instanceof B); System.out.println(c instanceof A); System.out.println(); System.out.println(c.getClass().isInstance(c)); System.out.println(c.getClass().isInstance(b)); System.out.println(c.getClass().isInstance(a)); System.out.println(); System.out.println(c.getClass().isInstance(bc)); System.out.println(c.getClass().isInstance(ac)); System.out.println(); System.out.println(A.class.isInstance(a)); System.out.println(A.class.isInstance(b)); System.out.println(A.class.isInstance(c)); System.out.println(A.class.isInstance(ac)); System.out.println(A.class.isInstance(bc)); System.out.println(); System.out.println(B.class.isInstance(a)); System.out.println(B.class.isInstance(b)); System.out.println(B.class.isInstance(c)); System.out.println(B.class.isInstance(ac)); System.out.println(B.class.isInstance(bc)); &#125; &#125; 1234567891011121314151617181920212223242526truetruetruetruefalsefalsetruetruetruetruetruetruetruefalsetruetruetruetrue 对象 instanceof 类1obj instanceof class 如果class obj1 = obj成立的话，返回true，否则返回false 类.isInstance(对象)1class.isInstance(obj) 如果class obj1 = obj成立的话，返回true，否则返回false instanceof运算符只被用于对象引用变量，检查左边的被测试对象是不是 右边类或接口的实例化。如果被测对象是null值，则测试结果总是false。形象地：自身实例或子类实例 instanceof 自身类 返回true例：12String s=new String(&quot;javaisland&quot;);System.out.println(s instanceof String); //true Class类的isInstance(Object obj)方法，obj是被测试的对象，如果obj是调用这个方法的class或接口 的实例，则返回true。这个方法是instanceof运算符的动态等价。形象地：自身类.class.isInstance(自身实例或子类实例) 返回true例：12String s=new String(&quot;javaisland&quot;);System.out.println(String.class.isInstance(s)); //true Class类的isAssignableFrom(Class cls)方法，如果调用这个方法的class或接口与 参数cls表示的类或接口相同，或者是参数cls表示的类或接口的父类，则返回true。形象地：自身类.class.isAssignableFrom(自身类或子类.class) 返回true例：12System.out.println(ArrayList.class.isAssignableFrom(Object.class)); //falseSystem.out.println(Object.class.isAssignableFrom(ArrayList.class)); //true","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"}]},{"title":"spring 后置处理器BeanFactoryPostProcessor和BeanPostProcessor的用法和区别","date":"2017-04-18T15:48:50.000Z","path":"2017/04/18/spring/spring_后置处理器BeanFactoryPostProcessor和BeanPostProcessor的用法和区别/","text":"主要区别就是：BeanFactoryPostProcessor(BeanFactory的后置处理器)可以修改BEAN的配置信息而BeanPostProcessor(Bean的后置处理器)不能: 1234567891011121314151617181920212223package com.springdemo.postProcessor; public class PostProcessorBean &#123; private String username; private String password; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; &#125; MyBeanPostProcessor类，实现了BeanPostProcessor接口: 12345678910111213141516171819202122232425262728293031323334353637package com.springdemo.postProcessor; import org.springframework.beans.BeansException; import org.springframework.beans.factory.config.BeanPostProcessor; import com.springdemo.form.LoginForm; public class MyBeanPostProcessor implements BeanPostProcessor &#123; public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; //如果是PostProcessorBean则username信息 if(bean instanceof PostProcessorBean) &#123; System.out.println(&quot;PostProcessorBean Bean initialized&quot;); PostProcessorBean pb = (PostProcessorBean)bean; System.out.println(&quot;username:&quot;+pb.getUsername()); &#125; return bean; &#125; public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; if(bean instanceof PostProcessorBean) &#123; System.out.println(&quot;PostProcessorBean Bean initializing&quot;); PostProcessorBean pb = (PostProcessorBean)bean; System.out.println(&quot;username:&quot;+pb.getUsername()); &#125; return bean; &#125; &#125; MyBeanFactoryPostProcessor实现了BeanFactoryPostProcessor接口: 12345678910111213141516171819202122232425package com.springdemo.postProcessor; import org.springframework.beans.BeansException; import org.springframework.beans.MutablePropertyValues; import org.springframework.beans.factory.config.BeanDefinition; import org.springframework.beans.factory.config.BeanFactoryPostProcessor; import org.springframework.beans.factory.config.ConfigurableListableBeanFactory; public class MyBeanFactoryPostProcessor implements BeanFactoryPostProcessor &#123; public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; //BeanFactoryPostProcessor可以修改BEAN的配置信息而BeanPostProcessor不能 //在这里修改postProcessorBean的username注入属性 BeanDefinition bd = beanFactory.getBeanDefinition(&quot;postProcessorBean&quot;); MutablePropertyValues pv = bd.getPropertyValues(); if(pv.contains(&quot;username&quot;)) &#123; pv.addPropertyValue(&quot;username&quot;, &quot;xiaojun&quot;); &#125; &#125; &#125; 编写测试用例： 1234567891011121314151617181920212223242526272829303132333435363738package com.springdemo.test; import org.springframework.context.ApplicationContext; import org.springframework.context.support.ClassPathXmlApplicationContext; import com.springdemo.factory.ApplicationContextFactory; import com.springdemo.postProcessor.PostProcessorBean; import junit.framework.TestCase; public class BeanPostPorcessorTest extends TestCase &#123; private ApplicationContext context; protected void setUp() throws Exception &#123; super.setUp(); String[] paths = &#123;&quot;classpath*:/spring/applicationContext-*.xml&quot;&#125;; context = new ClassPathXmlApplicationContext(paths); &#125; protected void tearDown() throws Exception &#123; super.tearDown(); &#125; public void testBeanPostProcessor() &#123; &#125; public void testBeanFactoryPostProcessor() &#123; PostProcessorBean bean =(PostProcessorBean)context.getBean(&quot;postProcessorBean&quot;); System.out.println(&quot;---------------testBeanFactoryPostProcessor----------------&quot;); System.out.println(&quot;username:&quot;+bean.getUsername()); System.out.println(&quot;password:&quot;+bean.getPassword()); &#125; &#125; spring配置文件如下（先不启用MyBeanFactoryPostProcessor）： 1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.0.xsd&quot;&gt; &lt;bean class=&quot;com.springdemo.postProcessor.MyBeanPostProcessor&quot;&gt;&lt;/bean&gt; &lt;!--我们先把BeanFactoryPostProcessor注释掉，不启用,然后查看测试输出结果 &lt;bean class=&quot;com.springdemo.postProcessor.MyBeanFactoryPostProcessor&quot;&gt;&lt;/bean&gt; --&gt; &lt;bean id=&quot;postProcessorBean&quot; class=&quot;com.springdemo.postProcessor.PostProcessorBean&quot; &gt; &lt;property name=&quot;username&quot; value=&quot;test&quot;&gt;&lt;/property&gt; &lt;property name=&quot;password&quot; value=&quot;test&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 测试输出结果如下：1234567PostProcessorBean Bean initializingusername:testPostProcessorBean Bean initializedusername:test---------------testBeanFactoryPostProcessor----------------username:testpassword:test 然后我们取消注释启用MyBeanFactoryPostProcessor，测试结果如下：1234567PostProcessorBean Bean initializingusername:xiaojunPostProcessorBean Bean initializedusername:xiaojun---------------testBeanFactoryPostProcessor----------------username:xiaojunpassword:test 从结果可以看出：BeanFactoryPostProcessor的回调比BeanPostProcessor要早，因为BeanPostProcess中输出的username已经变成了xiaojun,而不是test.还有就是BeanFactoryPostProcessor确实有能力改变初始化BEAN的内容. BeanPostProcessor也能改变bean的值。但值得奇怪的是，如果在BeanFactoryPostProcessor里面调用factory.getBean()，则会对bean进行初始化，但是这个初始化过程不会回调BeanPostProcessor的两个回调方法。","comments":true,"tags":[{"name":"spring","slug":"spring","permalink":"http://jishusuishouji.github.io/tags/spring/"}]},{"title":"学习Spring必学的Java基础知识----PropertyEditor","date":"2017-04-18T15:41:21.000Z","path":"2017/04/18/spring/学习Spring必学的Java基础知识----PropertyEditor/","text":"在Spring配置文件里是通过字面值为Bean各种类型的属性提供设置值：不管是double类型还是int类型，在配置文件中都对应字符串类型的字面值。BeanWrapper填充Bean属性时如何将这个字面值转换为对应的double或int等内部类型呢？ 任何实现java.beans.PropertyEditor接口的类都是属性编辑器。属性编辑器是将外部的设置值转换为JVM内部的对应类型，属性编辑器就是一个类型转换器。 PropertyEditor是JavaBean规范定义的接口。 JavaBean的编辑器Sun所制定的JavaBean规范，很大程度上是为IDE准备的——它让IDE能够以可视化的方式设置JavaBean的属性。如果在IDE中开发一个可视化应用程序，我们需要通过属性设置的方式对组成应用的各种组件进行定制，IDE通过属性编辑器让开发人员使用可视化的方式设置组件的属性。 一般的IDE都支持JavaBean规范所定义的属性编辑器，当组件开发商发布一个组件时，它往往将组件对应的属性编辑器捆绑发行，这样开发者就可以在IDE环境下方便地利用属性编辑器对组件进行定制工作。 JavaBean规范通过java.beans.PropertyEditor定义了设置JavaBean属性的方法，通过BeanInfo描述了JavaBean哪些属性是可定制的，此外还描述了可定制属性与PropertyEditor的对应关系。 BeanInfo与JavaBean之间的对应关系，通过两者之间规范的命名确立：对应JavaBean的BeanInfo采用如下的命名规范：BeanInfo。如ChartBean对应的BeanInfo为ChartBeanBeanInfo；Car对应的BeanInfo为CarBeanInfo。当JavaBean连同其属性编辑器相同的组件注册到IDE中后，当在开发界面中对JavaBean进行定制时，IDE就会根据JavaBean规范找到对应的BeanInfo，再根据BeanInfo中的描述信息找到JavaBean属性描述（是否开放、使用哪个属性编辑器），进而为JavaBean生成特定开发编辑界面。 JavaBean规范提供了一个管理默认属性编辑器的管理器：PropertyEditorManager，该管理器内保存着一些常见类型的属性编辑器，如果某个JavaBean的常见类型属性没有通过BeanInfo显式指定属性编辑器，IDE将自动使用PropertyEditorManager中注册的对应默认属性编辑器。 由于JavaBean对应的属性编辑器等IDE环境相关的资源和组件需要动态加载，所以在纯Java的IDE中开发基于组件的应用时，总会感觉IDE反应很迟钝，不像Delphi、C++Builder一样灵敏快捷。但在Eclipse开发环境中，设计包括可视化组件的应用时却很快捷，原因是Eclipse没有使用Java的标准用户界面组件库，当然也就没有按照JavaBean的规范开发设计GUI组件了。 PropertyEditorPropertyEditor是属性编辑器的接口，它规定了将外部设置值转换为内部JavaBean属性值的转换接口方法。PropertyEditor主要的接口方法说明如下： Object getValue()：返回属性的当前值。基本类型被封装成对应的封装类实例； void setValue(Object newValue)：设置属性的值，基本类型以封装类传入； String getAsText()：将属性对象用一个字符串表示，以便外部的属性编辑器能以可视化的方式显示。缺省返回null，表示该属性不能以字符串表示； void setAsText(String text)：用一个字符串去更新属性的内部值，这个字符串一般从外部属性编辑器传入； String[] getTags()：返回表示有效属性值的字符串数组（如boolean属性对应的有效Tag为true和false），以便属性编辑器能以下拉框的方式显示出来。缺省返回null，表示属性没有匹配的字符值有限集合； String getJavaInitializationString()：为属性提供一个表示初始值的字符串，属性编辑器以此值作为属性的默认值。 可以看出PropertyEditor接口方法是内部属性值和外部设置值的沟通桥梁。此外，我们可以很容易地发现该接口的很多方法是专为IDE中的可视化属性编辑器提供的：如getTags()、getJavaInitializationString()以及另外一些我们未此介绍的接口方法。 Java为PropertyEditor提供了一个方便类：PropertyEditorSupport，该类实现了PropertyEditor接口并提供默认实现，一般情况下，用户可以通过扩展这个方便类设计自己的属性编辑器。 BeanInfo BeanInfo主要描述了JavaBean哪些属性可以编辑以及对应的属性编辑器，每一个属性对应一个属性描述器PropertyDescriptor。PropertyDescriptor的构造函数有两个入参：PropertyDescriptor(String propertyName, Class beanClass) ，其中propertyName为属性名；而beanClass为JavaBean对应的Class。 此外PropertyDescriptor还有一个setPropertyEditorClass(Class propertyEditorClass)方法，为JavaBean属性指定编辑器。BeanInfo接口最重要的方法就是：PropertyDescriptor[] getPropertyDescriptors() ，该方法返回JavaBean的属性描述器数组。 BeanInfo接口有一个常用的实现类：SimpleBeanInfo，一般情况下，可以通过扩展SimpleBeanInfo实现自己的功能。 一个实例 在本节中，我们来看一个具体属性编辑器的实例，该实例根据《Core Java Ⅱ》上的一个例子改编而成。 ChartBean是一个可定制图表组件，允许通过属性的设置定制图表的样式以得到满足各种不同使用场合要求的图表。我们忽略ChartBean的其他属性，仅关注其中的两个属性： 代码清单5-2 CharBeanJava代码 收藏代码public class ChartBean extends JPanel{ private int titlePosition = CENTER; private boolean inverse; //省略get/setter方法} 下面，我们为titlePosition属性提供一个属性编辑器。我们不去直接实现PropertyEditor，而是通过扩展PropertyEditorSupport这个方便类来定义我们的属性编辑器： 代码清单5-3 TitlePositionEditorJava代码 收藏代码import java.beans.*; public class TitlePositionEditor extends PropertyEditorSupport{ private String[] options = { “Left”, “Center”, “Right” }; //①代表可选属性值的字符串标识数组 public String[] getTags() { return options; } //②代表属性初始值的字符串 public String getJavaInitializationString() { return &quot;&quot; + getValue(); } //③将内部属性值转换为对应的字符串表示形式，供属性编辑器显示之用 public String getAsText(){ int value = (Integer) getValue(); return options[value]; } //④将外部设置的字符串转换为内部属性的值 public void setAsText(String s){ for (int i = 0; i &lt; options.length; i++){ if (options[i].equals(s)){ setValue(i); return; } } } } ①处通过getTags()方法返回一个字符串数组，因此在IDE中该属性对应的编辑器将自动提供一个下拉框，下拉框中包含3个可选项：“Left”、“Center”、“Right”。而③和④处的两个方法分别完成属性值到字符串的双向转换功能。CharBean的inverse属性也有一个相似的编辑器InverseEditor，我们忽略不讲。 下面编写ChartBean对应的BeanInfo，根据JavaBean的命名规范，这个BeanInfo应该命名为ChartBeanBeanInfo，它负责将属性编辑器和ChartBean的属性挂钩起来： 代码清单5-4 ChartBeanBeanInfoJava代码 收藏代码import java.beans.*; public class ChartBeanBeanInfo extends SimpleBeanInfo{ public PropertyDescriptor[] getPropertyDescriptors() { try{ //①将TitlePositionEditor绑定到ChartBean的titlePosition属性中PropertyDescriptor titlePositionDescriptor = new PropertyDescriptor(“titlePosition”, ChartBean.class); titlePositionDescriptor.setPropertyEditorClass(TitlePositionEditor.class); //②将InverseEditor绑定到ChartBean的inverse属性中PropertyDescriptor inverseDescriptor = new PropertyDescriptor(“inverse”, ChartBean.class); inverseDescriptor.setPropertyEditorClass(InverseEditor.class); return new PropertyDescriptor[]{titlePositionDescriptor, inverseDescriptor}; } catch (IntrospectionException e){ e.printStackTrace(); return null; } } } 在ChartBeanBeanInfo中，我们分别为ChartBean和titlePosition和inverse属性指定对应的属性编辑器。将ChartBean连同属性编辑器以及ChartBeanBeanInfo打成JAR包，使用IDE组件扩展管理功能注册到IDE中。这样，我们就可以像使用TextField、Checkbox等这些组对ChartBean进行可视化的开发设计工作了。下面是ChartBean在NetBeans IDE中的属性编辑器效果图，如图5-5所示。 ChartBean可设置的属性都列在属性查看器中，当单击titlePosition属性时，下拉框中列出了我们提供的3个选项。 Spring默认属性编辑器 Spring的属性编辑器和传统的用于IDE开发时的属性编辑器不同，它们没有UI界面，仅负责将配置文件中的文本配置值转换为Bean属性的对应值，所以Spring的属性编辑器并非传统意义上的JavaBean属性编辑器。 Spring为常见的属性类型提供了默认的属性编辑器。从图5-4中，我们可以看出BeanWrapperImpl类扩展了PropertyEditorRegistrySupport类，Spring在PropertyEditor RegistrySupport中为常见属性类型提供了默认的属性编辑器，这些“常见的类型”共32个，可分为3大类，总结如下： 表5-1 Spring提供的默认属性编辑器类 别 说 明基础数据类型 分为几个小类： 1）基本数据类型，如：boolean、byte、short、int等； 2）基本数据类型封装类，如：Long、Character、Integer等； 3）两个基本数据类型的数组，char[]和byte[]； 4）大数类，BigDecimal和BigInteger集合类 为5种类型的集合类Collection、Set、SortedSet、List和SortedMap提供了编辑器资源类 用于访问外部资源的8个常见类Class、Class[]、File、InputStream、Locale、Properties、Resource[]和URL PropertyEditorRegistrySupport中有两个用于保存属性编辑器的Map类型变量： defaultEditors：用于保存默认属性类型的编辑器，元素的键为属性类型，值为对应的属性编辑器实例； customEditors：用于保存用户自定义的属性编辑器，元素的键值和defaultEditors相同。 PropertyEditorRegistrySupport通过类似以下的代码定义默认属性编辑器：Java代码 收藏代码this.defaultEditors.put(char.class, new CharacterEditor(false));this.defaultEditors.put(Character.class, new CharacterEditor(true));this.defaultEditors.put(Locale.class, new LocaleEditor());this.defaultEditors.put(Properties.class, new PropertiesEditor()); 这些默认的属性编辑器解决常见属性类型的注册问题，如果用户的应用包括一些特殊类型的属性，且希望在配置文件中以字面值提供配置值，那么就需要编写自定义属性编辑器并注册到Spring容器中。这样，Spring才能将配置文件中的属性配置值转换为对应的属性类型值。 自定义属性编辑器 Spring大部分默认属性编辑器都直接扩展于java.beans.PropertyEditorSupport类，用户也可以通过扩展PropertyEditorSupport实现自己的属性编辑器。比起用于IDE环境的属性编辑器来说，Spring环境下使用的属性编辑器的功能非常单一：仅需要将配置文件中字面值转换为属性类型的对象即可，并不需要提供UI界面，因此仅需要简单覆盖PropertyEditorSupport的setAsText()方法就可以了。 一个实例 我们继续使用第4章中Boss和Car的例子，假设我们现在希望在配置Boss时，不通过引用Bean的方式注入Boss的car属性，而希望直接通过字符串字面值提供配置。为了方便阅读，这里再次列出Boss和Car类的简要代码： 代码清单5-5 CarJava代码 收藏代码package com.baobaotao.editor;public class Car { private int maxSpeed; public String brand; private double price; //省略get/setter} 代码清单5-6 BossJava代码 收藏代码package com.baobaotao.editor;public class Boss { private String name; private Car car = new Car(); //省略get/setter} Boss有两个属性：name和car，分别对应String类型和Car类型。Spring拥有String类型的默认属性编辑器，因此对于String类型的属性我们不用操心。但Car类型是我们自定义的类型，要配置Boss的car属性，有两种方案：1）在配置文件中为car专门配置一个，然后在boss的中通过ref引用car Bean，这正是我们上一章中所用的方法；2）为Car类型提供一个自定义的属性编辑器，这样，我们就通过字面值为Boss的car属性提供配置值。 第一种方案是常用的方法，但是在有些情况下，这种方式需要将属性对象一步步肢解为最终可以用基本类型表示的Bean，使配置文件变得不够清晰，直接为属性类提供一个对应的自定义属性编辑器可能会是更好的替代方案。 现在，我们来为Car编写一个自定义的属性编辑器，其代码如下所示： 代码清单5-7 CustomCarEditorJava代码 收藏代码package com.baobaotao.editor;import java.beans.PropertyEditorSupport; public class CustomCarEditor extends PropertyEditorSupport { //①将字面值转换为属性类型对象 public void setAsText(String text){ if(text == null || text.indexOf(&quot;,&quot;) == -1){ throw new IllegalArgumentException(&quot;设置的字符串格式不正确&quot;); } String[] infos = text.split(&quot;,&quot;); Car car = new Car(); car.setBrand(infos[0]); car.setMaxSpeed(Integer.parseInt(infos[1])); car.setPrice(Double.parseDouble(infos[2])); //②调用父类的setValue()方法设置转换后的属性对象 setValue(car); } } CustomCarEditor很简单，它仅覆盖PropertyEditorSupport便利类的setAsText(String text)方法，该方法负责将配置文件以字符串提供的字面值转换为Car对象。字面值采用逗号分隔的格式同时为brand、maxSpeed和price属性值提供设置值，setAsText()方法解析这个字面值并生成对应的Car对象。由于我们并不需要将Boss内部的car属性反显到属性编辑器中，因此不需要覆盖getAsText()方法。 注册自定义的属性编辑器 在IDE环境下，自定义属性编辑器在使用之前必须通过扩展组件功能进行注册，在Spring环境中也需要通过一定的方法注册自定义的属性编辑器。 如果使用BeanFactory，用户需要手工调用registerCustomEditor(Class requiredType, PropertyEditor propertyEditor)方法注册自定义属性编辑器；如果使用ApplicationContext，则只需要在配置文件通过CustomEditorConfigurer注册就可以了。CustomEditorConfigurer实现BeanFactoryPostProcessor接口，因此是一个Bean工厂后处理器。我们知道Bean工厂后处理器在Spring容器加载配置文件并生成BeanDefinition半成品后就会被自动执行。因此CustomEditorConfigurer有容器启动时有机会注入自定义的属性编辑器。下面的配置片断定义了一个CustomEditorConfigurer： Xml代码 收藏代码 在①处，我们定义了用于注册自定义属性编辑器的CustomEditorConfigurer，Spring容器将通过反射机制自动调用这个Bean。CustomEditorConfigurer通过一个Map属性定义需要自动注册的自定义属性编辑器。在②处，我们为Car类型指定了对应属性编辑器CustomCarEditor，注意键是属性类型，而值是对应的属性编辑器Bean，而不是属性编辑器的类名。 最精彩的部分当然是③处的配置，我们原来通过一个元素标签配置好car Bean，然后在boss的中通过ref引用car Bean，但是现在我们直接通过value为car属性提供配置。BeanWrapper在设置boss的car属性时，它将检索自定义属性编辑器的注册表，当发现Car属性类型拥有对应的属性编辑器CustomCarEditor时，它就会利用CustomCarEditor将“红旗CA72,200,20000.00”转换为Car对象。 引用按照JavaBeans的规范，JavaBeans的基础设施会在JavaBean相同类包下查找是否存在Editor的类，如果存在，自动使用Editor作为该JavaBean的PropertyEditor。如com.baobaotao.domain.UserEditor会自动成为com.baobaotao.domain.User对应的PropertyEditor。Spring也支持这个规范，也即如果采用这种规约命令PropertyEditor，就无须显式在CustomEditorConfigurer中注册了，Spring将自动查找并注册这个PropertyEditor。 另：Spring 3.0除支持PropertyEditor外，还在核心包中引入了自建的ConversionService,它提供了更为强大的类型转换的能力，可以完成任意类型之间的转换，还可以在转换过程中参考目标对象所在宿主类的上下文信息。Spring的类型转换同时支持PropertyEdito和ConversionService。","comments":true,"tags":[{"name":"spring","slug":"spring","permalink":"http://jishusuishouji.github.io/tags/spring/"}]},{"title":"探秘Spring的PropertyEditor","date":"2017-04-18T14:03:18.000Z","path":"2017/04/18/spring/探秘Spring的PropertyEditor/","text":"java.beans.PropertyEditor是JDK自带的类，是提供给AWT。 Spring利用该接口来实现Bean的属性转换器。 Spring xml配置的bean属性都是字符串类型的值，但是对应到的每个具体的属性是各种类型的，Spring通过各种PropertyEditor来对各个属性进行类型转换。 Spring并不是直接实现PropertyEditor接口，而是继承PropertyEditorSupport类。 PropertyEditorRegistryBeanWrapperImpl是PropertyEditorRegistrySupport的子类。PropertyEditorRegistry是一个接口，PropertyEditorRegistrySupport是它的实现类。PropertyEditorRegistrySupport中的方法createDefaultEditors，该方法初始化Spring中默认PropertyEditor。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * Actually register the default editors for this registry instance. */private void createDefaultEditors() &#123; this.defaultEditors = new HashMap&lt;&gt;(64); // Simple editors, without parameterization capabilities. // The JDK does not contain a default editor for any of these target types. this.defaultEditors.put(Charset.class, new CharsetEditor()); this.defaultEditors.put(Class.class, new ClassEditor()); this.defaultEditors.put(Class[].class, new ClassArrayEditor()); this.defaultEditors.put(Currency.class, new CurrencyEditor()); this.defaultEditors.put(File.class, new FileEditor()); this.defaultEditors.put(InputStream.class, new InputStreamEditor()); this.defaultEditors.put(InputSource.class, new InputSourceEditor()); this.defaultEditors.put(Locale.class, new LocaleEditor()); this.defaultEditors.put(Path.class, new PathEditor()); this.defaultEditors.put(Pattern.class, new PatternEditor()); this.defaultEditors.put(Properties.class, new PropertiesEditor()); this.defaultEditors.put(Reader.class, new ReaderEditor()); this.defaultEditors.put(Resource[].class, new ResourceArrayPropertyEditor()); this.defaultEditors.put(TimeZone.class, new TimeZoneEditor()); this.defaultEditors.put(URI.class, new URIEditor()); this.defaultEditors.put(URL.class, new URLEditor()); this.defaultEditors.put(UUID.class, new UUIDEditor()); this.defaultEditors.put(ZoneId.class, new ZoneIdEditor()); // Default instances of collection editors. // Can be overridden by registering custom instances of those as custom editors. this.defaultEditors.put(Collection.class, new CustomCollectionEditor(Collection.class)); this.defaultEditors.put(Set.class, new CustomCollectionEditor(Set.class)); this.defaultEditors.put(SortedSet.class, new CustomCollectionEditor(SortedSet.class)); this.defaultEditors.put(List.class, new CustomCollectionEditor(List.class)); this.defaultEditors.put(SortedMap.class, new CustomMapEditor(SortedMap.class)); // Default editors for primitive arrays. this.defaultEditors.put(byte[].class, new ByteArrayPropertyEditor()); this.defaultEditors.put(char[].class, new CharArrayPropertyEditor()); // The JDK does not contain a default editor for char! this.defaultEditors.put(char.class, new CharacterEditor(false)); this.defaultEditors.put(Character.class, new CharacterEditor(true)); // Spring&apos;s CustomBooleanEditor accepts more flag values than the JDK&apos;s default editor. this.defaultEditors.put(boolean.class, new CustomBooleanEditor(false)); this.defaultEditors.put(Boolean.class, new CustomBooleanEditor(true)); // The JDK does not contain default editors for number wrapper types! // Override JDK primitive number editors with our own CustomNumberEditor. this.defaultEditors.put(byte.class, new CustomNumberEditor(Byte.class, false)); this.defaultEditors.put(Byte.class, new CustomNumberEditor(Byte.class, true)); this.defaultEditors.put(short.class, new CustomNumberEditor(Short.class, false)); this.defaultEditors.put(Short.class, new CustomNumberEditor(Short.class, true)); this.defaultEditors.put(int.class, new CustomNumberEditor(Integer.class, false)); this.defaultEditors.put(Integer.class, new CustomNumberEditor(Integer.class, true)); this.defaultEditors.put(long.class, new CustomNumberEditor(Long.class, false)); this.defaultEditors.put(Long.class, new CustomNumberEditor(Long.class, true)); this.defaultEditors.put(float.class, new CustomNumberEditor(Float.class, false)); this.defaultEditors.put(Float.class, new CustomNumberEditor(Float.class, true)); this.defaultEditors.put(double.class, new CustomNumberEditor(Double.class, false)); this.defaultEditors.put(Double.class, new CustomNumberEditor(Double.class, true)); this.defaultEditors.put(BigDecimal.class, new CustomNumberEditor(BigDecimal.class, true)); this.defaultEditors.put(BigInteger.class, new CustomNumberEditor(BigInteger.class, true)); // Only register config value editors if explicitly requested. if (this.configValueEditorsActive) &#123; StringArrayPropertyEditor sae = new StringArrayPropertyEditor(); this.defaultEditors.put(String[].class, sae); this.defaultEditors.put(short[].class, sae); this.defaultEditors.put(int[].class, sae); this.defaultEditors.put(long[].class, sae); &#125;&#125; 可能上面能够转换的类型还不能满足需求，那么可以通过另一种方式将PropertyEditor注入到Spring中。 PropertyEditorRegistrar该接口只有一个方法:1void registerCustomEditors(PropertyEditorRegistry registry) 实现该方法就可以往传入的registry添加自定义的PropertyEditor，一般情况下传入的registry是BeanWrapperImpl的实例，即将自定义的PropertyEditor注入到BeanWrapperImpl。 CustomEditorConfigurer1234567public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; if (this.propertyEditorRegistrars != null) &#123; for (PropertyEditorRegistrar propertyEditorRegistrar : this.propertyEditorRegistrars) &#123; beanFactory.addPropertyEditorRegistrar(propertyEditorRegistrar); &#125; &#125;&#125; 把PropertyEditorRegistrar添加到BeanFactory。 它是实现了BeanFactoryPostProcessor接口，即在构造完BeanDefinition之后会调用方法postProcessBeanFactory。 注入一个CustomEditorConfigurerBean(设置propertyEditorRegistrars和customEditors属性)就可以将自定义的PropertyEditor注入到Spring中了。 例子自定义PropertyEditor123456789101112public class CustomPropertyEditor extends PropertyEditorSupport &#123; @Override public void setAsText(String text) throws IllegalArgumentException &#123; super.setAsText(text); &#125; @Override public Object getValue() &#123; return super.getValue(); &#125;&#125; 将这个PropertyEditor注入到Spring里面中1234567&lt;bean class=&quot;org.springframework.beans.factory.config.CustomEditorConfigurer&quot;&gt; &lt;property name=&quot;customEditors&quot;&gt; &lt;map&gt; &lt;entry key=&quot;com.xx.foo.FooPojo&quot; value=&quot;com.xx.foo.CustomPropertyEditor&quot;/&gt; &lt;/map&gt; &lt;/property&gt;&lt;/bean&gt; ClassEditor的实现1234567891011121314151617181920212223242526272829303132public class ClassEditor extends PropertyEditorSupport &#123; private final ClassLoader classLoader; public ClassEditor() &#123; this(null); &#125; public ClassEditor(ClassLoader classLoader) &#123; this.classLoader = (classLoader != null ? classLoader : ClassUtils.getDefaultClassLoader()); &#125; public void setAsText(String text) throws IllegalArgumentException &#123; if (StringUtils.hasText(text)) &#123; setValue(ClassUtils.resolveClassName(text.trim(), this.classLoader)); &#125; else &#123; setValue(null); &#125; &#125; @Override public String getAsText() &#123; Class clazz = (Class) getValue(); if (clazz != null) &#123; return ClassUtils.getQualifiedName(clazz); &#125; else &#123; return &quot;&quot;; &#125; &#125;&#125;","comments":true,"tags":[{"name":"Spring","slug":"Spring","permalink":"http://jishusuishouji.github.io/tags/Spring/"},{"name":"PropertyEditor","slug":"PropertyEditor","permalink":"http://jishusuishouji.github.io/tags/PropertyEditor/"}]},{"title":"ServletContext总结","date":"2017-04-17T14:23:11.000Z","path":"2017/04/17/ServletContext总结.md/ServletContext总结/","text":"","comments":true,"tags":[]},{"title":"基于Keepalived+Haproxy搭建四层负载均衡器","date":"2017-04-07T05:07:53.000Z","path":"2017/04/07/jiqun/基于Keepalived_Haproxy搭建四层负载均衡器/","text":"一、前言Haproxy是稳定、高性能、高可用性的负载均衡解决方案，支持HTTP及TCP代理后端服务器池，因支持强大灵活的7层acl规则，广泛作为HTTP反向代理。本文则详细介绍如何利用它的四层交换与Keepalived实现一个负载均衡器，适用于Socket、ICE、mail、mysql、私有通讯等任意TCP服务。系统架构图如下： 点击在新窗口中浏览此图片 二、平台环境 OS:Centos5.4(64X)MASTER:192.168.0.20BACKUP:192.168.0.21VIP:192.168.0.100Serivce Port:11231三、平台安装配置 1、添加非本机ip邦定支持 #vi /etc/sysctl.confnet.ipv4.ip_nonlocal_bind=1 #sysctl –p2、配置平台日志支持 #vi /etc/syslog.conf添加：local3. /var/log/haproxy.loglocal0. /var/log/haproxy.log #vi /etc/sysconfig/syslog修改：SYSLOGD_OPTIONS=”-r -m 0” #/etc/init.d/syslog restart3、关闭SELINUX vi /etc/sysconfig/selinux修改：SELINUX=disabled #setenforce 04、配置iptables，添加VRRP通讯支持 iptables -A INPUT -d 224.0.0.18 -j accept5、Keepalived的安装、配置 #mkdir -p /home/install/keepalivedha #cd /home/install/keepalivedha #wget http://www.keepalived.org/software/keepalived-1.2.2.tar.gz #tar zxvf keepalived-1.2.2.tar.gz #cd keepalived-1.2.2 #./configure #make &amp;&amp; make install #cp /usr/local/etc/rc.d/init.d/keepalived /etc/rc.d/init.d/ #cp /usr/local/etc/sysconfig/keepalived /etc/sysconfig/ #mkdir /etc/keepalived #cp /usr/local/etc/keepalived/keepalived.conf /etc/keepalived/ #cp /usr/local/sbin/keepalived /usr/sbin/ #vi /etc/keepalived/keepalived.conf ! Configuration file for keepalived global_defs { notification_email { liutiansi@gmail.com } notification_email_from liutiansi@gmail.com smtp_connect_timeout 3 smtp_server 127.0.0.1 router_id LVS_DEVEL}vrrp_script chk_haproxy { script “killall -0 haproxy” interval 2 weight 2}vrrp_instance VI_1 { interface eth1 state MASTER # 从为BACKUP priority 101 # 从为100 virtual_router_id 50 #路由ID，可通过#tcpdump vrrp查看。 garp_master_delay 1 #主从切换时间，单位为秒。 authentication { auth_type PASS auth_pass KJj23576hYgu23IP } track_interface { eth0 eth1 } virtual_ipaddress { 192.168.0.100 } track_script { chk_haproxy } #状态通知 notify_master &quot;/etc/keepalived/Mailnotify.py master&quot; notify_backup &quot;/etc/keepalived/Mailnotify.py backup&quot; notify_fault &quot;/etc/keepalived/Mailnotify.py fault&quot; }6、Haproxy的安装与配置 #cd /home/install/keepalivedha #wget http://haproxy.1wt.eu/download/1.4/src/haproxy-1.4.11.tar.gz #tar -zxvf haproxy-1.4.11.tar.gz #cd haproxy-1.4.11 #make install #mkdir -p /usr/local/haproxy/etc #mkdir -p /usr/local/haproxy/sbin #cp examples/haproxy.cfg /usr/local/haproxy/etc #ln -s /usr/local/sbin/haproxy /usr/local/haproxy/sbin/haproxy #vi /usr/local/haproxy/etc/haproxy.cfg this config needs haproxy-1.1.28 or haproxy-1.2.1global log 127.0.0.1 local0log 127.0.0.1 local1 notice maxconn 5000 uid 99 gid 99 daemon pidfile /usr/local/haproxy/haproxy.pid defaults log global mode http #option httplog option dontlognull retries 3 option redispatch maxconn 2000 contimeout 5000 clitimeout 50000 srvtimeout 50000 listen ICE01 192.168.0.100:11231 mode tcp #配置TCP模式 maxconn 2000 balance roundrobin server ice-192.168.0.128 192.168.0.128:11231 check inter 5000 fall 1 rise 2 server ice-192.168.0.129 192.168.0.129:11231 check inter 5000 fall 1 rise 2 server ice-192.168.0.130 192.168.0.130:11231 check inter 5000 fall 1 rise 2 server ice-192.168.0.131 192.168.0.131:11231 check inter 5000 fall 1 rise 2 server ice-192.168.0.132 192.168.0.132:11231 check inter 5000 fall 1 rise 2 server ice-192.168.0.34 192.168.0.34:11231 check inter 5000 fall 1 rise 2 srvtimeout 20000 listen stats_auth 192.168.0.20:80 listen stats_auth 192.168.0.21:80 # backup configstats enable stats uri /admin-status #管理地址 stats auth admin:123456 #管理帐号:管理密码 stats admin if TRUE 7、邮件通知程序(python实现) #vi /etc/keepalived/Mailnotify.py #!/usr/local/bin/python #coding: utf-8from email.MIMEMultipart import MIMEMultipartfrom email.MIMEText import MIMETextfrom email.MIMEImage import MIMEImagefrom email.header import Headerimport sysimport smtplib #————————————————————— Name: Mailnotify.pyPurpose: Mail notify to SAAuthor: LiutiansiEmail: liutiansi@gamil.comCreated: 2011/03/09Copyright: (c) 2011#————————————————————–strFrom = ‘admin@domain.com’strTo = ‘liutiansi@gmail.com’smtp_server=’smtp.domain.com’smtp_pass=’123456’ if sys.argv[1]!=”master” and sys.argv[1]!=”backup” and sys.argv[1]!=”fault”: sys.exit()else: notify_type=sys.argv[1] mail_title=’[紧急]负载均衡器邮件通知’mail_body_plain=notify_type+’被激活，请做好应急处理。’mail_body_html=’‘+notify_type+’被激活，请做好应急处理。‘ msgRoot = MIMEMultipart(‘related’)msgRoot[‘Subject’] =Header(mail_title,’utf-8’)msgRoot[‘From’] = strFrommsgRoot[‘To’] = strTo msgAlternative = MIMEMultipart(‘alternative’)msgRoot.attach(msgAlternative) msgText = MIMEText(mail_body_plain, ‘plain’, ‘utf-8’)msgAlternative.attach(msgText) msgText = MIMEText(mail_body_html, ‘html’,’utf-8’)msgAlternative.attach(msgText) smtp = smtplib.SMTP()smtp.connect(smtp_server)smtp.login(smtp_user,smtp_pass)smtp.sendmail(strFrom, strTo, msgRoot.as_string())smtp.quit()注：修改成系统python实际路径“#!/usr/local/bin/python”(第一行) #chmod +x /etc/keepalived/Mailnotify.py #/usr/local/haproxy/sbin/haproxy -f /usr/local/haproxy/etc/haproxy.cfg #service keepalived start8、查看VRRP通讯记录 #tcpdump vrrptcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes15:49:05.270017 IP 192.168.0.20 &gt; VRRP.MCAST.NET: VRRPv2, Advertisement, vrid 50, prio 100, authtype simple, intvl 1s, length 20四、Haproxy界面 访问http://192.168.0.20/admin-status，输入帐号admin密码123456进入管理监控平台。 点击在新窗口中浏览此图片 haproxy-1.4.9以后版本最大的亮点是添加了手工启用/禁用功能，对升级变更应用时非常有用。 五、邮件通知 点击在新窗口中浏览此图片","comments":true,"tags":[{"name":"集群","slug":"集群","permalink":"http://jishusuishouji.github.io/tags/集群/"}]},{"title":"nginx+keepalive主从双机热备+自动切换解决方案","date":"2017-04-07T04:42:10.000Z","path":"2017/04/07/jiqun/nginx_keepalive主从双机热备_自动切换解决方案/","text":"cenots 6.3 64位 1yum install -y make wget 1.安装keepalive12tar zxvf keepalived-1.2.7.tar.gzcd keepalived-1.2.7 1234567891011yum install -y gcc openssl-devel popt-devel./configuremake &amp;&amp; make install cp /usr/local/etc/rc.d/init.d/keepalived /etc/init.d/cp /usr/local/etc/sysconfig/keepalived /etc/sysconfig/chmod +x /etc/init.d/keepalivedchkconfig --add keepalivedchkconfig keepalived onmkdir /etc/keepalivedln -s /usr/local/sbin/keepalived /usr/sbin/ 2.安装Nginx12tar zxvf nginx-1.2.5.tar.gzcd nginx-1.2.5 123yum install -y pcre-devel./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_stub_status_module --with-http_ssl_modulemake &amp;&amp; make install 3.配置keepalive两台服务器端keepalived.conf内容如下，都设置为backup，不抢占，注意修改优先级不同：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263! Configuration file for keepalivedglobal_defs &#123; notification_email &#123; admin@lvtao.net &#125; notification_email_from admin@lvtao.net smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_DEVEL&#125;#监控服务.NGINX mysql等vrrp_script chk_nginx &#123; script &quot;/home/check_nginx.sh&quot; interval 2 weight 2&#125;vrrp_instance VI_1 &#123; state BACKUP #主从设置 MASTER interface eth2 #网卡名 virtual_router_id 51 mcast_src_ip 10.0.1.133 #本机ip priority 50 #从机小于主机 advert_int 1 authentication &#123; auth_type PASS auth_pass chtopnet &#125; virtual_ipaddress &#123; 10.0.1.2 #VIP 的IP &#125; track_script &#123; chk_nginx #检测脚本 &#125;&#125;virtual_server 10.0.1.2 80 &#123; delay_loop 6 lb_algo rr lb_kind DR persistence_timeout 50 protocol TCP real_server 10.0.1.132 80 &#123; weight 3 TCP_CHECK &#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125; real_server 10.0.1.133 80 &#123; weight 3 TCP_CHECK &#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125;&#125; 启动相关服务。我在这儿使用的是nginx ，每个上面开了一个站点，通过IP可以直接访问的。启动keepalive后，就可以通过VIP的虚拟IP 10.0.1.2来访问站点了，测试方法就是 停止任何其中一个站点，看它是否能自动切换到从服务器上。 上面代码中nginx的检测脚本如下 ：12345678910#!/bin/bashif [ &quot;$(ps -ef | grep &quot;nginx: master process&quot;| grep -v grep )&quot; == &quot;&quot; ]then /usr/local/nginx/sbin/nginx sleep 5 if [ &quot;$(ps -ef | grep &quot;nginx: master process&quot;| grep -v grep )&quot; == &quot;&quot; ] then killall keepalived fifi 在两台Web Server上执行realserver.sh脚本，为lo:0绑定VIP地址10.0.1.2、抑制arp广播。123456789101112131415161718192021222324252627282930313233#!/bin/bash#description: Config realserverVIP=10.0.1.2 /etc/rc.d/init.d/functions case &quot;$1&quot; instart) /sbin/ifconfig lo:0 $VIP netmask 255.255.255.255 broadcast $VIP /sbin/route add -host $VIP dev lo:0 echo &quot;1&quot; &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore echo &quot;2&quot; &gt;/proc/sys/net/ipv4/conf/lo/arp_announce echo &quot;1&quot; &gt;/proc/sys/net/ipv4/conf/all/arp_ignore echo &quot;2&quot; &gt;/proc/sys/net/ipv4/conf/all/arp_announce sysctl -p &gt;/dev/null 2&gt;&amp;1 echo &quot;RealServer Start OK&quot; ;;stop) /sbin/ifconfig lo:0 down /sbin/route del $VIP &gt;/dev/null 2&gt;&amp;1 echo &quot;0&quot; &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore echo &quot;0&quot; &gt;/proc/sys/net/ipv4/conf/lo/arp_announce echo &quot;0&quot; &gt;/proc/sys/net/ipv4/conf/all/arp_ignore echo &quot;0&quot; &gt;/proc/sys/net/ipv4/conf/all/arp_announce echo &quot;RealServer Stoped&quot; ;;*) echo &quot;Usage: $0 &#123;start|stop&#125;&quot; exit 1esac exit 0 分别在主从机上执行sh realserver.sh start就可实现负载均衡及高可用集群了； keepalive相关参数说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 ! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; admin@lvtao.net #设置报警邮件地址，可以设置多个，每行一个。 需开启本机的sendmail服务 &#125; notification_email_from admin@lvtao.net #设置邮件的发送地址 smtp_server 127.0.0.1 #设置smtp server地址 smtp_connect_timeout 30 #设置连接smtp server的超时时间 router_id LVS_DEVEL #表示运行keepalived服务器的一个标识。发邮件时显示在邮件主题的信息&#125;vrrp_instance VI_1 &#123; state MASTER #指定keepalived的角色，MASTER表示此主机是主服务器，BACKUP表示此主机是备用服务器 interface eth0 #指定HA监测网络的接口 virtual_router_id 51 #虚拟路由标识，这个标识是一个数字，同一个vrrp实例使用唯一的标识。即同一vrrp_instance下，MASTER和BACKUP必须是一致的 priority 100 #定义优先级，数字越大，优先级越高，在同一个vrrp_instance下，MASTER的优先级必须大于BACKUP的优先级 advert_int 1 #设定MASTER与BACKUP负载均衡器之间同步检查的时间间隔，单位是秒 authentication &#123; #设置验证类型和密码 auth_type PASS #设置验证类型，主要有PASS和AH两种 auth_pass 1111 #设置验证密码，在同一个vrrp_instance下，MASTER与BACKUP必须使用相同的密码才能正常通信 &#125; virtual_ipaddress &#123; #设置虚拟IP地址，可以设置多个虚拟IP地址，每行一个 10.0.0.148 &#125;&#125;virtual_server 10.0.0.148 80 &#123; #设置虚拟服务器，需要指定虚拟IP地址和服务端口，IP与端口之间用空格隔开 delay_loop 6 #设置运行情况检查时间，单位是秒 lb_algo rr #设置负载调度算法，这里设置为rr，即轮询算法 lb_kind DR #设置LVS实现负载均衡的机制，有NAT、TUN、DR三个模式可选 persistence_timeout 50 #会话保持时间，单位是秒。这个选项对动态网页是非常有用的，为集群系统中的session共享提供了一个很好的解决方案。 #有了这个会话保持功能，用户的请求会被一直分发到某个服务节点，直到超过这个会话的保持时间。 #需要注意的是，这个会话保持时间是最大无响应超时时间，也就是说，用户在操作动态页面时，如果50秒内没有执行任何操作， #那么接下来的操作会被分发到另外的节点，但是如果用户一直在操作动态页面，则不受50秒的时间限制 protocol TCP #指定转发协议类型，有TCP和UDP两种 real_server 10.0.0.137 80 &#123; #配置服务节点1，需要指定real server的真实IP地址和端口，IP与端口之间用空格隔开 weight 3 #配置服务节点的权值，权值大小用数字表示，数字越大，权值越高，设置权值大小可以为不同性能的服务器 #分配不同的负载，可以为性能高的服务器设置较高的权值，而为性能较低的服务器设置相对较低的权值，这样才能合理地利用和分配系统资源 TCP_CHECK &#123; #realserver的状态检测设置部分，单位是秒 connect_timeout 10 #表示3秒无响应超时 nb_get_retry 3 #表示重试次数 delay_before_retry 3 #表示重试间隔 connect_port 80 &#125; &#125; real_server 10.0.0.139 80 &#123; weight 3 TCP_CHECK &#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125;&#125;","comments":true,"tags":[]},{"title":"反向代理为何叫反向代理？","date":"2017-04-07T04:19:19.000Z","path":"2017/04/07/fangxiangdaili/反向代理为何叫反向代理？/","text":"正向代理A同学准备找马云借钱，但是马云不同意；于是他通过马云的亲戚向马云借钱，事情成了。这里马云并不知道钱是谁借的，马云借给了自己的亲戚，亲戚最后转交给A同学。亲戚在这个过程中扮演了代理的角色(正向代理)。如果马云是服务器，大家访问它(跟他借钱)，而马云又不可能随随便便借钱给别人，那么那些马云的亲戚就是正向代理，代理客户端(A同学们)向马云借钱。 常说的代理也就是指正向代理，它隐藏了真实的请求客户端，服务端不知道真实的客户端是谁，客户端的都被代理服务器代替来请求。 科学上网工具扮演的就是正向代理角色。 反向代理拨打10086客服电话，一个地区的10086客服有几个或者几十个，你拨通了10086的总机号码，电话那头总会有人会回答你。这里的10086总机号码就是起了反向代理的作用。客户并不知道真正提供服务人的是谁。 反向代理隐藏了真实的服务端。 正向代理和反向代理的区别正向代理代理的对象是客户端，反向代理代理的对象是服务端","comments":true,"tags":[{"name":"反向代理","slug":"反向代理","permalink":"http://jishusuishouji.github.io/tags/反向代理/"}]},{"title":"反向代理","date":"2017-04-07T03:55:17.000Z","path":"2017/04/07/jiqun/反向代理/","text":"反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 工作方式通常的代理服务器(内部网络对Internet的连接请求)通常的代理服务器，只用于代理内部网络对Internet的连接请求，客户机必须指定代理服务器,并将本来要直接发送到Web服务器上的http请求发送到代理服务器中。 缺点外部网络上的主机并不会配置并使用这个代理服务器，普通代理服务器也被设计为在Internet上搜寻多个不确定的服务器,而不是针对客户机的请求访问某一个固定的服务器，因此普通的Web代理服务器不支持外部对内部网络的访问请求。 方向代理服务器当一个代理服务器代理外部网络上的主机，访问内部网络时，这种代理服务的方式称为反向代理服务。此时代理服务器对外就表现为一个Web服务器，外部网络就可以简单把它当作一个标准的Web服务器而不需要特定的配置。不同之处在于，这个服务器没有保存任何网页的真实数据，所有的静态网页或者CGI程序，都保存在内部的Web服务器上。因此对反向代理服务器的攻击并不会使得网页信息遭到破坏，这样就增强了Web服务器的安全性。 反向代理方式和包过滤方式或普通代理方式并无冲突，因此可以在防火墙设备中同时使用这两种方式，其中反向代理用于外部网络访问内部网络时使用，正向代理或包过滤方式用于拒绝其他外部访问方式并提供内部网络对外部网络的访问能力。因此可以结合这些方式提供最佳的安全访问方式。 CDNCDN的全称是Content Delivery Network，即内容分发网络。其基本思路是尽可能避开互联网上有可能影响数据传输速度和稳定性的瓶颈和环节，使内容传输得更快、更稳定。通过在网络各处放置反向代理服务器所构成的在现有的互联网基础之上的一层智能虚拟网络，CDN系统能够实时地根据网络流量和各节点的连接、负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。其目的是使用户可就近取得所需内容，解决Internet网络拥挤的状况，提高用户访问网站的响应速度。 代理服务器如果您的内容服务器具有必须保持安全的敏感信息，如信用卡号数据库，可在防火墙外部设置一个代理服务器作为内容服务器的替身。当外部客户机尝试访问内容服务器时，会将其送到代理服务器。实际内容位于内容服务器上，在内部受到防火墙安全保护。代理服务器位于防火墙外部，在外部客户机看来就像是内容服务器。当客户机向站点提出请求时，请求将转到代理服务器。然后，代理服务器通过防火墙中的特定通路，将客户机的请求发送到内容服务器。内容服务器再通过该通道将结果回传给代理服务器。代理服务器将检索到的信息发送给客户机，好像代理服务器就是实际的内容服务器。如果内容服务器返回错误消息，代理服务器会先行截取该消息并更改标头中列出的任何URL，然后再将消息发送给客户机。如此可防止外部客户机获取内部内容服务器的重定向URL。这样，代理服务器就在安全数据库和可能的恶意攻击之间提供了又一道屏障。与有权访问整个数据库的情况相对比，就算是侥幸攻击成功，作恶者充其量也仅限于访问单个事务中所涉及的信息。未经授权的用户无法访问到真正的内容服务器，因为防火墙通路只允许代理服务器有权进行访问。 可以配置防火墙路由器，使其只允许特定端口上的特定服务器有权通过防火墙进行访问，而不允许其他任何机器进出。 安全反向代理当代理服务器与其他机器之间有一个或多个连接使用安全套接字层(SSL) 协议加密数据时，即会进行安全反向代理。 用途可以提供从防火墙外部代理服务器到防火墙内部安全内容服务器的加密连接。可以允许客户机安全地连接到代理服务器，从而有利于安全地传输信息（如信用卡号）。安全反向代理会造成各安全连接因加密数据所涉及的系统开销而变慢。但是，由于 SSL 提供了高速缓存机制，所以连接双方可以重复使用先前协商的安全参数，从而大大降低后续连接的系统开销。 配置方法配置安全反向代理服务器的方法有三种： Secure client to proxy如果未经授权的用户很少或根本没有机会访问代理服务器与内容服务器之间交换的信息，则此方案很有效。 Secure proxy to content server如果客户机在防火墙外部而内容服务器在防火墙内部，则此方案很有效。在此方案中，代理服务器可以充当站点之间的安全通道 Secure client to proxy and secure proxy to content server如果需要保护服务器、代理服务器和客户机三者间所交换信息的安全，则此方案很有效。在此方案中，代理服务器既可起到站点间安全通道的作用，又可增加客户机验证的安全性。 除了SSL之外，代理服务器还可以使用客户机验证，这种方法要求向代理服务器提出请求的计算机提供证书（或标识表单）以核实其身份。 比较标准的代理缓冲服务器一个标准的代理缓冲服务被用于缓存静态的网页（例如：html文件和图片文件等）到本地网络上的一台主机上（即代理服务器）。当被缓存的页面被第二次访问的时候，浏览器将直接从本地代理服务器那里请求数据而不再向原web站点请求数据。这样就节省了宝贵的网络带宽，而且提高了访问速度。但是，要想实现这种方式，必须在每一个内部主机的浏览器上明确指明代理服务器的IP地址和端口号。客户端上网时，每次都把请求送给代理服务器处理，代理服务器根据请求确定是否连接到远程web服务器获取数据。如果在本地缓冲区有目标文件，则直接将文件传给用户即可。如果没有的话则先取回文件，先在本地保存一份缓冲，然后将文件发给客户端浏览器。 透明代理缓冲服务器透明代理缓冲服务和标准代理服务器的功能完全相同。但是，代理操作对客户端的浏览器是透明的（即不需指明代理服务器的IP和端口）。透明代理服务器阻断网络通信，并且过滤出访问外部的HTTP（80端口）流量。如果客户端的请求在本地有缓冲则将缓冲的数据直接发给用户，如果在本地没有缓冲则向远程web服务器发出请求，其余操作和标准的代理服务器完全相同。对于Linux操作系统来说，透明代理使用Iptables或者Ipchains实现。因为不需要对浏览器作任何设置，所以，透明代理对于ISP（Internet服务器提供商）特别有用。 反向代理缓冲服务器反向代理是和前两种代理完全不同的一种代理服务。使用它可以降低原始WEB服务器的负载。反向代理服务器承担了对原始WEB服务器的静态页面的请求，防止原始服务器过载。它位于本地WEB服务器和Internet之间，处理所有对WEB服务器的请求，阻止了WEB服务器和Internet的直接通信。如果互联网用户请求的页面在代理服务器上有缓冲的话，代理服务器直接将缓冲内容发送给用户。如果没有缓冲则先向WEB服务器发出请求，取回数据，本地缓存后再发送给用户。这种方式通过降低了向WEB服务器的请求数从而降低了WEB服务器的负载。","comments":true,"tags":[{"name":"反向代理","slug":"反向代理","permalink":"http://jishusuishouji.github.io/tags/反向代理/"}]},{"title":"Nginx/LVS/HAProxy负载均衡软件的优缺点详解","date":"2017-04-07T03:42:08.000Z","path":"2017/04/07/fuzaijunheng/Nginx_LVS_HAProxy负载均衡软件的优缺点详解/","text":"根据网站规模不同使用不同的技术。中小型的Web应用(日PV小于1000万,平均下来一秒也就处理一百多个请求)用Nginx就可以了；如果机器不少，可以用DNS轮询，LVS需要的机器比较多；大型网站或重要的服务，且服务器比较多时，可以考虑用LVS。 硬件F5和Array等商用的负载均衡器 优点有专业的维护团队进行维护 缺点花销太大 软件Nginx/LVS/HAProxy等基于Linux的开源免费的负载均衡软件，通过软件级别来实现，费用非常低廉。 合理流行的架构方案webNginx/HAProxy+Keepalived作负载均衡器 后端MySQL数据库一主多从和读写分离，采用LVS+Keepalived的架构。 Nginx优点1、工作在网络协议的第7层，可以针对http应用做一些分流的策略，比如针对域名、目录结构，它的正则规则比HAProxy更为强大和灵活，这也是它目前广泛流行的主要原因之一，Nginx单凭这点可利用的场合就远多于LVS了。2、Nginx对网络稳定性的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势之一；相反LVS对网络稳定性依赖比较大；3、Nginx安装和配置比较简单，测试起来比较方便，日志功能很强大。LVS的配置、测试就要花比较长的时间了，LVS对网络依赖比较大。3、可以承担高负载压力且稳定，在硬件不差的情况下一般能支撑几万次的并发量，负载度比LVS相对小些。4、Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url检测。比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能会因此而不满。5、Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。LNMP也是近几年非常流行的web架构，在高流量的环境中稳定性也很好。6、Nginx现在作为Web反向加速缓存越来越成熟了，速度比传统的Squid服务器更快，可以考虑用其作为反向代理加速器。7、Nginx可作为中层反向代理使用，这一层面Nginx基本上无对手，唯一可以对比Nginx的就只有lighttpd了，不过lighttpd目前还没有做到Nginx完全的功能，配置也不那么清晰易读，社区资料也远远没Nginx活跃。8、Nginx也可作为静态网页和图片服务器，这方面的性能也无对手。还有Nginx社区非常活跃，第三方模块也很多。 淘宝的前端使用的Tengine就是基于nginx做的二次开发定制版。 Nginx常规的HTTP请求和响应流程图： nginx Nginx的缺点是：1、Nginx仅支持http、https和Email协议，适用范围比较小。2、对后端服务器的健康检查，只支持通过端口来检测，不支持通过url来检测。不支持Session的直接保持，但能通过ip_hash来解决。 二、LVS使用Linux内核集群实现一个高性能、高可用的负载均衡服务器，它具有很好的可伸缩性（Scalability)、可靠性（Reliability)和可管理性（Manageability)。 优点1、抗负载能力强、工作在网络协议第四层，仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的，对内存和cpu资源消耗比较低。2、配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率。3、工作稳定，因为其本身抗负载能力很强，自身有完整的双机热备方案，如LVS+Keepalived，不过在项目实施中用得最多的还是LVS/DR+Keepalived。4、无流量，LVS只分发请求，而流量并不从它本身出去，这点保证了均衡器IO的性能不会收到大流量的影响。5、应用范围比较广，因为LVS工作在4层，所以它几乎可以对所有应用做负载均衡，包括http、数据库、在线聊天室等等。 LVS DR(Direct Routing)模式的网络流程图： lvs_dr 缺点1、软件本身不支持正则表达式处理，不能做动静分离；而现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在。2、如果是网站应用比较庞大的话，LVS/DR+Keepalived实施起来就比较复杂了，特别后面有Windows Server的机器的话，实施、配置、维护比较复杂了，相对而言，Nginx/HAProxy+Keepalived简单多了。 三、HAProxy###特点 1、HAProxy也是支持虚拟主机的。2、HAProxy的优点能够补充Nginx的一些缺点，比如支持Session的保持，Cookie的引导；同时支持通过获取指定的url来检测后端服务器的状态。3、HAProxy跟LVS类似，本身就只是一款负载均衡软件；单纯从效率上来讲HAProxy会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的。4、HAProxy支持TCP协议的负载均衡转发，可以对MySQL读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，可以用LVS+Keepalived对MySQL主从做负载均衡。5、HAProxy负载均衡策略非常多，HAProxy的负载均衡算法现在具体有如下8种：① roundrobin，表示轮询；② static-rr，表示根据权重，建议关注；③ leastconn，表示最少连接者先处理，建议关注；④ source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法，建议关注；⑤ ri，表示根据请求的URI；⑥ rl_param，表示根据请求的URl参数’balance url_param’ requires an URL parameter name；⑦ hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求；⑧ rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。 四、总结Nginx和LVS对比：1、Nginx工作在网络的7层，所以它可以针对http应用本身来做分流策略，比如针对域名、目录结构等，相比之下LVS并不具备这样的功能，所以Nginx单凭这点可利用的场合就远多于LVS了；但Nginx配置灵活，配置人员易出错。2、Nginx对网络稳定性的依赖较小，理论上只要ping得通，网页访问正常，Nginx就能连得通，这是Nginx的一大优势！Nginx同时还能区分内外网，如果是同时拥有内外网的节点，就相当于单机拥有了备份线路；LVS就比较依赖于网络环境，目前来看服务器在同一网段内并且LVS使用direct方式分流，效果较能得到保证。另外注意，LVS需要向托管商至少申请多一个ip来做Visual IP，貌似是不能用本身的IP来做VIP的。要做好LVS管理员，确实得跟进学习很多有关网络通信方面的知识，就不再是一个HTTP那么简单了。3、Nginx安装和配置比较简单，测试起来也很方便，因为它基本能把错误用日志打印出来。LVS的安装和配置、测试就要花比较长的时间了；LVS对网络依赖比较大，很多时候不能配置成功都是因为网络问题而不是配置问题，出了问题要解决也相应的会麻烦得多。4、Nginx也同样能承受很高负载且稳定，但负载度和稳定度差LVS还有几个等级：Nginx处理所有流量所以受限于机器IO和配置；本身的bug也还是难以避免的。5、Nginx可以检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点。目前LVS中 ldirectd也能支持针对服务器内部的情况来监控，但LVS的原理使其不能重发请求。比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能会因此而恼火。6、Nginx对请求的异步处理可以帮助节点服务器减轻负载，假如使用apache直接对外服务，那么出现很多的窄带链接时apache服务器将会占用大量内存而不能释放，使用多一个Nginx做apache代理的话，这些窄带链接会被Nginx挡住，apache上就不会堆积过多的请求，这样就减少了相当多的资源占用。这点使用squid也有相同的作用，即使squid本身配置为不缓存，对apache还是有很大帮助的。7、Nginx能支持http、https和email（email的功能比较少用），LVS所支持的应用会比Nginx多。在使用上，一般最前端所采取的策略应是LVS，也就是DNS的指向应为LVS均衡器，LVS的优点令它非常适合做这个任务。重要的ip地址，最好交由LVS托管，比如数据库的 ip、webservice服务器的ip等等，这些ip地址随着时间推移，使用面会越来越大，如果更换ip则故障会接踵而至。所以将这些重要ip交给LVS托管是最为稳妥的，这样做的唯一缺点是需要的VIP数量会比较多。Nginx可作为LVS节点机器使用，一是可以利用Nginx的功能，二是可以利用Nginx的性能。当然这一层面也可以直接使用squid，squid的功能方面就比Nginx弱不少了，性能上也有所逊色于Nginx。Nginx也可作为中层代理使用，这一层面Nginx基本上无对手，唯一可以撼动Nginx的就只有lighttpd了，不过lighttpd目前还没有能做到 Nginx完全的功能，配置也不那么清晰易读。另外，中层代理的IP也是重要的，所以中层代理也拥有一个VIP和LVS是最完美的方案了。具体的应用还得具体分析，如果是比较小的网站（日PV小于1000万），用Nginx就完全可以了，如果机器也不少，可以用DNS轮询，LVS所耗费的机器还是比较多的；大型网站或者重要的服务，机器不发愁的时候，要多多考虑利用LVS。 现在对网络负载均衡的使用是随着网站规模的提升根据不同的阶段来使用不同的技术： 第一阶段：利用Nginx或HAProxy进行单点的负载均衡，这一阶段服务器规模刚脱离开单服务器、单数据库的模式，需要一定的负载均衡，但是仍然规模较小没有专业的维护团队来进行维护，也没有需要进行大规模的网站部署。这样利用Nginx或HAproxy就是第一选择，此时这些东西上手快， 配置容易，在七层之上利用HTTP协议就可以。这时是第一选择。 第二阶段：随着网络服务进一步扩大，这时单点的Nginx已经不能满足，这时使用LVS或者商用Array就是首要选择，Nginx此时就作为LVS或者Array的节点来使用，具体LVS或Array的是选择是根据公司规模和预算来选择，Array的应用交付功能非常强大，本人在某项目中使用过，性价比也远高于F5，商用首选！但是一般来说这阶段相关人才跟不上业务的提升，所以购买商业负载均衡已经成为了必经之路。 第三阶段：这时网络服务已经成为主流产品，此时随着公司知名度也进一步扩展，相关人才的能力以及数量也随之提升，这时无论从开发适合自身产品的定制，以及降低成本来讲开源的LVS，已经成为首选，这时LVS会成为主流。最终形成比较理想的基本架构为：Array/LVS — Nginx/Haproxy — Squid/Varnish — AppServer。","comments":true,"tags":[{"name":"负载均衡","slug":"负载均衡","permalink":"http://jishusuishouji.github.io/tags/负载均衡/"}]},{"title":"Java集群--大型网站是怎样解决多用户高并发访问的","date":"2017-04-07T00:06:33.000Z","path":"2017/04/07/jiqun/Java集群--大型网站是怎样解决多用户高并发访问的/","text":"为了解决大型网站的访问量大、并发量高、海量数据的问题，一般会考虑业务拆分和分布式部署。可以把那些关联不太大的业务独立出来，部署到不同的机器上，从而实现大规模的分布式系统。但这之中也有一个问题，那就是用户如何选择相应的机器的问题，这也被称为访问统一入口问题，而解决的方法是我们可以在集群机器的前面增加负载均衡设备，实现流量分发。负载均衡:将负载（工作任务、访问请求等）进行平衡、分摊到多个操作单元（服务器、组件等）上进行执行，是解决高性能，单点故障（高可用，如果你是单机版网络，一旦服务器挂掉了，那么用户就无法请求了，但对于集群来说，一台服务器挂掉了，负载均衡器会把用户的请求发送给其他的服务器进行处理），扩展性（这里主要是指水平伸缩）的终极解决方案。负载均衡设备为Nginx(F5太贵了，不过比较稳定)，这是一款轻量级的Web服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，具有占用内存少、并发能力强等，中国大陆使用nginx网站用户有：百度、网易、新浪、腾讯等。1.nginx的负载均衡配置中默认是采用轮询的方式，这种方式中，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除，但存在各个服务器的session共享问题。2.另外一种方式是ip_hash:每个请求按访问的ip的hash结果分配，如果访问的IP是固定的，那么在正常情况下，该用户的请求都会分配到后台的同一台服务器去处理，但是如果用户每次请求的IP都不同呢？所以这种方式也同1的方式一样都存在这么一个问题：session在各个服务器上的共享问题。3.如果集群中的服务器的性能不一，可以通过配置各个服务器的权值来实现资源利用率的最大化，即性能好的优先选择 也许你会问，既然IP可能变化，那么用户用页面请求时的cookie的ID应该是确定的吧！那么我们可以用cookie_id来进行hash，然后在通过负载均衡器分发到对应的服务器上，这样就可以解决session问题了，其实当初本人也有想到这个方案，但最后本人也放弃这个方案了，因为是根据cookid_id确实可以把该用户的请求唯一的分发到那台独一无二的服务器上，那如果这台服务器挂掉了，那么根据这种分发策略，岂不是在这服务器上请求资源的用户都不能访问了。解决服务器共享session问题：使用redis来共享各个服务器的session，并同时通过redis来缓存一些常用的资源，加快用户获得请求资源的速度（memcache不能做到持久化，这样这台服务器一挂掉，那么所有的资源也都没有了）。 进行集群部署，最好配上数据库的主从部署，因为如果在集群中只分配一个数据库服务器，那么这个系统的瓶颈将会出现在数据库的操作上，虽然redis能减轻这种负担，但对于数据量大的还是有一定影响的，而且数据库的主从部署也可以防止因某个数据库服务器的挂掉而丢失用户的信息。","comments":true,"tags":[{"name":"集群","slug":"集群","permalink":"http://jishusuishouji.github.io/tags/集群/"}]},{"title":"浅谈web应用的负载均衡、集群、高可用(HA)解决方案","date":"2017-04-06T23:31:58.000Z","path":"2017/04/07/web/浅谈web应用的负载均衡、集群、高可用_HA_解决方案/","text":"1、几个组件1.1、apacheApache软件基金会开放源代码的跨平台网页服务器，属于老牌的web服务器了，支持基于Ip或者域名的虚拟主机，支持代理服务器，支持安全Socket层(SSL)等等，目前主要用它做静态资源服务器，也可以做代理服务器转发请求(如：图片链等)，结合tomcat等servlet容器。 1.2、ngnix俄罗斯人开发的一个高性能的HTTP和反向代理服务器。由于Nginx超越Apache的高性能和稳定性，使得国内使用Nginx作为Web服务器的网站也越来越多，其中包括新浪博客、新浪播客、网易新闻、腾讯网、搜狐博客等门户网站频道等，在3w以上的高并发环境下，ngnix处理能力相当于apache的10倍。 1.3、lvsLinux Virtual Server的简写，意即Linux虚拟服务器，是一个虚拟的服务器集群系统。由毕业于国防科技大学的章文嵩博士于1998年5月创立，可以实现LINUX平台下的简单负载均衡。 1.4、HAProxyHAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。HAProxy特别适用于那些负载特大的web站点， 这些站点通常又需要会话保持或七层处理。HAProxy运行在当前的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全地整合进您当前的架构中，同时可以保护你的web服务器不被暴露到网络上. 1.5、keepalived可以实现web服务器的高可用(HA high availably)。它可以检测web服务器的工作状态，如果该服务器出现故障被检测到，将其剔除服务器群中，直至正常工作后，keepalive会自动检测到并加入到服务器群里面。实现主备服务器发生故障时ip瞬时无缝交接。它是LVS集群节点健康检测的一个用户空间守护进程，也是LVS的引导故障转移模块（director failover）。Keepalived守护进程可以检查LVS池的状态。如果LVS服务器池当中的某一个服务器宕机了。keepalived会通过一个setsockopt呼叫通知内核将这个节点从LVS拓扑图中移除。 1.6、memcached一个高性能分布式内存对象缓存系统。当初是Danga Interactive为了LiveJournal快速发展开发的系统，用于对业务查询数据缓存，减轻数据库的负载。其守护进程(daemon)是用C写的，但是客户端支持几乎所有语言(客户端基本上有3种版本[memcache client for java;spymemcached;xMecache])，服务端和客户端通过简单的协议通信；在memcached里面缓存的数据必须序列化。 1.7、terracotta是一款由美国Terracotta公司开发的著名开源Java集群平台。它在JVM与Java应用之间实现了一个专门处理集群功能的抽象层，允许用户在不改变系统代码的情况下实现java应用的集群。支持数据的持久化、session的复制以及高可用(HA)。 2、关键术语2.1、负载均衡（load balance）如何处理高并发带来的系统性能问题，最终大家都会使用负载均衡机制。它是根据某种负载策略把请求分发到集群中的每一台服务器上，让整个服务器群来处理网站的请求。公司比较有钱的，可以购买专门负责负载均衡的硬件（如：F5）,效果肯定会很好。对于大部分公司，会选择廉价有效的方法扩展整个系统的架构，来增加服务器的吞吐量和处理能力，以及承载能力。 2.2、集群（Cluster）用N台服务器构成一个松耦合的多处理器系统(对外来说，他们就是一个服务器)，它们之间通过网络实现通信。让N台服务器之间相互协作，共同承载一个网站的请求压力。 2.3、高可用（HA）在集群服务器架构中，当主服务器故障时，备份服务器能够自动接管主服务器的工作，并及时切换过去，以实现对用户的不间断服务。ps：这里我感觉它跟故障转移(failover)是一个意思。 2.4、session复制/共享在访问系统的会话过程中，用户登录系统后，不管访问系统的任何资源地址都不需要重复登录，这里面servlet容易保存了该用户的会话(session)。如果两个tomcat(A、B)提供集群服务时候，用户在A-tomcat上登录，接下来的请求web服务器根据策略分发到B-tomcat，因为B-tomcat没有保存用户的会话(session)信息，不知道其登录，会跳转到登录界面。这时候我们需要让B-tomcat也保存有A-tomcat的会话，我们可以使用tomcat的session复制实现或者通过其他手段让session共享。 3、常用web集群3.1、tomcat集群方案apache+tomcat；ngnix+tomcat；lvs+ngnix+tomcat。(lvs负责集群调度，nginx负责静态文件处理，tomcat负责动态文件处理[最优选择])。 以apache+tomcat集群为例：1、他们之间的通信有三种方式：ajp_proxy、mod_jk链接器、http_proxy。2、apache的分发策略有4种。权重(默认)、流量(bytraffic)、请求次数(byRequests)、繁忙程度(byBusyness根据活跃请求数的多少)3、apache支持stickysession(粘性session)，即为：访问用户访问了A-tomcat，那么他的所有请求都会转发到A-tomcat，而不会到B-tomcat。[这样的负载均衡效果不好，适用于小型网站，下面说非粘性session]4、它们之间的架构如图1： 问题1：只有一个web服务器，明显的单点故障。如果该apache出现问题，整个网站就会瘫痪。 3.2、session复制如果不采用stickysession(粘性session)，那么我们可以采用tomcat的session复制使所有节点tomcat的会话相同，tomcat使用组播技术，只要集群中一个tomcat节点的session发生改变，会广播通知所有tomcat节点发生改变。 问题2：据网友测试，当tomcat节点数达到4个以上时候，集群性能呈线性下滑；另外当用户访问量大到一定程度，会话内容随之增多，tomcat节点相互之间通信产生大量的网络消耗，产生网络阻塞，整个集群的吞吐量不能再上升。 4、高可用(HA)和session共享(解决上面提到的两个问题)4.1、使用lvs+keepalive实现集群高可用，达到更健壮的LB可以前端使用lvs来做负载均衡，根据lvs的8种调度算法(可设置)，分发请求到对应的web服务器集群上。lvs做双机热备，通过keepalived模块能够达到故障自动转移到备份服务器，不间断提供服务，结构如图2： 说明：据查询了解，一般在WEB端使用的负载均衡比较多的是HAProxy+keepalived+nginx；数据库mysql集群使用Lvs+keepalived+mysql实现。因为HAProxy和nginx一样是工作在网络7层之上，并且前者弥补了nginx的一些缺点如session的保持，cookie的引导等，且它本身是个负责均衡软件，处理负载均衡上面必然优于nginx；lvs比较笨重，对于比较庞大的网络应用实施比较复杂，虽然它运行在网络4层之上，仅做分发没有流量产生，但是它不能做正则处理也不能也不能做动静分离，所以一般用lvs+keepalived或heatbeat做数据库层的负载均衡。 4.2、使用terracotta或者memcached使session共享4.2.1、terracotta是jvm级别的session共享它基本原理是对于集群间共享的数据，当在一个节点发生变化的时候，Terracotta只把变化的部分发送给Terracotta服务器，然后由服务器把它转发给真正需要这个数据的节点，并且共享的数据对象不需要序列化。 4.2.2、通过memcached实现内存级session共享通过memcached-session-manager（msm）插件，通过tomcat上一定的配置，即可实现把session存储到memcached服务器上。注意：tomcat支持tomcat6+，并且memcached可以支持分布式内存，msm同时支持黏性session（sticky sessions）或者非黏性session（non-sticky sessions）两种模式，在memcached内存中共享的对象需要序列化。结构如图3： 通过一定的配置，可以实现故障转移(只支持对非粘性session)。如：123456789&lt;Context&gt; ... &lt;Manager className=&quot;de.javakaffee.web.msm.MemcachedBackupSessionManager&quot; memcachedNodes=&quot;n1:host1.yourdomain.com:11211,n2:host2.yourdomain.com:11211&quot; failoverNodes=&quot;n1&quot; requestUriIgnorePattern=&quot;.*\\.(ico|png|gif|jpg|css|js)$&quot; transcoderFactoryClass=&quot;de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory&quot; /&gt; &lt;/Context&gt; 说明：failoverNodes：故障转移节点，对非粘性session不可用。属性failoverNodes=&quot;n1&quot;的作用是告诉msm最好是把session保存在memcached “n2”节点上，只有在n2节点不可用的情况下才把session保存在n1节点。这样即使host2上的tomcat宕机，仍然可以通过host1上的tomcat访问存放在memcached “n1” 节点中的session。 4.2.3、其他方案通过cookie保存用户信息(一般是登录信息)，每一个请求到达web应用的时候，web应用从cookie中取出数据进行处理（这里尽量对cookie做加密处理）；另外一种是把用户信息的关键属性保存到数据库，这样就不需要session了。请求过来从数据库查询关键属性数据，做相应处理。缺点：加大了数据库的负载，使数据库成为集群的瓶颈。","comments":true,"tags":[{"name":"负载均衡","slug":"负载均衡","permalink":"http://jishusuishouji.github.io/tags/负载均衡/"},{"name":"集群","slug":"集群","permalink":"http://jishusuishouji.github.io/tags/集群/"},{"name":"高可用","slug":"高可用","permalink":"http://jishusuishouji.github.io/tags/高可用/"}]},{"title":"js如何把相对路基的url转换为绝对路径","date":"2017-04-06T13:50:53.000Z","path":"2017/04/06/js/js如何把相对路基的url转换为绝对路径/","text":"12345var absolutePath = function(href) &#123; var link = document.createElement(&quot;a&quot;); link.href = href; return (link.protocol+&quot;//&quot;+link.host+link.pathname+link.search+link.hash);&#125;","comments":true,"tags":[{"name":"javascript","slug":"javascript","permalink":"http://jishusuishouji.github.io/tags/javascript/"},{"name":"js","slug":"js","permalink":"http://jishusuishouji.github.io/tags/js/"},{"name":"相对路径","slug":"相对路径","permalink":"http://jishusuishouji.github.io/tags/相对路径/"},{"name":"绝对路径","slug":"绝对路径","permalink":"http://jishusuishouji.github.io/tags/绝对路径/"}]},{"title":"设计模式六大原则","date":"2017-04-05T23:43:16.000Z","path":"2017/04/06/shejiyuanze/设计模式六大原则/","text":"开闭原则单一职责原则迪米特原则面向对象的： 接口隔离原则 依赖倒转原则 里氏替换原则 单一职责原则定义：不要存在多于一个导致类变更的原因。 问题由来：类T负责两个不同的职责：职责P1，职责P2。当由于职责P1需求发生改变而需要修改类T时，有可能会导致原本运行正常的职责P2功能发生故障。 解决方案：遵循单一职责原则。分别建立两个类T1、T2，使T1完成职责P1功能，T2完成职责P2功能。这样，当修改类T1时，不会使职责P2发生故障风险；同理，当修改T2时，也不会使职责P1发生故障风险。 遵循单一职责原则可以避免因为修改了一个功能导致其他功能发生异常。 职责扩散职责扩散：因为某种原因，职责P被分化为粒度更细的职责P1和P2。比如：类T只负责一个职责P，这样设计是符合单一职责原则的。后来由于需求变更了，需要将职责P细分为粒度更细的职责P1，P2，这时如果要使程序遵循单一职责原则，需要将类T分解为两个类T1和T2，分别负责P1、P2两个职责。但是在程序已经写好的情况下，这样做简直太费时间了。所以，简单的修改类T，用它来负责两个职责是一个比较不错的选择，虽然这样做有悖于单一职责原则。（这样做的风险在于职责扩散的不确定性，因为我们不会想到这个职责P，在未来可能会扩散为P1，P2，P3，P4……Pn。所以记住，在职责扩散到我们无法控制的程度之前，立刻对代码进行重构。） 职责扩散例子说明，用一个类描述动物呼吸这个场景：12345class Animal&#123; public void breathe(String animal)&#123; System.out.println(animal+&quot;呼吸空气&quot;); &#125;&#125; 12345678public class Client&#123; public static void main(String[] args)&#123; Animal animal = new Animal(); animal.breathe(&quot;牛&quot;); animal.breathe(&quot;羊&quot;); animal.breathe(&quot;猪&quot;); &#125;&#125; 运行结果： 123牛呼吸空气羊呼吸空气猪呼吸空气 程序上线后，发现问题了，并不是所有的动物都呼吸空气的，比如鱼就是呼吸水的。修改时如果遵循单一职责原则，需要将Animal类细分为陆生动物类Terrestrial，水生动物Aquatic，代码如下：12345class Terrestrial&#123; public void breathe(String animal)&#123; System.out.println(animal+&quot;呼吸空气&quot;); &#125;&#125; 12345class Aquatic&#123; public void breathe(String animal)&#123; System.out.println(animal+&quot;呼吸水&quot;); &#125;&#125; 1234567891011public class Client&#123; public static void main(String[] args)&#123; Terrestrial terrestrial = new Terrestrial(); terrestrial.breathe(&quot;牛&quot;); terrestrial.breathe(&quot;羊&quot;); terrestrial.breathe(&quot;猪&quot;); Aquatic aquatic = new Aquatic(); aquatic.breathe(&quot;鱼&quot;); &#125;&#125; 运行结果：1234牛呼吸空气羊呼吸空气猪呼吸空气鱼呼吸水 我们会发现如果这样修改花销是很大的，除了将原来的类分解之外，还需要修改客户端。而直接修改类Animal来达成目的虽然违背了单一职责原则，但花销却小得多，代码如下：123456789class Animal&#123; public void breathe(String animal)&#123; if(&quot;鱼&quot;.equals(animal))&#123; System.out.println(animal+&quot;呼吸水&quot;); &#125;else&#123; System.out.println(animal+&quot;呼吸空气&quot;); &#125; &#125;&#125; 123456789public class Client&#123; public static void main(String[] args)&#123; Animal animal = new Animal(); animal.breathe(&quot;牛&quot;); animal.breathe(&quot;羊&quot;); animal.breathe(&quot;猪&quot;); animal.breathe(&quot;鱼&quot;); &#125;&#125; 可以看到，这种修改方式要简单得多。但是却存在着隐患：有一天需要将鱼分为呼吸淡水的鱼和呼吸海水的鱼，则又需要修改Animal类的breathe方法，而对原有代码的修改会对调用“猪”“牛”“羊”等相关功能带来风险，也许某一天你会发现程序运行的结果变为“牛呼吸水”了。(不要认为这是不可能的，这是绝对可能的，修改代码本来就应该认为是极其危险的，你可以扩展但是最好不要修改，修改了就一定要好好测试！)这种修改方式直接在代码级别上违背了单一职责原则，虽然修改起来最简单，但隐患却是最大的。还有一种修改方式： 123456789class Animal&#123; public void breathe(String animal)&#123; System.out.println(animal+&quot;呼吸空气&quot;); &#125; public void breathe2(String animal)&#123; System.out.println(animal+&quot;呼吸水&quot;); &#125;&#125; 123456789public class Client&#123; public static void main(String[] args)&#123; Animal animal = new Animal(); animal.breathe(&quot;牛&quot;); animal.breathe(&quot;羊&quot;); animal.breathe(&quot;猪&quot;); animal.breathe2(&quot;鱼&quot;); &#125;&#125; 可以看到，这种修改方式没有改动原来的方法，而是在类中新加了一个方法，这样虽然也违背了单一职责原则，但在方法级别上却是符合单一职责原则的，因为它并没有动原方法的代码。这三种方式各有优缺点，那么在实际编程中，采用哪一种呢？这需要根据实际情况来确定。原则是：只有逻辑足够简单，才可以在代码级别上违反单一职责原则；只有类中方法数量足够少，才可以在方法级别上违反单一职责原则； 例如本文所举的这个例子，它太简单了，它只有一个方法，所以，无论是在代码级别上违反单一职责原则，还是在方法级别上违反，都不会造成太大的影响。实际应用中的类要复杂得多，一旦发生职责扩散而需要修改类时，除非这个类本身非常简单，否则还是遵循单一职责原则的好。 遵循单一职责原的优点有： 可以降低类的复杂度，一个类只负责一项职责，其逻辑肯定要比负责多项职责简单得多； 提高类的可读性，提高系统的可维护性； 降低变更引起的风险，变更是必然的，如果单一职责原则遵守得好，当修改一个功能时，可以显著降低对其他功能的影响。 需要说明的一点是单一职责原则不只是面向对象编程思想所特有的，只要是模块化的程序设计，都适用单一职责原则。 里氏替换原则在1988年麻省理工学院的一位姓里的女士（Barbara Liskov）提出来的。 定义1：如果对每一个类型为T1的对象o1，都有类型为T2的对象o2,使得在程序中所有的对象o1都代换成o2时，程序P的行为没有发生变化，那么类型T2是类型T1的子类型。 定义2：所有引用基类的地方必须能透明地使用其子类的对象。 问题由来：有一功能P1，由类A完成。现需要将功能P1进行扩展，扩展后的功能为P，其中P由原有功能P1与新功能P2组成。新功能P由类A的子类B来完成，则子类B在完成新功能P2的同时，有可能会导致原有功能P1发生故障。 解决方案：当使用继承时，遵循里氏替换原则。类B继承类A时，除添加新的方法完成新增功能P2外，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。 继承包含这样一层含义：父类中凡是已经实现好的方法（相对于抽象方法而言），实际上是在设定一系列的规范和契约，虽然它不强制要求所有的子类必须遵从这些契约，但是如果子类对这些非抽象方法任意修改，就会对整个继承体系造成破坏。而里氏替换原则就是表达了这一层含义。 继承作为面向对象三大特性之一，在给程序设计带来巨大便利的同时，也带来了弊端。比如使用继承会给程序带来侵入性，程序的可移植性降低，增加了对象间的耦合性，如果一个类被其他的类所继承，则当这个类需要修改时，必须考虑到所有的子类，并且父类修改后，所有涉及到子类的功能都有可能会产生故障。 例子一个两数相减的功能由类A来负责。12345class A&#123; public int func1(int a, int b)&#123; return a-b; &#125;&#125; 1234567public class Client&#123; public static void main(String[] args)&#123; A a = new A(); System.out.println(&quot;100-50=&quot;+a.func1(100, 50)); System.out.println(&quot;100-80=&quot;+a.func1(100, 80)); &#125;&#125; 运行结果：123100-50=50100-80=20 后来，需要增加一个新的功能：完成两数相加，然后再与100求和，由类B来负责。即类B需要完成两个功能： 两数相减。 两数相加，然后再加100。 由于类A已经实现了第一个功能，所以类B继承类A后，只需要再完成第二个功能就可以了，代码如下：123456789class B extends A&#123; public int func1(int a, int b)&#123; return a+b; &#125; public int func2(int a, int b)&#123; return func1(a,b)+100; &#125;&#125; 12345678public class Client&#123; public static void main(String[] args)&#123; B b = new B(); System.out.println(&quot;100-50=&quot;+b.func1(100, 50)); System.out.println(&quot;100-80=&quot;+b.func1(100, 80)); System.out.println(&quot;100+20+100=&quot;+b.func2(100, 20)); &#125;&#125; 类B完成后，运行结果：123100-50=150100-80=180100+20+100=220 我们发现原本运行正常的相减功能发生了错误。原因就是类B在给方法起名时无意中重写了父类的方法，造成所有运行相减功能的代码全部调用了类B重写后的方法，造成原本运行正常的功能出现了错误。在本例中，引用基类A完成的功能，换成子类B之后，发生了异常。在实际编程中，我们常常会通过重写父类的方法来完成新的功能，这样写起来虽然简单，但是整个继承体系的可复用性会比较差，特别是运用多态比较频繁时，程序运行出错的几率非常大。如果非要重写父类的方法，比较通用的做法是：原来的父类和子类都继承一个更通俗的基类，原有的继承关系去掉，采用依赖、聚合，组合等关系代替。 里氏替换原则通俗的来讲就是：子类可以扩展父类的功能，但不能改变父类原有的功能。它包含以下4层含义： 子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。 子类中可以增加自己特有的方法。 当子类的方法重载父类的方法时，方法的前置条件（即方法的形参）要比父类方法的输入参数更宽松。 当子类的方法实现父类的抽象方法时，方法的后置条件（即方法的返回值）要比父类更严格。 看上去很不可思议，因为我们会发现在自己编程中常常会违反里氏替换原则，程序照样跑的好好的。所以大家都会产生这样的疑问，假如我非要不遵循里氏替换原则会有什么后果？ 后果就是：你写的代码出问题的几率将会大大增加。 依赖倒置原则定义：高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象。 问题由来：类A直接依赖类B，假如要将类A改为依赖类C，则必须通过修改类A的代码来达成。这种场景下，类A一般是高层模块，负责复杂的业务逻辑；类B和类C是低层模块，负责基本的原子操作；假如修改类A，会给程序带来不必要的风险。 解决方案：将类A修改为依赖接口I，类B和类C各自实现接口I，类A通过接口I间接与类B或者类C发生联系，则会大大降低修改类A的几率。 依赖倒置原则基于这样一个事实：相对于细节的多变性，抽象的东西要稳定得多。以抽象为基础搭建起来的架构比以细节为基础搭建起来的架构要稳定得多。在java中，抽象指的是接口或者抽象类，细节就是具体的实现类，使用接口或者抽象类的目的是制定好规范和契约，而不去涉及任何具体的操作，把细节的任务交给他们的实现类去完成。 依赖倒置原则的核心思想是面向接口编程。Spring Ioc的好处在小项目是体会不到的，当你的项目大了，你就能体会到了。比如有一个项目有30多个maven子模块，在某个子模块中你根本就不知道服务层注入的到底是那个对象，你只知道那些接口，这样接口的实现可以随意变动，另一个人不会影响到你。 场景是这样的，母亲给孩子讲故事，只要给她一本书，她就可以照着书给孩子讲故事了。12345class Book&#123; public String getContent()&#123; return &quot;很久很久以前有一个阿拉伯的故事……&quot;; &#125;&#125; 123456class Mother&#123; public void narrate(Book book)&#123; System.out.println(&quot;妈妈开始讲故事&quot;); System.out.println(book.getContent()); &#125;&#125; 123456public class Client&#123; public static void main(String[] args)&#123; Mother mother = new Mother(); mother.narrate(new Book()); &#125;&#125; 运行结果：12妈妈开始讲故事很久很久以前有一个阿拉伯的故事…… 运行良好，假如有一天，需求变成这样：不是给书而是给一份报纸，让这位母亲讲一下报纸上的故事，报纸的代码如下：12345class Newspaper&#123; public String getContent()&#123; return &quot;林书豪38+7领导尼克斯击败湖人……&quot;; &#125;&#125; 这位母亲却办不到，因为她居然不会读报纸上的故事，这太荒唐了，只是将书换成报纸，居然必须要修改Mother才能读。假如以后需求换成杂志呢？换成网页呢？还要不断地修改Mother，这显然不是好的设计。原因就是Mother与Book之间的耦合性太高了，必须降低他们之间的耦合度才行。 我们引入一个抽象的接口IReader。读物，只要是带字的都属于读物：123interface IReader&#123; public String getContent();&#125; Mother类与接口IReader发生依赖关系，而Book和Newspaper都属于读物的范畴，他们各自都去实现IReader接口，这样就符合依赖倒置原则了，代码修改为：12345class Newspaper implements IReader &#123; public String getContent()&#123; return &quot;林书豪17+9助尼克斯击败老鹰……&quot;; &#125;&#125; 12345class Book implements IReader&#123; public String getContent()&#123; return &quot;很久很久以前有一个阿拉伯的故事……&quot;; &#125;&#125; 123456class Mother&#123; public void narrate(IReader reader)&#123; System.out.println(&quot;妈妈开始讲故事&quot;); System.out.println(reader.getContent()); &#125;&#125; 1234567public class Client&#123; public static void main(String[] args)&#123; Mother mother = new Mother(); mother.narrate(new Book()); mother.narrate(new Newspaper()); &#125;&#125; 运行结果：1234妈妈开始讲故事很久很久以前有一个阿拉伯的故事……妈妈开始讲故事林书豪17+9助尼克斯击败老鹰…… 这样修改后，无论以后怎样扩展Client类，都不需要再修改Mother类了。这只是一个简单的例子，实际情况中，代表高层模块的Mother类将负责完成主要的业务逻辑，一旦需要对它进行修改，引入错误的风险极大。所以遵循依赖倒置原则可以降低类之间的耦合性，提高系统的稳定性，降低修改程序造成的风险。 采用依赖倒置原则给多人并行开发带来了极大的便利，比如上例中，原本Mother类与Book类直接耦合时，Mother类必须等Book类编码完成后才可以进行编码，因为Mother类依赖于Book类。修改后的程序则可以同时开工，互不影响，因为Mother与Book类一点关系也没有。参与协作开发的人越多、项目越庞大，采用依赖导致原则的意义就越重大。现在很流行的TDD开发模式就是依赖倒置原则最成功的应用。 传递依赖关系有三种方式，以上的例子中使用的方法是接口传递，另外还有两种传递方式：构造方法传递和setter方法传递，相信用过Spring框架的，对依赖的传递方式一定不会陌生。 在实际编程中，我们一般需要做到如下3点： 低层模块尽量都要有抽象类或接口，或者两者都有。 变量的声明类型尽量是抽象类或接口。 使用继承时遵循里氏替换原则。 依赖倒置原则的核心就是要我们面向接口编程，理解了面向接口编程，也就理解了依赖倒置。 接口隔离原则定义：客户端不应该依赖它不需要的接口；一个类对另一个类的依赖应该建立在最小的接口上。 问题由来：类A通过接口I依赖类B，类C通过接口I依赖类D，如果接口I对于类A和类C来说不是最小接口，则类B和类D必须去实现他们不需要的方法。 解决方案：将臃肿的接口I拆分为独立的几个接口，类A和类C分别与它们需要的接口建立依赖关系。也就是采用接口隔离原则。 举例来说明接口隔离原则： 这个图的意思是：类A依赖接口I中的方法1、方法2、方法3，类B是对类A依赖的实现。类C依赖接口I中的方法1、方法4、方法5，类D是对类C依赖的实现。对于类B和类D来说，虽然它们都存在着用不到的方法（也就是图中红色字体标记的方法），但由于实现了接口I，所以也必须要实现这些用不到的方法。 1234567interface I &#123; public void method1(); public void method2(); public void method3(); public void method4(); public void method5();&#125; 1234567891011class A&#123; public void depend1(I i)&#123; i.method1(); &#125; public void depend2(I i)&#123; i.method2(); &#125; public void depend3(I i)&#123; i.method3(); &#125;&#125; 123456789101112131415class B implements I&#123; public void method1() &#123; System.out.println(&quot;类B实现接口I的方法1&quot;); &#125; public void method2() &#123; System.out.println(&quot;类B实现接口I的方法2&quot;); &#125; public void method3() &#123; System.out.println(&quot;类B实现接口I的方法3&quot;); &#125; //对于类B来说，method4和method5不是必需的，但是由于接口A中有这两个方法， //所以在实现过程中即使这两个方法的方法体为空，也要将这两个没有作用的方法进行实现。 public void method4() &#123;&#125; public void method5() &#123;&#125;&#125; 1234567891011class C&#123; public void depend1(I i)&#123; i.method1(); &#125; public void depend2(I i)&#123; i.method4(); &#125; public void depend3(I i)&#123; i.method5(); &#125;&#125; 12345678910111213141516class D implements I&#123; public void method1() &#123; System.out.println(&quot;类D实现接口I的方法1&quot;); &#125; //对于类D来说，method2和method3不是必需的，但是由于接口A中有这两个方法， //所以在实现过程中即使这两个方法的方法体为空，也要将这两个没有作用的方法进行实现。 public void method2() &#123;&#125; public void method3() &#123;&#125; public void method4() &#123; System.out.println(&quot;类D实现接口I的方法4&quot;); &#125; public void method5() &#123; System.out.println(&quot;类D实现接口I的方法5&quot;); &#125;&#125; 12345678910111213public class Client&#123; public static void main(String[] args)&#123; A a = new A(); a.depend1(new B()); a.depend2(new B()); a.depend3(new B()); C c = new C(); c.depend1(new D()); c.depend2(new D()); c.depend3(new D()); &#125;&#125; 可以看到，如果接口过于臃肿，只要接口中出现的方法，不管对依赖于它的类有没有用处，实现类中都必须去实现这些方法，这显然不是好的设计。如果将这个设计修改为符合接口隔离原则，就必须对接口I进行拆分。在这里我们将原有的接口I拆分为三个接口，拆分后的设计如图2所示： 123 interface I1 &#123; public void method1();&#125; 1234interface I2 &#123; public void method2(); public void method3();&#125; 1234interface I3 &#123; public void method4(); public void method5();&#125; 1234567891011class A&#123; public void depend1(I1 i)&#123; i.method1(); &#125; public void depend2(I2 i)&#123; i.method2(); &#125; public void depend3(I2 i)&#123; i.method3(); &#125;&#125; 1234567891011class B implements I1, I2&#123; public void method1() &#123; System.out.println(&quot;类B实现接口I1的方法1&quot;); &#125; public void method2() &#123; System.out.println(&quot;类B实现接口I2的方法2&quot;); &#125; public void method3() &#123; System.out.println(&quot;类B实现接口I2的方法3&quot;); &#125;&#125; 1234567891011class C&#123; public void depend1(I1 i)&#123; i.method1(); &#125; public void depend2(I3 i)&#123; i.method4(); &#125; public void depend3(I3 i)&#123; i.method5(); &#125;&#125; 1234567891011class D implements I1, I3&#123; public void method1() &#123; System.out.println(&quot;类D实现接口I1的方法1&quot;); &#125; public void method4() &#123; System.out.println(&quot;类D实现接口I3的方法4&quot;); &#125; public void method5() &#123; System.out.println(&quot;类D实现接口I3的方法5&quot;); &#125;&#125; 接口隔离原则的含义是：建立单一接口，不要建立庞大臃肿的接口，尽量细化接口，接口中的方法尽量少。也就是说，我们要为各个类建立专用的接口，而不要试图去建立一个很庞大的接口供所有依赖它的类去调用。本文例子中，将一个庞大的接口变更为3个专用的接口所采用的就是接口隔离原则。在程序设计中，依赖几个专用的接口要比依赖一个综合的接口更灵活。接口是设计时对外部设定的“契约”，通过分散定义多个接口，可以预防外来变更的扩散，提高系统的灵活性和可维护性。 说到这里，很多人会觉的接口隔离原则跟之前的单一职责原则很相似，其实不然。其一，单一职责原则原注重的是职责；而接口隔离原则注重对接口依赖的隔离。其二，单一职责原则主要是约束类，其次才是接口和方法，它针对的是程序中的实现和细节；而接口隔离原则主要约束接口接口，主要针对抽象，针对程序整体框架的构建。 采用接口隔离原则对接口进行约束时，要注意以下几点： 接口尽量小，但是要有限度。对接口进行细化可以提高程序设计灵活性是不挣的事实，但是如果过小，则会造成接口数量过多，使设计复杂化。所以一定要适度。 为依赖接口的类定制服务，只暴露给调用的类它需要的方法，它不需要的方法则隐藏起来。只有专注地为一个模块提供定制服务，才能建立最小的依赖关系。 提高内聚，减少对外交互。使接口用最少的方法去完成最多的事情。 运用接口隔离原则，一定要适度，接口设计的过大或过小都不好。设计接口的时候，只有多花些时间去思考和筹划，才能准确地实践这一原则。 迪米特法则(最少知道原则)定义：一个对象应该对其他对象保持最少的了解。 问题由来：类与类之间的关系越密切，耦合度越大，当一个类发生改变时，对另一个类的影响也越大。 解决方案：尽量降低类与类之间的耦合。 低耦合，高内聚。无论是面向过程编程还是面向对象编程，只有使各个模块之间的耦合尽量得低，才能提高代码的复用率。低耦合的优点不言而喻，但是怎么样编程才能做到低耦合呢？那正是迪米特法则要去完成的。 一个类对自己依赖的类知道得越少越好。也就是说，对于被依赖的类来说，无论逻辑多么复杂，都尽量地将逻辑封装在类的内部，对外除了提供的public方法，不对外泄漏任何信息。迪米特法则还有一个更简单的定义：只与直接的朋友通信。首先来解释一下什么是直接的朋友：每个对象都会与其他对象有耦合关系，只要两个对象之间有耦合关系，我们就说这两个对象之间是朋友关系。耦合的方式很多，依赖、关联、组合、聚合等。其中，我们称出现成员变量、方法参数、方法返回值中的类为直接的朋友，而出现在局部变量中的类则不是直接的朋友。也就是说，陌生的类最好不要作为局部变量的形式出现在类的内部。 举一个例子：有一个集团公司，下属单位有分公司和直属部门，现在要求打印出所有下属单位的员工ID。先来看一下违反迪米特法则的设计。12345678910 //总公司员工class Employee&#123; private String id; public void setId(String id)&#123; this.id = id; &#125; public String getId()&#123; return id; &#125;&#125; 12345678910//分公司员工class SubEmployee&#123; private String id; public void setId(String id)&#123; this.id = id; &#125; public String getId()&#123; return id; &#125;&#125; 123456789101112class SubCompanyManager&#123; public List&lt;SubEmployee&gt; getAllEmployee()&#123; List&lt;SubEmployee&gt; list = new ArrayList&lt;SubEmployee&gt;(); for(int i=0; i&lt;100; i++)&#123; SubEmployee emp = new SubEmployee(); //为分公司人员按顺序分配一个ID emp.setId(&quot;分公司&quot;+i); list.add(emp); &#125; return list; &#125;&#125; 12345678910111213141516171819202122232425class CompanyManager&#123; public List&lt;Employee&gt; getAllEmployee()&#123; List&lt;Employee&gt; list = new ArrayList&lt;Employee&gt;(); for(int i=0; i&lt;30; i++)&#123; Employee emp = new Employee(); //为总公司人员按顺序分配一个ID emp.setId(&quot;总公司&quot;+i); list.add(emp); &#125; return list; &#125; public void printAllEmployee(SubCompanyManager sub)&#123; List&lt;SubEmployee&gt; list1 = sub.getAllEmployee(); for(SubEmployee e:list1)&#123; System.out.println(e.getId()); &#125; List&lt;Employee&gt; list2 = this.getAllEmployee(); for(Employee e:list2)&#123; System.out.println(e.getId()); &#125; &#125;&#125; 123456public class Client&#123; public static void main(String[] args)&#123; CompanyManager e = new CompanyManager(); e.printAllEmployee(new SubCompanyManager()); &#125;&#125; 现在这个设计的主要问题出在CompanyManager中，根据迪米特法则，只与直接的朋友发生通信，而SubEmployee类并不是CompanyManager类的直接朋友（以局部变量出现的耦合不属于直接朋友），从逻辑上讲总公司只与他的分公司耦合就行了，与分公司的员工并没有任何联系，这样设计显然是增加了不必要的耦合。按照迪米特法则，应该避免类中出现这样非直接朋友关系的耦合。修改后的代码如下:123456789101112131415161718class SubCompanyManager&#123; public List&lt;SubEmployee&gt; getAllEmployee()&#123; List&lt;SubEmployee&gt; list = new ArrayList&lt;SubEmployee&gt;(); for(int i=0; i&lt;100; i++)&#123; SubEmployee emp = new SubEmployee(); //为分公司人员按顺序分配一个ID emp.setId(&quot;分公司&quot;+i); list.add(emp); &#125; return list; &#125; public void printEmployee()&#123; List&lt;SubEmployee&gt; list = this.getAllEmployee(); for(SubEmployee e:list)&#123; System.out.println(e.getId()); &#125; &#125;&#125; 1234567891011121314151617181920class CompanyManager&#123; public List&lt;Employee&gt; getAllEmployee()&#123; List&lt;Employee&gt; list = new ArrayList&lt;Employee&gt;(); for(int i=0; i&lt;30; i++)&#123; Employee emp = new Employee(); //为总公司人员按顺序分配一个ID emp.setId(&quot;总公司&quot;+i); list.add(emp); &#125; return list; &#125; public void printAllEmployee(SubCompanyManager sub)&#123; sub.printEmployee(); List&lt;Employee&gt; list2 = this.getAllEmployee(); for(Employee e:list2)&#123; System.out.println(e.getId()); &#125; &#125;&#125; 修改后，为分公司增加了打印人员ID的方法，总公司直接调用来打印，从而避免了与分公司的员工发生耦合。 迪米特法则的初衷是降低类之间的耦合，由于每个类都减少了不必要的依赖，因此的确可以降低耦合关系。但是凡事都有度，虽然可以避免与非直接的类通信，但是要通信，必然会通过一个“中介”来发生联系，例如本例中，总公司就是通过分公司这个“中介”来与分公司的员工发生联系的。过分地使用迪米特原则，会产生大量这样的中介和传递类，导致系统复杂度变大。所以在采用迪米特法则时要反复权衡，既做到结构清晰，又要高内聚低耦合。 开闭原则定义：一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。 问题由来：在软件的生命周期内，因为变化、升级和维护等原因需要对软件原有代码进行修改时，可能会给旧代码中引入错误，也可能会使我们不得不对整个功能进行重构，并且需要原有代码经过重新测试。 解决方案：当软件需要变化时，尽量通过扩展软件实体的行为来实现变化，而不是通过修改已有的代码来实现变化。 开闭原则是面向对象设计中最基础的设计原则，它指导我们如何建立稳定灵活的系统。开闭原则可能是设计模式六项原则中定义最模糊的一个了，它只告诉我们对扩展开放，对修改关闭，可是到底如何才能做到对扩展开放，对修改关闭，并没有明确地告诉我们。以前，如果有人告诉我“你进行设计的时候一定要遵守开闭原则”，我会觉得他什么都没说，但貌似又什么都说了。因为开闭原则真得太虚了。 在仔细思考以及仔细阅读很多设计模式的文章后，终于对开闭原则有了一点认识。其实，我们遵循设计模式前面5大原则，以及使用23种设计模式的目的就是遵循开闭原则。也就是说，只要我们对前面5项原则遵守得好了，设计出的软件自然是符合开闭原则的，这个开闭原则更像是前面五项原则遵守程度的“平均得分”，前面5项原则遵守得好，平均分自然就高，说明软件设计开闭原则遵守得好；如果前面5项原则遵守得不好，则说明开闭原则遵守得不好。 其实笔者认为，开闭原则无非就是想表达这样一层意思：用抽象构建框架，用实现扩展细节。因为抽象灵活性好，适应性广，只要抽象得合理，可以基本保持软件架构的稳定。而软件中易变的细节，我们用从抽象派生的实现类来进行扩展，当软件需要发生变化时，我们只需要根据需求重新派生一个实现类来扩展就可以了。当然前提是我们的抽象要合理，要对需求的变更有前瞻性和预见性才行。 说到这里，再回想一下前面说的5项原则，恰恰是告诉我们用抽象构建框架，用实现扩展细节的注意事项而已：单一职责原则告诉我们实现类要职责单一；里氏替换原则告诉我们不要破坏继承体系；依赖倒置原则告诉我们要面向接口编程；接口隔离原则告诉我们在设计接口的时候要精简单一；迪米特法则告诉我们要降低耦合。而开闭原则是总纲，它告诉我们要对扩展开放，对修改关闭。 最后说明一下如何去遵守这六个原则。对这六个原则的遵守并不是是和否的问题，而是多和少的问题，也就是说，我们一般不会说有没有遵守，而是说遵守程度的多少。任何事都是过犹不及，设计模式的六个设计原则也是一样，制定这六个原则的目的并不是要我们刻板地遵守他们，而需要根据实际情况灵活运用。对他们的遵守程度只要在一个合理的范围内，就算是良好的设计。 图中的每一条维度各代表一项原则，我们依据对这项原则的遵守程度在维度上画一个点，则如果对这项原则遵守得合理的话，这个点应该落在红色的同心圆内部；如果遵守得差，点将会在小圆内部；如果过度遵守，点将会落在大圆外部。一个良好的设计体现在图中，应该是六个顶点都在同心圆中的六边形。 在上图中，设计1、设计2属于良好的设计，他们对六项原则的遵守程度都在合理的范围内；设计3、设计4设计虽然有些不足，但也基本可以接受；设计5则严重不足，对各项原则都没有很好的遵守；而设计6则遵守过渡了，设计5和设计6都是迫切需要重构的设计。","comments":true,"tags":[{"name":"设计原则","slug":"设计原则","permalink":"http://jishusuishouji.github.io/tags/设计原则/"}]},{"title":"Java 类的加载机制","date":"2017-04-05T23:05:01.000Z","path":"2017/04/06/java/Java_类的加载机制/","text":"类的加载类的加载:将类的.class文件的二进制数据读入到内存中，将其放在方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。 类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器在程序首次主动使用该类时才报告错误（LinkageError错误）,否则如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误 加载.class文件的方式– 从本地系统中直接加载– 通过网络下载.class文件– 从zip，jar等归档文件中加载.class文件– 从专有数据库中提取.class文件– 将Java源文件动态编译为.class文件 类的生命周期类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也成为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。 加载：查找并加载类的二进制数据加载是类加载过程的第一个阶段，在加载阶段，虚拟机需要完成以下三件事情：1、通过一个类的全限定名来获取其定义的二进制字节流。2、将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。3、在Java堆中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口。 相对于类加载的其他阶段而言，加载阶段（准确地说，是加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个java.lang.Class类的对象，这样便可以通过该对象访问方法区中的这些数据。 连接验证：确保被加载的类的正确性验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作： 文件格式验证：验证字节流是否符合Class文件格式的规范；例如：是否以0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。 元数据验证：对字节码描述的信息进行语义分析（注意：对比javac编译阶段的语义分析），以保证其描述的信息符合Java语言规范的要求；例如：这个类是否有除了java.lang.Object之外的父类。 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证：确保解析动作能正确执行。 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 准备：为类的静态变量分配内存，并将其初始化为默认值准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意：1、这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。2、这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。 假设一个类变量的定义为：public static int value = 3；那么变量value在准备阶段过后的初始值为0，而不是3，因为这时候尚未开始执行任何Java方法，而把value赋值为3的put static指令是在程序编译后，存放于类构造器&lt;clinit&gt;()方法之中的，所以把value赋值为3的动作将在初始化阶段才会执行。 这里还需要注意如下几点： · 对基本数据类型来说，对于类变量（static）和全局变量，如果不显式地对其赋值而直接使用，则系统会为其赋予默认的零值，而对于局部变量来说，在使用前必须显式地为其赋值，否则编译时不通过。· 对于同时被static和final修饰的常量，必须在声明的时候就为其显式地赋值，否则编译时不通过；而只被final修饰的常量则既可以在声明时显式地为其赋值，也可以在类初始化时显式地为其赋值，总之，在使用前必须为其显式地赋值，系统不会为其赋予默认零值。· 对于引用数据类型reference来说，如数组引用、对象引用等，如果没有对其进行显式地赋值而直接使用，系统都会为其赋予默认的零值，即null。· 如果在数组初始化时没有对数组中的各元素赋值，那么其中的元素将根据对应的数据类型而被赋予默认的零值。3、如果类字段的字段属性表中存在ConstantValue属性，即同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值。 假设上面的类变量value被定义为： public static final int value = 3； 编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为3。我们可以理解为static final常量在编译期就将其结果放入了调用它的类的常量池中 解析：把类中的符号引用转换为直接引用解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。符号引用就是一组符号来描述目标，可以是任何字面量。 直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。 初始化初始化，为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始值设定有两种方式： ①声明类变量是指定初始值 ②使用静态代码块为类变量指定初始值 JVM初始化步骤1、假如这个类还没有被加载和连接，则程序先加载并连接该类2、假如该类的直接父类还没有被初始化，则先初始化其直接父类3、假如类中有初始化语句，则系统依次执行这些初始化语句 类初始化时机：只有当对类的主动使用的时候才会导致类的初始化，类的主动使用包括以下六种：– 创建类的实例，也就是new的方式– 访问某个类或接口的静态变量，或者对该静态变量赋值– 调用类的静态方法– 反射（如Class.forName(“com.shengsiyuan.Test”)）– 初始化某个类的子类，则其父类也会被初始化– Java虚拟机启动时被标明为启动类的类（Java Test），直接使用java.exe命令来运行某个主类 结束生命周期•在如下几种情况下，Java虚拟机将结束生命周期 – 执行了System.exit()方法– 程序正常执行结束– 程序在执行过程中遇到了异常或错误而异常终止– 由于操作系统出现错误而导致Java虚拟机进程终止 类加载器12345678public class ClassLoaderTest &#123; public static void main(String[] args) &#123; ClassLoader loader = Thread.currentThread().getContextClassLoader(); System.out.println(loader); System.out.println(loader.getParent()); System.out.println(loader.getParent().getParent()); &#125;&#125; 运行后，输出结果：123sun.misc.Launcher$AppClassLoader@64fef26asun.misc.Launcher$ExtClassLoader@1ddd40f3null 从上面的结果可以看出，并没有获取到ExtClassLoader的父Loader，原因是Bootstrap Loader（引导类加载器）是用C语言实现的，找不到一个确定的返回父Loader的方式，于是就返回null。 这几种类加载器的层次关系如下图所示：注意：这里父类加载器并不是通过继承关系来实现的，而是采用组合实现的。站在Java虚拟机的角度来讲，只存在两种不同的类加载器：启动类加载器：它使用C++实现（这里仅限于Hotspot，也就是JDK1.5之后默认的虚拟机，有很多其他的虚拟机是用Java语言实现的），是虚拟机自身的一部分；所有其他的类加载器：这些类加载器都由Java语言实现，独立于虚拟机之外，并且全部继承自抽象类java.lang.ClassLoader，这些类加载器需要由启动类加载器加载到内存中之后才能去加载其他的类。 站在Java开发人员的角度来看，类加载器可以大致划分为以下三类： 启动类加载器：Bootstrap ClassLoader，负责加载存放在JDK\\jre\\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库（如rt.jar，所有的java.*开头的类均被Bootstrap ClassLoader加载）。启动类加载器是无法被Java程序直接引用的。 扩展类加载器：Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载DK\\jre\\lib\\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库（如javax.*开头的类），开发者可以直接使用扩展类加载器。 应用程序类加载器：Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 应用程序都是由这三种类加载器互相配合进行加载的，如果有必要，我们还可以加入自定义的类加载器。因为JVM自带的ClassLoader只是懂得从本地文件系统加载标准的java class文件，因此如果编写了自己的ClassLoader，便可以做到如下几点： 1）在执行非置信代码之前，自动验证数字签名。2）动态地创建符合用户特定需要的定制化构建类。3）从特定的场所取得java class，例如数据库中和网络中。 JVM类加载机制•全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入•父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类•缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效 4、类的加载类加载有三种方式： 1、命令行启动应用时候由JVM初始化加载2、通过Class.forName()方法动态加载3、通过ClassLoader.loadClass()方法动态加载 例子： 123456789101112public class loaderTest &#123; public static void main(String[] args) throws ClassNotFoundException &#123; ClassLoader loader = HelloWorld.class.getClassLoader(); System.out.println(loader); //使用ClassLoader.loadClass()来加载类，不会执行初始化块 loader.loadClass(&quot;Test2&quot;); //使用Class.forName()来加载类，默认会执行初始化块 Class.forName(&quot;Test2&quot;); //使用Class.forName()来加载类，并指定ClassLoader，初始化时不执行静态块 Class.forName(&quot;Test2&quot;, false, loader); &#125; &#125; demo类 12345public class Test2 &#123; static &#123; System.out.println(&quot;静态初始化块执行了！&quot;); &#125; &#125; 分别切换加载方式，会有不同的输出结果。 Class.forName()和ClassLoader.loadClass()区别Class.forName()：将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块；ClassLoader.loadClass()：只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容,只有在new Instance才会去执行static块。 注：Class.forName(name, initialize, loader)带参函数也可控制是否加载static块。并且只有调用了new Instance()方法采用调用构造函数，创建类的对象 。 双亲委派模型双亲委派模型的工作流程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。 双亲委派机制:1、当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。2、当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。3、如果BootStrapClassLoader加载失败（例如在$JAVA_HOME/jre/lib里未查找到该class），会使用ExtClassLoader来尝试加载；4、若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。 ClassLoader源码分析：123456789101112131415161718192021222324252627public Class&lt;?&gt; loadClass(String name)throws ClassNotFoundException &#123; return loadClass(name, false); &#125; protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve)throws ClassNotFoundException &#123; // 首先判断该类型是否已经被加载 Class c = findLoadedClass(name); if (c == null) &#123; //如果没有被加载，就委托给父类加载或者委派给启动类加载器加载 try &#123; if (parent != null) &#123; //如果存在父类加载器，就委派给父类加载器加载 c = parent.loadClass(name, false); &#125; else &#123; //如果不存在父类加载器，就检查是否是由启动类加载器加载的类，通过调用本地方法native Class findBootstrapClass(String name) c = findBootstrapClass0(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // 如果父类加载器和启动类加载器都不能完成加载任务，才调用自身的加载功能 c = findClass(name); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; 双亲委派模型意义： -系统类防止内存中出现多份同样的字节码-保证Java程序安全稳定运行 6、自定义类加载器应用是通过网络来传输Java类的字节码，为保证安全性，这些字节码经过了加密处理，这时系统类加载器就无法对其进行加载，这样则需要自定义类加载器来实现。自定义类加载器一般都是继承自ClassLoader类，从上面对loadClass方法来分析来看，我们只需要重写findClass 方法即可。下面我们通过一个示例来演示自定义类加载器的流程： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import java.io.*; public class MyClassLoader extends ClassLoader &#123; private String root; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = loadClassData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; private byte[] loadClassData(String className) &#123; String fileName = root + File.separatorChar + className.replace(&apos;.&apos;, File.separatorChar) + &quot;.class&quot;; try &#123; InputStream ins = new FileInputStream(fileName); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 1024; byte[] buffer = new byte[bufferSize]; int length = 0; while ((length = ins.read(buffer)) != -1) &#123; baos.write(buffer, 0, length); &#125; return baos.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; public String getRoot() &#123; return root; &#125; public void setRoot(String root) &#123; this.root = root; &#125; public static void main(String[] args) &#123; MyClassLoader classLoader = new MyClassLoader(); classLoader.setRoot(&quot;E:\\\\temp&quot;); Class&lt;?&gt; testClass = null; try &#123; testClass = classLoader.loadClass(&quot;com.neo.classloader.Test2&quot;); Object object = testClass.newInstance(); System.out.println(object.getClass().getClassLoader()); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 自定义类加载器的核心在于对字节码文件的获取，如果是加密的字节码则需要在该类中对文件进行解密。由于这里只是演示，我并未对class文件进行加密，因此没有解密的过程。这里有几点需要注意： 1、这里传递的文件名需要是类的全限定性名称，即com.paddx.test.classloading.Test格式的，因为 defineClass 方法是按这种格式进行处理的。 2、最好不要重写loadClass方法，因为这样容易破坏双亲委托模式。 3、这类Test 类本身可以被 AppClassLoader 类加载，因此我们不能把 com/paddx/test/classloading/Test.class 放在类路径下。否则，由于双亲委托机制的存在，会直接导致该类由AppClassLoader 加载，而不会通过我们自定义类加载器来加载。","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"}]},{"title":"启动ActiveMQ的Broker","date":"2017-04-05T22:57:20.000Z","path":"2017/04/06/activemq/启动ActiveMQ的Broker/","text":"1、直接运行安装目录的bin\\activemq.bat2、可以通过在应用程序中以编码的方式启动broker，例如：1234BrokerService broker =new BrokerService(); broker.setBrokerName(&quot;testName&quot;);//如果启动多个Broker时，必须为Broker设置一个名称 broker.addConnector(&quot;tcp://localhost:61616&quot;); broker.start(); 3、可以通过BrokerFactory来创建broker，例如：BrokerService broker =BrokerFactory.createBroker(new URI(&quot;broker:tcp://localhost:61616&quot;)); broker.start(); 4、测代码import java.net.URI; import org.apache.activemq.broker.BrokerFactory; import org.apache.activemq.broker.BrokerService; /** * 启动ActiveMQ的代理Broker */ public class RunningBroker { public static void main(String[] args){ try { codeByRunning() ; //启动Broker } catch (Exception e) { e.printStackTrace(); } } /** * 应用程序中以编码的方式启动 */ public static void codeByRunning() throws Exception{ BrokerService broker =new BrokerService(); broker.setBrokerName(&quot;testName&quot;);//如果启动多个Broker时，必须为Broker设置一个名称 broker.addConnector(&quot;tcp://localhost:61616&quot;); broker.start(); } /** * 以BrokerFactory的方式启动 */ public static void factoryByRunning()throws Exception{ BrokerService broker =BrokerFactory.createBroker(new URI(&quot;broker:tcp://localhost:61616&quot;)); broker.start(); } }","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://jishusuishouji.github.io/tags/ActiveMQ/"},{"name":"JMS","slug":"JMS","permalink":"http://jishusuishouji.github.io/tags/JMS/"}]},{"title":"ActiveMQ实现负载均衡+高可用部署方案","date":"2017-04-05T22:29:04.000Z","path":"2017/04/06/activemq/ActiveMQ实现负载均衡_高可用部署方案/","text":"一、架构和技术介绍1、简介ActiveMQ完全支持JMS1.1和J2EE 1.4规范的JMS Provider实现。 2、activemq的特性 多种语言和协议编写客户端。语言: Java, C, C++, C#, Ruby, Perl, Python,PHP。应用协议: OpenWire,Stomp REST,WS Notification,XMPP,AMQP 完全支持JMS1.1和J2EE 1.4规范 (持久化,XA消息,事务) 对Spring的支持,ActiveMQ可以很容易内嵌到使用Spring的系统里面去,而且也支持Spring2.0的特性 通过了常见J2EE服务器(如 Geronimo,JBoss 4, GlassFish,WebLogic)的测试,其中通过JCA 1.5 resourceadaptors的配置,可以让ActiveMQ可以自动地部署到任何兼容J2EE1.4商业服务器上 支持多种传送协议:in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA 支持通过JDBC和journal提供高速的消息持久化 从设计上保证了高性能的集群,客户端-服务器,点对点 支持Ajax 支持与Axis的整合 可以很容易得调用内嵌JMS provider,进行测试 3、下载和安装ActiveMQ1、下载2、安装如果是在windows系统中运行，可以直接解压apache-activemq-5.9.0-bin.zip，并运行bin目录下的activemq.bat文件，此时使用的是默认的服务端口：61616和默认的console端口：8161。 如果是在linux或unix下运行，在bin目录下执行命令：./activemq setup 3、修改ActiveMQ的服务端口和console端口A、修改服务端口：打开conf/activemq.xml文件123 &lt;transportConnectors&gt; &lt;transportConnector name=&quot;openwire&quot; uri=&quot;tcp://10.42.220.72:61618&quot;discoveryUri=&quot;multicast://default&quot;/&gt;&lt;/transportConnectors&gt; B、修改console的地址和端口:打开conf/jetty.xml文件123 &lt;bean id=&quot;jettyPort&quot;class=&quot;org.apache.activemq.web.WebConsolePort&quot;init-method=&quot;start&quot;&gt; &lt;property name=&quot;port&quot; value=&quot;8162&quot;/&gt;&lt;/bean&gt; 4、通过客户端代码试用ActiveMQ需要提前将activemq解压包中的lib目录下的相关包引入到工程中，再进行如下编码： 1、发送端的代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869importjavax.jms.Connection;importjavax.jms.ConnectionFactory;importjavax.jms.DeliveryMode;importjavax.jms.Destination;importjavax.jms.MessageProducer;importjavax.jms.Session;importjavax.jms.TextMessage;importorg.apache.activemq.ActiveMQConnection;importorg.apache.activemq.ActiveMQConnectionFactory;publicclass Sender &#123; private static finalint SEND_NUMBER = 5; publicstaticvoid main(String[] args) &#123; // ConnectionFactory：连接工厂，JMS用它创建连接 ConnectionFactory connectionFactory; // Connection：JMS客户端到JMS Provider的连接 Connection connection = null; // Session：一个发送或接收消息的线程 Session session; // Destination：消息的目的地;消息发送给谁. Destination destination; // MessageProducer：消息发送者 MessageProducer producer; TextMessage message; //构造ConnectionFactory实例对象，此处采用ActiveMq的实现jar connectionFactory = new ActiveMQConnectionFactory( ActiveMQConnection.DEFAULT_USER, ActiveMQConnection.DEFAULT_PASSWORD, &quot;failover:(tcp://10.42.220.72:61617,tcp://10.42.220.72:61618)&quot;); try &#123; //构造从工厂得到连接对象 connection =connectionFactory.createConnection(); //启动 connection.start(); //获取操作连接 session = connection.createSession(true, Session.AUTO_ACKNOWLEDGE); //获取session destination = session.createQueue(&quot;FirstQueue&quot;); //得到消息生成者【发送者】 producer =session.createProducer(destination); //设置不持久化，此处学习，实际根据项目决定 producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT); //构造消息，此处写死，项目就是参数，或者方法获取 sendMessage(session, producer); session.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (null != connection) connection.close(); &#125; catch (Throwable ignore) &#123; &#125; &#125; &#125; publicstaticvoid sendMessage(Session session,MessageProducer producer) throws Exception &#123; for (int i = 1; i &lt;=SEND_NUMBER; i++) &#123; TextMessage message = session .createTextMessage(&quot;ActiveMq发送的消息&quot; + i); //发送消息到目的地方 System.out.println(&quot;发送消息：&quot; + &quot;ActiveMq 发送的消息&quot; + i); producer.send(message); &#125; &#125;&#125; 2、接收端代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758importjavax.jms.Connection;importjavax.jms.ConnectionFactory;importjavax.jms.Destination;importjavax.jms.MessageConsumer;importjavax.jms.Session;importjavax.jms.TextMessage;importorg.apache.activemq.ActiveMQConnection;importorg.apache.activemq.ActiveMQConnectionFactory; publicclass Receive &#123; publicstaticvoid main(String[] args) &#123; // ConnectionFactory：连接工厂，JMS用它创建连接 ConnectionFactory connectionFactory; // Connection：JMS客户端到JMS Provider的连接 Connection connection = null; // Session：一个发送或接收消息的线程 Session session; // Destination：消息的目的地;消息发送给谁. Destination destination; //消费者，消息接收者 MessageConsumer consumer; connectionFactory = new ActiveMQConnectionFactory( ActiveMQConnection.DEFAULT_USER, ActiveMQConnection.DEFAULT_PASSWORD, &quot;failover:(tcp://10.42.220.72:61617,tcp://10.42.220.72:61618)&quot;); try &#123; //构造从工厂得到连接对象 connection =connectionFactory.createConnection(); //启动 connection.start(); //获取操作连接 session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //获取session destination = session.createQueue(&quot;FirstQueue&quot;); consumer =session.createConsumer(destination); while (true) &#123; //设置接收者接收消息的时间，为了便于测试，这里谁定为100s TextMessage message =(TextMessage) consumer.receive(100000); if (null != message) &#123; System.out.println(&quot;收到消息&quot; + message.getText()); &#125; else &#123; break; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (null != connection) connection.close(); &#125; catch (Throwable ignore) &#123; &#125; &#125; &#125;&#125; 3、通过监控查看消息堆栈的记录：登陆http://localhost:8162/admin/queues.jsp，默认的用户名和密码：admin/admin 二、ActiveMQ的多种部署方式单点的ActiveMQ作为企业应用无法满足高可用和集群的需求，所以ActiveMQ提供了master-slave、broker cluster等多种部署方式，但通过分析多种部署方式之后我认为需要将两种部署方式相结合才能满足我们公司分布式和高可用的需求，所以后面就重点将解如何将两种部署方式相结合。 1、Master-Slave部署方式1）shared filesystem Master-Slave部署方式主要是通过共享存储目录来实现master和slave的热备，所有的ActiveMQ应用都在不断地获取共享目录的控制权，哪个应用抢到了控制权，它就成为master。 多个共享存储目录的应用，谁先启动，谁就可以最早取得共享目录的控制权成为master，其他的应用就只能作为slave。 2）shared database Master-Slave方式与shared filesystem方式类似，只是共享的存储介质由文件系统改成了数据库而已。 3）Replicated LevelDB Store方式这种主备方式是ActiveMQ5.9以后才新增的特性，使用ZooKeeper协调选择一个node作为master。被选择的master broker node开启并接受客户端连接。其他node转入slave模式，连接master并同步他们的存储状态。slave不接受客户端连接。所有的存储操作都将被复制到连接至Master的slaves。 如果master死了，得到了最新更新的slave被允许成为master。fialed node能够重新加入到网络中并连接master进入slave mode。所有需要同步的disk的消息操作都将等待存储状态被复制到其他法定节点的操作完成才能完成。所以，如果你配置了replicas=3，那么法定大小是(3/2)+1=2. Master将会存储并更新然后等待 (2-1)=1个slave存储和更新完成，才汇报success。至于为什么是2-1，熟悉Zookeeper的应该知道，有一个node要作为观擦者存在。 当一个新的master被选中，你需要至少保障一个法定node在线以能够找到拥有最新状态的node。这个node将会成为新的master。因此，推荐运行至少3个replica nodes，以防止一个node失败了，服务中断。 2、Broker-Cluster部署方式前面的Master-Slave的方式虽然能解决多服务热备的高可用问题，但无法解决负载均衡和分布式的问题。Broker-Cluster的部署方式就可以解决负载均衡的问题。 Broker-Cluster部署方式中，各个broker通过网络互相连接，并共享queue。当broker-A上面指定的queue-A中接收到一个message处于pending状态，而此时没有consumer连接broker-A时。如果cluster中的broker-B上面有一个consumer在消费queue-A的消息，那么broker-B会先通过内部网络获取到broker-A上面的message，并通知自己的consumer来消费。 1）static Broker-Cluster部署在activemq.xml文件中静态指定Broker需要建立桥连接的其他Broker： 1、首先在Broker-A节点中添加networkConnector节点：123&lt;networkConnectors&gt; &lt;networkConnector uri=&quot;static:(tcp:// 0.0.0.0:61617)&quot;duplex=&quot;false&quot;/&gt;&lt;/networkConnectors&gt; 2、修改Broker-A节点中的服务提供端口为61616：123&lt;transportConnectors&gt; &lt;transportConnectorname=&quot;openwire&quot;uri=&quot;tcp://0.0.0.0:61616?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;&lt;/transportConnectors&gt; #####3、 在Broker-B节点中添加networkConnector节点：123&lt;networkConnectors&gt; &lt;networkConnector uri=&quot;static:(tcp:// 0.0.0.0:61616)&quot;duplex=&quot;false&quot;/&gt;&lt;/networkConnectors&gt; 4、修改Broker-A节点中的服务提供端口为61617：123&lt;transportConnectors&gt; &lt;transportConnectorname=&quot;openwire&quot;uri=&quot;tcp://0.0.0.0:61617?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;&lt;/transportConnectors&gt; 5、分别启动Broker-A和Broker-B。2）Dynamic Broker-Cluster部署在activemq.xml文件中不直接指定Broker需要建立桥连接的其他Broker，由activemq在启动后动态查找： 1、首先在Broker-A节点中添加networkConnector节点：1234567&lt;networkConnectors&gt; &lt;networkConnectoruri=&quot;multicast://default&quot; dynamicOnly=&quot;true&quot; networkTTL=&quot;3&quot; prefetchSize=&quot;1&quot; decreaseNetworkConsumerPriority=&quot;true&quot; /&gt;&lt;/networkConnectors&gt; 2、修改Broker-A节点中的服务提供端口为61616：123&lt;transportConnectors&gt; &lt;transportConnectorname=&quot;openwire&quot;uri=&quot;tcp://0.0.0.0:61616? &quot; discoveryUri=&quot;multicast://default&quot;/&gt;&lt;/transportConnectors&gt; 3、在Broker-B节点中添加networkConnector节点：1234567&lt;networkConnectors&gt; &lt;networkConnectoruri=&quot;multicast://default&quot; dynamicOnly=&quot;true&quot; networkTTL=&quot;3&quot; prefetchSize=&quot;1&quot; decreaseNetworkConsumerPriority=&quot;true&quot; /&gt;&lt;/networkConnectors&gt; 4、修改Broker-B节点中的服务提供端口为61617：123&lt;transportConnectors&gt; &lt;transportConnectorname=&quot;openwire&quot;uri=&quot;tcp://0.0.0.0:61617&quot; discoveryUri=&quot;multicast://default&quot;/&gt;&lt;/transportConnectors&gt; 5、启动Broker-A和Broker-B2、Master-Slave与Broker-Cluster相结合的部署方式可以看到Master-Slave的部署方式虽然解决了高可用的问题，但不支持负载均衡，Broker-Cluster解决了负载均衡，但当其中一个Broker突然宕掉的话，那么存在于该Broker上处于Pending状态的message将会丢失，无法达到高可用的目的。 1、部署的配置修改这里以Broker-A + Broker-B建立cluster，Broker-C作为Broker-B的slave为例： 1）首先在Broker-A节点中添加networkConnector节点：123&lt;networkConnectors&gt; &lt;networkConnector uri=&quot;masterslave:(tcp://0.0.0.0:61617,tcp:// 0.0.0.0:61618)&quot; duplex=&quot;false&quot;/&gt;&lt;/networkConnectors&gt; 2）修改Broker-A节点中的服务提供端口为61616：123&lt;transportConnectors&gt; &lt;transportConnectorname=&quot;openwire&quot;uri=&quot;tcp://0.0.0.0:61616?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;&lt;/transportConnectors&gt; 3）在Broker-B节点中添加networkConnector节点：123&lt;networkConnectors&gt; &lt;networkConnector uri=&quot;static:(tcp:// 0.0.0.0:61616)&quot;duplex=&quot;false&quot;/&gt;&lt;/networkConnectors&gt; 4）修改Broker-B节点中的服务提供端口为61617：12345&lt;transportConnectors&gt; &lt;transportConnectorname=&quot;openwire&quot;uri=&quot;tcp://0.0.0.0:61617?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;&lt;/transportConnectors&gt; 5）修改Broker-B节点中的持久化方式：123&lt;persistenceAdapter&gt; &lt;kahaDB directory=&quot;/localhost/kahadb&quot;/&gt; &lt;/persistenceAdapter&gt; 6）在Broker-C节点中添加networkConnector节点：123&lt;networkConnectors&gt; &lt;networkConnector uri=&quot;static:(tcp:// 0.0.0.0:61616)&quot;duplex=&quot;false&quot;/&gt;&lt;/networkConnectors&gt; 7）修改Broker-C节点中的服务提供端口为61618：123&lt;transportConnectors&gt; &lt;transportConnectorname=&quot;openwire&quot;uri=&quot;tcp://0.0.0.0:61618?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;&lt;/transportConnectors&gt; 8）修改Broker-C节点中的持久化方式：123&lt;persistenceAdapter&gt; &lt;kahaDB directory=&quot;/localhost/kahadb&quot;/&gt; &lt;/persistenceAdapter&gt; 9）分别启动broker-A、broker-B、broker-C，因为是broker-B先启动，所以“/localhost/kahadb”目录被lock住，broker-C将一直处于挂起状态，当人为停掉broker-B之后，broker-C将获取目录“/localhost/kahadb”的控制权，重新与broker-A组成cluster提供服务。","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://jishusuishouji.github.io/tags/ActiveMQ/"}]},{"title":"ActiveMQ理解","date":"2017-04-05T20:25:34.000Z","path":"2017/04/06/activemq/ActiveMQ理解/","text":"Running Broker直接运行bin/activemq脚本可以启动一个broker。 此外也可以通过Broker Configuration URI或Broker XBean URI对broker进行配置，以下是一些命令行参数的例子： activemq Runs a broker using the default ‘xbean:activemq.xml‘ as the broker configuration file. activemq xbean:myconfig.xml Runs a broker using the file myconfig.xml as the broker configuration file that is located in the classpath. activemq xbean:file:./conf/broker1.xml Runs a broker using the file broker1.xml as the broker configuration file that is located in the relative file path ./conf/broker1.xml activemq xbean:file:C:/ActiveMQ/conf/broker2.xml Runs a broker using the file broker2.xml as the broker configuration file that is located in the absolute file path C:/ActiveMQ/conf/broker2.xml activemq broker:(tcp://localhost:61616, tcp://localhost:5000)?useJmx=true Runs a broker with two transport connectors and JMX enabled. activemq broker:(tcp://localhost:61616, network:tcp://localhost:5000)?persistent=false Runs a broker with 1 transport connector and 1 network connector with persistence disabled. Embedded Broker可以通过在应用程序中以编码的方式启动broker，例如： 123BrokerService broker = new BrokerService(); broker.addConnector(&quot;tcp://localhost:61616&quot;); broker.start(); 如果需要启动多个broker，那么需要为broker设置一个名字。例如： 1234BrokerService broker = new BrokerService(); broker.setName(&quot;fred&quot;); broker.addConnector(&quot;tcp://localhost:61616&quot;); broker.start(); 如果希望在同一个JVM内访问这个broker，那么可以使用VM Transport，URI是：vm://brokerName。 可以通过BrokerFactory来创建broker，例如：1BrokerService broker = BrokerFactory.createBroker(new URI(someURI)); someURI的可选值如下： 类型 示例 描述 xbean: xbean:activemq.xml Searches the classpath for an XML document with the given URI (activemq.xml in this case) which will then be used as the Xml Configuration file: file:foo/bar/activemq.xml Loads the given file (in this example foo/bar/activemq.xml) as the Xml Configuration broker: broker:tcp://localhost:61616 Uses the Broker Configuration URI to configure the broker 当使用XBean的配置方式的时候，需要指定一个xml配置文件，例如：1BrokerService broker = BrokerFactory.createBroker(new URI(&quot;xbean:com/test/activemq.xml&quot;)); 使用Spring的配置方式如下：1234&lt;bean id=&quot;broker&quot; class=&quot;org.apache.activemq.xbean.BrokerFactoryBean&quot;&gt; &lt;property name=&quot;config&quot; value=&quot;classpath:org/apache/activemq/xbean/activemq.xml&quot; /&gt; &lt;property name=&quot;start&quot; value=&quot;true&quot; /&gt; &lt;/bean&gt; Monitoring BrokerJMX在使用JMX监控broker之前，首先要启用broker的JMX监控功能，例如在配置文件中设置useJmx=&quot;true&quot;，如下： 123456&lt;broker useJmx=&quot;true&quot; brokerName=&quot;broker1&gt; &lt;managementContext&gt; &lt;managementContext createConnector=&quot;true&quot;/&gt; &lt;/managementContext&gt; ... &lt;/broker&gt; 接下来运行JDK自带的jconsole。在运行了jconsole后，它会弹出对话框来选择需要连接到的agent。如果是在启动broker的主机上运行jconsole，那么ActiveMQ broker会出现在jconsole的Local标签中。如果要连接到远程的broker，那么可以在Advanced标签中指定JMX URL，以下是一个连接到本机的JMX URL：service:jmx:rmi:///jndi/rmi://localhost:1099/jmxrmi在jconsole的MBeans标签中，可以查看详细信息，也可以执行相应的operation。需要注意的是，在jconsole连接到broker的时候，并不需要输入用户名和密码，如果这存在潜在的安全问题，那么就需要为JMX Connector配置密码保护（需要使用1.5以上版本的JDK）。 首先要禁止ActiveMQ创建自己的connector，例如： 12345&lt;broker xmlns=&quot;http://activemq.org/config/1.0&quot; brokerName=&quot;localhost&quot;useJmx=&quot;true&quot;&gt; &lt;managementContext&gt; &lt;managementContext createConnector=&quot;false&quot;/&gt; &lt;/managementContext&gt; &lt;/broker&gt; 然后在ActiveMQ的conf目录下创建一个访问控制文件和密码文件，如下： 12345conf/jmx.access： # The &quot;monitorRole&quot; role has readonly access. # The &quot;controlRole&quot; role has readwrite access. monitorRole readonly controlRole readwrite 12345conf/jmx.password： # The &quot;monitorRole&quot; role has password &quot;abc123&quot;. # The &quot;controlRole&quot; role has password &quot;abcd1234&quot;. monitorRole abc123 controlRole abcd1234 然后修改ActiveMQ的bin目录下activemq的启动脚本，查找包含”SUNJMX=“的一行如下： 1REM set SUNJMX=-Dcom.sun.management.jmxremote.port=1616 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false 把它替换成 1set SUNJMX=-Dcom.sun.management.jmxremote.port=1616 -Dcom.sun.management.jmxremote.authenticate=true -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.password.file=%ACTIVEMQ_BASE%/conf/jmx.password -Dcom.sun.management.jmxremote.access.file=%ACTIVEMQ_BASE%/conf/jmx.access 最后重启ActiveMQ和jconsole，这时候需要强制login。如果在启动activemq的过程中出现以下错误，那么需要为这个文件增加访问控制。1Error: Password file read access must be restricted: D:\\apache-activemq-5.0.0\\bin\\../conf/jmx.password Web ConsoleWeb Console被集成到了ActiveMQ的二进制发布包中，因此缺省访问http://localhost:8161/admin即可访问Web Console。在配置文件中，可以通过修改nioConnector的port属性来修改Web console的缺省端口： 123456&lt;jetty xmlns=&quot;http://mortbay.com/schemas/jetty/1.0&quot;&gt; &lt;connectors&gt; &lt;nioConnector port=&quot;8161&quot; /&gt; &lt;/connectors&gt; ... &lt;/jetty&gt; 出于安全性或者可靠性的考虑，Web Console可以被部署到不同于ActiveMQ的进程中。例如把activemq-web-console.war部署到一个单独的web容器中（Tomcat，Jetty等）。在ActiveMQ5.0的二进制发布包中不包含activemq-web-console.war，因此需要下载 ActiveMQ的源码，然后进入到${activemq.base}/src/activemq-web-console目录中执行mvn instanll。如果一切正常，那么缺省会在${activemq.base}/src/activemq-web-console/target目录中生成activemq-web-console-5.0.0.war。然后将activemq-web-console-5.0.0.war拷贝到Tomcat的webapps目录中，并重命名成activemq-web-console.war。需要注意的是，要将activemq-all-5.0.0.jar拷贝到WEB-INF\\lib目录中（可能还需要拷贝jms.jar）。还要为Tomcat设置以下五个系统属性（修改catalina.bat文件）：12345set JAVA_OPTS=%JAVA_OPTS% -Dwebconsole.type=&quot;properties&quot; set JAVA_OPTS=%JAVA_OPTS% -Dwebconsole.jms.url=&quot;tcp://localhost:61616&quot; set JAVA_OPTS=%JAVA_OPTS% -Dwebconsole.jmx.url=&quot;service:jmx:rmi:///jndi/rmi://localhost:1099/jmxrmi&quot; set JAVA_OPTS=%JAVA_OPTS% -Dwebconsole.jmx.role=&quot;&quot; set JAVA_OPTS=%JAVA_OPTS% -Dwebconsole.jmx.password=&quot;&quot; 如果JMX没有配置密码保护，那么webconsole.jmx.role和webconsole.jmx.password设置成&quot;&quot;即可。如果broker被配置成了Master/Slave模式，那么可以配置成使用failover transport，例如： -Dwebconsole.jms.url=failover:(tcp://serverA:61616,tcp://serverB:61616) 顺便说一下，由于webconsole.type属性是properties，因此实际上起作用的Web Console的配置文件是WEB-INF/webconsole-properties.xml。最后启动被监控的ActiveMQ，访问http://localhost:8080 /activemq-web-console/，查看显示是否正常。 Advisory MessageActiveMQ支持Advisory Messages，它允许你通过标准的JMS消息来监控系统。目前的Advisory Messages支持：• consumers, producers and connections starting and stopping• temporary destinations being created and destroyed• messages expiring on topics and queues• brokers sending messages to destinations with no consumers.• connections starting and stopping Advisory Messages可以被想象成某种的管理通道，通过它你可以得到关于JMS provider、producers、consumers和destinations的信息。Advisory topics都使用ActiveMQ.Advisory.这个前缀，以下是目前支持的topics： Client based advisoriesAdvisory Topics DescriptionActiveMQ.Advisory.Connection Connection start &amp; stop messagesActiveMQ.Advisory.Producer.Queue Producer start &amp; stop messages on a QueueActiveMQ.Advisory.Producer.Topic Producer start &amp; stop messages on a TopicActiveMQ.Advisory.Consumer.Queue Consumer start &amp; stop messages on a QueueActiveMQ.Advisory.Consumer.Topic Consumer start &amp; stop messages on a Topic 在消费者启动/停止的Advisory Messages的消息头中有个consumerCount属性，它用来指明目前desination上活跃的consumer的数量。Destination and Message based advisoriesAdvisory Topics DescriptionActiveMQ.Advisory.Queue Queue create &amp; destroyActiveMQ.Advisory.Topic Topic create &amp; destroyActiveMQ.Advisory.TempQueue Temporary Queue create &amp; destroyActiveMQ.Advisory.TempTopic Temporary Topic create &amp; destroyActiveMQ.Advisory.Expired.Queue Expired messages on a QueueActiveMQ.Advisory.Expired.Topic Expired messages on a TopicActiveMQ.Advisory.NoConsumer.Queue No consumer is available to process messages being sent on a QueueActiveMQ.Advisory.NoConsumer.Topic No consumer is available to process messages being sent on a Topic 以上的这些destnations都可以用来作为前缀，在其后面追加其它的重要信息，例如topic、queue、clientID、 producderID和consumerID等。这令你可以利用Wildcards和Selectors来过滤Advisory Messages。例如，如果你希望订阅FOO.BAR这个queue上Consumer的start/stop的消息，那么可以订阅ActiveMQ.Advisory.Consumer.Queue.FOO.BAR；如果希望订阅所有queue上的start/stop消息，那么可以订阅ActiveMQ.Advisory.Consumer.Queue.；如果希望订阅所有queue或者topic上的start/stop消息，那么可以订阅ActiveMQ.Advisory.Consumer.。org.apache.activemq.advisory.AdvisorySupport类上有如下的helper methods，用来在程序中得到advisory destination objects。1234567AdvisorySupport.getConsumerAdvisoryTopic() AdvisorySupport.getProducerAdvisoryTopic() AdvisorySupport.getDestinationAdvisoryTopic() AdvisorySupport.getExpiredTopicMessageAdvisoryTopic() AdvisorySupport.getExpiredQueueMessageAdvisoryTopic() AdvisorySupport.getNoTopicConsumersAdvisoryTopic() AdvisorySupport.getNoQueueConsumersAdvisoryTopic() 以下是段使用Advisory Messages的程序代码：1234567891011121314Destination advisoryDestination = AdvisorySupport.getProducerAdvisoryTopic(destination) MessageConsumer consumer = session.createConsumer(advisoryDestination); consumer.setMessageListener(this); ... public void onMessage(Message msg)&#123; if (msg instanceof ActiveMQMessage)&#123; try &#123; ActiveMQMessage aMsg = (ActiveMQMessage)msg; ProducerInfo prod = (ProducerInfo) aMsg.getDataStructure(); &#125; catch (JMSException e) &#123; log.error(&quot;Failed to process message: &quot; + msg); &#125; &#125; &#125; Command Agent在介绍Command Agent前首先简要介绍一下XMPP(Jabber)协议，XMPP是一种基于XML的即时通信协议，它由Jabber软件基金会开发。在配置文件中通过增加transportConnector来支持XMPP协议：123456&lt;broker xmlns=&quot;http://activemq.org/config/1.0&quot;&gt; &lt;transportConnectors&gt; ... &lt;transportConnector name=&quot;xmpp&quot; uri=&quot;xmpp://localhost:61222&quot;/&gt; &lt;/transportConnectors&gt; &lt;/broker&gt; ActiveMQ提供了ActiveMQ messages和XMPP之间的双向桥接：• 如果客户加入了一个聊天室，那么这个聊天室的名字会被映射到一个JMS topic。• 尝试在聊天室内发送消息会导致一个JMS消息被发送到这个topic。• 呆在一个聊天室中意味着这将保持一个对相应JMS topic的订阅。因此发送到这个topic的JMS消息也会被发送到聊天室。 从4.2版本起，ActiveMQ支持Command Agent。在配置文件中，通过设置commandAgent来启用Command Agent： 123456&lt;beans&gt; &lt;broker useJmx=&quot;true&quot; xmlns=&quot;http://activemq.org/config/1.0&quot;&gt; ... &lt;/broker&gt; &lt;commandAgent xmlns=&quot;http://activemq.org/config/1.0&quot;/&gt; &lt;/beans&gt; 启用了Command Agent的broker上会有一个来自Command Agent的连接，它同时订阅topic：ActiveMQ.Agent。在你启动XMPP客户端，加入到ActiveMQ.Agent聊天室后，就可以同broker进行交谈了。通过在XMPP客户端中键入help，可以得到帮助信息。需要注意的是，ActiveMQ5.0版本有个小bug，如果broker没有采用缺省的用户名和密码，那么Command Agent便无法正常启动。Apache官方文档说，此bug已经被修正，预定在5.2.0版本上体现。修改方式如下：1&lt;commandAgent xmlns=&quot;http://activemq.org/config/1.0&quot; brokerUser=&quot;user&quot; brokerPassword=&quot;passward&quot;/&gt; Visualization pluginActiveMQ支持以broker插件的形式生成DOT文件(可以用agrviewer来查看)，以图表的方式描述connections、sessions、producers、consumers、destinations等信息。配置方式如下：1234567&lt;broker xmlns=&quot;http://activemq.org/config/1.0&quot; brokerName=&quot;localhost&quot; useJmx=&quot;true&quot;&gt; ... &lt;plugins&gt; &lt;connectionDotFilePlugin file=&quot;connection.dot&quot;/&gt; &lt;destinationDotFilePlugin file=&quot;destination.dot&quot;/&gt; &lt;/plugins&gt; &lt;/broker&gt; 需要注意的是，笔者认为ActiveMQ5.0版本的Visualization Plugin尚不稳定，存在诸多问题。例如：如果使用connectionDotFilePlugin，那么brokerName必须是localhost；如果使用destinationDotFilePlugin可能会导致ArrayStoreException。 TransportActiveMQ目前支持的transport有：VM Transport、TCP Transport、SSL Transport、Peer Transport、UDP Transport、Multicast Transport、HTTP and HTTPS Transport、Failover Transport、Fanout Transport、Discovery Transport、ZeroConf Transport等。 VM TransportVM transport允许在VM内部通信，从而避免了网络传输的开销。这时候采用的连接不是socket连接，而是直接地方法调用。 第一个创建VM连接的客户会启动一个embed VM broker，接下来所有使用相同的broker name的VM连接都会使用这个broker。当这个broker上所有的连接都关闭的时候，这个broker也会自动关闭。 1vm://brokerName?transportOptions 例如：vm://broker1?marshal=false&amp;broker.persistent=falseTransport Options的可选值如下： Option Name Default Value Description Marshal false If true, forces each command sent over the transport to be marshlled and unmarshlled using a WireFormat wireFormat default The name of the WireFormat to use wireFormat. All the properties with this prefix are used to configure the wireFormat || create | true | If the broker should be created on demand if it does not allready exist. Only supported in ActiveMQ 4.1 || broker. | All | the properties with this prefix are used to configure the broker. See Configuring Wire Formats for more information | 以下是高级配置语法：12vm:(broker:(tcp://localhost)?brokerOptions)?transportOptions vm:broker:(tcp://localhost)?brokerOptions 例如：vm:(broker:(tcp://localhost:6000)?persistent=false)?marshal=false 使用配置文件的配置语法：vm://localhost?brokerConfig=xbean:activemq.xml例如：vm:// localhost?brokerConfig=xbean:com/test/activemq.xml 使用Spring的配置：12345678&lt;bean id=&quot;broker&quot; class=&quot;org.apache.activemq.xbean.BrokerFactoryBean&quot;&gt; &lt;property name=&quot;config&quot; value=&quot;classpath:org/apache/activemq/xbean/activemq.xml&quot; /&gt; &lt;property name=&quot;start&quot; value=&quot;true&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;connectionFactory&quot; class=&quot;org.apache.activemq.ActiveMQConnectionFactory&quot; depends-on=&quot;broker&quot;&gt; &lt;property name=&quot;brokerURL&quot; value=&quot;vm://localhost&quot;/&gt; &lt;/bean&gt; 如果persistent是true，那么ActiveMQ会在当前目录下创建一个缺省值是activemq-data的目录用于持久化保存数据。需要注意的是，如果程序中启动了多个不同名字的VM broker，那么可能会有如下警告：Failed to start jmx connector: Cannot bind to URL [rmi://localhost:1099/jmxrmi]:javax.naming.NameAlreadyBoundException…可以通过在transportOptions中追加broker.useJmx=false来禁用JMX来避免这个警告。 TCP TransportTCP transport 允许客户端通过TCP socket连接到远程的broker。以下是配置语法：1tcp://hostname:port?transportOptions Transport Options的可选值如下： Option Name Default Value Description minmumWireFormatVersion 0 The minimum version wireformat that is allowed trace false Causes all commands that are sent over the transport to be logged useLocalHost true When true, it causes the local machines name to resolve to “localhost”. socketBufferSize 64 * 1024 Sets the socket buffer size in bytes soTimeout 0 sets the socket timeout in milliseconds || connectionTimeout | 30000 | A non-zero value specifies the connection timeout in milliseconds. A zero value means wait forever for the connection to be established. Negative values are ignored. || wireFormat | default | The name of the WireFormat to use wireFormat.* All the properties with this prefix are used to configure the wireFormat. See Configuring Wire Formats for more information | 例如：tcp://localhost:61616?trace=false Failover TransportFailover Transport是一种重新连接的机制，它工作于其它transport的上层，用于建立可靠的传输。它的配置语法允许制定任意多个复合的URI。Failover transport会自动选择其中的一个URI来尝试建立连接。如果没有成功，那么会选择一个其它的URI来建立一个新的连接。以下是配置语法：12failover:(uri1,...,uriN)?transportOptions failover:uri1,...,uriN Transport Options的可选值如下： Option Name Default Value Description initialReconnectDelay 10 How long to wait before the first reconnect attempt (in ms) maxReconnectDelay 30000 The maximum amount of time we ever wait between reconnect attempts (in ms) useExponentialBackOff true Should an exponential backoff be used between reconnect attempts backOffMultiplier 2 The exponent used in the exponential backoff attempts maxReconnectAttempts 0 If not 0, then this is the maximum number of reconnect attempts before an error is sent back to the client randomize true use a random algorithm to choose the URI to use for reconnect from the list provided backup false initialize and hold a second transport connection - to enable fast failover 例如：failover:(tcp://localhost:61616,tcp://remotehost:61616)?initialReconnectDelay=100 Discovery transportDiscovery transport是可靠的tranport。它使用Discovery transport来定位用来连接的URI列表。以下是配置语法：12discovery:(discoveryAgentURI)?transportOptions discovery:discoveryAgentURI Transport Options的可选值如下： Option Name Default Value Description initialReconnectDelay 10 How long to wait before the first reconnect attempt maxReconnectDelay 30000 The maximum amount of time we ever wait between reconnect attempts useExponentialBackOff true Should an exponential backoff be used btween reconnect attempts backOffMultiplier 2 The exponent used in the exponential backoff attempts maxReconnectAttempts 0 If not 0, then this is the maximum number of reconnect attempts before an error is sent back to the client 例如：discovery:(multicast://default)?initialReconnectDelay=100为了使用Discovery来发现broker，需要为broker启用discovery agent。 以下是XML配置文件中的一个例子：123456&lt;broker name=&quot;foo&quot;&gt; &lt;transportConnectors&gt; &lt;transportConnector uri=&quot;tcp://localhost:0&quot; discoveryUri=&quot;multicast://default&quot;/&gt; &lt;/transportConnectors&gt; ... &lt;/broker&gt; 在使用Failover Transport或Discovery transport等能够自动重连的transport的时候，需要注意的是：设想有两个broker，它们都启用AMQ Message Store作为持久化存储，有一个producer和一个consumer连接到某个queue。当因其中一个broker失效时而切换到另一个 broker的时候，如果失效的broker的queue中还有未被consumer消费的消息，那么这个queue里的消息仍然滞留在失效broker 的中，直到失效的broker被修复并重新切换回这个被修复的broker后，之前被保留的消息才会被consumer消费掉。如果被处理的消息有时序限制，那么应用程序就需要处理这个问题。另外也可以通过ActiveMQ集群来解决这个问题。在transport重连的时候，可以在connection上注册TransportListener来获得回调，例如：123456789101112131415(ActiveMQConnection)connection).addTransportListener(new TransportListener() &#123; public void onCommand(Object cmd) &#123; &#125; public void onException(IOException exp) &#123; &#125; public void transportInterupted() &#123; // The transport has suffered an interruption from which it hopes to recover. &#125; public void transportResumed() &#123; // The transport has resumed after an interruption. &#125; &#125;); PersistenceAMQ Message StoreAMQ Message Store是ActiveMQ5.0缺省的持久化存储。Message commands被保存到transactional journal（由rolling data logs组成）。Messages被保存到data logs中，同时被reference store进行索引以提高存取速度。Date logs由一些单独的data log文件组成，缺省的文件大小是32M，如果某个消息的大小超过了data log文件的大小，那么可以修改配置以增加data log文件的大小。如果某个data log文件中所有的消息都被成功消费了，那么这个data log文件将会被标记，以便在下一轮的清理中被删除或者归档。以下是其配置的一个例子：12345&lt;broker brokerName=&quot;broker&quot; persistent=&quot;true&quot; useShutdownHook=&quot;false&quot;&gt; &lt;persistenceAdapter&gt; &lt;amqPersistenceAdapter directory=&quot;$&#123;activemq.base&#125;/data&quot; maxFileLength=&quot;32mb&quot;/&gt; &lt;/persistenceAdapter&gt; &lt;/broker&gt; Property name Default value Comments directory activemq-data the path to the directory to use to store the message store data and log files useNIO true use NIO to write messages to the data logs syncOnWrite false sync every write to disk maxFileLength 32mb a hint to set the maximum size of the message data logs persistentIndex true use a persistent index for the message logs. If this is false, an in-memory structure is maintained maxCheckpointMessageAddSize 4kb the maximum number of messages to keep in a transaction before automatically committing cleanupInterval 30000 time (ms) before checking for a discarding/moving message data logs that are no longer used indexBinSize 1024 default number of bins used by the index. The bigger the bin size - the better the relative performance of the index indexKeySize 96 the size of the index key - the key is the message id indexPageSize 16kb the size of the index page - the bigger the page - the better the write performance of the index || directoryArchive | archive | the path to the directory to use to store discarded data logs || archiveDataLogs | false | if true data logs are moved to the archive directory instead of being deleted | Kaha PersistenceKaha Persistence 是一个专门针对消息持久化的解决方案。它对典型的消息使用模式进行了优化。在Kaha中，数据被追加到data logs中。当不再需要log文件中的数据的时候，log文件会被丢弃。以下是其配置的一个例子：12345&lt;broker brokerName=&quot;broker&quot; persistent=&quot;true&quot; useShutdownHook=&quot;false&quot;&gt; &lt;persistenceAdapter&gt; &lt;kahaPersistenceAdapter directory=&quot;activemq-data&quot; maxDataFileLength=&quot;33554432&quot;/&gt; &lt;/persistenceAdapter&gt; &lt;/broker&gt; JDBC Persistence目前支持的数据库有Apache Derby, Axion, DB2, HSQL, Informix, MaxDB, MySQL, Oracle, Postgresql, SQLServer, Sybase。如果你使用的数据库不被支持，那么可以调整StatementProvider来保证使用正确的SQL方言（flavour of SQL）。通常绝大多数数据库支持以下adaptor：• org.activemq.store.jdbc.adapter.BlobJDBCAdapter• org.activemq.store.jdbc.adapter.BytesJDBCAdapter• org.activemq.store.jdbc.adapter.DefaultJDBCAdapter• org.activemq.store.jdbc.adapter.ImageJDBCAdapter 也可以在配置文件中直接指定JDBC adaptor，例如：1&lt;jdbcPersistenceAdapter adapterClass=&quot;org.apache.activemq.store.jdbc.adapter.ImageBasedJDBCAdaptor&quot;/&gt; 以下是其配置的一个例子： &lt;persistence&gt; &lt;jdbcPersistence dataSourceRef=&quot; mysql-ds&quot;/&gt; &lt;/persistence&gt; &lt;bean id=&quot;mysql-ds&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost/activemq?relaxAutoCommit=true&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;activemq&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;activemq&quot;/&gt; &lt;property name=&quot;poolPreparedStatements&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt; 需要注意的是，如果使用MySQL，那么需要设置relaxAutoCommit标志为true。 Disable Persistence以下是其配置的一个例子： 1&lt;broker persistent=&quot;false&quot;&gt;&lt;/broker&gt; SecurityActiveMQ支持可插拔的安全机制，用以在不同的provider之间切换。 Simple Authentication PluginSimple Authentication Plugin适用于简单的认证需求，或者用于建立测试环境。它允许在XML配置文件中指定用户、用户组和密码等信息。以下是ActiveMQ配置的一个例子： 12345678910&lt;plugins&gt; ... &lt;simpleAuthenticationPlugin&gt; &lt;users&gt; &lt;authenticationUser username=&quot;system&quot; password=&quot;manager&quot; groups=&quot;users,admins&quot;/&gt; &lt;authenticationUser username=&quot;user&quot; password=&quot;password&quot; groups=&quot;users&quot;/&gt; &lt;authenticationUser username=&quot;guest&quot; password=&quot;password&quot; groups=&quot;guests&quot;/&gt; &lt;/users&gt; &lt;/simpleAuthenticationPlugin&gt; &lt;/plugins&gt; JAAS Authentication PluginJAAS Authentication Plugin依赖标准的JAAS机制来实现认证。通常情况下，你需要通过设置java.security.auth.login.config系统属性来配置login modules的配置文件。如果没有指定这个系统属性，那么JAAS Authentication Plugin会缺省使用login.config作为文件名。以下是一个login.config文件的例子：123activemq-domain &#123; org.apache.activemq.jaas.PropertiesLoginModule required debug=true org.apache.activemq.jaas.properties.user=&quot;users.properties&quot; org.apache.activemq.jaas.properties.group=&quot;groups.properties&quot;; &#125;; 这个login.config文件中设置了两个属性：org.apache.activemq.jaas.properties.user和org.apache.activemq.jaas.properties.group分别用来指向user.properties和group.properties文件。需要注意的是，PropertiesLoginModule使用本地文件的查找方式，而且查找时采用的base directory是login.config文件所在的目录。因此这个login.config说明user.properties和group.properties文件存放在跟login.config文件相同的目录里。以下是ActiveMQ配置的一个例子： &lt;plugins&gt; ... &lt;jaasAuthenticationPlugin configuration=&quot;activemq-domain&quot; /&gt; &lt;/plugins&gt; 基于以上的配置，在JAAS的LoginContext中会使用activemq-domain中配置的PropertiesLoginModule来进行登陆。ActiveMQ JAAS还支持LDAPLoginModule、CertificateLoginModule、TextFileCertificateLoginModule等login module。 Custom Authentication Implementation可以通过编码的方式为ActiveMQ增加认证功能。例如编写一个类继承自XBeanBrokerService。 123456789101112131415161718192021222324252627282930313233343536373839404142package com.yourpackage; import java.net.URI; import java.util.HashMap; import java.util.Map; import org.apache.activemq.broker.Broker; import org.apache.activemq.broker.BrokerFactory; import org.apache.activemq.broker.BrokerService; import org.apache.activemq.security.SimpleAuthenticationBroker; import org.apache.activemq.xbean.XBeanBrokerService; public class SimpleAuthBroker extends XBeanBrokerService &#123; // private String user; private String password; @SuppressWarnings(&quot;unchecked&quot;) protected Broker addInterceptors(Broker broker) throws Exception &#123; broker = super.addInterceptors(broker); Map passwords = new HashMap(); passwords.put(getUser(), getPassword()); broker = new SimpleAuthenticationBroker(broker, passwords, new HashMap()); return broker; &#125; public String getUser() &#123; return user; &#125; public void setUser(String user) &#123; this.user = user; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; &#125; 以下是ActiveMQ配置文件的一个例子： 123456789101112&lt;beans&gt; … &lt;auth:SimpleAuthBroker xmlns:auth=&quot;java://com.yourpackage&quot; xmlns=&quot;http://activemq.org/config/1.0&quot; brokerName=&quot;SimpleAuthBroker1&quot; user=&quot;user&quot; password=&quot;password&quot; useJmx=&quot;true&quot;&gt; &lt;transportConnectors&gt; &lt;transportConnector uri=&quot;tcp://localhost:61616&quot;/&gt; &lt;/transportConnectors&gt; &lt;/auth:SimpleAuthBroker&gt; … &lt;/beans&gt; 在这个配置文件中增加了一个namespace auth，用于指向之前编写的哪个类。同时为SimpleAuthBroker注入了两个属性值user和password，因此在被SimpleAuthBroker改写的addInterceptors方法里，可以使用这两个属性进行认证了。ActiveMQ提供的SimpleAuthenticationBroker类继承自BrokerFilter可以简单的看成是Broker的Adaptor），它的构造函数中的两个Map分别是userPasswords和userGroups。SimpleAuthenticationBroker在addConnection方法中使用userPasswords进行认证，同时会把userGroups的信息保存到ConnectionContext中。 Authorization Plugin可以通过Authorization Plugin为认证后的用户授权，以下ActiveMQ配置文件的一个例子：12345678910111213141516171819&lt;plugins&gt; &lt;jaasAuthenticationPlugin configuration=&quot;activemq-domain&quot;/&gt; &lt;authorizationPlugin&gt; &lt;map&gt; &lt;authorizationMap&gt; &lt;authorizationEntries&gt; &lt;authorizationEntry queue=&quot;&gt;&quot; read=&quot;admins&quot; write=&quot;admins&quot; admin=&quot;admins&quot; /&gt; &lt;authorizationEntry queue=&quot;USERS.&gt;&quot; read=&quot;users&quot; write=&quot;users&quot; admin=&quot;users&quot; /&gt; &lt;authorizationEntry queue=&quot;GUEST.&gt;&quot; read=&quot;guests&quot; write=&quot;guests,users&quot; admin=&quot;guests,users&quot; /&gt; &lt;authorizationEntry topic=&quot;&gt;&quot; read=&quot;admins&quot; write=&quot;admins&quot; admin=&quot;admins&quot; /&gt; &lt;authorizationEntry topic=&quot;USERS.&gt;&quot; read=&quot;users&quot; write=&quot;users&quot; admin=&quot;users&quot; /&gt; &lt;authorizationEntry topic=&quot;GUEST.&gt;&quot; read=&quot;guests&quot; write=&quot;guests,users&quot; admin=&quot;guests,users&quot; /&gt; &lt;authorizationEntry topic=&quot;ActiveMQ.Advisory.&gt;&quot; read=&quot;guests,users&quot; write=&quot;guests,users&quot; admin=&quot;guests,users&quot;/&gt; &lt;/authorizationEntries&gt; &lt;/authorizationMap&gt; &lt;/map&gt; &lt;/authorizationPlugin&gt; &lt;/plugins&gt; ClusteringActiveMQ从多种不同的方面提供了集群的支持。 Queue consumer clustersActiveMQ支持订阅同一个queue的consumers上的集群。如果一个consumer失效，那么所有未被确认 （unacknowledged）的消息都会被发送到这个queue上其它的consumers。如果某个consumer的处理速度比其它consumers更快，那么这个consumer就会消费更多的消息。需要注意的是，笔者发现AcitveMQ5.0版本的Queue consumer clusters存在一个bug：采用AMQ Message Store，运行一个producer，两个consumer，并采用如下的配置文件：12345678910111213&lt;beans&gt; &lt;broker xmlns=&quot;http://activemq.org/config/1.0&quot; brokerName=&quot;BugBroker1&quot; useJmx=&quot;true&quot;&gt; &lt;transportConnectors&gt; &lt;transportConnector uri=&quot;tcp://localhost:61616&quot;/&gt; &lt;/transportConnectors&gt; &lt;persistenceAdapter&gt; &lt;amqPersistenceAdapter directory=&quot;activemq-data/BugBroker1&quot; maxFileLength=&quot;32mb&quot;/&gt; &lt;/persistenceAdapter&gt; &lt;/broker&gt; &lt;/beans&gt; 那么经过一段时间后可能会报出如下错误：1ERROR [ActiveMQ Transport: tcp:///127.0.0.1:1843 - RecoveryListenerAdapter.java:58 - RecoveryListenerAdapter] Message id ID:versus-1837-1203915536609-0:2:1:1:419 could not be recovered from the data store! Apache官方文档说，此bug已经被修正，预定在5.1.0版本上体现。 Broker clusters一个常见的场景是有多个JMS broker，一个客户连接到其中一个broker。如果这个broker失效，那么客户会自动重新连接到其它的broker。在ActiveMQ中使用failover:// 协议来实现这个功能。ActiveMQ3.x版本的reliable://协议已经变更为failover://。如果某个网络上有多个brokers而且客户使用静态发现（使用Static Transport或Failover Transport）或动态发现（使用Discovery Transport），那么客户可以容易地在某个broker失效的情况下切换到其它的brokers。然而，stand alone brokers并不了解其它brokers上的consumers，也就是说如果某个broker上没有consumers，那么这个broker上的消息可能会因得不到处理而积压起来。目前的解决方案是使用Network of brokers，以便在broker之间存储转发消息。ActiveMQ在未来会有更好的特性，用来在客户端处理这个问题。从ActiveMQ1.1版本起，ActiveMQ支持networks of brokers。它支持分布式的queues和topics。一个broker会相同对待所有的订阅（subscription）：不管他们是来自本地的客户连接，还是来自远程broker，它都会递送有关的消息拷贝到每个订阅。远程broker得到这个消息拷贝后，会依次把它递送到其内部的本地连接上。有两种方式配置Network of brokers，一种是使用static transport：12345678910&lt;broker brokerName=&quot;receiver&quot; persistent=&quot;false&quot; useJmx=&quot;false&quot;&gt; &lt;transportConnectors&gt; &lt;transportConnector uri=&quot;tcp://localhost:62002&quot;/&gt; &lt;/transportConnectors&gt; &lt;networkConnectors&gt; &lt;networkConnector uri=&quot;static:( tcp://localhost:61616,tcp://remotehost:61616)&quot;/&gt; &lt;/networkConnectors&gt; … &lt;/broker&gt; 另外一种是使用multicast discovery，如下：123456789&lt;broker name=&quot;sender&quot; persistent=&quot;false&quot; useJmx=&quot;false&quot;&gt; &lt;transportConnectors&gt; &lt;transportConnector uri=&quot;tcp://localhost:0&quot; discoveryUri=&quot;multicast://default&quot;/&gt; &lt;/transportConnectors&gt; &lt;networkConnectors&gt; &lt;networkConnector uri=&quot;multicast://default&quot;/&gt; &lt;/networkConnectors&gt; ... &lt;/broker&gt; Network Connector有以下属性： Property Default Value Description name bridge name of the network - for more than one network connector between the same two brokers - use different names dynamicOnly false if true, only forward messages if a consumer is active on the connected broker decreaseNetworkConsumerPriority false decrease the priority for dispatching to a Queue consumer the further away it is (in network hops) from the producer networkTTL 1 the number of brokers in the network that messages and subscriptions can pass through conduitSubscriptions true multiple consumers subscribing to the same destination are treated as one consumer by the network excludedDestinations empty destinations matching this list won’t be forwarded across the network dynamicallyIncludedDestinations empty destinations that match this list will be forwarded across the network n.b. an empty list means all destinations not in the excluded list will be forwarded staticallyIncludedDestinations empty destinations that match will always be passed across the network - even if no consumers have ever registered an interest duplex false if true, a network connection will be used to both produce AND Consume messages. This is useful for hub and spoke scenarios when the hub is behind a firewall etc. 关于conduitSubscriptions属性，这里稍稍说明一下。设想有两个brokers，分别是brokerA和brokerB，它们之间用 forwarding bridge连接。有一个consumer连接到brokerA并订阅queue：Q.TEST。有两个consumers连接到brokerB，也是订 阅queue：Q.TEST。这三个consumers有相同的优先级。然后启动一个producer。","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://jishusuishouji.github.io/tags/ActiveMQ/"},{"name":"JMS","slug":"JMS","permalink":"http://jishusuishouji.github.io/tags/JMS/"}]},{"title":"JMS概念","date":"2017-04-05T05:45:24.000Z","path":"2017/04/05/activemq/ActiveMQ_初步入门及相关概念理解/","text":"JMS的基本构件连接工厂连接工厂是客户用来创建连接的对象，例如ActiveMQ提供的ActiveMQConnectionFactory。 连接JMS Connection封装了客户与JMS提供者之间的一个虚拟的连接。 会话JMS Session是生产和消费消息的一个单线程上下文。会话用于创建消息生产者（producer）、消息消费者（consumer）和消息（message）等。会话提供了一个事务性的上下文，在这个上下文中，一组发送和接收被组合到了一个原子操作中。 目的地目的地是客户用来指定它生产的消息的目标和它消费的消息的来源的对象。JMS1.0.2规范中定义了两种消息传递域：点对点（PTP）消息传递域和发布/订阅消息传递域。 点对点消息传递域的特点如下：• 每个消息只能有一个消费者。• 消息的生产者和消费者之间没有时间上的相关性。无论消费者在生产者发送消息的时候是否处于运行状态，它都可以提取消息。(前提是没有其他消费者消费了该消息)• 在点对点消息传递域中，目的地被称为队列（queue） 发布/订阅消息传递域的特点如下：• 每个消息可以有多个消费者。• 生产者和消费者之间有时间上的相关性。订阅一个主题的消费者只能消费自它订阅之后发布的消息。JMS规范允许客户创建持久订阅，这在一定程度上放松了时间上的相关性要求。持久订阅允许消费者消费它在未处于激活状态时发送的消息。• 在发布/订阅消息传递域中，目的地被称为主题（topic）。 消息生产者消息生产者是由会话创建的一个对象，用于把消息发送到一个目的地。 消息消费者消息消费者是由会话创建的一个对象，它用于接收发送到目的地的消息。消息的消费可以采用以下两种方法之一： • 同步消费。通过调用消费者的receive方法从目的地中显式提取消息。receive方法可以一直阻塞到消息到达。• 异步消费。客户可以为消费者注册一个消息监听器，以定义在消息到达时所采取的动作。 消息JMS消息由以下三部分组成：• 消息头。每个消息头字段都有相应的getter和setter方法。• 消息属性。如果需要除消息头字段以外的值，那么可以使用消息属性。• 消息体。JMS定义的消息类型有TextMessage、MapMessage、BytesMessage、StreamMessage和ObjectMessage。 JMS的可靠性机制确认JMS消息只有在被确认之后，才认为已经被成功地消费了。消息的成功消费通常包含三个阶段：客户接收消息、客户处理消息和消息被确认。在事务性会话中，当一个事务被提交的时候，确认自动发生。在非事务性会话中，消息何时被确认取决于创建会话时的应答模式（acknowledgement mode）。该参数有以下三个可选值：• Session.AUTO_ACKNOWLEDGE。当客户成功地从receive方法返回的时候，或者从MessageListener.onMessage方法成功返回的时候，会话自动确认客户收到的消息。• Session.CLIENT_ACKNOWLEDGE。 客户通过消息的acknowledge方法确认消息。需要注意的是，在这种模式中，确认是在会话层上进行：确认一个被消费的消息将自动确认所有已被会话消费的消息。例如，如果一个消息消费者消费了10个消息，然后确认第5个消息，那么所有10个消息都被确认。• Session.DUPS_OK_ACKNOWLEDGE。 The duplicates okay acknowledgement mode closely resembles the auto acknowledgement mode. However, rather than pass Session.AUTO_ACKNOWLEDGE, you specify Session.DUPS_OK_ACKNOWLEDGE as the acknowledgement mode of createSession()‘s second argument. With less overhead than auto mode, in duplicates okay mode, the JMS provider guarantees at-least-once message delivery. During failure recovery, certain messages are probably delivered more than once.如果JMS provider失败，那么可能会导致一些重复的消息。如果是重复的消息，那么JMS provider必须把消息头的JMSRedelivered字段设置为true。 持久性JMS 支持以下两种消息提交模式：• PERSISTENT。指示JMS provider持久保存消息，以保证消息不会因为JMS provider的失败而丢失。• NON_PERSISTENT。不要求JMS provider持久保存消息。 优先级可以使用消息优先级来指示JMS provider首先提交紧急的消息。优先级分10个级别，从0（最低）到9（最高）。如果不指定优先级，默认级别是4。需要注意的是，JMS provider并不一定保证按照优先级的顺序提交消息。 消息过期可以设置消息在一定时间后过期，默认是永不过期。 临时目的地可以通过会话上的createTemporaryQueue方法和createTemporaryTopic方法来创建临时目的地。它们的存在时间只限于创建它们的连接所保持的时间。只有创建该临时目的地的连接上的消息消费者才能够从临时目的地中提取消息。 持久订阅首先消息生产者必须使用PERSISTENT提交消息。客户可以通过会话上的createDurableSubscriber方法来创建一个持久订阅，该方法的第一个参数必须是一个topic。第二个参数是订阅的名称。JMS provider会存储发布到持久订阅对应的topic上的消息。如果最初创建持久订阅的客户或者任何其它客户使用相同的连接工厂和连接的客户ID、相同的主题和相同的订阅名再次调用会话上的createDurableSubscriber方法，那么该持久订阅就会被激活。JMS provider会向客户发送客户处于非激活状态时所发布的消息。持久订阅在某个时刻只能有一个激活的订阅者。持久订阅在创建之后会一直保留，直到应用程序调用会话上的unsubscribe方法。 本地事务在一个JMS客户端，可以使用本地事务来组合消息的发送和接收。JMS Session接口提供了commit和rollback方法。事务提交意味着生产的所有消息被发送，消费的所有消息被确认；事务回滚意味着生产的所有消息被销毁，消费的所有消息被恢复并重新提交，除非它们已经过期。 需要注意的是，如果使用请求/回复机制，即发送一个消息，同时希望在同一个事务中等待接收该消息的回复，那么程序将被挂起，因为直到事务提交，发送操作才会真正执行。所以，消息的生产和消费不能包含在同一个事务中。 JMS 规范的变迁JMS最新版本是1.1。它和1.0.2版本最大的差别是，JMS1.1通过统一消息传递域简化了消息传递。这不仅简化了JMS API，也有利于开发人员灵活选择消息传递域，同时也有助于程序的重用和维护。以下是不同消息传递域的相应接口： JMS公共 点对点域 发布/订阅域 ConnectionFactory QueueConnectionFactory TopicConnectionFactory Connection QueueConnection TopicConnection Destination Queue Topic Session QueueSession TopicSession MessageProducer QueueSender TopicPublisher MessageConsumer QueueReceiver TopicSubscriber","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"},{"name":"JMS","slug":"JMS","permalink":"http://jishusuishouji.github.io/tags/JMS/"}]},{"title":"ActiveMq性能优化","date":"2017-04-05T05:30:41.000Z","path":"2017/04/05/activemq/ActiveMq性能优化/","text":"ActiveMq是比较稳定的，吞吐速度也很快，如果出现入队列或者出队列慢问题，先检查一下自己的代码，是不是本身取到数据后处理过慢。 1. 使用spring的JmsTemplateJmsTemplate的send和convertAndSend会使用持久化mode，即使你设置了NON_PERSISTENT。这会导致入队列速度变得非常慢。 解决办法，使用下面的MyJmsTemplate代替JmsTemplate。 public class MyJmsTemplate extends JmsTemplate { private Session session; public MyJmsTemplate() { super(); } public MyJmsTemplate(ConnectionFactory connectionFactory) { super(connectionFactory); } public void doSend(MessageProducer producer, Message message) throws JMSException { if (isExplicitQosEnabled()) { producer.send(message, getDeliveryMode(), getPriority(), getTimeToLive()); } else { producer.send(message); } } public Session getSession() { return session; } public void setSession(Session session) { this.session = session; } } 2. DeliveryMode的选择，如果你入队列的数据，不考虑MQ挂掉的情况（这概率很小），使用NON_PERSISTENT会显著提高数据写入速度。3. 生产者使用事务会提高入队列性能，但是消费者如果启动了事务则会显著影响数据的消费速度。1Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); 代码中的false代表不启动事物。 4. 消费者的消息处理即onMessage方法优化:1234567891011121314151617181920212223242526272829303132public class SmsMoPool implements MessageListener &#123; private final static Logger logger = LoggerFactory.getLogger(SmsMoPool.class); private DefaultEventPubliser moEventPublisher; private final EventFactory eventFactory = new DefaultEventFactory(); private DefaultDataGather dataGather; private ExecutorService pool = Executors.newFixedThreadPool(5); @Override public void onMessage(final Message message) &#123; pool.execute(new Runnable() &#123; @Override public void run() &#123; final ObjectMessage msg = (ObjectMessage) message; Serializable obj = null; try &#123; obj = msg.getObject(); &#125; catch (JMSException e) &#123; logger.error(&quot;从消息队列获得上行信息异常&#123;&#125;&quot;, e); &#125; if (obj != null) &#123; dataGather.incrementDateCount(MasEntityConstants.TRAFFIC_SMS_MO_IN); AgentToServerReq req = (AgentToServerReq) obj; if (logger.isInfoEnabled()) &#123; logger.info(&quot;驱动--&gt;调度：&#123;&#125;&quot;, req.toXmlStr()); &#125; Event event = eventFactory.createMoEvent(req); moEventPublisher.publishEvent(event); &#125; &#125; &#125;); &#125;&#125; 这段代码使用了线程池，另一点要注意的是msg.getObject();这个方法是一个比较耗时的方法，你的代码中不应该出现多次getObject()。 5. 消费者使用预取，如何使用预取，下面以spring版本为例123&lt;bean class=&quot;org.apache.activemq.command.ActiveMQQueue&quot;&gt; &lt;constructor-arg value=&quot;data.mo?consumer.prefetchSize=100&quot;/&gt;&lt;/bean&gt; 预取数量根据具体入队列数据而定，以上设置100，是针对2000/sec入队列速度设定的。另外如果是慢消费者，这里可设置为1。 6. 检查你的MQ数据吞吐速度，保持生产和消费的平衡，不会出现大量积压。7. ActiveMQ使用TCP协议时tcpNoDelay=默认是false ，设置为true可以提高性能。还是spring版本的：123456&lt;bean id=&quot;mqPoolConnectionFactory&quot; class=&quot;org.apache.activemq.pool.PooledConnectionFactory&quot; destroy-method=&quot;stop&quot;&gt; &lt;property name=&quot;connectionFactory&quot;&gt; &lt;bean id=&quot;mqConnectionFactory&quot; class=&quot;org.apache.activemq.ActiveMQConnectionFactory&quot; p:useAsyncSend=&quot;true&quot; p:brokerURL=&quot;failover://(tcp://127.0.0.1:61616?tcpNoDelay=true)&quot;/&gt; &lt;/property&gt; &lt;/bean&gt;","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://jishusuishouji.github.io/tags/ActiveMQ/"},{"name":"JMS","slug":"JMS","permalink":"http://jishusuishouji.github.io/tags/JMS/"}]},{"title":"深入浅出JMS(一)--JMS基本概念","date":"2017-04-05T05:15:49.000Z","path":"2017/04/05/activemq/深入浅出JMS_一_--JMS基本概念/","text":"The Java Message Service (JMS) API is a messaging standard that allows application components based on the Java Platform Enterprise Edition (Java EE) to create, send, receive, and read messages. It enables distributed communication that is loosely coupled, reliable, and asynchronous. JMS（JAVA Message Service,java消息服务）API是一个消息服务的标准(规范)，允许基于JavaEE平台的应用程序组件创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠并采用异步方式。 基本概念JMS是java的消息服务，JMS的客户端之间通过JMS服务进行异步消息传输。 消息模型 Point-to-Point(P2P) Publish/Subscribe(Pub/Sub) 即点对点和发布订阅模型 P2P 消息队列（Queue） 发送者(Sender) 接收者(Receiver) 每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到它们被消费或超时。 P2P的特点每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在消息队列中)发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列；接收者在成功接收消息之后需向队列应答成功；如果你希望发送的每个消息都应该被成功处理的话，那么你需要P2P模式。 Pub/Sub 主题（Topic） 发布者（Publisher） 订阅者（Subscriber） 多个发布者将消息发送到Topic,系统将这些消息传递给多个订阅者。 Pub/Sub的特点 每个消息可以有多个消费者 发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息，而且为了消费消息，订阅者必须保持运行的状态。 为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。 如果你希望发送的消息可以不被做任何处理、或者被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用Pub/Sub模型 消息的消费在JMS中，消息的产生和消息是异步的。 同步订阅者或接收者调用receive方法来接收消息，receive方法在能够接收到消息之前（或超时之前）将一直阻塞 异步订阅者或接收者可以注册为一个消息监听器。当消息到达之后，系统自动调用监听器的onMessage方法。 JMS编程模型(1) ConnectionFactory 创建Connection对象的工厂，针对两种不同的jms消息模型，分别有QueueConnectionFactory和TopicConnectionFactory两种。可以通过JNDI来查找ConnectionFactory对象。 (2) Destination Destination的意思是消息生产者的消息发送目标或者说消息消费者的消息来源。对于消息生产者或消费者来说，它的Destination是某个队列（Queue）或某个主题（Topic）。 Destination实际上就是两种类型的对象：Queue、Topic。(3) Connection Connection表示在客户端和JMS系统之间建立的链接（对TCP/IP socket的包装）。Connection可以产生一个或多个Session。跟ConnectionFactory一样，Connection也有两种类型：QueueConnection和TopicConnection。 (4) Session Session是操作消息的接口。可以通过session创建生产者、消费者、消息等。Session提供了事务的功能。当需要使用session发送/接收多个消息时，可以将这些发送/接收动作放到一个事务中。同样，也分QueueSession和TopicSession。 (5) 消息的生产者 消息生产者由Session创建，并用于将消息发送到Destination。同样，消息生产者分两种类型：QueueSender和TopicPublisher。可以调用消息生产者的方法（send或publish方法）发送消息。 (6) 消息消费者 消息消费者由Session创建，用于接收被发送到Destination的消息。两种类型：QueueReceiver和TopicSubscriber。可分别通过session的createReceiver(Queue)或createSubscriber(Topic)来创建。当然，也可以session的creatDurableSubscriber方法来创建持久化的订阅者。 (7) MessageListener 消息监听器。如果注册了消息监听器，一旦消息到达，将自动调用监听器的onMessage方法。EJB中的MDB（Message-Driven Bean）就是一种MessageListener。 企业消息系统的好处应用程序A将Message发送到服务器上，然后应用程序B从服务器中接收A发来的消息： 提供消息灵活性 松散耦合 异步性","comments":true,"tags":[{"name":"JMS","slug":"JMS","permalink":"http://jishusuishouji.github.io/tags/JMS/"}]},{"title":"ActiveMQ入门实例","date":"2017-04-05T05:08:11.000Z","path":"2017/04/05/activemq/ActiveMQ入门实例/","text":"1.下载ActiveMQ去官方网站下载：http://activemq.apache.org/ 2.运行ActiveMQ解压缩apache-activemq-5.5.1-bin.zip，然后双击apache-activemq-5.5.1\\bin\\activemq.bat运行ActiveMQ程序。 启动ActiveMQ以后，登陆：http://localhost:8161/admin/，创建一个Queue，命名为FirstQueue。 3.创建Eclipse项目并运行创建project：ActiveMQ-5.5，并导入apache-activemq-5.5.1\\lib目录下需要用到的jar文件，项目结构如下图所示： 3.1.Sender.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package com.xuwei.activemq;import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.DeliveryMode;import javax.jms.Destination;import javax.jms.MessageProducer;import javax.jms.Session;import javax.jms.TextMessage;import org.apache.activemq.ActiveMQConnection;import org.apache.activemq.ActiveMQConnectionFactory;public class Sender &#123; private static final int SEND_NUMBER = 5; public static void main(String[] args) &#123; // ConnectionFactory ：连接工厂，JMS 用它创建连接 ConnectionFactory connectionFactory; // Connection ：JMS 客户端到JMS Provider 的连接 Connection connection = null; // Session： 一个发送或接收消息的线程 Session session; // Destination ：消息的目的地;消息发送给谁. Destination destination; // MessageProducer：消息发送者 MessageProducer producer; // TextMessage message; // 构造ConnectionFactory实例对象，此处采用ActiveMq的实现jar connectionFactory = new ActiveMQConnectionFactory( ActiveMQConnection.DEFAULT_USER, ActiveMQConnection.DEFAULT_PASSWORD, &quot;tcp://localhost:61616&quot;); try &#123; // 构造从工厂得到连接对象 connection = connectionFactory.createConnection(); // 启动 connection.start(); // 获取操作连接 session = connection.createSession(Boolean.TRUE, Session.AUTO_ACKNOWLEDGE); destination = session.createQueue(&quot;FirstQueue&quot;); // 得到消息生成者【发送者】 producer = session.createProducer(destination); // 设置不持久化，此处学习，实际根据项目决定 producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT); // 构造消息，此处写死 sendMessage(session, producer); session.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (null != connection) connection.close(); &#125; catch (Throwable ignore) &#123; &#125; &#125; &#125; public static void sendMessage(Session session, MessageProducer producer) throws Exception &#123; for (int i = 1; i &lt;= SEND_NUMBER; i++) &#123; TextMessage message = session .createTextMessage(&quot;ActiveMq 发送的消息&quot; + i); // 发送消息到目的地方 System.out.println(&quot;发送消息：&quot; + &quot;ActiveMq 发送的消息&quot; + i); producer.send(message); &#125; &#125;&#125; 3.2.Receiver.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.xuwei.activemq;import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.Destination;import javax.jms.MessageConsumer;import javax.jms.Session;import javax.jms.TextMessage;import org.apache.activemq.ActiveMQConnection;import org.apache.activemq.ActiveMQConnectionFactory;public class Receiver &#123; public static void main(String[] args) &#123; // ConnectionFactory ：连接工厂，JMS 用它创建连接 ConnectionFactory connectionFactory; // Connection ：JMS 客户端到JMS Provider 的连接 Connection connection = null; // Session： 一个发送或接收消息的线程 Session session; // Destination ：消息的目的地;消息发送给谁. Destination destination; // 消费者，消息接收者 MessageConsumer consumer; connectionFactory = new ActiveMQConnectionFactory( ActiveMQConnection.DEFAULT_USER, ActiveMQConnection.DEFAULT_PASSWORD, &quot;tcp://localhost:61616&quot;); try &#123; // 构造从工厂得到连接对象 connection = connectionFactory.createConnection(); // 启动 connection.start(); // 获取操作连接 session = connection.createSession(Boolean.FALSE, Session.AUTO_ACKNOWLEDGE); destination = session.createQueue(&quot;FirstQueue&quot;); consumer = session.createConsumer(destination); while (true) &#123; //设置接收者接收消息的时间，为了便于测试，这里谁定为100s TextMessage message = (TextMessage) consumer.receive(100000); if (null != message) &#123; System.out.println(&quot;收到消息&quot; + message.getText()); &#125; else &#123; break; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (null != connection) connection.close(); &#125; catch (Throwable ignore) &#123; &#125; &#125; &#125;&#125; 4.注意事项最后接收者跟发送者在不同的机器上测试 5.测试过程运行Receiver后没有任何信息，运行Sender以后，显示如下信息：12345发送消息：ActiveMq 发送的消息1发送消息：ActiveMq 发送的消息2发送消息：ActiveMq 发送的消息3发送消息：ActiveMq 发送的消息4发送消息：ActiveMq 发送的消息5 而Receiver现如下信息：12345收到消息ActiveMq 发送的消息1收到消息ActiveMq 发送的消息2收到消息ActiveMq 发送的消息3收到消息ActiveMq 发送的消息4收到消息ActiveMq 发送的消息5","comments":true,"tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://jishusuishouji.github.io/tags/ActiveMQ/"}]},{"title":"activemq的几种基本通信方式总结","date":"2017-04-05T03:09:12.000Z","path":"2017/04/05/activemq/activemq的几种基本通信方式总结/","text":"简介面向消息队列是一个总体比较合理的应用系统集成方案。ActiveMQ是JMS消息通信规范的一个实现。消息通信模式主要有发布-订阅、点对点。 基础流程ActiveMQ启动服务的过程: 获得JMS connection factory，通过提供特定环境的连接信息来构造factory。 利用factory构造JMS connection. 启动connection 通过connection创建JMS session. 指定JMS destination. 创建JMS producer和JMS message并提供destination. 创建JMS consumer和注册JMS message listener. 发送和接收JMS message. 关闭所有JMS资源，包括connection, session, producer, consumer等。 publish-subscribe发布订阅模式类似于订阅报纸。 例子publisherpublisher是属于发布信息的一方，它通过定义一个或者多个topic，然后给这些topic发送消息。publisher的构造函数如下： public Publisher() throws JMSException { factory = new ActiveMQConnectionFactory(brokerURL); connection = factory.createConnection(); try { connection.start(); } catch (JMSException jmse) { connection.close(); throw jmse; } session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); producer = session.createProducer(null); } 按照前面说的流程定义了基本的connectionFactory, connection,session,producer。。 接着定义一系列的topic让所有的consumer来订阅protected void setTopics(String[] stocks) throws JMSException { destinations = new Destination[stocks.length]; for(int i = 0; i &lt; stocks.length; i++) { destinations[i] = session.createTopic(&quot;STOCKS.&quot; + stocks[i]); } } 定义好topic之后要给这些指定的topic发消息：protected void sendMessage(String[] stocks) throws JMSException { for(int i = 0; i &lt; stocks.length; i++) { Message message = createStockMessage(stocks[i], session); System.out.println(&quot;Sending: &quot; + ((ActiveMQMapMessage)message).getContentMap() + &quot; on destination: &quot; + destinations[i]); producer.send(destinations[i], message); } } protected Message createStockMessage(String stock, Session session) throws JMSException { MapMessage message = session.createMapMessage(); message.setString(&quot;stock&quot;, stock); message.setDouble(&quot;price&quot;, 1.00); message.setDouble(&quot;offer&quot;, 0.01); message.setBoolean(&quot;up&quot;, true); return message; } 在sendMessage方法里遍历每个topic，然后给每个topic发送定义的Message消息。 publisher发布消息public static void main(String[] args) throws JMSException { if(args.length &lt; 1) throw new IllegalArgumentException(); // Create publisher Publisher publisher = new Publisher(); // Set topics publisher.setTopics(args); for(int i = 0; i &lt; 10; i++) { publisher.sendMessage(args); System.out.println(&quot;Publisher &apos;&quot; + i + &quot; price messages&quot;); try { Thread.sleep(1000); } catch(InterruptedException e) { e.printStackTrace(); } } // Close all resources publisher.close(); } close方法关闭资源：public void close() throws JMSException { if (connection != null) { connection.close(); } } consumer具体的步骤:1.初始化资源。 接收消息。 必要的时候关闭资源。 初始化资源放到构造函数里面：public Consumer() throws JMSException { factory = new ActiveMQConnectionFactory(brokerURL); connection = factory.createConnection(); connection.start(); session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); } 接收和处理消息的方法分为同步和异步的： 同步 MessageConsumer.receive()方法 异步 注册MessageListener，使用MessageConsumer.setMessageListener()。 public static void main(String[] args) throws JMSException { Consumer consumer = new Consumer(); for (String stock : args) { Destination destination = consumer.getSession().createTopic(&quot;STOCKS.&quot; + stock); MessageConsumer messageConsumer = consumer.getSession().createConsumer(destination); messageConsumer.setMessageListener(new Listener()); } } public Session getSession() { return session; } 这里的代码不要当真了，写得很烂 Listener负责处理接收到的消息：public class Listener implements MessageListener { public void onMessage(Message message) { try { MapMessage map = (MapMessage)message; String stock = map.getString(&quot;stock&quot;); double price = map.getDouble(&quot;price&quot;); double offer = map.getDouble(&quot;offer&quot;); boolean up = map.getBoolean(&quot;up&quot;); DecimalFormat df = new DecimalFormat( &quot;#,###,###,##0.00&quot; ); System.out.println(stock + &quot;\\t&quot; + df.format(price) + &quot;\\t&quot; + df.format(offer) + &quot;\\t&quot; + (up?&quot;up&quot;:&quot;down&quot;)); } catch (Exception e) { e.printStackTrace(); } } } 实现了MessageListener接口，里面的onMessage方法在接收到消息之后会被调用的方法。 实现pub-sub模式的步骤两者设定一个共同的topic。 在publisher端通过session创建producer，根据指定的参数创建destination，然后将消息和destination作为producer.send()方法的参数。 在consumer端也要创建类似的connection,session。通过session得到destination，再通过session.createConsumer(destination)来得到一个MessageConsumer对象。有了这个MessageConsumer就可以自行选择是直接同步的receive消息还是注册listener了。 p2p 在p2p的场景里，相互通信的双方是通过一个类似于队列的方式来进行交流。和pub-sub的区别在于一个消息会发送给订阅此topic的多个订阅者，而在p2p里queue的消息只能被一个接受者接受。 发送者public Publisher() throws JMSException { factory = new ActiveMQConnectionFactory(brokerURL); connection = factory.createConnection(); connection.start(); session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); producer = session.createProducer(null); } 发送消息：public void sendMessage() throws JMSException { for(int i = 0; i &lt; jobs.length; i++) { String job = jobs[i]; Destination destination = session.createQueue(&quot;JOBS.&quot; + job); Message message = session.createObjectMessage(i); System.out.println(&quot;Sending: id: &quot; + ((ObjectMessage)message).getObject() + &quot; on queue: &quot; + destination); producer.send(destination, message); } } 消息发送者的启动代码：public static void main(String[] args) throws JMSException { Publisher publisher = new Publisher(); for(int i = 0; i &lt; 10; i++) { publisher.sendMessage(); System.out.println(&quot;Published &quot; + i + &quot; job messages&quot;); try { Thread.sleep(1000); } catch (InterruptedException x) { e.printStackTrace(); } } publisher.close(); } 在这里发送10条消息，在每个sendMessage的方法里实际上是针对每个queue发送了10条。 接收者public Consumer() throws JMSException { factory = new ActiveMQConnectionFactory(brokerURL); connection = factory.createConnection(); connection.start(); session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); } public static void main(String[] args) throws JMSException { Consumer consumer = new Consumer(); for (String job : consumer.jobs) { Destination destination = consumer.getSession().createQueue(&quot;JOBS.&quot; + job); MessageConsumer messageConsumer = consumer.getSession().createConsumer(destination); messageConsumer.setMessageListener(new Listener(job)); } } public Session getSession() { return session; } MessageListener接口实现类import javax.jms.Message; import javax.jms.MessageListener; import javax.jms.ObjectMessage; public class Listener implements MessageListener { private String job; public Listener(String job) { this.job = job; } public void onMessage(Message message) { try { //do something here System.out.println(job + &quot; id:&quot; + ((ObjectMessage)message).getObject()); } catch (Exception e) { e.printStackTrace(); } } } 比较pub-sub和p2p模式基本的处理流程都是类似的，除了在pub-sub中要通过createTopic来设置topic，而在p2p中要通过createQueue来创建通信队列。 request-response和前面两种方式比较起来，request-response的通信方式很常见，但是不是默认提供的一种模式。在前面的两种模式中都是一方负责发送消息而另外一方负责处理。而实际中的很多应用需要双方都能给对方发送消息。请求-应答方式并不是JMS规范系统默认提供的一种通信方式，而是通过在现有通信方式的基础上稍微运用一点技巧实现的。 以下这种方式只能说是很差，并不是什么高明的做法 在JMS里面，如果要实现请求/应答的方式，可以利用JMSReplyTo和JMSCorrelationID消息头来将通信的双方关联起来。另外，QueueRequestor和TopicRequestor能够支持简单的请求/应答过程。 // client side Destination tempDest = session.createTemporaryQueue(); MessageConsumer responseConsumer = session.createConsumer(tempDest); ... // send a request.. message.setJMSReplyTo(tempDest) message.setJMSCorrelationID(myCorrelationID); producer.send(message); client端创建一个临时队列并在发送的消息里指定了发送返回消息的destination以及correlationID。那么在处理消息的server端得到这个消息后就知道该发送给谁了。Server端的大致流程如下： public void onMessage(Message request) { Message response = session.createMessage(); response.setJMSCorrelationID(request.getJMSCorrelationID()) producer.send(request.getJMSReplyTo(), response) } 这里是在server端注册MessageListener，通过设置返回信息的CorrelationID和JMSReplyTo将信息返回。 Client:public Client() { ActiveMQConnectionFactory connectionFactory = new ActiveMQConnectionFactory(&quot;tcp://localhost:61616&quot;); Connection connection; try { connection = connectionFactory.createConnection(); connection.start(); Session session = connection.createSession(transacted, ackMode); Destination adminQueue = session.createQueue(clientQueueName); //Setup a message producer to send message to the queue the server is consuming from this.producer = session.createProducer(adminQueue); this.producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT); //Create a temporary queue that this client will listen for responses on then create a consumer //that consumes message from this temporary queue...for a real application a client should reuse //the same temp queue for each message to the server...one temp queue per client Destination tempDest = session.createTemporaryQueue(); MessageConsumer responseConsumer = session.createConsumer(tempDest); //This class will handle the messages to the temp queue as well responseConsumer.setMessageListener(this); //Now create the actual message you want to send TextMessage txtMessage = session.createTextMessage(); txtMessage.setText(&quot;MyProtocolMessage&quot;); //Set the reply to field to the temp queue you created above, this is the queue the server //will respond to txtMessage.setJMSReplyTo(tempDest); //Set a correlation ID so when you get a response you know which sent message the response is for //If there is never more than one outstanding message to the server then the //same correlation ID can be used for all the messages...if there is more than one outstanding //message to the server you would presumably want to associate the correlation ID with this //message somehow...a Map works good String correlationId = this.createRandomString(); txtMessage.setJMSCorrelationID(correlationId); this.producer.send(txtMessage); } catch (JMSException e) { //Handle the exception appropriately } } 这里的代码除了初始化构造函数里的参数还同时设置了两个destination，一个是自己要发送消息出去的destination，在session.createProducer(adminQueue);这一句设置。另外一个是自己要接收的消息destination, 通过Destination tempDest = session.createTemporaryQueue(); responseConsumer = session.createConsumer(tempDest); 这两句指定了要接收消息的目的地。这里是用的一个临时队列。在前面指定了返回消息的通信队列之后，需要通知server端知道发送返回消息给哪个队列。于是txtMessage.setJMSReplyTo(tempDest);指定了这一部分，同时txtMessage.setJMSCorrelationID(correlationId);方法主要是为了保证每次发送回来请求的server端能够知道对应的是哪个请求。这里一个请求和一个应答是相当于对应一个相同的序列号一样。 同时，因为client端在发送消息之后还要接收server端返回的消息，所以它也要实现一个消息receiver的功能。这里采用实现MessageListener接口的方式： public void onMessage(Message message) { String messageText = null; try { if (message instanceof TextMessage) { TextMessage textMessage = (TextMessage) message; messageText = textMessage.getText(); System.out.println(&quot;messageText = &quot; + messageText); } } catch (JMSException e) { //Handle the exception appropriately } } Server:这里server端要执行的过程和client端相反，它是先接收消息，在接收到消息后根据提供的JMSCorelationID来发送返回的消息： public void onMessage(Message message) { try { TextMessage response = this.session.createTextMessage(); if (message instanceof TextMessage) { TextMessage txtMsg = (TextMessage) message; String messageText = txtMsg.getText(); response.setText(this.messageProtocol.handleProtocolMessage(messageText)); } //Set the correlation ID from the received message to be the correlation id of the response message //this lets the client identify which message this is a response to if it has more than //one outstanding message to the server response.setJMSCorrelationID(message.getJMSCorrelationID()); //Send the response to the Destination specified by the JMSReplyTo field of the received message, //this is presumably a temporary queue created by the client this.replyProducer.send(message.getJMSReplyTo(), response); } catch (JMSException e) { //Handle the exception appropriately } } 前面，在replyProducer.send()方法里，message.getJMSReplyTo()就得到了要发送消息回去的destination。另外，设置这些发送返回信息的replyProducer的信息主要在构造函数相关的方法里实现了： public Server() { try { //This message broker is embedded BrokerService broker = new BrokerService(); broker.setPersistent(false); broker.setUseJmx(false); broker.addConnector(messageBrokerUrl); broker.start(); } catch (Exception e) { //Handle the exception appropriately } //Delegating the handling of messages to another class, instantiate it before setting up JMS so it //is ready to handle messages this.messageProtocol = new MessageProtocol(); this.setupMessageQueueConsumer(); } private void setupMessageQueueConsumer() { ActiveMQConnectionFactory connectionFactory = new ActiveMQConnectionFactory(messageBrokerUrl); Connection connection; try { connection = connectionFactory.createConnection(); connection.start(); this.session = connection.createSession(this.transacted, ackMode); Destination adminQueue = this.session.createQueue(messageQueueName); //Setup a message producer to respond to messages from clients, we will get the destination //to send to from the JMSReplyTo header field from a Message this.replyProducer = this.session.createProducer(null); this.replyProducer.setDeliveryMode(DeliveryMode.NON_PERSISTENT); //Set up a consumer to consume messages off of the admin queue MessageConsumer consumer = this.session.createConsumer(adminQueue); consumer.setMessageListener(this); } catch (JMSException e) { //Handle the exception appropriately } } 对于请求/应答的方式来说，这种典型交互的过程就是Client端在设定正常发送请求的Queue同时也设定一个临时的Queue。同时在要发送的message里头指定要返回消息的destination以及CorelationID，这些就好比是一封信里面所带的回执。根据这个信息人家才知道怎么给你回信。对于Server端来说则要额外创建一个producer，在处理接收到消息的方法里再利用producer将消息发回去。这一系列的过程看起来很像http协议里面请求-应答的方式，都是一问一答。 一些应用和改进回顾前面三种基本的通信方式，发现它们都存在着一定的共同点，比如说都要初始化ConnectionFactory, Connection, Session等。在使用完之后都要将这些资源关闭。如果每一个实现它的通信端都这么写一通的话，其实是一种简单的重复。从工程的角度来看是完全没有必要的。 解决方法通过工厂方法封装这些对象的创建和销毁，然后简单的通过调用工厂方法的方式得到它们。既然基本的流程都是在开头创建资源在结尾销毁，也可以采用Template Method模式的思路。通过继承一个抽象类，在抽象类里提供了资源的封装。所有继承的类只要实现怎么去使用这些资源的方法就可以了。","comments":true,"tags":[{"name":"activeMQ","slug":"activeMQ","permalink":"http://jishusuishouji.github.io/tags/activeMQ/"}]},{"title":"基于ZooKeeper和Thrift构建动态RPC调用","date":"2017-04-03T10:49:07.000Z","path":"2017/04/03/thrift/基于ZooKeeper和Thrift构建动态RPC调用/","text":"一、基本功能实现服务端向ZooKeeper集群注册自己提供的服务，并且把自己的IP地址和服务端口创建到具体的服务目录下。客户端向ZooKeeper集群监听自己关注的RPC服务（例如：sayHello和天气服务）， 监听服务目录下的IP地址列表变化。若要在自己的项目中使用，可以采用阿里的Dubbo分布式服务框架。在WEB端展示可以访问的RPC服务，WEB端可以通过RPC客户端向指定IP地址的RPC服务器发出调用RPC服务，RPC服务端向客户端反馈提供的服务内容，WEB客户端展示内容。只是展示动态RPC基本原理，真正的调用一般都不是web端触发的，应该是RPC的客户端根据监听到的多个IP服务提供者，根据每个IP的负载情况，动态选择最优可用的RPC服务端并且调用服务。 我们提供2个基本RPC服务，网络及应用部署如图: 二、ZooKeeper介绍ZooKeeper是一个开放源代码的分布式应用程序协调服务，由知名互联网公司雅虎创建，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。它是一个为分布式应用提供一致性服务的软件，以下是ZooKeeper典型的应用场景 数据发布和订阅：就是发布者将数据发布到ZooKeeper的一个或一系列节点上，供订阅者进行数据订阅，进而达到动态获取数据的目的，实现配置信息的集中管理和数据的动态更新。 负载均衡：用来对多个计算机、网络连接、CPU、磁盘驱动或其他资源进分配负载，已达到优化资源使用、最大化吞吐率、最下化响应和避免过载。 命名服务：命名服务是分布式系统最基本的公共服务之一。在分布式系统中，被命名的实体通常可以就是集群中的机器、提供的服务地址或远程对象等–这些我们都可以统称它们的名称（Name），其中较常见的就是一些分布式服务框架（如RPC、RMI）中的服务地址列表，通过使用命名服务，客户端应用能够指定名字来获取资源的实体、服务地址和提供者的信息。 集群管理：随着分布式系统规模的日益扩大，集群中的机器规模也随之变大、因此集群监控与集群控制就变得很重要。 分布式锁：分布式锁就是控制分布式系统之间同步访问共享资源的一种方式。在分布式系统中，常常需要协调他们的动作。如果不同的系统或是同一个系统的不同主机之间共享了一个或一组资源，那么访问这些资源的时候，往往需要互斥来防止彼此干扰来保证一致性，在这种情况下，便需要使用到分布式锁。 分布式队列：利用Zookeeper的功能我们也可以实现类似于ActiveMQ、Kafka和HornetQ等的消息中间件。 三、构建ZooKeeper集群机及RPC服务机在Ubuntu桌面系统下完成，利用Oracle下的虚拟机软件VirtualBox。虚拟出了５个Ubuntu 操作系统，３个ZooKeeper机，分别是ZooKeeper-1,ZooKeeper-2,ZooKeeper-3个构建出一个ZooKeeper集群。２个RPC服务机，把在宿主机编写好的程序，通过打包的方式，发布到RPC服务机的jetty下，提供RPC服务 。 四、配置ZooKeeper从官方网站下载后，解压到了虚拟机的/work/目录下，将/work/zookeeper-3.4.8/conf/目录下的zoo_sample.cfg重新复制一份命名为zoo.cfg,打开zoo.cfg文件。 修改配置文件：123456tickTime=2000 ddataDir=/work/data/zookeeper clientPort=2181 Server.1=192.168.0.3:2888:3888Server.2=192.168.0.4:2888:3888Server.3=192.168.0.5:2888:3888 参数说明:tickTime: zookeeper中使用的基本时间单位, 毫秒值.dataDir: 数据和日志的目录. 可以是任意目录.此处我们配置到了/work/data/zookeeper目录下clientPort: 监听client连接的端口号.Server.X=HOST/IP:port:port Server.X ：X是我们配置zookeeper集群服务每台机子的编号，需要在每台机子的/work/data/zookeeper/下创建myid文件，内容就是机子的编号。 五、启动、关闭切换到/work/zookeeper-3.4.8/bin目录下 1. 启动1234./zkServer.sh startZooKeeper JMX enabled by defaultUsing config: /work/zookeeper-3.4.8/bin/../conf/zoo.cfgStarting zookeeper ... STARTED 2.验证12./zkCli.sh[zk: localhost:2181(CONNECTED) 0] 进入ZooKeeper 客户端终端命令就说明ZooKeeper启动成功了。 3. 关闭12345./zkServer.sh stopZooKeeper JMX enabled by defaultUsing config: /work/tool/zookeeper-3.4.8/bin/../conf/zoo.cfgStopping zookeeper ... STOPPED 六、利用Thrift提供RPC服务定义Weather.thrift文件1234namespace java com.rpc.weather service weather&#123; string getWeather(1:string city) &#125; 生成JAVA文件接口在windows环境下使用Thrift工具编译.thrift文件，就会生成相应的.java 文件。该文件包含了在.thrift文件中描述的服务类的接口定义，即.Iface接口，以及服务调用的底层通信细节。命令如下: 1thrift.exe -r -gen java weather.thrift 该命令会自动生产相应的JAVA文件 gen-java目录就是生成好代码的地方 实现RPC接口功能weather的接口实现比较复杂，在这里我们用简单些Hello来说明，道理是一样的。Hello接口的实现： hello只是一个简单的反馈功能，它把客户端传递过来的参数经过简单的组合一起反馈给ＲＰＣ的客户端，本例只是简单展示了一下ＲＰＣ服务处理能力，实现上面已经生产好的Hello.Iface 接口。代码如下：public class HelloServiceImpl implements com.rpc.sayhello.Hello.Iface { public String helloString(String para) throws TException { System.out.println(“helloString be calling”); return “你好:” + para + “,欢迎来到”+GetIP.IP()+”服务器!”; }}123456123456 七、RPC服务注册我们在ZooKeeper注册了2个服务（2个ZNode节点），分别是sayHello及Weather。用2个IP提供RPC的服务。目录结构如图-：这里写图片描述在Zookeeper的每个节点，都可以分为持久节点和临时节点 持久节点是指一旦这个节点被创建了，除非主动进行删除操作，否则这个节点将一直保存在ＺooKeeper中.而临时节点就不一样了，它的生命周期和客户端回话绑定，一旦客户端回话失效，那么这个客户端创建的所有临时节点都会被移除。ZooKeeper主要是利用了“心跳检测”功能，它会定时向各个服务提供者发送一个请求，如果长期没有响应，服务中心就认为该服务提供者已经“挂了”，并将其剔除。注意临时节点下不可以在创建任何节点。 注册天气服务的主要代码： private void createServerHost() { Stat stat = zookeeper.exists(WeatherConstants.RPCNAME + “/“ + GetIP.IP() + “:” + WeatherConstants.WeahterPort,false);//检查节点是否存在 if (stat == null) { // 这里是临时的节点，会因服务器的宕机、网络失效而消失 path = zookeeper.create(WeatherConstants.RPCNAME + “/“ + GetIP.IP() + “:” + WeatherConstants.WeahterPort, “”.getBytes(),Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);//创建节点 } }12345671234567 八、RPC客戶端服务监听Watcher(事件监听器)，是ZooKeeper的一个很重要的特性。ZooKeeper允许用户在指定的节点上注册一些Watcher，并且在一些特定的事件触发的时候，ZooKeeper服务器会将事件通知到感兴趣的客户端。利用Watcher监听2个服务节点下的IP变化，一旦我们监听的服务下的节点有变化（增加或减少）ZooKeeper就会向我们注册的监听类发送“NodeChildrenChanged”事件，我们就可以在此时更新地址列表变化，从而进行更新。需要注意的是ZooKeeper服务器在向客户端发送Watcher的通知的时候，仅仅只会发出一个通知，而不会把节点的变化情况发送给客户端，客户端需要自己重新获取。另外，由于Watcher通知是一次性的，一旦触发一次通知后，该Watcher就失效了，因此客户端需要反复注册Watcher。 监听服务列表的变化在监听WatchWeather类内我们定义了一个weatherlist的数组列表，用来存储提供天气的所有ＲＰＣ服务的地址和端口。通过zookeeper.getChildren获取在zookeeper注册的所有提供天气的ＩＰ地址。并且注册了在这个节点下的监听类。 weatherlist = zookeeper.getChildren(WeatherConstants.RPCNAME, this); //在监听的WatchWeather实现Watcher接口的process方法： public void process(WatchedEvent event) { if (EventType.NodeChildrenChanged == event.getType()) { weatherlist = zookeeper.getChildren(WeatherConstants.RPCNAME, this); } } 1234567812345678只要我们监听的节点下有变动就会接受到NodeChildrenChanged 事件，在这里我们再次获取了节点下的最新ＩＰ地址列表，并且重新注册了监听类。 九、调用RPC服务public class CallWeatherRPC { public String callWeather(String ip, int port, String city) { String retString = null; TTransport transport = new TSocket(ip, port); transport.open(); TProtocol protocol = new TBinaryProtocol(transport); weather.Client client = new weather.Client(protocol);//weather为定义接口实现的文件 retString = client.getWeather(city);//调用ＲＰＣ服务 transport.close(); return retString; }}123456789101112123456789101112此处是使用了Thrift的客户端调用RPC服务端的相应程序，主要特点是IP地址不固定，可以有多地址可以调用。","comments":true,"tags":[{"name":"Thrift","slug":"Thrift","permalink":"http://jishusuishouji.github.io/tags/Thrift/"},{"name":"RPC","slug":"RPC","permalink":"http://jishusuishouji.github.io/tags/RPC/"},{"name":"ZoopKeeper","slug":"ZoopKeeper","permalink":"http://jishusuishouji.github.io/tags/ZoopKeeper/"}]},{"title":"Apache Thrift学习之一（入门及Java实例演示）","date":"2017-04-03T09:58:39.000Z","path":"2017/04/03/thrift/Apache_Thrift学习之一（入门及Java实例演示）/","text":"一、概述Apache Thrift是Facebook实现的一种高效的、支持多种编程语言的远程服务调用的框架。Thrift是由Facebook开发的，并在2008年捐给了Apache基金会，成为了一个孵化器项目。 Thrift是一个软件框架，用来进行可扩展且跨语言的服务开发。它结合了功能强大的软件堆栈和代码生成引擎， Thrift是一个驱动层接口，它提供了用于客户端使用多种语言实现的API。Thrift是个代码生成库，支持的客户端语言包括C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, and OCaml 。它的目标是为了各种流行的语言提供便利的RPC调用机制，而不需要使用那些开销巨大的方式，比如SOAP。 要使用Thrift，就要使用一个语言中立的服务定义文件，描述数据类型和服务接口。这个文件会被用作引擎的输入，编译器为每种支持的语言生成代码。这种静态生成的设计让它非常容易被开发者所使用，而且因为类型验证都发生在编译期而非运行期，所以代码可以很有效率地运行。 Thrift的设计提供了以下这些特性：1、语言无关的类型因为类型是使用定义文件按照语言中立的方式规定的，所以它们可以被不同的语言分享。比如，C++的结构可以和Python的字典类型相互交换数据。2、通用传输接口不论你使用的是磁盘文件、内存数据还是socket流，都可以使用同一段应用代码。3、协议无关Thrift会对数据类型进行编码和解码，可以跨协议使用。4、支持版本数据类型可以加入版本信息，来支持客户端API的更新。 二、下载配置1）安装thrift：到thrift官网下载exe文件，然后将文件重命名为thrift.exe,拷贝到D:\\EBOOK\\thrift目录下(或者任何目录下)，然后就可以在dos环境下使用了1D:\\EBOOK\\thrift&gt;thrift -gen java D:\\work\\workspace\\thriftworkspace\\demo1\\demoHello.thrift 输出的java文件默认输出到当前目录下D:\\EBOOK\\thrift\\gen-java，也可以使用-o参数指定输出路径; 2）下载相关依赖包2.1）libthrift.jar ，下载地址：http://repo1.maven.org/maven2/org/apache/thrift/libthrift/0.9.0/2.2）slf4j-api.jar2.3）slf4j-simple.jar到官网http://thrift.apache.org/download 下载最新版本，截止今日（2016-05-23）最新版本为0.9.3 3) Maven项目设置依赖包如果是Maven构建项目的，直接在pom.xml中添加如下内容：12345&lt;dependency&gt; &lt;groupId&gt;org.apache.thrift&lt;/groupId&gt; &lt;artifactId&gt;libthrift&lt;/artifactId&gt; &lt;version&gt;0.8.0&lt;/version&gt;&lt;/dependency&gt; 4).手动编译如果自己编译lib包，把下载的压缩包解压到X盘，然后在X:\\thrift-0.8.0\\lib\\java 目录下运行ant进行自动编译，会在X:\\thrift-0.8.0\\lib\\java\\build\\ 目录下看到编译好的lib包：libthrift-0.8.0.jar 三、基本概念1.数据类型基本类型：bool：布尔值，true或false，对应Java的booleanbyte：8位有符号整数，对应Java的bytei16：16位有符号整数，对应Java的shorti32：32位有符号整数，对应Java的inti64：64位有符号整数，对应Java的longdouble：64 位浮点数，对应Java的doublestring：utf-8编码的字符串，对应Java的String 结构体类型：struct：定义公共的对象，类似于C语言中的结构体定义，在Java中是一个JavaBean 容器类型：list：对应Java的ArrayListset：对应Java的HashSetmap：对应Java的HashMap 异常类型：exception：对应Java的Exception 服务类型：service：对应服务的类 2.服务端编码基本步骤： 实现服务处理接口impl 创建TProcessor(业务处理器) 创建TServerTransport() 创建TProtocol(传输协议) 创建TServer 启动Server 3.客户端编码基本步骤： 创建Transport 创建TProtocol 基于TTransport和TProtocol创建Client 调用Client的相应方法 4.数据传输协议TBinaryProtocol: 二进制格式.TCompactProtocol: 压缩格式TJSONProtocol: JSON格式TSimpleJSONProtocol: 提供JSON只写协议, 生成的文件很容易通过脚本语言解析 客户端和服务端的协议要一致 ##四、实例演示 1. thrift生成代码创建Thrift文件：D:\\work\\workspace\\thriftworkspace\\demo1\\demoHello.thrift ,内容如下：12345namespace java com.dxz.thrift.demo service HelloWorldService &#123; string sayHello(1:string username)&#125; thrift-0.8.0.exe是官网提供的windows下编译工具，运用这个工具生成相关代码：1D:\\EBOOK\\thrift&gt;thrift-0.9.3.exe -r -gen java D:\\work\\workspace\\thriftworkspace\\demo1\\demoHello.thrift 将生成的HelloWorldService.java文件copy到自己测试的工程中，我的工程是用maven构建的，故在pom.xml中增加如下内容：12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.thrift&lt;/groupId&gt; &lt;artifactId&gt;libthrift&lt;/artifactId&gt; &lt;version&gt;0.8.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.5.8&lt;/version&gt;&lt;/dependency&gt; 如果是ant构建的工程，将libthrift-0.9.3.jar加入到工程中 2. 实现接口Ifacejava代码：HelloWorldImpl.java 12345678910package com.dxz.thrift.demo;import org.apache.thrift.TException;public class HelloWorldImpl implements HelloWorldService.Iface &#123; public HelloWorldImpl() &#123; &#125; @Override public String sayHello(String username) throws TException &#123; return &quot;Hi,&quot; + username + &quot; welcome to thrift world&quot;; &#125;&#125; 3.TSimpleServer服务端简单的单线程服务模型，一般用于测试。编写服务端server代码：HelloServerDemo.java1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.dxz.thrift.demo;import org.apache.thrift.TProcessor;import org.apache.thrift.protocol.TBinaryProtocol;import org.apache.thrift.protocol.TCompactProtocol;import org.apache.thrift.protocol.TJSONProtocol;import org.apache.thrift.protocol.TSimpleJSONProtocol;import org.apache.thrift.server.TServer;import org.apache.thrift.server.TSimpleServer;import org.apache.thrift.transport.TServerSocket;public class HelloServerDemo &#123; public static final int SERVER_PORT = 8090; public void startServer() &#123; try &#123; System.out.println(&quot;HelloWorld TSimpleServer start ....&quot;); TProcessor tprocessor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldImpl()); //HelloWorldService.Processor&lt;HelloWorldService.Iface&gt; tprocessor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldImpl()); // 简单的单线程服务模型，一般用于测试 TServerSocket serverTransport = new TServerSocket(SERVER_PORT); TServer.Args tArgs = new TServer.Args(serverTransport); tArgs.processor(tprocessor); tArgs.protocolFactory(new TBinaryProtocol.Factory()); // tArgs.protocolFactory(new TCompactProtocol.Factory()); // tArgs.protocolFactory(new TJSONProtocol.Factory()); TServer server = new TSimpleServer(tArgs); server.serve(); &#125; catch (Exception e) &#123; System.out.println(&quot;Server start error!!!&quot;); e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; HelloServerDemo server = new HelloServerDemo(); server.startServer(); &#125;&#125; 编写客户端Client代码：HelloClientDemo.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.dxz.thrift.demo;import org.apache.thrift.TException;import org.apache.thrift.protocol.TBinaryProtocol;import org.apache.thrift.protocol.TCompactProtocol;import org.apache.thrift.protocol.TJSONProtocol;import org.apache.thrift.protocol.TProtocol;import org.apache.thrift.transport.TSocket;import org.apache.thrift.transport.TTransport;import org.apache.thrift.transport.TTransportException;public class HelloClientDemo &#123; public static final String SERVER_IP = &quot;localhost&quot;; public static final int SERVER_PORT = 8090; public static final int TIMEOUT = 30000; public void startClient(String userName) &#123; TTransport transport = null; try &#123; transport = new TSocket(SERVER_IP, SERVER_PORT, TIMEOUT); // 协议要和服务端一致 TProtocol protocol = new TBinaryProtocol(transport); // TProtocol protocol = new TCompactProtocol(transport); // TProtocol protocol = new TJSONProtocol(transport); HelloWorldService.Client client = new HelloWorldService.Client(protocol); transport.open(); String result = client.sayHello(userName); System.out.println(&quot;Thrify client result =: &quot; + result); &#125; catch (TTransportException e) &#123; e.printStackTrace(); &#125; catch (TException e) &#123; e.printStackTrace(); &#125; finally &#123; if (null != transport) &#123; transport.close(); &#125; &#125; &#125; public static void main(String[] args) &#123; HelloClientDemo client = new HelloClientDemo(); client.startClient(&quot;china&quot;); &#125;&#125; 先运行服务端程序，日志如下：1HelloWorld TSimpleServer start .... 再运行客户端调用程序，日志如下：1Thrify client result =: Hi,china welcome to thrift world. 测试成功，和预期的返回信息一致。 4.TThreadPoolServer 服务模型线程池服务模型，使用标准的阻塞式IO，预先创建一组线程处理请求。 编写服务端代码：HelloServerDemo2.java1234567891011121314151617181920212223242526272829303132333435363738package com.dxz.thrift.demo;import org.apache.thrift.TProcessor;import org.apache.thrift.protocol.TBinaryProtocol;import org.apache.thrift.server.TServer;import org.apache.thrift.server.TThreadPoolServer;import org.apache.thrift.transport.TServerSocket;public class HelloServerDemo2 &#123; public static final int SERVER_PORT = 8090; public void startServer() &#123; try &#123; System.out.println(&quot;HelloWorld TThreadPoolServer start ....&quot;); TProcessor tprocessor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldImpl()); TServerSocket serverTransport = new TServerSocket(SERVER_PORT); TThreadPoolServer.Args ttpsArgs = new TThreadPoolServer.Args(serverTransport); ttpsArgs.processor(tprocessor); ttpsArgs.protocolFactory(new TBinaryProtocol.Factory()); // 线程池服务模型，使用标准的阻塞式IO，预先创建一组线程处理请求。 TServer server = new TThreadPoolServer(ttpsArgs); server.serve(); &#125; catch (Exception e) &#123; System.out.println(&quot;Server start error!!!&quot;); e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; HelloServerDemo2 server = new HelloServerDemo2(); server.startServer(); &#125;&#125; 客户端Client代码和之前的一样，只要数据传输的协议一致即可，客户端测试成功，结果如下：1Thrify client result =: Hi,china welcome to thrift world. 5.TNonblockingServer 服务模型使用非阻塞式IO，服务端和客户端需要指定TFramedTransport数据传输的方式。 编写服务端代码：HelloServerDemo3.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.dxz.thrift.demo;import org.apache.thrift.TProcessor;import org.apache.thrift.protocol.TBinaryProtocol;import org.apache.thrift.protocol.TCompactProtocol;import org.apache.thrift.server.TNonblockingServer;import org.apache.thrift.server.TServer;import org.apache.thrift.server.TThreadPoolServer;import org.apache.thrift.transport.TFramedTransport;import org.apache.thrift.transport.TNonblockingServerSocket;import org.apache.thrift.transport.TServerSocket;public class HelloServerDemo3 &#123; public static final int SERVER_PORT = 8090; public void startServer() &#123; try &#123; System.out.println(&quot;HelloWorld TNonblockingServer start ....&quot;); TProcessor tprocessor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldImpl()); TNonblockingServerSocket tnbSocketTransport = new TNonblockingServerSocket(SERVER_PORT); TNonblockingServer.Args tnbArgs = new TNonblockingServer.Args(tnbSocketTransport); tnbArgs.processor(tprocessor); tnbArgs.transportFactory(new TFramedTransport.Factory()); tnbArgs.protocolFactory(new TCompactProtocol.Factory()); // 使用非阻塞式IO，服务端和客户端需要指定TFramedTransport数据传输的方式 TServer server = new TNonblockingServer(tnbArgs); server.serve(); &#125; catch (Exception e) &#123; System.out.println(&quot;Server start error!!!&quot;); e.printStackTrace(); &#125; &#125; /** * @param args */ public static void main(String[] args) &#123; HelloServerDemo3 server = new HelloServerDemo3(); server.startServer(); &#125;&#125; 编写客户端代码：HelloClientDemo3.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.dxz.thrift.demo;import org.apache.thrift.TException;import org.apache.thrift.protocol.TBinaryProtocol;import org.apache.thrift.protocol.TCompactProtocol;import org.apache.thrift.protocol.TJSONProtocol;import org.apache.thrift.protocol.TProtocol;import org.apache.thrift.transport.TSocket;import org.apache.thrift.transport.TTransport;import org.apache.thrift.transport.TTransportException;import org.apache.thrift.TException;import org.apache.thrift.protocol.TCompactProtocol;import org.apache.thrift.protocol.TProtocol;import org.apache.thrift.transport.TFramedTransport;import org.apache.thrift.transport.TSocket;import org.apache.thrift.transport.TTransport;import org.apache.thrift.transport.TTransportException;public class HelloClientDemo3 &#123; public static final String SERVER_IP = &quot;localhost&quot;; public static final int SERVER_PORT = 8090; public static final int TIMEOUT = 30000; public void startClient(String userName) &#123; TTransport transport = null; try &#123; transport = new TFramedTransport(new TSocket(SERVER_IP, SERVER_PORT, TIMEOUT)); // 协议要和服务端一致 TProtocol protocol = new TCompactProtocol(transport); HelloWorldService.Client client = new HelloWorldService.Client(protocol); transport.open(); String result = client.sayHello(userName); System.out.println(&quot;Thrify client result =: &quot; + result); &#125; catch (TTransportException e) &#123; e.printStackTrace(); &#125; catch (TException e) &#123; e.printStackTrace(); &#125; finally &#123; if (null != transport) &#123; transport.close(); &#125; &#125; &#125; /** * @param args */ public static void main(String[] args) &#123; HelloClientDemo3 client = new HelloClientDemo3(); client.startClient(&quot;HelloClientDemo3&quot;); &#125;&#125; 客户端的测试成功，结果如下：1Thrify client result =: Hi,HelloClientDemo3 welcome to thrift world. 6.THsHaServer服务模型半同步半异步的服务端模型，需要指定为：TFramedTransport数据传输的方式。 编写服务端代码：HelloServerDemo4.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.dxz.thrift.demo;import org.apache.thrift.TProcessor;import org.apache.thrift.protocol.TBinaryProtocol;import org.apache.thrift.protocol.TCompactProtocol;import org.apache.thrift.server.THsHaServer;import org.apache.thrift.server.TNonblockingServer;import org.apache.thrift.server.TServer;import org.apache.thrift.server.TSimpleServer;import org.apache.thrift.server.TThreadPoolServer;import org.apache.thrift.transport.TFramedTransport;import org.apache.thrift.transport.TNonblockingServerSocket;import org.apache.thrift.transport.TServerSocket;public class HelloServerDemo4 &#123; public static final int SERVER_PORT = 8090; public void startServer() &#123; try &#123; System.out.println(&quot;HelloWorld THsHaServer start ....&quot;); TProcessor tprocessor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldImpl()); TNonblockingServerSocket tnbSocketTransport = new TNonblockingServerSocket(SERVER_PORT); THsHaServer.Args thhsArgs = new THsHaServer.Args(tnbSocketTransport); thhsArgs.processor(tprocessor); thhsArgs.transportFactory(new TFramedTransport.Factory()); thhsArgs.protocolFactory(new TBinaryProtocol.Factory()); // 半同步半异步的服务模型 TServer server = new THsHaServer(thhsArgs); server.serve(); &#125; catch (Exception e) &#123; System.out.println(&quot;Server start error!!!&quot;); e.printStackTrace(); &#125; &#125; /** * @param args */ public static void main(String[] args) &#123; HelloServerDemo4 server = new HelloServerDemo4(); server.startServer(); &#125;&#125; 客户端代码HelloClientDemo4.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.dxz.thrift.demo;import java.io.IOException;import org.apache.thrift.TException;import org.apache.thrift.protocol.TBinaryProtocol;import org.apache.thrift.protocol.TCompactProtocol;import org.apache.thrift.protocol.TProtocol;import org.apache.thrift.transport.TSocket;import org.apache.thrift.transport.TTransport;import org.apache.thrift.transport.TTransportException;public class HelloClientDemo4 &#123; public static final String SERVER_IP = &quot;localhost&quot;; public static final int SERVER_PORT = 8090; public static final int TIMEOUT = 30000; public void startClient(String userName) &#123; TTransport transport = null; try &#123; transport = new TFramedTransport(new TSocket(SERVER_IP, SERVER_PORT, TIMEOUT)); // 协议要和服务端一致 TProtocol protocol = new TBinaryProtocol(transport); // TProtocol protocol = new TCompactProtocol(transport); // TProtocol protocol = new TJSONProtocol(transport); HelloWorldService.Client client = new HelloWorldService.Client(protocol); transport.open(); String result = client.sayHello(userName); System.out.println(&quot;Thrify client result =: &quot; + result); &#125; catch (TTransportException e) &#123; e.printStackTrace(); &#125; catch (TException e) &#123; e.printStackTrace(); &#125; finally &#123; if (null != transport) &#123; transport.close(); &#125; &#125; &#125; /** * @param args */ public static void main(String[] args) &#123; HelloClientDemo4 client = new HelloClientDemo4(); client.startClient(&quot;HelloClientDemo4&quot;); &#125;&#125; 结果：Thrify client result =: Hi,HelloClientDemo4 welcome to thrift world. 7.异步客户端编写服务端代码：HelloServerDemo5.java 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.dxz.thrift.demo;import org.apache.thrift.TProcessor;import org.apache.thrift.protocol.TCompactProtocol;import org.apache.thrift.server.TNonblockingServer;import org.apache.thrift.server.TServer;import org.apache.thrift.transport.TFramedTransport;import org.apache.thrift.transport.TNonblockingServerSocket;public class HelloServerDemo5 &#123; public static final int SERVER_PORT = 8090; public void startServer() &#123; try &#123; System.out.println(&quot;HelloWorld TNonblockingServer start ....&quot;); TProcessor tprocessor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldImpl()); TNonblockingServerSocket tnbSocketTransport = new TNonblockingServerSocket(SERVER_PORT); TNonblockingServer.Args tnbArgs = new TNonblockingServer.Args(tnbSocketTransport); tnbArgs.processor(tprocessor); tnbArgs.transportFactory(new TFramedTransport.Factory()); tnbArgs.protocolFactory(new TCompactProtocol.Factory()); // 使用非阻塞式IO，服务端和客户端需要指定TFramedTransport数据传输的方式 TServer server = new TNonblockingServer(tnbArgs); server.serve(); &#125; catch (Exception e) &#123; System.out.println(&quot;Server start error!!!&quot;); e.printStackTrace(); &#125; &#125; /** * @param args */ public static void main(String[] args) &#123; HelloServerDemo5 server = new HelloServerDemo5(); server.startServer(); &#125;&#125; 编写客户端Client代码：HelloAsynClientDemo.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package com.dxz.thrift.demo;import java.util.concurrent.CountDownLatch;import java.util.concurrent.TimeUnit;import org.apache.thrift.TException;import org.apache.thrift.async.AsyncMethodCallback;import org.apache.thrift.async.TAsyncClientManager;import org.apache.thrift.protocol.TCompactProtocol;import org.apache.thrift.protocol.TProtocolFactory;import org.apache.thrift.transport.TNonblockingSocket;import org.apache.thrift.transport.TNonblockingTransport;import com.dxz.thrift.demo.HelloWorldService.AsyncClient.sayHello_call;public class HelloAsynClientDemo &#123; public static final String SERVER_IP = &quot;localhost&quot;; public static final int SERVER_PORT = 8090; public static final int TIMEOUT = 30000; public void startClient(String userName) &#123; try &#123; TAsyncClientManager clientManager = new TAsyncClientManager(); TNonblockingTransport transport = new TNonblockingSocket(SERVER_IP, SERVER_PORT, TIMEOUT); TProtocolFactory tprotocol = new TCompactProtocol.Factory(); HelloWorldService.AsyncClient asyncClient = new HelloWorldService.AsyncClient(tprotocol, clientManager, transport); System.out.println(&quot;Client start .....&quot;); CountDownLatch latch = new CountDownLatch(1); AsynCallback callBack = new AsynCallback(latch); System.out.println(&quot;call method sayHello start ...&quot;); asyncClient.sayHello(userName, callBack); System.out.println(&quot;call method sayHello .... end&quot;); boolean wait = latch.await(30, TimeUnit.SECONDS); System.out.println(&quot;latch.await =:&quot; + wait); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;startClient end.&quot;); &#125; public class AsynCallback implements AsyncMethodCallback&lt;sayHello_call&gt; &#123; private CountDownLatch latch; public AsynCallback(CountDownLatch latch) &#123; this.latch = latch; &#125; @Override public void onComplete(sayHello_call response) &#123; System.out.println(&quot;onComplete&quot;); try &#123; // Thread.sleep(1000L * 1); System.out.println(&quot;AsynCall result =:&quot; + response.getResult().toString()); &#125; catch (TException e) &#123; e.printStackTrace(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; latch.countDown(); &#125; &#125; @Override public void onError(Exception exception) &#123; System.out.println(&quot;onError :&quot; + exception.getMessage()); latch.countDown(); &#125; &#125; /** * @param args */ public static void main(String[] args) &#123; HelloAsynClientDemo client = new HelloAsynClientDemo(); client.startClient(&quot;HelloAsynClientDemo&quot;); &#125;&#125; 先运行服务程序，再运行客户端程序，测试结果如下：1234567Client start .....call method sayHello start ...call method sayHello .... endonCompleteAsynCall result =:Hi,HelloAsynClientDemo welcome to thrift world.latch.await =:truestartClient end.","comments":true,"tags":[{"name":"Thrift","slug":"Thrift","permalink":"http://jishusuishouji.github.io/tags/Thrift/"},{"name":"facebook","slug":"facebook","permalink":"http://jishusuishouji.github.io/tags/facebook/"},{"name":"RPC","slug":"RPC","permalink":"http://jishusuishouji.github.io/tags/RPC/"}]},{"title":"facebook的thriff 基于rpc的远程调用实现","date":"2017-04-03T09:05:33.000Z","path":"2017/04/03/thriff/facebook的thriff_基于rpc的远程调用实现/","text":"RPC、RMI、JMS概念：RPC与RMI的对比-远程过程调用 (RPC)是平台中立的，它不理会操作系统之间以及编程语言之间的差异。即RPC支持多种语言，而RMI只支持Java写的应用程序。另外RMI调用远程对象方法，允许方法返回Java对象以及基本数据类型。而RPC不支持对象的概念，传送到RPC服务的消息由外部数据表示 (External Data Representation, XDR) 语言表示，这种语言抽象了字节序类和数据类型结构之间的差异。只有由XDR定义的数据类型才能被传递，RPC不允许传递对象。可以说RMI是面向对象方式的Java RPC。 JMSJava消息服务(Java Messaging Service, JMS) 是一种允许应用程序创建、发送、接受和读取消息的Java API。JMS与RMI的区别在于，采用JMS服务，对象是在物理上被异步从网络的某个JVM上直接移动到另一个JVM上。(严重怀疑) 而RMI对象是绑定在本地JVM中，只有函数参数和返回值是通过网络传送的。 thrift概念是facebook提供的一种跨平台远程通信框架，效率比较高。 thirift用法1.编写一个thrift文件Test.thrift，用于确定连接双方的接口。简单例子：123service Test &#123; void ping(1: i32 length)&#125; 2.使用thrift编译thrift可以用不同命令生成不同文件： a.生成java文件1thrift -gen java Test.thrift 完成后生成一个java文件：12345public class Test &#123; public interfaceIface &#123; public void ping(int length)throws org.apache.thrift.TException; &#125;&#125; b.生成node.js文件：thrift原生支持node.js1thrift -gen js:node Test.thrift 完成后生成Test.js和Test_types.js两个文件： 12345678910111213var Thrift = require(&apos;thrift&apos;).Thrift; var ttypes = require(&apos;./Test_types&apos;);//HELPER FUNCTIONS AND STRUCTURES var Test_ping_args =function(args) &#123; this.length = null; if(args) &#123; if(args.length !== undefined) &#123; this.length = args.length; &#125; &#125;&#125; 不过需要在node.js里加载thrift库：1npm intall thrift 准备工作到此结束！ 3.实战：使用java当客户端,Node.js当服务端。java客户端代码如下：123456789101112131415161718192021222324252627282930package apache.thrift; import org.apache.thrift.TException;import org.apache.thrift.protocol.TBinaryProtocol;import org.apache.thrift.protocol.TProtocol;import org.apache.thrift.transport.TFramedTransport;import org.apache.thrift.transport.TSocket;import org.apache.thrift.transport.TTransport;import org.apache.thrift.transport.TTransportException; public class TestUserStorage &#123; public static void main(String[] args) &#123; TTransport transport =new TFramedTransport(new TSocket(&quot;localhost&quot;,9799)); try&#123; transport.open(); &#125;catch(TTransportException e1) &#123; e1.printStackTrace(); &#125; TProtocol protocol =new TBinaryProtocol(transport); UserStorage.Client client =new UserStorage.Client(protocol); try&#123; client.store(new UserProfile(1,&quot;&quot;,&quot;&quot;)); System.out.println(client.retrieve(1)); &#125;catch(TException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 注意两个地方：thrift在java中的实现很多，但是node-thrift模块目前只支持TFramedTransport，TBinaryProtocol，所以使用其他实现时server会出错。另外transport是需要先open进行连接的。 node服务端代码： var thrift = require(&apos;thrift&apos;); var UserStorage = require(&apos;./gen-nodejs/UserStorage.js&apos;), ttypes = require(&apos;./gen-nodejs/user_types&apos;); var users = {}; var server = thrift.createServer(UserStorage, { store:function(user, success) { console.log(&quot;server stored:&quot;, user.uid); users[user.uid] = user; success(); }, retrieve:function(uid, success) { console.log(&quot;server retrieved:&quot;, uid); success(users[uid]); }, }); server.listen(9799); 输出结果：123client: UserProfile(uid:1, name:, blurb:)server: server stored: 1server retrieved: 1","comments":true,"tags":[{"name":"facebook","slug":"facebook","permalink":"http://jishusuishouji.github.io/tags/facebook/"},{"name":"thriff","slug":"thriff","permalink":"http://jishusuishouji.github.io/tags/thriff/"},{"name":"rpc","slug":"rpc","permalink":"http://jishusuishouji.github.io/tags/rpc/"}]},{"title":"hexo安装部署","date":"2017-04-03T02:39:14.000Z","path":"2017/04/03/hexo/hexo安装部署/","text":"Hexo安装1npm install hexo -g #-g表示全局安装, npm默认为当前项目安装 Hexo博客的初始化123456cd ~/githexo init hexo #执行init命令初始化到你指定的hexo目录cd hexonpm install #install before start blogginghexo generate #自动根据当前目录下文件,生成静态网页hexo server #运行本地服务 浏览器输入http://localhost:4000就可以看到效果。 Hexo博客目录结构1234567891011.├── .deploy #需要部署的文件├── node_modules #Hexo插件├── public #生成的静态网页文件├── scaffolds #模板├── source #博客正文和其他源文件, 404 favicon CNAME 等都应该放在这里| ├── _drafts #草稿| └── _posts #文章├── themes #主题├── _config.yml #全局配置文件└── package.json 安装git插件1npm install hexo-deployer-git --save 自动生成分类和标签的index.html分类页 go to your hexo folder hexo new page categories in the source\\categories\\index.md, add type: &quot;tags&quot; if you don’t want to have comments on that page, also add comments: false 标签页 go to your hexo folder hexo new page tags in the source\\tags\\index.md, add type: &quot;tags&quot; if you don’t want to have comments on that page, also add comments: false","comments":true,"tags":[{"name":"hexo","slug":"hexo","permalink":"http://jishusuishouji.github.io/tags/hexo/"}]},{"title":"Redis Cluster实现原理","date":"2017-04-03T00:56:20.000Z","path":"2017/04/03/redis/Redis_Cluster实现原理/","text":"一、Redis Cluster主要特性和设计集群目标1）高性能和线性扩展，最大可以支撑到1000个节点；Cluster架构中无Proxy层，Master与slave之间使用异步replication，且不存在操作的merge。（即操作不能跨多个nodes，不存在merge层） 2）一定程度上保证writes的安全性，需要客户端容忍一定程度的数据丢失;集群将会尽可能（best-effort）保存客户端write操作的数据；通常在failover期间，会有短暂时间内的数据丢失（因为异步replication引起）；当客户端与少数派的节点处于网络分区时（network partition），丢失数据的可能性会更高。（因为节点有效性检测、failover需要更长的时间） 3）可用性：只要集群中大多数master可达、且失效的master至少有一个slave可达时，集群都可以继续提供服务；同时“replicas migration”可以将那些拥有多个slaves的master的某个slave，迁移到没有slave的master下，即将整个集群相对slaves的分布更加平衡，尽力确保每个master都有一定数量的slave备份。 （Redis Cluster集群由多个shard组成，每个shard可以由一个master和多个slaves构成，数据根据hash slots配额分布在多个shard节点上，节点之间建立双向TCP链接用于有效性检测、Failover等，Client直接与shard节点进行通讯；Cluster集群没有Proxy层，也没有中央式的Master用于协调集群状态或者state存储；集群暂不提供动态reblance(再平衡)策略） 备注：下文中提到的query、查询等语义，泛指redis的读写操作。 Mutli-key操作Redis单实例支持的命令，Cluster也都支持，但是对于“multi-key”操作（即一次RPC调用中需要进行多个key的操作）比如Set类型的交集、并集等，则要求这些key必须属于同一个node。Cluster不能进行跨Nodes操作，也没有nodes提供merge层代理。 Cluster中实现了一个称为“hash tags”的概念，每个key都可以包含一个自定义的“tags”，那么在存储时将根据tags计算此key应该分布在哪个nodes上（而不是使用key计算，但是存储层面仍然是key）；此特性，可以强制某些keys被保存在同一个节点上，以便于进行“multikey”操作，比如“foo”和“{foo}.student”将会被保存在同一个node上。不过在人工对slots进行resharding期间，multikey操作可能不可用。 我们在Redis单例中，偶尔会用到“SELECT”指令，即可以将key保存在特定的database中（默认database索引号为0）；但是在Cluster环境下，将不支持SELECT命令，所有的key都将保存在默认的database中。 客户端与Server角色集群中nodes负责存储数据，保持集群的状态，包括keys与nodes的对应关系（内部其实为slots与nodes对应关系）。nodes也能够自动发现其他的nodes，检测失效的节点，当某个master失效时还应该能将合适的slave提升为master。 为了达成这些行为，集群中的每个节点都通过TCP与其他所有nodes建立连接，它们之间的通信协议和方式称为“Redis Cluster Bus”。Nodes之间使用gossip协议向其他nodes传播集群信息，以达到自动发现的特性，通过发送ping来确认其他nodes工作是否正常，也会在合适的时机发送集群的信息。当然在Failover时（包括人为failover）也会使用Bus来传播消息。（gossip：最终一致性，分布式服务数据同步算法，node首先需要知道（可以读取配置）集群中至少一个seed node，此node向seed发送ping请求，此时seed节点pong返回自己已知的所有nodes列表，然后node解析nodes列表并与它们都建立tcp连接，同时也会向每个nodes发送ping，并从它们的pong结果中merge出全局nodes列表，并逐步与所有的nodes建立连接…….数据传输的方式也是类似，网络拓扑结构为full mesh） 因为Node并不提供Proxy机制，当Client将请求发给错误的nodes时（此node上不存在此key所属的slot），node将会反馈“MOVED”或者“ASK”错误信息，以便Client重新定向到合适的node。理论上，Client可以将请求发送给任意一个nodes，然后根据再根据错误信息转发给合适的node，客户端可以不用保存集群的状态信息，当然这种情况下性能比较低效，因为Client可能需要2次TCP调用才能获取key的结果，通常客户端会缓存集群中nodes与slots的映射关系，并在遇到“Redirected”错误反馈时，才会更新本地的缓存。 安全写入（write safety）在Master-slaves之间使用异步replication机制，在failover之后，新的Master将会最终替代其他的replicas（即slave）。在出现网络分区时（network partition），总会有一个窗口期（node timeout）可能会导致数据丢失；不过，Client与多数派的Master、少数派Master处于一个分区（网络分区，因为网络阻断问题，导致Clients与Nodes被隔离成2部分）时，这两种情况下影响并不相同。 1）write提交到master，master执行完毕后向Client反馈“OK”，不过此时可能数据还没有传播给slaves（异步replication）；如果此时master不可达的时间超过阀值（node timeout，参见配置参数），那么将触发slave被选举为新的Master（即Failover），这意味着那些没有replication到slaves的writes将永远丢失了！2）还有一种情况导致数据丢失：A）因为网络分区，此时master不可达，且Master与Client处于一个分区，且是少数派分区。B）Failover机制，将其中一个slave提升为新Master。C）此后网络分区消除，旧的Master再次可达，此时它将被切换成slave。D）那么在网络分区期间，处于少数派分区的Client仍然将write提交到旧的Master，因为它们觉得Master仍然有效；当旧的Master再次加入集群，切换成slave之后，这些数据将永远丢失。 在第二种情况下，如果Master无法与其他大多数Masters通讯的时间超过阀值后，此Master也将不再接收Writes，自动切换为readonly状态。当网络分区消除后，仍然会有一小段时间，客户端的write请求被拒绝，因为此时旧的Master需要更新本地的集群状态、与其他节点建立连接、角色切换为slave等等，同时Client端的路由信息也需要更新。只有当此master被大多数其他master不可达的时间达到阀值时，才会触发Failover，这个时间称为NODE_TIMEOUT，可以通过配置设定。所以当网络分区在此时间被消除的话，writes不会有任何丢失。反之，如果网络分区持续时间超过此值，处于“小分区”（minority）端的Master将会切换为readonly状态，拒绝客户端继续提交writes请求，那么“大分区”端将会进行failover，这意味着NODE_TIMEOUT期间发生在“小分区”端的writes操作将丢失（因为新的Master上没有同步到那些数据）。 可用性处于“小分区”的集群节点是不可用的；“大分区”端必须持有大多数Masters，同时每个不可达的Master至少有一个slave也在“大分区”端，当NODE_TIMEOUT时，触发failover，此后集群才是可用的。Redis Cluster在小部分nodes失效后仍然可以恢复有效性，如果application希望大面积节点失效仍然有效，那么Cluster不适合这种情况。 比如集群有N个Master，且每个Master都有一个slave，那么集群的有效性只能容忍一个节点（master）被分区隔离（即一个master处于小分区端，其他处于大分区端），当第二个节点被分区隔离之前仍保持可用性的概率为1 - (1/(N 2 - 1))（解释：当第一个节点失效后，剩余N 2 -1个节点，此时没有slave的Master失效的概率为1/(N 2 -1)）。比如有5个Master，每个Master有一个slave，当2个nodes被隔离出去（或者失效）后，集群可用性的概率只有1/(5 2 - 1) = 11.11%。幸好Redis Cluster提供了“replicas migration”机制，在实际应用方面，可以有效的提高集群的可用性，当每次failover发生后，集群都会重新配置、平衡slaves的分布，以更好的抵御下一次失效情况的发生。 性能Redis Cluster并没有提供Proxy层，而是告知客户端将key的请求转发给合适的nodes。Client保存集群中nodes与keys的映射关系（slots），并保持此数据的更新，所以通常Client总能够将请求直接发送到正确的nodes上。因为采用异步replication，所以master不会等待slaves也保存成功后才向客户端反馈结果，除非显式的指定了WAIT指令。multi-key指令仅限于单个节点内，除了resharding操作外，节点的数据不会在节点间迁移。每个操作只会在特定的一个节点上执行，所以集群的性能为master节点的线性扩展。同时，Clients与每个nodes保持链接，所以请求的延迟等同于单个节点，即请求的延迟并不会因为Cluster的规模增大而受到影响。高性能和扩展性，同时保持合理的数据安全性，是Redis Cluster的设计目标。 Redis Cluster没有Proxy层，Client请求的数据也无法在nodes间merge；因为Redis核心就是K-V数据存储，没有scan类型（sort，limit，group by）的操作，因此merge操作并不被Redis Cluster所接受，而且这种特性会极大增加了Cluster的设计复杂度。 二、Cluster主要组件keys分布模型集群将key分成16384个slots（hash 槽），slot是数据映射的单位，言外之意，Redis Cluster最多支持16384个nodes（每个nodes持有一个slot）。集群中的每个master持有16384个slots中的一部分，处于“stable”状态时，集群中没有任何slots在节点间迁移，即任意一个hash slot只会被单个node所服务（master，当然可以有多个slave用于replicas，slave也可以用来扩展read请求）。keys与slot的映射关系，是按照如下算法计算的：HASH_SLOT = CRC16(key) mod 16384。其中CRC16是一种冗余码校验和，可以将字符串转换成16位的数字。 hash tags在计算hash slots时有一个意外的情况，用于支持“hash tags”；hash tags用于确保多个keys能够被分配在同一个hash slot中，用于支持multi-key操作。hash tags的实现比较简单，key中“{}”之间的字符串就是当前key的hash tags，如果存在多个“{}”，首个符合规则的字符串作为hash tags，如果“{}”存在多级嵌套，那么最内层首个完整的字符串作为hash tags，比如“{foo}.student”，那么“foo”是hash tags。如果key中存在合法的hash tags，那么在计算hash slots时，将使用hash tags，而不再使用原始的key。即“foo”与“{foo}.student”将得到相同的slot值，不过“{foo}.student”仍作为key来保存数据，即redis中数据的key仍为“{foo}.student”。 集群节点的属性集群中每个节点都有唯一的名字，称之为node ID，一个160位随机数字的16进制表示，在每个节点首次启动时创建。每个节点都将各自的ID保存在实例的配置文件中，此后将一直使用此ID，或者说只要配置文件不被删除，或者没有使用“CLUSTER RESET”指令重置集群，那么此ID将永不会修改。 集群通过node ID来标识节点，而不是使用IP + port，因为node可以修改它的IP和port，不过如果ID不变，我们仍然认定它是集群中合法一员。集群可以在cluster Bus中通过gossip协议来探测IP、port的变更，并重新配置。 node ID并不是与node相关的唯一信息，不过是唯一一个全局一致的。每个node还持有如下相关的信息，有些信息是关系集群配置的，其他的信息比如最后ping时间等。每个node也保存其他节点的IP、Port、flags（比如flags表示它是master还是slave）、最近ping的时间、最近pong接收时间、当前配置的epoch、链接的状态，最重要的是还包含此node上持有的hash slots。这些信息均可通过“CLUSTER NODES”指令开查看。 Cluster Bus每个Node都有一个特定的TCP端口，用来接收其他nodes的链接；此端口号为面向Client的端口号+10000，比如客户端端口号为6379，那么此node的BUS端口号为16379，客户端端口号可以在配置文件中声明。由此可见，nodes之间的交互通讯是通过Bus端口进行，使用了特定的二进制协议，此端口通常应该只对nodes可用，可以借助防火墙技术来屏蔽其他非法访问。 集群拓扑Redis Cluster中每个node都与其他nodes的Bus端口建立TCP链接（full mesh，全网）。比如在由N个节点组成的集群中，每个node有N-1个向外发出的TCP链接，以及N-1个其他nodes发过来的TCP链接；这些TCP链接总是keepalive，不是按需创建的。如果ping发出之后，node在足够长的时间内仍然没有pong响应，那么此node将会被标记为“不可达”，那么与此node的链接将会被刷新或者重建。Nodes之间通过gossip协议和配置更新的机制，来避免每次都交互大量的消息，最终确保在nodes之间的信息传送量是可控的。 节点间handshakeNodes通过Bus端口发送ping、pong；如果一个节点不属于集群，那么它的消息将会被其他nodes全部丢弃。一个节点被认为是集群成员的方式有2种：1）如果此node在“Cluster meet”指令中引入，此命令的主要意义就是将指定node加入集群。那么对于当前节点，将认为指定的node为“可信任的”。（此后将会通过gossip协议传播给其他nodes）2）当其他nodes通过gossip引入了新的nodes，这些nodes也是被认为是“可信任的”。 只要我们将一个节点加入集群，最终此节点将会与其他节点建立链接，即cluster可以通过信息交换来自动发现新的节点，链接拓扑仍然是full mesh。 三、重定向与reshardingMOVED重定向理论上，Client可以将请求随意发给任何一个node，包括slaves，此node解析query，如果可以执行（比如语法正确，multiple keys都应该在一个node slots上），它会查看key应该属于哪个slot、以及此slot所在的nodes，如果当前node持有此slot，那么query直接执行即可，否则当前node将会向Client反馈“MOVED”错误： GET X -MOVED 3999 127.0.0.1:6381 错误信息中包括此key对应的slot（3999），以及此slot所在node的ip和port，对于Client 而言，收到MOVED信息后，它需要将请求重新发给指定的node。不过，当node向Client返回MOVED之前，集群的配置也在变更（节点调整、resharding、failover等，可能会导致slot的位置发生变更），此时Client可能需要等待更长的时间，不过最终node会反馈MOVED信息，且信息中包含指定的新的node位置。虽然Cluster使用ID标识node，但是在MOVED信息中尽可能地暴露给客户端便于使用的ip + port。 当Client遇到“MOVED”错误时，将会使用“CLUSTER NODES”或者“CLUSTER SLOTS”指令获取集群的最新信息，主要是nodes与slots的映射关系；因为遇到MOVED，一般也不会仅仅一个slot发生的变更，通常是一个或者多个节点的slots发生了变化，所以进行一次全局刷新是有必要的；我们还应该明白，Client将会把集群的这些信息在被缓存，以便提高query的性能。 还有一个错误信息：“ASK”，它与“MOVED”都属于重定向错误，客户端的处理机制基本相同，只是ASK不会触发Client刷新本地的集群信息。 集群运行时重新配置（live reconfiguration）我们可以在Cluster运行时增加、删除nodes，这两种操作都会导致：slots在nodes的迁移；当然这种机制也可用来集群数据的rebalance等等。 1）集群中新增一个node，我们需要将其他nodes上的部分slots迁移到此新nodes上，以实现数据负载的均衡分配。2）集群中移除一个node，那么在移除节点之前，必须将此节点上（如果此节点没有任何slaves）的slots迁移到其他nodes。3）如果数据负载不均衡，比如某些slots数据集较大、负载较大时，我们需要它们迁移到负载较小的nodes上（即手动resharding），以实现集群的负载平衡。 Cluster支持slots在nodes间移动；从实际的角度来看，一个slot只是一序列keys的逻辑标识，所以Cluster中slot的迁移，其实就是一序列keys的迁移，不过resharding操作只能以slot为单位（而不能仅仅迁移某些keys）。Redis提供了如下几个操作： 1）CLUSTER ADDSLOTS [slot] ….2）CLUSTER DELSLOTS [slot] …3）CLUSTER SETSLOT [slot] NODE [node]4）CLUSTER SETSLOT [slot] MIGRATING [destination-node]5）CLUSTER SETSLOT [slot] IMPORTING [source-node] 前两个指令：ADDSLOTS和DELSLOTS，用于向当前node分配或者移除slots，指令可以接受多个slot值。分配slots的意思是告知指定的master（即此指令需要在某个master节点执行）此后由它接管相应slots的服务；slots分配后，这些信息将会通过gossip发给集群的其他nodes。ADDSLOTS指令通常在创建一个新的Cluster时使用，一个新的Cluster有多个空的Masters构成，此后管理员需要手动为每个master分配slots，并将16384个slots分配完毕，集群才能正常服务。简而言之，ADDSLOTS只能操作那些尚未分配的（即不被任何nodes持有）slots，我们通常在创建新的集群或者修复一个broken的集群（集群中某些slots因为nodes的永久失效而丢失）时使用。为了避免出错，Redis Cluster提供了一个redis-trib辅助工具，方便我们做这些事情。 DELSLOTS就是将指定的slots删除，前提是这些slots必须在当前node上，被删除的slots处于“未分配”状态（当然其对应的keys数据也被clear），即尚未被任何nodes覆盖，这种情况可能导致集群处于不可用状态，此指令通常用于debug，在实际环境中很少使用。那些被删除的slots，可以通过ADDSLOTS重新分配。 SETSLOT是个很重要的指令，对集群slots进行reshard的最重要手段；它用来将单个slot在两个nodes间迁移。根据slot的操作方式，它有两种状态“MIGRATING”、“IMPORTING”（或者说迁移的方式）1）MIGRATING：将slot的状态设置为“MIGRATING”，并迁移到destination-node上，需要注意当前node必须是slot的持有者。在迁移期间，Client的查询操作仍在当前node上执行，如果key不存在，则会向Client反馈“-ASK”重定向信息，此后Client将会把请求重新提交给迁移的目标node。2）IMPORTING：将slot的状态设置为“IMPORTING”，并将其从source-node迁移到当前node上，前提是source-node必须是slot的持有者。Client交互机制同上。 假如我们有两个节点A、B，其中slot 8在A上，我们希望将8从A迁移到B，可以使用如下方式：1）在B上：CLUSTER SETSLOT 8 IMPORTING A2）在A上：CLUSTER SETSLOT 8 MIGRATING B在迁移期间，集群中其他的nodes的集群信息不会改变，即slot 8仍对应A，即此期间，Client查询仍在A上：1）如果key在A上存在，则由A执行。2）否则，将向客户端返回ASK，客户端将请求重定向到B。这种方式下，新key的创建就不会在A上执行，而是在B上执行，这也就是ASK重定向的原因（迁移之前的keys在A，迁移期间created的keys在B上）；当上述SETSLOT执行完毕后，slot的状态也会被自动清除，同时将slot迁移信息传播给其他nodes，至此集群中slot的映射关系将会变更，此后slot 8的数据请求将会直接提交到B上。 ASK重定向在上文中，我们已经介绍了MOVED重定向，ASK与其非常相似。在resharding期间，为什么不能用MOVED？MOVED意思为hash slots已经永久被另一个node接管、接下来的相应的查询应该与它交互，ASK的意思是当前query暂时与指定的node交互；在迁移期间，slot 8的keys有可能仍在A上，所以Client的请求仍然需要首先经由A，对于A上不存在的，我们才需要到B上进行尝试。迁移期间，Redis Cluster并没有粗暴的将slot 8的请求全部阻塞、直到迁移结束，这种方式尽管不再需要ASK，但是会影响集群的可用性。1）当Client接收到ASK重定向，它仅仅将当前query重定向到指定的node；此后的请求仍然交付给旧的节点。2）客户端并不会更新本地的slots映射，仍然保持slot 8与A的映射；直到集群迁移完毕，且遇到MOVED重定向。 一旦slot 8迁移完毕之后（集群的映射信息也已更新），如果Client再次在A上访问slot 8时，将会得到MOVED重定向信息，此后客户端也更新本地的集群映射信息。 客户端首次链接以及重定向处理可能有些Cluster客户端的实现，不会在内存中保存slots映射关系（即nodes与slots的关系），每次请求都从声明的、已知的nodes中，随机访问一个node，并根据重定向（MOVED）信息来寻找合适的node，这种访问模式，通常是非常低效的。当然，Client应该尽可能的将slots配置信息缓存在本地，不过配置信息也不需要绝对的实时更新，因为在请求时偶尔出现“重定向”，Client也能兼容此次请求的正确转发，此时再更新slots配置。（所以Client通常不需要间歇性的检测Cluster中配置信息是否已经更新）客户端通常是全量更新slots配置：1）首次链接到集群的某个节点2）当遇到MOVED重定向消息时遇到MOVED时，客户端仅仅更新特定的slot是不够的，因为集群中的reshard通常会影响到多个slots。客户端通过向任意一个nodes发送“CLUSTER NODES”或者“CLUSTER SLOTS”指令均可以获得当前集群最新的slots映射信息；“CLUSTER SLOTS”指令返回的信息更易于Client解析。如果集群处于broken状态，即某些slots尚未被任何nodes覆盖，指令返回的结果可能是不完整的。 Multikeys操作前文已经介绍，基于hash tags机制，我们可以在集群中使用Multikeys操作。不过，在resharding期间，Multikeys操作将可能不可用，比如这些keys不存在于同一个slot（迁移会导致keys被分离）；比如Multikeys逻辑上属于同一个slot，但是因为resharding，它们可能暂时不处于同一个nodes，有些可能在迁移的目标节点上（比如Multikeys包含a、b、c三个keys，逻辑上它们都属于slot 8，但是其中c在迁移期间创建，它被存储在节点B上，a、b仍然在节点A），此时将会向客户端返回“-TRYAGAIN”错误，那么客户端此后将需要重试一次，或者直接返回错误（如果迁移操作被中断），无论如何最终Multikeys的访问逻辑是一致的，slots的状态也是最终确定的。 slaves扩展reads请求通常情况下，read、write请求都将有持有slots的master节点处理；因为redis的slaves可以支持read操作（前提是application能够容忍stale数据），所以客户端可以使用“READONLY”指令来扩展read请求。“READONLY”表明其可以访问集群的slaves节点，能够容忍stale数据，而且此次链接不会执行writes操作。当链接设定为readonly模式后，Cluster只有当keys不被slave的master节点持有时才会发送重定向消息（即Client的read请求总是发给slave，只有当此slave的master不持有slots时才会重定向，很好理解）：1）此slave的master节点不持有相应的slots2）集群重新配置，比如reshard或者slave迁移到了其他master上，此slave本身也不持有此slot。 此时Client更新本地的slot配置信息，同上文所述。（目前很多Client实现均基于连接池，所以不能非常便捷的设置READLONLY选项，非常遗憾） 四、容错（Fault Tolerance）心跳与gossip消息集群中的nodes持续的交换ping、pong数据，这两种数据包的结构一样，同样都能携带集群的配置信息，唯一不同的就是message中的type字段。通常，一个node发送ping消息，那么接收者将会反馈pong消息；不过有时候并非如此，或许接收者将pong信息发给其他的nodes，而不是直接反馈给发送者，比如当集群中添加新的node时。通常一个node每秒都会随机向几个nodes发送ping，所以无论集群规模多大，每个nodes发送的ping数据包的总量是恒定的。每个node都确保尽可能的向那些在半个NODE_TIMEOUT时间内，尚未发送过ping或者接收到它们的pong消息的nodes发送ping。在NODE_TIMEOUT逾期之前，nodes也会尝试与那些通讯异常的nodes重新建立TCP链接，确保不能仅仅因为当前链接异常而认为它们就是不可达的。 当NODE_TIMEOUT值较小、集群中nodes规模较大时，那么全局交换的信息量也会非常庞大，因为每个node都尽力在半个NODE_TIMEOUT时间内，向其他nodes发送ping。比如有100个nodes，NODE_TIMEOUT为60秒，那么每个node在30秒内向其他99各nodes发送ping，平均每秒3.3个消息，那么整个集群全局就是每秒330个消息。这些消息量，并不会对集群的带宽带来不良问题。 心跳数据包的内容1）node ID2）currentEpoch和configEpoch3）node flags：比如表示此node是maste、slave等4）hash slots：发送者持有的slots5）如果发送者是slave，那么其master的ID6）其他.. ping和pong数据包中也包含gossip部分，这部分信息包含sender持有的集群视图，不过它只包含sender已知的随机几个nodes，nodes的数量根据集群规模的大小按比例计算。gossip部分包含了nodes的ID、ip+port、flags，那么接收者将根据sender的视图，来判定节点的状态，这对故障检测、节点自动发现非常有用。 失效检测集群失效检测就是，当某个master或者slave不能被大多数nodes可达时，用于故障迁移并将合适的slave提升为master。当slave提升未能有效实施时，集群将处于error状态且停止接收Client端查询。如上所述，每个node有持有其已知nodes的列表包括flags，有2个flag状态：PFAIL和FAIL；PFAIL表示“可能失效”，是一种尚未完全确认的失效状态（即某个节点或者少数masters认为其不可达）。FAIL表示此node已经被集群大多数masters判定为失效（大多数master已认定为不可达，且不可达时间已达到设定值，需要failover）。 PFAIL：一个被标记为PFAIL的节点，表示此node不可达的时间超过NODE_TIMEOUT，master和slave有可以被标记为PFAIL。所谓不可达，就是当“active ping”（发送ping且能受到pong）尚未成功的时间超过NODE_TIMEOUT，因此我们设定的NODE_TIMEOUT的值应该比网络交互往返的时间延迟要大一些（通常要大的多，以至于交互往返时间可以忽略）。为了避免误判，当一个node在半个NODE_TIMEOUT时间内仍未能pong，那么当前node将会尽力尝试重新建立连接进行重试，以排除pong未能接收是因为当前链接故障的问题。 FAIL：PFAIL只是当前node有关于其他nodes的本地视图，可能每个node对其他nodes的本地视图都不一样，所以PFAIL还不足以触发Failover。处于PFAIL状态下的node可以被提升到FAIL状态。如上所述，每个node在向其他nodes发送gossip消息时，都会包含本地视图中几个随机nodes的状态信息；每个node最终都会从其他nodes发送的消息中获得一组nodes的flags。因此，每个node都可以通过这种机制来通知其他nodes，它检测到的故障情况。 PFAIL被上升为FAIL的集中情况：1）比如A节点，认为B为PFAIL2）那么A通过gossip信息，收集集群中大多数masters关于B的状态视图。3）多数master都认为B为PFAIL，或者PFAIL情况持续时间为NODE_TIMEOUT * FAIL_REPORT_VALIDITY_MULT（此值当前为2） 如果上述条件成立，那么A将会：1）将B节点设定为FAIL2）将FAIL信息发送给其所有能到达的所有节点。 每个接收到FAIL消息的节点都会强制将此node标记为FAIL状态，不管此节点在本地视图中是否为PFAIL。FAIL状态是单向的，即PFAIL可以转换为FAIL，但是FAIL状态只能清除，不能回转为PFAIL： 1）当此node已经变的可达，且为slave，这种情况下FAIL状态将会被清除，因为没有发生failover。2）此node已经可达，且是一个没有服务任何slots的master（空的master）；这种情况下，FAIL将会被清除，因为master没有持有slots，所以它并没有真正参与到集群中，需要等到重新配置以便它加入集群。3）此node已经可达，且是master，且在较长时间内（N倍的NODE_TIMEOUT）没有检测到slave的提升，即没有slave发生failover（比如此master下没有slave），那么它只能重新加入集群且仍为master。 需要注意的是PFAIL-&gt;FAIL的转变，使用了“协议”（agreement）的形式：1）nodes会间歇性的收集其他nodes的视图，即使大多数masters都“agree”，事实上这个状态，仅仅是我们从不同的nodes、不同的时间收集到的，我们无法确认（也不需要）在特定时刻大多数masters是否“agree”。我们丢弃较旧的故障报告，所以此故障（FAIL）是有大多数masters在一段时间内的信号。2）虽然每个node在检测到FAIL情况时，都会通过FAIL消息发送给其他nodes，但是无法保证消息一定会到达所有的nodes，比如可能当前节点（发送消息的node）因为网络分区与其他部分nodes隔离了。 如果只有少数master认为某个node为FAIL，并不会触发相应的slave提升，即failover，因为可能是因为网络分区导致。FAIL标记只是用来触发slave 提升；在原理上，当master不可达时将会触发slave提升，不过当master仍然被大多数可达时，它会拒绝提供相应的确认。 五、Failover相关的配置集群currentEpochRedis Cluster使用了类似于Raft算法“term”（任期）的概念，那么在redis Cluster中term称为epoch，用来给events增量版本号。当多个nodes提供了信息有冲突时，它可以作为node来知道哪个状态是最新的。currentEpoch为一个64位无签名数字。在集群node创建时，master和slave都会将各自的currentEpoch设置为0，每次从其他node接收到数据包时，如果发现发送者的epoch值比自己的大，那么当前node将自己的currentEpoch设置为发送者的epoch。由此，最终所有的nodes都会认同集群中最大的epoch值；当集群的状态变更，或者node为了执行某个行为需求agreement时，都将需要epoch（传递或者比较）。 当前来说，只有在slave提升期间发生；currentEpoch为集群的逻辑时钟（logical clock），指使持有较大值的获胜。（currentEpoch，当前集群已达成认同的epoch值，通常所有的nodes应该一样） configEpoch每个master总会在ping、pong数据包中携带自己的configEpoch以及它持有的slots列表。新创建的node，其configEpoch为0，slaves通过递增它们的configEpoch来替代失效的master，并尝试获得其他大多数master的授权（认同）。当slave被授权，一个新的configEpoch被生成，slave提升为master且使用此configEpoch。接下来介绍configEpoch帮助解决冲突，当不同的nodes宣称有分歧的配置时。slaves在ping、pong数据包中也会携带自己的configEpoch信息，不过这个epoch为它与master在最近一次数据交换时，master的configEpoch。每当节点发现configEpoch值变更时，都会将新值写入nodes.conf文件，当然currentEpoch也也是如此。这两个变量在写入文件后会伴随磁盘的fsync，持久写入。严格来说，集群中所有的master都持有唯一的configEpoch值。同一组master-slaves持有相同的configEpoch。 slave选举与提升在slaves节点中进行选举，在其他masters的帮助下进行投票，选举出一个slave并提升为master。当master处于FAIL状态时，将会触发slave的选举。slaves都希望将自己提升为master，此master的所有slaves都可以开启选举，不过最终只有一个slave获胜。当如下情况满足时，slave将会开始选举：1）当此slave的master处于FAIL状态2）此master持有非零个slots3）此slave的replication链接与master断开时间没有超过设定值，为了确保此被提升的slave的数据是新鲜的，这个时间用户可以配置。 为了选举，第一步，就是slave自增它的currentEpoch值，然后向其他masters请求投票（需求支持，votes）。slave通过向其他masters传播“FAILOVER_AUTH_REQUEST”数据包，然后最长等待2倍的NODE_TIMEOUT时间，来接收反馈。一旦一个master向此slave投票，将会响应“FAILOVER_AUTH_ACK”，此后在2 NODE_TIMOUT时间内，它将不会向同一个master的slaves投票；虽然这对保证安全上没有必要，但是对避免多个slaves同时选举时有帮助的。slave将会丢弃那些epoch值小于自己的currentEpoch的AUTH_ACK反馈，即不会对上一次选举的投票计数（只对当前轮次的投票计数）。一旦此slave获取了大多数master的ACKs，它将在此次选举中获胜；否则如果大多数master不可达（在2 NODE_TIMEOUT）或者投票额不足，那么它的选举将会被中断，那么其他的slave将会继续尝试。 slave rank（次序）当master处于FAIL状态时，slave将会随机等待一段时间，然后才尝试选举，等待的时间：1DELAY = 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000ms 一定的延迟确保我们等待FAIL状态在集群中传播，否则slave立即尝试选举（不进行等待的话），不过此时其他masters或许尚未意识到FAIL状态，可能会拒绝投票。 延迟的时间是随机的，这用来“去同步”（desynchronize），避免slaves同时开始选举。SLAVE_RANK表示此slave已经从master复制数据的总量的rank。当master失效时，slaves之间交换消息以尽可能的构建rank，持有replication offset最新的rank为0，第二最新的为1，依次轮推。这种方式下，持有最新数据的slave将会首先发起选举（理论上）。当然rank顺序也不是严格执行的，如果一个持有较小rank的slave选举失败，其他slaves将会稍后继续。 一旦，slave选举成功，它将获取一个新的、唯一的、自增的configEpoch值，此值比集群中任何masters持有的都要大，它开始宣称自己是master，并通过ping、pong数据包传播，并提供自己的新的configEpoch以及持有的slots列表。为了加快其他nodes的重新配置，pong数据包将会在集群中广播。当前node不可达的那些节点，它们可以从其他节点的ping或者pong中获知信息（gossip），并重新配置。 其他节点也会检测到这个新的master和旧master持有相同的slots，且持有更高的configEpoch，此时也会更新自己的配置（epoch，以及master）；旧master的slaves不仅仅更新配置信息，也会重新配置并与新的master跟进（slave of）。 Masters响应slave的投票请求当Master接收到slave的“FAILOVER_AUTH_REQUEST”请求后，开始投票，不过需要满足如下条件：1）此master只会对指定的epoch投票一次，并且拒绝对旧的epoch投票：每个master都持有一个lastVoteEpoch，将会拒绝AUTH_REQUEST中currentEpoch比lastVoteEpoch小的请求。当master响应投票时，将会把lastVoteEpoch保存在磁盘中。2）此slave的master处于FAIL状态时，master才会投票。3）如果slave的currentEpoch比此master的currentEpoch小，那么AUTH_REQUEST将会被忽略。因为master只会响应那些与自己的currentEpoch相等的请求。如果同一个slave再此请求投票，持有已经增加的currentEpoch，它（slave）将保证旧的投票响应不能参与计票。 比如master的currentEpoch为5，lastVoteEpoch为1：1）slave的currentEpoch为32）slave在选举开始时，使用epoch为4（先自增），因为小于master的epoch，所以投票响应被延缓。3）slave在一段时间后将重新选举，使用epoch为5（4 + 1，再次自增），此时master上延缓的响应发给slave，接收后视为有效。 1）master在2 * NODE_TIMEOUT超时之前，不会对同一个master的slave再次投票。这并不是严格需要，因为也不太可能两个slave在相同的epoch下同时赢得选举。不过，它确保当一个slave选举成功后，它（slave）有一段缓冲时间来通知其他的slaves，避免另一个slave赢得了新的一轮的选择，避免不必要的二次failover。2）master并不会尽力选举最合适的slave。当slave的master处于FAIL状态，此master在当前任期（term）内并不投票，只是批准主动投票者（即master不发起选举，只批准别人的投票）。最合适的slave应该在其他slaves之前，首先发起选举。3）当master拒绝一个slave投票，并不会发出一个“否决”响应，而是简单的忽略。4）slave发送的configEpoch是其master的，还包括其master持有的slots；master不会向持有相同slots、但configEpoch只较低的slave投票。 Hash Slots配置传播Redis Cluster中重要的一部分就是传播集群中哪些节点上持有的哪些hash slots信息；无论是启动一个新的集群，还是当master失效其slave提升后更新配置，这对它们都至关重要。有2种方式用于hash slot配置的传播：1）heartbeat 消息：发送者的ping、pong消息中，总是携带自己目前持有的slots信息，不管自己是master还是slave。2）UPDATE 消息：因为每个心跳消息中会包含发送者的configEpoch和其持有的slots，如果接收者发现发送者的信息已经stale（比如发送者的configEpoch值小于持有相同slots的master的值），它会向发送者反馈新的配置信息（UPDATE），强制stale节点更新它。 当一个新的节点加入集群，其本地的hash slots映射表将初始为NULL，即每个hash slot都没有与任何节点绑定。Rule 1：如果此node本地视图中一个hash slot尚未分配（设置为NULL），并且有一个已知的node声明持有它，那么此node将会修改本地hash slot的映射表，将此slot与那个node关联。slave的failover操作、reshard操作都会导致hash slots映射的变更，新的配置信息将会通过心跳在集群中传播。Rule 2：如果此node的本地视图中一个hash slot已经分配，并且一个已知的node也声明持有它，且此node的configEpoch比当前slot关联的master的configEpoch值更大，那么此node将会把slot重新绑定到新的node上。根据此规则，最终集群中所有的nodes都赞同那个持有声明持有slot、且configEpoch最大值的nodes为slot的持有者。 nodes如何重新加入集群node A被告知slot 1、2现在由node B接管，假如这两个slots目前由A持有，且A只持有这两个slots，那么此后A将放弃这2个slots，成为空的节点；此后A将会被重新配置，成为其他新master的slave。这个规则可能有些复杂，A离群一段时间后重新加入集群，此时A发现此前自己持有的slots已经被其他多个nodes接管，比如slot 1被B接管，slot 2被C接管。在重新配置时，最终此节点上的slots将会被清空，那个窃取自己最后一个slot的node，将成为它的新master。节点重新加入集群，通常发生在failover之后，旧的master（也可以为slave）离群，然后重新加入集群。 Replica迁移Redis Cluster实现了一个成为“Replica migration”的概念，用来提升集群的可用性。比如集群中每个master都有一个slave，当集群中有一个master或者slave失效时，而不是master与它的slave同时失效，集群仍然可以继续提供服务。1）master A，有一个slave A12）master A失效，A1被提升为master3）一段时间后，A1也失效了，那么此时集群中没有其他的slave可以接管服务，集群将不能继续服务。 如果masters与slaves之间的映射关系是固定的（fixed），提高集群抗灾能力的唯一方式，就是给每个master增加更多的slaves，不过这种方式开支很大，需要更多的redis实例。解决这个问题的方案，我们可以将集群非对称，且在运行时可以动态调整master-slaves的布局（而不是固定master-slaves的映射），比如集群中有三个master A、B、C，它们对应的slave为A1、B1、C1、C2，即C节点有2个slaves。“Replica迁移”可以自动的重新配置slave，将其迁移到某个没有slave的master下。1）A失效，A1被提升为master2）此时A1没有任何slave，但是C仍然有2个slave，此时C2被迁移到A1下，成为A1的slave3）此后某刻，A1失效，那么C2将被提升为master。集群可以继续提供服务。 Replica迁移算法迁移算法并没有使用“agree”形式，而是使用一种算法来避免大规模迁移，这个算法确保最终每个master至少有一个slave即可。起初，我们先定义哪个slave是良好的：一个良好的slave不能处于FAIL状态。触发时机为，任何一个slave检测到某个master没有一个良好slave时。参与迁移的slave必须为，持有最多slaves的master的其中一个slave，且不处于FAIL状态，且持有最小的node ID。比如有10个masters都持有一个slave，有2个masters各持有5个slaves，那么迁移将会发生在持有5个slaves的masters中，且node ID最小的slave node上。我们不再使用“agreement”，不过也有可能当集群的配置不够稳定时，有一种竞争情况的发生，即多个slaves都认为它们自己的ID最小；如果这种情况发生，结果就是可能多个slaves会迁移到同一个master下，不过这并没有什么害处，但是最坏的结果是导致原来的master迁出了所有的slaves，让自己变得单一。但是迁移算法（进程）会在迁移完毕之后重新判断，如果尚未平衡，那么将会重新迁移。最终，每个master最少持有一个slave；这个算法由用户配置的“cluster-migration-barrier”，此配置参数表示一个master至少保留多少个slaves，其他多余的slaves可以被迁出。此值通常为1，如果设置为2，表示一个master持有的slaves个数大于2时，多余的slaves才可以迁移到持有更少slaves的master下。 configEpoch冲突解决算法在slave failover期间，会生成新的configEpoch值，需要保证唯一性。不过有2种不同的event会导致configEpoch的创建是不安全的：仅仅自增本地的currentEpoch并希望它不会发生冲突。这两个事件有系统管理员触发：1）CLUSTER FAILOVER：这个指令，就是人为的将某个slave提升为master，而不需要要求大多数masters的投票参与。2）slots的迁移，用于平衡集群的数据分布（reshard）；此时本地的configEpoch也会修改，因为性能的考虑，这个过程也不需要“agreement”。 在手动reshard期间，当一个hash slot从A迁移到B，resharding程序将强制B更新自己的配置信息、epoch值也修改为集群的最大值 + 1（除非B的configEpoch已经是最大值），这种变更则不需要其他nodes的agreement（注意与failover的原理不同）。通常每次resharding都会迁移多个slots，且有多个nodes参与，如果每个slots迁移都需要agreement，才能生成新的epoch，这种性能是很差的，也不可取。我们在首个slots迁移开始时，只会生成一个新的configEpoch，在迁移完毕后，将新的配置传播给集群即可，这种方式在生产环境中更加高效。 因为上述两个情况，有可能（虽然概率极小）最终多个nodes产生了相同的configEpoch；比如管理员正在进行resharding，但是此时failover发生了…无论是failover还是resharding都是将currentEpoch自增，而且resharding不使用agreement形式（即其他nodes或许不知道，而且网络传播可能延迟），这就会发生epoch值的冲突问题。 当持有不同slots的masters持有相同的configEpoch，这并不会有什么问题。比较遗憾的是，人工干预或者resharding会以不同的方式修改了集群的配置，Cluster要求所有的slots都应该被nodes覆盖，所以在任何情况下，我们都希望所有的master都持有不同的configEpoch。避免冲突的算法，就是用来解决当2个nodes持有相同的configEpoch：1）如果一个master节点发现其他master持有相同的configEpoch。2）并且此master逻辑上持有较小的node ID（字典顺序）3）然后此master将自己的currentEpoch加1，并作为自己新的configEpoch。 如果有多个nodes持有相同的congfigEpoch，那么除了持有最大ID的节点外，其他的nodes都将往前推进（+1，直到冲突解决），最终保证每个master都持有唯一的configEpoch（slave的configEpoch与master一样）。对于新创建的cluster也是同理，所有的nodes都初始为不同的configEpoch。 Node resets所有的nodes都可以进行软件级的reset（不需要重启、重新部署它们），reset为了重用集群（重新设定集群），必须需要将某个（些）节点重置后添加到其他集群。我们可以使用“CLUSTER RESET”指令：1）CLUSTER RESET SOFT2）CLUSTER RESET HARD 指令必须直接发给需要reset的节点，如果没有指定reset类型，默认为SOFT。1）soft和hard：如果节点为slave，那么节点将会转换为master，并清空其持有的数据，成为一个空的master。如果此节点为master，且持有slots数据，那么reset操作将被中断。2）soft和hard：其上持有的slots将会被释放3）soft和hard：此节点上的nodes映射表将会被清除，此后此node将不会知道其他节点的存在与状态。4）hard：currentEpoch、configEpoch、lastVoteEpoch值将被重置为0。5）hard：此nodeID将会重新生成。 持有数据的（slot映射不为空的）master不能被reset（除非现将此master上的slot手动迁移到其他nodes上，或者手动failover，将其切换成slave）；在某些特定的场景下，在执行reset之前，或许需要执行FLUSHALL来清空原有的数据。 集群中移除节点我们已经知道，将node移除集群之前，首先将其上的slots迁移到其他nodes上（reshard），然后关闭它。不过这似乎还并未结束，因为其他nodes仍然记住了它的ID，仍然会尝试与它建立连接。因此，当我们确定将节点移除集群时，可以使用“CLUSTER FORGET ”指令：1）将此node从nodes映射表中移除。2）然后设定一个60秒的隔离时间，阻止持有相同ID的node再次加入集群。 之所以2）规则，因为FORGET指令将会通过gossip协议传播给其他nodes，集群中所有的节点都收到消息是需要一定的时间延迟。","comments":true,"tags":[{"name":"Redis","slug":"Redis","permalink":"http://jishusuishouji.github.io/tags/Redis/"}]},{"title":"全面剖析Redis Cluster原理和应用","date":"2017-04-02T15:57:30.000Z","path":"2017/04/02/redis/全面剖析Redis_Cluster原理和应用/","text":"1.Redis Cluster总览1.1 设计原则和初衷在官方文档ClusterSpec中，作者详细介绍了Redis集群为什么要设计成现在的样子。最核心的目标有三个： 性能：这是Redis赖以生存的看家本领，增加集群功能后当然不能对性能产生太大影响，所以Redis采取了P2P而非Proxy方式、异步复制、客户端重定向等设计，而牺牲了部分的一致性、使用性。 水平扩展：集群的最重要能力当然是扩展，文档中称可以线性扩展到1000结点。 可用性：在Cluster推出之前，可用性要靠Sentinel保证。有了集群之后也自动具有了Sentinel的监控和自动Failover能力。 1.2 架构变化与CAP理论Redis Cluster集群功能推出已经有一段时间了。在单机版的Redis中，每个Master之间是没有任何通信的，所以我们一般在Jedis客户端或者Codis这样的代理中做Pre-sharding。按照CAP理论来说，单机版的Redis属于保证CP(Consistency &amp; Partition-Tolerancy)而牺牲A(Availability)，也就说Redis能够保证所有用户看到相同的数据（一致性，因为Redis不自动冗余数据）和网络通信出问题时，暂时隔离开的子系统能继续运行（分区容忍性，因为Master之间没有直接关系，不需要通信），但是不保证某些结点故障时，所有请求都能被响应（可用性，某个Master结点挂了的话，那么它上面分片的数据就无法访问了）。 有了Cluster功能后，Redis从一个单纯的NoSQL内存数据库变成了分布式NoSQL数据库，CAP模型也从CP变成了AP。也就是说，通过自动分片和冗余数据，Redis具有了真正的分布式能力，某个结点挂了的话，因为数据在其他结点上有备份，所以其他结点顶上来就可以继续提供服务，保证了Availability。然而，也正因为这一点，Redis无法保证曾经的强一致性了。这也是CAP理论要求的，三者只能取其二。 简单分析了Redis在架构上的变化后，咱们就一起来体验一下Redis Cluster功能吧！ 2.Redis集群初探 Redis的安装很简单，以前已经介绍过，就不详细说了。关于Redis Cluster的基础知识之前也有过整理，请参考《Redis集群功能预览》。如果需要全面的了解，那一定要看官方文档Cluster Tutorial，只看这一个就够了！ 2.1 集群配置 要想开启Redis Cluster模式，有几项配置是必须的。此外为了方便使用和后续的测试，我还额外做了一些配置： 绑定地址：bind 192.168.XXX.XXX。不能绑定到127.0.0.1或localhost，否则指导客户端重定向时会报”Connection refused”的错误。开启Cluster：cluster-enabled yes集群配置文件：cluster-config-file nodes-7000.conf。这个配置文件不是要我们去配的，而是Redis运行时保存配置的文件，所以我们也不可以修改这个文件。集群超时时间：cluster-node-timeout 15000。结点超时多久则认为它宕机了。槽是否全覆盖：cluster-require-full-coverage no。默认是yes，只要有结点宕机导致16384个槽没全被覆盖，整个集群就全部停止服务，所以一定要改为no后台运行：daemonize yes输出日志：logfile “./redis.log”监听端口：port 7000配置好后，根据我们的集群规模，拷贝出来几份同样的配置文件，唯一不同的就是监听端口，可以依次改为7001、7002… 因为Redis Cluster如果数据冗余是1的话，至少要3个Master和3个Slave，所以我们拷贝出6个实例的配置文件。为了避免相互影响，为6个实例的配置文件建立独立的文件夹。 [root@8gVm redis-3.0.4]# pwd/root/Software/redis-3.0.4[root@8gVm redis-3.0.4]# tree -I “log|nodes“ cfg-cluster/cfg-cluster/├── 7000│ └── redis.conf.7000├── 7001│ └── redis.conf.7001├── 7002│ └── redis.conf.7002├── 7003│ └── redis.conf.7003├── 7004│ └── redis.conf.7004└── 7005 └── redis.conf.7005 6 directories, 6 files1234567891011121314151617181234567891011121314151617182.2 redis-trib管理器 Redis作者应该是个Ruby爱好者，Ruby客户端就是他开发的。这次集群的管理功能没有嵌入到Redis代码中，于是作者又顺手写了个叫做redis-trib的管理脚本。redis-trib依赖Ruby和RubyGems，以及redis扩展。可以先用which命令查看是否已安装ruby和rubygems，用gem list –local查看本地是否已安装redis扩展。 最简便的方法就是用apt或yum包管理器安装RubyGems后执行gem install redis。如果网络或环境受限的话，可以手动安装RubyGems和redis扩展（国外链接可能无法下载，可以从CSDN下载）： [root@8gVm Software]# wget https://github.com/rubygems/rubygems/releases/download/v2.2.3/rubygems-2.2.3.tgz[root@8gVm Software]# tar xzvf rubygems-2.2.3.tgz[root@8gVm Software]# cd rubygems-2.2.3[root@8gVm rubygems-2.2.3]# ruby setup.rb –no-rdoc –no-ri [root@8gVm Software]# wget https://rubygems.org/downloads/redis-3.2.1.gem[root@8gVm Software]# gem install redis-3.2.1.gem –local –no-rdoc –no-riSuccessfully installed redis-3.2.11 gem installed1234567891234567892.3 集群建立 首先，启动我们配置好的6个Redis实例。 [root@8gVm redis-3.0.4]# for ((i=0; i&lt;6; ++i)) docd cfg-cluster/700$i &amp;&amp; ../../src/redis-server redis.conf.700$i &amp;&amp; cd -done12341234此时6个实例还没有形成集群，现在用redis-trb.rb管理脚本建立起集群。可以看到，redis-trib默认用前3个实例作为Master，后3个作为Slave。因为Redis基于Master-Slave做数据备份，而非像Cassandra或Hazelcast一样不区分结点角色，自动复制并分配Slot的位置到各个结点。 [root@8gVm redis-3.0.4]# src/redis-trib.rb create –replicas 1 192.168.1.100:7000 192.168.1.100:7001 192.168.1.100:7002 192.168.1.100:7003 192.168.1.100:7004 192.168.1.100:7005 Creating clusterConnecting to node 192.168.1.100:7000: OKConnecting to node 192.168.1.100:7001: OKConnecting to node 192.168.1.100:7002: OKConnecting to node 192.168.1.100:7003: OKConnecting to node 192.168.1.100:7004: OKConnecting to node 192.168.1.100:7005: OKPerforming hash slots allocation on 6 nodes…Using 3 masters:192.168.1.100:7000192.168.1.100:7001192.168.1.100:7002Adding replica 192.168.1.100:7003 to 192.168.1.100:7000Adding replica 192.168.1.100:7004 to 192.168.1.100:7001Adding replica 192.168.1.100:7005 to 192.168.1.100:7002 …Can I set the above configuration? (type ‘yes’ to accept): yesNodes configuration updatedAssign a different config epoch to each nodeSending CLUSTER MEET messages to join the clusterWaiting for the cluster to join….Performing Cluster Check (using node 192.168.1.100:7000) …[OK] All nodes agree about slots configuration.Check for open slots…Check slots coverage…[OK] All 16384 slots covered.1234567891011121314151617181920212223242526272812345678910111213141516171819202122232425262728至此，集群就已经建立成功了！“贴心”的Redis还在utils/create-cluster下提供了一个create-cluster脚本，能够创建出一个集群，类似我们上面建立起的3主3从的集群。 2.4 简单测试 我们连接到集群中的任意一个结点，启动redis-cli时要加-c选项，存取两个Key-Value感受一下Redis久违的集群功能。 [root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000192.168.1.100:7000&gt; set foo bar-&gt; Redirected to slot [12182] located at 192.168.1.100:7002OK192.168.1.100:7002&gt; set hello world-&gt; Redirected to slot [866] located at 192.168.1.100:7000OK192.168.1.100:7000&gt; get foo-&gt; Redirected to slot [12182] located at 192.168.1.100:7002“bar”192.168.1.100:7002&gt; get hello-&gt; Redirected to slot [866] located at 192.168.1.100:7000“world”1234567891011121312345678910111213仔细观察能够注意到，redis-cli根据指示，不断在7000和7002结点之前重定向跳转。如果启动时不加-c选项的话，就能看到以错误形式显示出的MOVED重定向消息。 [root@8gVm redis-3.0.4]# src/redis-cli -h 192.168.1.100 -p 7000192.168.1.100:7000&gt; get foo(error) MOVED 12182 192.168.1.100:70021231232.5 集群重启 目前redis-trib的功能还比较弱，需要重启集群的话先手动kill掉各个进程，然后重新启动就可以了。这也有点太… 网上有人重启后会碰到问题，我还比较幸运，这种“土鳖”的方式重启试了两次还没发现问题。 [root@8gVm redis-3.0.4]# ps -ef | grep redis | awk ‘{print $2}’ | xargs kill113.高级功能尝鲜 说是“高级功能”，其实在其他分布式系统中早就都有实现了，只不过在Redis世界里是比较新鲜的。本部分主要试验一下Redis Cluster中的数据迁移(Resharding)和故障转移功能。 3.1 数据迁移 本小节我们体验一下Redis集群的Resharding功能！ 3.1.1 创建测试数据 首先保存foo1~10共10个Key-Value作为测试数据。 [root@8gVm redis-3.0.4]# for ((i=0; i&lt;10; ++i)) dosrc/redis-cli -c -h 192.168.1.100 -p 7000 set foo$i bardone [root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000192.168.1.100:7000&gt; keys 1) “foo6”2) “foo7”3) “foo3”4) “foo2”192.168.1.100:7000&gt; get foo4-&gt; Redirected to slot [9426] located at 192.168.1.100:7001“bar”192.168.1.100:7001&gt; keys 1) “foo4”2) “foo8”192.168.1.100:7001&gt; get foo5-&gt; Redirected to slot [13555] located at 192.168.1.100:7002“bar”192.168.1.100:7002&gt; keys *1) “foo5”2) “foo1”3) “foo10”4) “foo9”12345678910111213141516171819202122232425123456789101112131415161718192021222324253.1.2 启动新结点 参照之前的方法新拷贝出两份redis.conf配置文件redis.conf.7010和7011，与之前结点的配置文件做一下区分。启动新的两个Redis实例之后，通过redis-trib.rb脚本添加新的Master和Slave到集群中。 [root@8gVm redis-3.0.4]# cd cfg-cluster/7010 &amp;&amp; ../../src/redis-server redis.conf.7010 &amp;&amp; cd -[root@8gVm redis-3.0.4]# cd cfg-cluster/7011 &amp;&amp; ../../src/redis-server redis.conf.7011 &amp;&amp; cd -12123.1.3 添加到集群 使用redis-trib.rb add-node分别将两个新结点添加到集群中，一个作为Master，一个作为其Slave。 [root@8gVm redis-3.0.4]# src/redis-trib.rb add-node 192.168.1.100:7010 192.168.1.100:7000 Adding node 192.168.1.100:7010 to cluster 192.168.1.100:7000Connecting to node 192.168.1.100:7000: OKConnecting to node 192.168.1.100:7001: OKConnecting to node 192.168.1.100:7002: OKConnecting to node 192.168.1.100:7005: OKConnecting to node 192.168.1.100:7003: OKConnecting to node 192.168.1.100:7004: OKPerforming Cluster Check (using node 192.168.1.100:7000) …[OK] All nodes agree about slots configuration.Check for open slots…Check slots coverage…[OK] All 16384 slots covered.Connecting to node 192.168.1.100:7010: OKSend CLUSTER MEET to node 192.168.1.100:7010 to make it join the cluster.[OK] New node added correctly. [root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9 192.168.1.100:7010 master - 0 1442452249525 0 connected … [root@8gVm redis-3.0.4]# src/redis-trib.rb add-node –slave –master-id 0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9 192.168.1.100:7011 192.168.1.100:7000 Adding node 192.168.1.100:7011 to cluster 192.168.1.100:7000Connecting to node 192.168.1.100:7000: OKConnecting to node 192.168.1.100:7010: OKConnecting to node 192.168.1.100:7001: OKConnecting to node 192.168.1.100:7002: OKConnecting to node 192.168.1.100:7005: OKConnecting to node 192.168.1.100:7003: OKConnecting to node 192.168.1.100:7004: OKPerforming Cluster Check (using node 192.168.1.100:7000) …[OK] All nodes agree about slots configuration.Check for open slots…Check slots coverage…[OK] All 16384 slots covered.Connecting to node 192.168.1.100:7011: OKSend CLUSTER MEET to node 192.168.1.100:7011 to make it join the cluster.Waiting for the cluster to join.Configure node as replica of 192.168.1.100:7010.[OK] New node added correctly.1234567891011121314151617181920212223242526272829303132333435363738394041421234567891011121314151617181920212223242526272829303132333435363738394041423.1.4 Resharding 通过redis-trib.rb reshard可以交互式地迁移Slot。下面的例子将5000个Slot从7000~7002迁移到7010上。也可以通过./redis-trib.rb reshard : –from –to –slots –yes在程序中自动完成迁移。 [root@8gVm redis-3.0.4]# src/redis-trib.rb reshard 192.168.1.100:7000Connecting to node 192.168.1.100:7000: OKConnecting to node 192.168.1.100:7010: OKConnecting to node 192.168.1.100:7001: OKConnecting to node 192.168.1.100:7002: OKConnecting to node 192.168.1.100:7005: OKConnecting to node 192.168.1.100:7011: OKConnecting to node 192.168.1.100:7003: OKConnecting to node 192.168.1.100:7004: OK Performing Cluster Check (using node 192.168.1.100:7000)M: b2036adda128b2eeffa36c3a2056444d23b548a8 192.168.1.100:7000 slots:0-5460 (4128 slots) master 1 additional replica(s)M: 0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9 192.168.1.100:7010 slots:0 (4000 slots) master 1 additional replica(s) …[OK] All nodes agree about slots configuration.Check for open slots…Check slots coverage…[OK] All 16384 slots covered.How many slots do you want to move (from 1 to 16384)? 5000What is the receiving node ID? 0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9Please enter all the source node IDs. Type ‘all’ to use all the nodes as source nodes for the hash slots. Type ‘done’ once you entered all the source nodes IDs.Source node #1:all [root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9 192.168.1.100:7010 master - 0 1442455872019 7 connected 0-1332 5461-6794 10923-12255b2036adda128b2eeffa36c3a2056444d23b548a8 192.168.1.100:7000 myself,master - 0 0 1 connected 1333-5460b5ab302f5c2395e3c8194c354a85d02f89bace62 192.168.1.100:7001 master - 0 1442455875022 2 connected 6795-109220c565e207ce3118470fd5ed3c806eb78f1fdfc01 192.168.1.100:7002 master - 0 1442455874521 3 connected 12256-16383 …1234567891011121314151617181920212223242526272829303132333412345678910111213141516171819202122232425262728293031323334迁移完成后，查看之前保存的foo1~10的分布情况，可以看到部分Key已经迁移到了新的结点7010上。 [root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 keys ““1) “foo3”2) “foo7”[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7001 keys ““1) “foo4”2) “foo8”3) “foo0”[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7002 keys ““1) “foo1”2) “foo9”3) “foo5”[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7010 keys ““1) “foo6”2) “foo2”123456789101112131412345678910111213143.2 故障转移 在高可用性方面，Redis可算是能够”Auto”一把了！Redis Cluster重用了Sentinel的代码逻辑，不需要单独启动一个Sentinel集群，Redis Cluster本身就能自动进行Master选举和Failover切换。 下面我们故意kill掉7010结点，之后可以看到结点状态变成了fail，而Slave 7011被选举为新的Master。 [root@8gVm redis-3.0.4]# kill 43637 [root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9 192.168.1.100:7010 master,fail - 1442456829380 1442456825674 7 disconnectedb2036adda128b2eeffa36c3a2056444d23b548a8 192.168.1.100:7000 myself,master - 0 0 1 connected 1333-5460b5ab302f5c2395e3c8194c354a85d02f89bace62 192.168.1.100:7001 master - 0 1442456848722 2 connected 6795-109220c565e207ce3118470fd5ed3c806eb78f1fdfc01 192.168.1.100:7002 master - 0 1442456846717 3 connected 12256-163835a3c67248b1df554fbf2c93112ba429f31b1d3d1 192.168.1.100:7005 slave 0c565e207ce3118470fd5ed3c806eb78f1fdfc01 0 1442456847720 6 connected99bff22b97119cf158d225c2b450732a1c0d3c44 192.168.1.100:7011 master - 0 1442456849725 8 connected 0-1332 5461-6794 10923-12255cd305d509c34842a8047e19239b64df94c13cb96 192.168.1.100:7003 slave b2036adda128b2eeffa36c3a2056444d23b548a8 0 1442456848220 4 connected64b544cdd75c1ce395fb9d0af024b7f2b77213a3 192.168.1.100:7004 slave b5ab302f5c2395e3c8194c354a85d02f89bace62 0 1442456845715 5 connected12345678910111234567891011尝试查询之前保存在7010上的Key，可以看到7011顶替上来继续提供服务，整个集群没有受到影响。 [root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 get foo6“bar”[root@8gVm redis-3.0.4]#[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 get foo2“bar”12345123454.内部原理剖析 前面我们已经学习过，用Redis提供的redis-trib或create-cluster脚本能几步甚至一步就建立起一个Redis集群。这一部分我们为了深入学习，所以要暂时抛开这些方便的工具，完全手动建立一遍上面的3主3从集群。 4.1 集群发现：MEET 最开始时，每个Redis实例自己是一个集群，我们通过cluster meet让各个结点互相“握手”。这也是Redis Cluster目前的一个欠缺之处：缺少结点的自动发现功能。 [root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes33c0bd93d7c7403ef0239ff01eb79bfa15d2a32c :7000 myself,master - 0 0 0 connected [root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster meet 192.168.1.100 7001OK …[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster meet 192.168.1.100 7005OK [root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes7b953ec26bbdbf67179e5d37e3cf91626774e96f 192.168.1.100:7003 master - 0 1442466369259 4 connected5d9f14cec1f731b6477c1e1055cecd6eff3812d4 192.168.1.100:7005 master - 0 1442466368659 4 connected33c0bd93d7c7403ef0239ff01eb79bfa15d2a32c 192.168.1.100:7000 myself,master - 0 0 1 connected63162ed000db9d5309e622ec319a1dcb29a3304e 192.168.1.100:7001 master - 0 1442466371262 3 connected45baa2cb45435398ba5d559cdb574cfae4083893 192.168.1.100:7002 master - 0 1442466372264 2 connectedcdd5b3a244761023f653e08cb14721f70c399b82 192.168.1.100:7004 master - 0 1442466370261 0 connecte12345678910111213141516123456789101112131415164.2 角色设置：REPLICATE 结点全部“握手”成功后，就可以用cluster replicate命令为结点指定角色了，默认每个结点都是Master。 [root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7003 cluster replicate 33c0bd93d7c7403ef0239ff01eb79bfa15d2a32cOK[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7004 cluster replicate 63162ed000db9d5309e622ec319a1dcb29a3304eOK[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7005 cluster replicate 45baa2cb45435398ba5d559cdb574cfae4083893OK [root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes7b953ec26bbdbf67179e5d37e3cf91626774e96f 192.168.1.100:7003 slave 33c0bd93d7c7403ef0239ff01eb79bfa15d2a32c 0 1442466812984 4 connected5d9f14cec1f731b6477c1e1055cecd6eff3812d4 192.168.1.100:7005 slave 45baa2cb45435398ba5d559cdb574cfae4083893 0 1442466813986 5 connected33c0bd93d7c7403ef0239ff01eb79bfa15d2a32c 192.168.1.100:7000 myself,master - 0 0 1 connected63162ed000db9d5309e622ec319a1dcb29a3304e 192.168.1.100:7001 master - 0 1442466814987 3 connected45baa2cb45435398ba5d559cdb574cfae4083893 192.168.1.100:7002 master - 0 1442466811982 2 connectedcdd5b3a244761023f653e08cb14721f70c399b82 192.168.1.100:7004 slave 63162ed000db9d5309e622ec319a1dcb29a3304e 0 1442466812483 3 connected123456789101112131412345678910111213144.3 槽指派：ADDSLOTS 设置好主从关系之后，就可以用cluster addslots命令指派16384个槽的位置了。有点恶心的是，ADDSLOTS命令需要在参数中一个个指明槽的ID，而不能指定范围。这里用Bash 3.0的特性简化了，不然就得用Bash的循环来完成了： [root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster addslots {0..5000}OK[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7001 cluster addslots {5001..10000}OK[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7001 cluster addslots {10001..16383}OK [root@8gVm redis-3.0.4]# src/redis-trib.rb check 192.168.1.100:7000Connecting to node 192.168.1.100:7000: OK … Performing Cluster Check (using node 192.168.1.100:7000) …[OK] All nodes agree about slots configuration.Check for open slots…Check slots coverage…[OK] All 16384 slots covered.1234567891011121314151612345678910111213141516这样我们就通过手动执行命令得到了与之前一样的集群。 4.4 数据迁移：MIGRATE 真正开始Resharding之前，redis-trib会先在源结点和目的结点上执行cluster setslot importing和cluster setslot migrating命令，将要迁移的槽分别标记为迁出中和导入中的状态。然后，执行cluster getkeysinslot获得Slot中的所有Key。最后就可以对每个Key执行migrate命令进行迁移了。槽迁移完成后，执行cluster setslot命令通知整个集群槽的指派已经发生变化。 关于迁移过程中的数据访问，客户端访问源结点时，如果Key还在源结点上就直接操作。如果已经不在源结点了，就向客户端返回一个ASK错误，将客户端重定向到目的结点。 4.5 内部数据结构 Redis Cluster功能涉及三个核心的数据结构clusterState、clusterNode、clusterLink都在cluster.h中定义。这三个数据结构中最重要的属性就是：clusterState.slots、clusterState.slots_to_keys和clusterNode.slots了，它们保存了三种映射关系： clusterState：集群状态nodes：所有结点migrating_slots_to：迁出中的槽importing_slots_from：导入中的槽slots_to_keys：槽中包含的所有Key，用于迁移Slot时获得其包含的Keyslots：Slot所属的结点，用于处理请求时判断Key所在Slot是否自己负责clusterNode：结点信息slots：结点负责的所有Slot，用于发送Gossip消息通知其他结点自己负责的Slot。通过位图方式保存节省空间，16384/8恰好是2048字节，所以槽总数16384不是随意定的。clusterLink：与其他结点通信的连接// 集群状态，每个节点都保存着一个这样的状态，记录了它们眼中的集群的样子。// 另外，虽然这个结构主要用于记录集群的属性，但是为了节约资源，// 有些与节点有关的属性，比如 slots_to_keys 、 failover_auth_count// 也被放到了这个结构里面。typedef struct clusterState { … // 指向当前节点的指针 clusterNode myself; / This node */ // 集群当前的状态：是在线还是下线 int state; /* REDIS_CLUSTER_OK, REDIS_CLUSTER_FAIL, ... */ // 集群节点名单（包括 myself 节点） // 字典的键为节点的名字，字典的值为 clusterNode 结构 dict *nodes; /* Hash table of name -&gt; clusterNode structures */ // 记录要从当前节点迁移到目标节点的槽，以及迁移的目标节点 // migrating_slots_to[i] = NULL 表示槽 i 未被迁移 // migrating_slots_to[i] = clusterNode_A 表示槽 i 要从本节点迁移至节点 A clusterNode *migrating_slots_to[REDIS_CLUSTER_SLOTS]; // 记录要从源节点迁移到本节点的槽，以及进行迁移的源节点 // importing_slots_from[i] = NULL 表示槽 i 未进行导入 // importing_slots_from[i] = clusterNode_A 表示正从节点 A 中导入槽 i clusterNode *importing_slots_from[REDIS_CLUSTER_SLOTS]; // 负责处理各个槽的节点 // 例如 slots[i] = clusterNode_A 表示槽 i 由节点 A 处理 clusterNode *slots[REDIS_CLUSTER_SLOTS]; // 跳跃表，表中以槽作为分值，键作为成员，对槽进行有序排序 // 当需要对某些槽进行区间（range）操作时，这个跳跃表可以提供方便 // 具体操作定义在 db.c 里面 zskiplist *slots_to_keys; ... } clusterState; // 节点状态struct clusterNode { … // 节点标识 // 使用各种不同的标识值记录节点的角色（比如主节点或者从节点）， // 以及节点目前所处的状态（比如在线或者下线）。 int flags; / REDISNODE… / // 由这个节点负责处理的槽 // 一共有 REDIS_CLUSTER_SLOTS / 8 个字节长 // 每个字节的每个位记录了一个槽的保存状态 // 位的值为 1 表示槽正由本节点处理，值为 0 则表示槽并非本节点处理 // 比如 slots[0] 的第一个位保存了槽 0 的保存情况 // slots[0] 的第二个位保存了槽 1 的保存情况，以此类推 unsigned char slots[REDIS_CLUSTER_SLOTS/8]; /* slots handled by this node */ // 指针数组，指向各个从节点 struct clusterNode **slaves; /* pointers to slave nodes */ // 如果这是一个从节点，那么指向主节点 struct clusterNode *slaveof; /* pointer to the master node */ ... }; / clusterLink encapsulates everything needed to talk with a remote node. /// clusterLink 包含了与其他节点进行通讯所需的全部信息typedef struct clusterLink { … // TCP 套接字描述符 int fd; / TCP socket file descriptor / // 与这个连接相关联的节点，如果没有的话就为 NULL struct clusterNode *node; /* Node related to this link if any, or NULL */ ... } clusterLink;1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071721234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071724.6 处理流程全梳理 在单机模式下，Redis对请求的处理很简单。Key存在的话，就执行请求中的操作；Key不存在的话，就告诉客户端Key不存在。然而在集群模式下，因为涉及到请求重定向和Slot迁移，所以对请求的处理变得很复杂，流程如下： 检查Key所在Slot是否属于当前Node？2.1 计算crc16(key) % 16384得到Slot2.2 查询clusterState.slots负责Slot的结点指针2.3 与myself指针比较若不属于，则响应MOVED错误重定向客户端若属于且Key存在，则直接操作，返回结果给客户端若Key不存在，检查该Slot是否迁出中？(clusterState.migrating_slots_to)若Slot迁出中，返回ASK错误重定向客户端到迁移的目的服务器上若Slot未迁出，检查Slot是否导入中？(clusterState.importing_slots_from)若Slot导入中且有ASKING标记，则直接操作否则响应MOVED错误重定向客户端5.应用案例收集 5.1 有道：Redis Cluster使用经验 详情请参见原文，关键内容摘录如下： 5.1.1 两个缺点 “redis cluster的设计在这块有点奇葩，跟集群相关的操作需要一个外部的ruby脚本来协助（当然可能是为了让主程序的代码足够简洁？），然后那个脚本还只支持填实例的ip不支持host，还不告诉你不支持让你用host之后各种莫名其妙。” “第一个缺点就是严格依赖客户端driver的成熟度。如果把redis cluster设计成类似Cassandra，请求集群中任何一个节点都可以负责转发请求，client会好写一些。” “第二个缺点完全是设计问题了，就是一个redis进程既负责读写数据又负责集群交互，虽然设计者已经尽可能简化了代码和逻辑，但还是让redis从一个内存NoSQL变成了一个分布式NoSQL。分布式系统很容易有坑，一旦有坑必须升级redis。” 5.1.2 去中心化 vs. Proxy “关于redis cluster的设计，Gossip/P2P的去中心化架构本身不是问题，但一旦有了中心节点，能做的事情就多了，比如sharding不均匀是很容易自动rebalance的，而无中心的只能靠外界来搞。然后redis cluster又是slot的形式而非C*式的一致性哈希，新节点分slot又不自动，依赖外界（ruby脚本）来分配显得不方便更不优美和谐。而且因为是master-slave的系统而非W+R&gt;N的那种，master挂掉之后尽快发现是比较重要的，gossip对于节点挂掉的发现终究没有中心节点/zookeeper方便快速。” “基于proxy做转发意味着屏蔽了下层存储，完全可以根据前缀/tag/冷热程度，来把部分甚至大多数数据放在磁盘从而节约成本又保证一致性，这都是有中心节点所带来的好处。” 5.2 奇虎360：Redis Cluster浅析和Bada对比 详情请参见原文，关键内容摘录如下： 5.2.1 负载均衡问题 “redis cluster的主备是以节点为单位，而bada则是以partition为单位，这样，同样是3个节点，1024个partition的情况下，redis cluster的主节点负责整个1024个partition的服务，而两个从节点则只负责异步备份，导致集群负载不均，再看bada，将1024个partition的主均分到3个节点中，每个节点各有主备，主对外提供服务，这样均分了访问压力，有效的利用了资源。” 5.2.2 一致性的保证 “redis cluster与bada一样，最终一致性，读写都只请求主节点，当一条写请求在对应的主节点写成功后，会立刻返回给客户端成功，然后主节点通过异步的方式将新的数据同步到对应的从节点，这样的方式减少了客户端多个节点写成功等待的时间，不过在某些情况下会造成写丢失： 1）当主节点接受一条写请求，写入并返回给客户端成功后不幸宕掉，此时刚才的写还未同步给其对应的从节点，而从节点在发现主节点挂掉并重新选主后，新的主节点则永久丢失了之前老的主节点向用户确认的写 2）当网络发生割裂，将集群分裂成少数派与多数派，这样在客户端不知情的情况下，会将写继续写入到少数派中的某些主节点中，而当割裂超过一定时长后，集群感知到异常，此时少数派中的所有主节点会停止响应所有的写请求，多数派的其对应的从节点则会发起选举成为新的主节点，假设过了一会后割裂恢复，老的主节点发现有更新的主存在，自动变成其从节点，而新的主节点中则会永久丢失掉网络割裂至集群感知异常进行切主这个阶段老主节点确认的所有写 相对于redis cluster的永久丢失，bada通过binlog merge有效的解决了这一问题。所有partition的主节点在响应客户端的写请求时，都会在本地记录binlog，binlog实质就是带有时间戳的KV对。当老主以从节点的身份重新加入集群时，会触发binlog merge操作，新主会比较并且合并二者的binlog，这样就可以将之前丢失掉得写再补回来。” 5.2.3 请求重定向问题 “bada服务端节点在收到本不该由自己负责的Partition请求后，不会向客户端返回重定向信息，而是通过代理的方式，直接在集群内部向正确节点转发客户端的请求，并将结果同meta信息再转发回客户端。” “再看multi key操作，redis cluster为了追求高性能，支持multi key的前提是所有的key必须在同一个节点中, 不过这样的处理需要交给用户，对需要进行multi key操作的所有key，在写入前人为的加上hash tags。当redis cluster进行resharding的时候，也就是将某些slot从一个节点迁移到另一个节点时，此时的multi key操作可能会失败，因为在迁移的slot中的key此时存在于两个节点。 bada怎么做呢？用户如果对multi key操作性能很在乎时，可以采用与redis cluster同样的方式，给这些key加上hash tags来让它们落在同一个节点，如果可以接受性能的稍微损耗而解放用户的处理逻辑，则可以像single key操作一样，请求任一bada节点，它会代理所有的key请求并将结果返回给用户。并且在multi key操作在任何时候都可以，即使在进行partition的迁移，bada也会提前进行切主，保证服务的正常提供。” 5.3 芒果TV：Redis服务解决方案 详情请参见原文，关键内容摘录如下： 芒果TV在Redis Cluster基础上进行开发，主要增加了两个组件： 监控管理：以Python为主要开发框架的Web应用程序Redis-ctl请求代理：以C++11为开发语言的轻量数据代理程序cerberus。其作用和优点为：集群代理程序的自动请求分发/重试机制使得应用不必修改自身代码或更新Redis库代理节点为所有Redis节点加上统一管理和状态监测, 可以查阅历史数据, 或在发生任何问题之后快速响应修复代理进程的无状态性使之可在故障后快速恢复, 不影响后端集群数据完整性这两个组件都已开源到GitHub上，大家可以关注一下！ 6.Pros &amp; Cons总结 关于Redis Cluster带来的种种优势就不说了，在这里主要是“鸡蛋里挑骨头”，总结一下现阶段集群功能的欠缺之处和可能的“坑”。 6.1 无中心化架构 6.1.1 Gossip消息 Gossip消息的网络开销和时延是决定Redis Cluster能够线性扩展的因素之一。关于这个问题，在《redis cluster百万QPS的挑战》一文中有所提及。 6.1.2 结点粒度备份 此外，Redis Cluster也许是为了简化设计采用了Master-Slave复制的数据备份方案，并没有采取如Cassandra或IMDG等对等分布式系统中常见的Slot粒度（或叫Partition/Bucket等）的自动冗余和指派。 这种设计虽然避免比较复杂的分布式技术，但也带来了一些问题： Slave完全闲置：即便是读请求也不会被重定向到Slave结点上，Slave属于“冷备”写压力无法分摊：Slave闲置导致的另一个问题就是写压力也都在Master上6.2 客户端的挑战 由于Redis Cluster的设计，客户端要担负起一部分责任： Cluster协议支持：不管Dummy还是Smart模式，都要具备解析Cluster协议的能力网络开销：Dummy客户端不断重定向的网络开销连接维护：Smart客户端对连接到集群中每个结点Socket的维护缓存路由表：Smart客户端Slot路由表的缓存和更新内存消耗：Smart客户端上述维护的信息都是有内存消耗的MultiOp有限支持：对于MultiOp，由客户端通过KeyTag保证所有Key都在同一Slot。而即便如此，迁移时也会导致MultiOp失败。同理，对Pipeline和Transaction的支持也受限于必须操作同一Slot内的Key。6.3 Redis实现问题 尽管属于无中心化架构一类的分布式系统，但不同产品的细节实现和代码质量还是有不少差异的，就比如Redis Cluster有些地方的设计看起来就有一些“奇葩”和简陋： 不能自动发现：无Auto Discovery功能。集群建立时以及运行中新增结点时，都要通过手动执行MEET命令或redis-trib.rb脚本添加到集群中不能自动Resharding：不仅不自动，连Resharding算法都没有，要自己计算从哪些结点上迁移多少Slot，然后还是得通过redis-trib.rb操作严重依赖外部redis-trib：如上所述，像集群健康状况检查、结点加入、Resharding等等功能全都抽离到一个Ruby脚本中了。还不清楚上面提到的缺失功能未来是要继续加到这个脚本里还是会集成到集群结点中？redis-trib也许要变成Codis中Dashboard的角色无监控管理UI：即便未来加了UI，像迁移进度这种信息在无中心化设计中很难得到只保证最终一致性：写Master成功后立即返回，如需强一致性，自行通过WAIT命令实现。但对于“脑裂”问题，目前Redis没提供网络恢复后的Merge功能，“脑裂”期间的更新可能丢失6.4 性能损耗 由于之前手头没有空闲的物理机资源，所以只在虚拟机上做了简单的单机测试，在单独的一台压力机使用YCSB测试框架向虚拟机产生读写负载。虚拟机的配置为8核Intel Xeon CPU X5650@2.67GHz，16GB内存，分别搭建了4结点的单机版Redis和集群版Redis，测试一下Redis Cluster的性能损耗。由于不是最近做的测试，所以Jedis用的2.6.2版本。注：当然Redis Cluster可以通过多机部署获得水平扩展带来的性能提升，这里只是由于环境有限所以做的简单单机测试。 由于YCSB本身仅支持Redis单机版，所以需要我们自己增加扩展插件，具体方法请参照《YCSB性能测试工具使用》。通过YCSB产生2000w随机数据，Value大约100Byte左右。然后通过YCSB测试Read-Mostly(90% Read)和Read-Write-Mixed(50% Read)两种情况： 数据加载：吞吐量上有约18%的下降。Read-Mostly：吞吐量上有约3.5%~7.9%的下降。Read-Write-Mixed：吞吐量上有约3.3%~5.5%下降。内存占用：Jedis客户端多占用380MB内存。6.5 最后的总结 从现阶段看来，相比Sentinel或Codis等方案，Redis Cluster的优势还真是有限，个人觉得最大的优点有两个： 官方提供的Slot实现而不用像Codis那样去改源码了；不用额外的Sentinel集群或类似的代码实现了。同其他分布式系统，如Cassandra，或内存型的IMDG如Hazelcast和GridGain，除了性能方面外，从功能上Redis Cluster简直被爆得体无完肤… 看看我之前总结过的GridGain介绍《开源IMDG之GridGain》： 结点自动发现和Rebalance分区粒度的备份故障时分区角色自动调整结果聚合（不会重定向客户端）“脑裂”恢复后的Merge（Hazelcast支持多种合并策略）多Primary分区写操作（见Replicated模式）这些都是Redis Cluster没有或者要手动完成的。当然这也不足为奇，因为这与Redis的设计初衷有关，毕竟作者都已经说了，最核心的设计目标就是性能、水平伸缩和可用性。 从Redis Cluster的环境搭建使用到高级功能和内部原理剖析，再到应用案例收集和优缺点的分析罗列，讲了这么多，关于Redis集群到底如何，相信大家根据自己切身和项目的具体情况一定有了自己的结论。不管是评估测试也好，二次开发也好，还是直接上线使用也好，相信随着官方的不断迭代更新和大家的力量，Redis Cluster一定会逐渐完善成熟的！ 顶13 踩0 上一篇操作系统内核Hack：(一)实验环境搭建下一篇Redis Cluster架构优化我的同类文章Redis（13）•Redis Cluster架构优化2015-09-25阅读11969•Redis监控工具,命令和调优2015-08-16阅读15729•豌豆夹Redis解决方案Codis安装使用2015-07-25阅读17653•用Netty解析Redis网络协议2015-06-19阅读4886•Redis源码学习：Lua脚本2015-05-22阅读2327•Jedis分片Sentinel连接池实验2015-08-29阅读6353•豌豆夹Redis解决方案Codis源码剖析：Dashboard2015-08-08阅读4675•豌豆夹Redis解决方案Codis源码剖析：Proxy代理2015-07-03阅读8979•Redis源码学习：字符串2015-05-30阅读1772•Redis集群功能预览2015-02-28阅读4059更多文章参考知识库imgPython知识库22194关注|1364收录imgC++知识库9249关注|1393收录imgRedis知识库5139关注|738收录img软件测试知识库4272关注|318收录imgMySQL知识库21472关注|1448收录img算法与数据结构知识库15138关注|2320收录img大型网站架构知识库8321关注|708收录猜你在找","comments":true,"tags":[{"name":"redis","slug":"redis","permalink":"http://jishusuishouji.github.io/tags/redis/"}]},{"title":"Hibernate缓存 查询缓存","date":"2017-03-30T05:58:14.000Z","path":"2017/03/30/hibernate/Hibernate缓存_查询缓存/","text":"网上说query.setCacheable(true)或criteria.setCacheable(true)`` 这两种方式的缓存命中率低，个人认为谈论这个“无卵用”； 我在测试的时候发现，上面的操作会受配置的限制，必须在配置文件中打开hibernate.cache.use_query_cache=true，之后setCacheable`才起作用； 查询缓存可以解决二级缓存的不足；它的作用范围也是SessionFactory； 可以缓存hql语句查询，也可以缓存query和criteria查询； 下面针对query和criteria进行测试：1234567891011121314151617181920212223242526/** * 对查询缓存测试 &lt;br&gt; * 1. 只有B处起作用，作用于session; &lt;br&gt; * 2. 配置文件中打开query_cache的前提下，setCacheable 是起作用的 */@Testpublic void testCriteriaInCache() &#123; System.out.println(&quot;=============&quot;); Session session = hibernateTemplate.getSessionFactory().openSession(); Criteria criteria = session.createCriteria(UserModel.class); criteria.setCacheable(true); // 这里仅对B处起作用 criteria.add(Restrictions.eq(&quot;name&quot;, &quot;Sucre&quot;)); System.out.println(&quot;=============A&quot; + criteria.list()); System.out.println(&quot;=============B&quot; + criteria.list()); // B criteria.add(Restrictions.eq(&quot;id&quot;, 1)); System.out.println(&quot;=============C&quot; + criteria.list()); criteria = session.createCriteria(UserModel.class); criteria.setCacheable(true); criteria.add(Restrictions.eq(&quot;id&quot;, 1)); System.out.println(&quot;=============D&quot; + criteria.list()); session = hibernateTemplate.getSessionFactory().openSession(); criteria = session.createCriteria(UserModel.class); criteria.setCacheable(true); criteria.add(Restrictions.eq(&quot;id&quot;, 1)); System.out.println(&quot;=============E&quot; + criteria.list());&#125; 1234567891011121314151617181920212223242526272829/** * 测试查询缓存 &lt;br&gt; * 1. BC两处都是使用的A产生的缓存，作用于SessionFactory &lt;br&gt; * 2. 配置文件中打开query_cache的前提下，setCacheable 是起作用的 */@Testpublic void testQueryInCache() &#123; System.out.println(&quot;=============&quot;); Session session = hibernateTemplate.getSessionFactory().openSession(); Query query = session .createQuery(&quot;select u.name from UserModel as u where u.id=?&quot;); query.setParameter(0, 1); query.setCacheable(true); String name = (String) query.list().get(0); System.out.println(&quot;=============A&quot; + name); // A query = session .createQuery(&quot;select u.name from UserModel as u where u.id=?&quot;); query.setParameter(0, 1); query.setCacheable(true); name = (String) query.list().get(0); System.out.println(&quot;=============B&quot; + name); // B session = hibernateTemplate.getSessionFactory().openSession(); query = session .createQuery(&quot;select u.name from UserModel as u where u.id=?&quot;); query.setParameter(0, 1); query.setCacheable(true); name = (String) query.list().get(0); System.out.println(&quot;=============C&quot; + name); // C&#125;","comments":true,"tags":[{"name":"hibernate","slug":"hibernate","permalink":"http://jishusuishouji.github.io/tags/hibernate/"}]},{"title":"hibernate的查询缓存","date":"2017-03-30T05:47:52.000Z","path":"2017/03/30/hibernate/hibernate的查询缓存/","text":"hibernate的查询缓存主要是针对普通属性结果集的缓存，而对于实体对象的结果集只缓存id。在一级缓存,二级缓存和查询缓存都打开的情况下做查询操作时这样的：查询普通属性，会先到查询缓存中取，如果没有，则查询数据库；查询实体，会先到查询缓存中取id，如果有，则根据id到缓存(一级/二级)中取实体，如果缓存中取不到实体，再查询数据库。 和一级/二级缓存不同，查询缓存的生命周期是不确定的，当前关联的表发生改变时，查询缓存的生命周期结束。查询缓存的配置和使用也是很简单的：1&gt;查询缓存的启用不但要在配置文件中进行配置1&lt;property name=&quot;hibernate.cache.use_query_cache&quot;&gt;true&lt;/property&gt; 2&gt;还要在程序中显示的进行启用1query.setCacheable(true); 1&gt;查询缓存的启用不但要在配置文件中进行配置 ——-换成spring配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;bean id=&quot;propertyConfigurer&quot; class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt; &lt;property name=&quot;locations&quot;&gt; &lt;list&gt; &lt;value&gt;/WEB-INF/config/jdbc.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt; &lt;property name=&quot;driverClass&quot; value=&quot;$&#123;jdbc.driverClassName&#125;&quot; /&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;$&#123;jdbc.url&#125;&quot; /&gt; &lt;property name=&quot;user&quot; value=&quot;$&#123;jdbc.username&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot; /&gt; &lt;property name=&quot;autoCommitOnClose&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;checkoutTimeout&quot; value=&quot;$&#123;cpool.checkoutTimeout&#125;&quot;/&gt; &lt;property name=&quot;initialPoolSize&quot; value=&quot;$&#123;cpool.minPoolSize&#125;&quot;/&gt; &lt;property name=&quot;minPoolSize&quot; value=&quot;$&#123;cpool.minPoolSize&#125;&quot;/&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;$&#123;cpool.maxPoolSize&#125;&quot;/&gt; &lt;property name=&quot;maxIdleTime&quot; value=&quot;$&#123;cpool.maxIdleTime&#125;&quot;/&gt; &lt;property name=&quot;acquireIncrement&quot; value=&quot;$&#123;cpool.acquireIncrement&#125;&quot;/&gt; &lt;property name=&quot;maxIdleTimeExcessConnections&quot; value=&quot;$&#123;cpool.maxIdleTimeExcessConnections&#125;&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;sessionFactory&quot; class=&quot;org.springframework.orm.hibernate3.LocalSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;property name=&quot;mappingLocations&quot;&gt; &lt;list&gt; &lt;value&gt;classpath*:/com/jeecms/core/entity/hbm/*.hbm.xml&lt;/value&gt; &lt;value&gt;classpath*:/com/jeecms/cms/entity/main/hbm/*.hbm.xml&lt;/value&gt; &lt;value&gt;classpath*:/com/jeecms/cms/entity/assist/hbm/*.hbm.xml&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name=&quot;hibernateProperties&quot;&gt; &lt;value&gt; hibernate.dialect=org.hibernate.dialect.MySQLInnoDBDialect hibernate.show_sql=false hibernate.format_sql=false hibernate.query.substitutions=true 1, false 0 hibernate.jdbc.batch_size=20 //查询缓存配置 hibernate.cache.use_query_cache=true &lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;entityInterceptor&quot;&gt; &lt;ref local=&quot;treeInterceptor&quot;/&gt; &lt;/property&gt; &lt;property name=&quot;cacheProvider&quot;&gt; &lt;ref local=&quot;cacheProvider&quot;/&gt; &lt;/property&gt; &lt;property name=&quot;lobHandler&quot;&gt; &lt;ref bean=&quot;lobHandler&quot; /&gt; &lt;/property&gt;&lt;/bean&gt; 2&gt;还要在程序中显示的进行启用1234public List&lt;CmsSite&gt; getList(boolean cacheable) &#123; String hql = &quot;from CmsSite bean order by bean.id asc&quot;; return getSession().createQuery(hql).setCacheable(cacheable).list(); &#125; 1.实体类：public class Student { private Integer id; private String name; //一系列的setter.getter方法 } ##2.映射文件 Student.hbm.xml1234567891011&lt;class name=&quot;com.sxt.hibernate.cache.entity.Student&quot; table=&quot;sxt_hibernate_student&quot;&gt; &lt;!-- 指定本类的对象使用二级缓存(这也可以放在hibernate.cfg.xml中统一指定) --&gt; &lt;!-- &lt;cache usage=&quot;read-only&quot;/&gt; --&gt; &lt;id name=&quot;id&quot; length=&quot;4&quot;&gt; &lt;generator class=&quot;native&quot;&gt;&lt;/generator&gt; &lt;/id&gt; &lt;property name=&quot;name&quot; length=&quot;10&quot;&gt;&lt;/property&gt; &lt;/class&gt; 3.hibernate配置文件：hibernate.cfg.xml &lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;property name=&quot;hibernate.connection.url&quot;&gt;jdbc:oracle:thin:@localhost:1521:ORCL10&lt;/property&gt; &lt;property name=&quot;hibernate.connection.driver_class&quot;&gt;oracle.jdbc.driver.OracleDriver&lt;/property&gt; &lt;property name=&quot;hibernate.connection.username&quot;&gt;scott&lt;/property&gt; &lt;property name=&quot;hibernate.connection.password&quot;&gt;yf123&lt;/property&gt; &lt;property name=&quot;hibernate.dialect&quot;&gt;org.hibernate.dialect.Oracle9Dialect&lt;/property&gt; &lt;property name=&quot;hibernate.show_sql&quot;&gt;true&lt;/property&gt; &lt;!-- 开启二级缓存,其实hibernate默认就是开启的,这里显示的指定一下 --&gt; &lt;property name=&quot;hibernate.cache.use_second_level_cache&quot;&gt;true&lt;/property&gt; &lt;!-- 指定二级缓存产品的提供商 --&gt; &lt;property name=&quot;hibernate.cache.provider_class&quot;&gt;org.hibernate.cache.EhCacheProvider&lt;/property&gt; &lt;!-- 启用查询缓存 --&gt; &lt;property name=&quot;hibernate.cache.use_query_cache&quot;&gt;true&lt;/property&gt; &lt;mapping resource=&quot;com/sxt/hibernate/cache/entity/Student.hbm.xml&quot;/&gt; &lt;!-- 指定那些类使用二级缓存 --&gt; &lt;class-cache usage=&quot;read-only&quot; class=&quot;com.sxt.hibernate.cache.entity.Student&quot;/&gt; &lt;/session-factory&gt; &lt;/hibernate-configuration&gt; 4.测试方法：1234567891011121314151617181920212223242526272829303132333435363738public static void main(String[] args) &#123; Session session = null; Transaction t = null; *//** * 开启查询缓存,关闭二级缓存, 开启一个session,分别调用query.list */ //如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. /* try &#123; session = HibernateUtils.getSession(); t = session.beginTransaction(); Query query = session.createQuery(&quot;select s.name from Student s&quot;); //启用查询缓存 query.setCacheable(true); List&lt;String&gt; names = query.list(); for (Iterator&lt;String&gt; it = names.iterator(); it.hasNext();) &#123; String name = it.next(); System.out.println(name); &#125; System.out.println(&quot;================================&quot;); query = session.createQuery(&quot;select s.name from Student s&quot;); //启用查询缓存 query.setCacheable(true); //没有发出查询语句,因为这里使用的查询缓存 names = query.list(); for (Iterator&lt;String&gt; it = names.iterator(); it.hasNext();) &#123; String name = it.next(); System.out.println(name); &#125; t.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); t.rollback(); &#125; finally &#123; HibernateUtils.closeSession(session); &#125; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@SuppressWarnings(&quot;unchecked&quot;) public static void main(String[] args) &#123; Session session = null; Transaction t = null; *//** * 开启查询缓存,关闭二级缓存, 开启两个session,分别调用query.list *//* //如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. try &#123; session = HibernateUtils.getSession(); t = session.beginTransaction(); Query query = session.createQuery(&quot;select s.name from Student s&quot;); //启用查询缓存 //query.setCacheable(true); List&lt;String&gt; names = query.list(); for (Iterator&lt;String&gt; it = names.iterator(); it.hasNext();) &#123; String name = it.next(); System.out.println(name); &#125; t.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); t.rollback(); &#125; finally &#123; HibernateUtils.closeSession(session); &#125; System.out.println(&quot;================================&quot;); try &#123; session = HibernateUtils.getSession(); t = session.beginTransaction(); Query query = session.createQuery(&quot;select s.name from Student s&quot;); //启用查询缓存 //query.setCacheable(true); //不会发出查询语句,因为查询缓存和session无关. List&lt;String&gt; names = query.list(); for (Iterator&lt;String&gt; it = names.iterator(); it.hasNext();) &#123; String name = it.next(); System.out.println(name); &#125; t.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); t.rollback(); &#125; finally &#123; HibernateUtils.closeSession(session); &#125; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@SuppressWarnings(&quot;unchecked&quot;) public static void main(String[] args) &#123; Session session = null; Transaction t = null; *//** * 开启查询缓存,关闭二级缓存, 开启两个session,分别调用query.iterate *//* //如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. try &#123; session = HibernateUtils.getSession(); t = session.beginTransaction(); Query query = session.createQuery(&quot;select s.name from Student s&quot;); //启用查询缓存 query.setCacheable(true); for (Iterator&lt;String&gt; it = query.iterate(); it.hasNext();) &#123; String name = it.next(); System.out.println(name); &#125; t.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); t.rollback(); &#125; finally &#123; HibernateUtils.closeSession(session); &#125; System.out.println(&quot;================================&quot;); try &#123; session = HibernateUtils.getSession(); t = session.beginTransaction(); Query query = session.createQuery(&quot;select s.name from Student s&quot;); //启用查询缓存 query.setCacheable(true); //会发出查询语句,因为query.iterate不使用查询缓存 for (Iterator&lt;String&gt; it = query.iterate(); it.hasNext();) &#123; String name = it.next(); System.out.println(name); &#125; t.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); t.rollback(); &#125; finally &#123; HibernateUtils.closeSession(session); &#125; &#125; ``` @SuppressWarnings(“unchecked”) public static void main(String[] args) { Session session = null; Transaction t = null; *//** * 关闭查询缓存,关闭二级缓存, 开启两个session,分别调用query.list查询实体对象 *//* //如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. try { session = HibernateUtils.getSession(); t = session.beginTransaction(); Query query = session.createQuery(&quot;select s from Student s&quot;); //启用查询缓存 //query.setCacheable(true); List&lt;Student&gt; students = query.list(); for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { Student s = it.next(); System.out.println(s.getName()); } t.commit(); } catch (Exception e) { e.printStackTrace(); t.rollback(); } finally { HibernateUtils.closeSession(session); } System.out.println(&quot;================================&quot;); try { session = HibernateUtils.getSession(); t = session.beginTransaction(); Query query = session.createQuery(&quot;select s from Student s&quot;); //启用查询缓存 //query.setCacheable(true); //会发出查询语句,因为list默认每次都会发出sql语句 List&lt;Student&gt; students = query.list(); for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { Student s = it.next(); System.out.println(s.getName()); } t.commit(); } catch (Exception e) { e.printStackTrace(); t.rollback(); } finally { HibernateUtils.closeSession(session); } }*/ /* @SuppressWarnings(“unchecked”) public static void main(String[] args) { Session session = null; Transaction t = null; *//** * 开启查询缓存,关闭二级缓存, 开启两个session,分别调用query.list查询实体对象 *//* //如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. try { session = HibernateUtils.getSession(); t = session.beginTransaction(); Query query = session.createQuery(&quot;select s from Student s&quot;); //启用查询缓存 query.setCacheable(true); List&lt;Student&gt; students = query.list(); for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { Student s = it.next(); System.out.println(s.getName()); } t.commit(); } catch (Exception e) { e.printStackTrace(); t.rollback(); } finally { HibernateUtils.closeSession(session); } System.out.println(&quot;================================&quot;); try { session = HibernateUtils.getSession(); t = session.beginTransaction(); Query query = session.createQuery(&quot;select s from Student s&quot;); //启用查询缓存 query.setCacheable(true); //会发出根据id查询实体的n条查询语句,因为这种情况下,查询过程是这样的： // 在第一次执行list时,会把查询对象的id缓存到查询缓存里 // 第二次执行list时, 会遍历查询缓存里的id到缓存里去找实体对象,由于这里没找到实体对象, //所以就发出n条查询语句到数据库中查询. List&lt;Student&gt; students = query.list(); for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { Student s = it.next(); System.out.println(s.getName()); } t.commit(); } catch (Exception e) { e.printStackTrace(); t.rollback(); } finally { HibernateUtils.closeSession(session); } }*/ @SuppressWarnings(“unchecked”) public static void main(String[] args) { Session session = null; Transaction t = null; /** * 开启查询缓存,开启二级缓存, 开启两个session,分别调用query.list查询实体对象 */ //如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. try { session = HibernateUtils.getSession(); t = session.beginTransaction(); Query query = session.createQuery(&quot;select s from Student s&quot;); //启用查询缓存 query.setCacheable(true); List&lt;Student&gt; students = query.list(); for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { Student s = it.next(); System.out.println(s.getName()); } t.commit(); } catch (Exception e) { e.printStackTrace(); t.rollback(); } finally { HibernateUtils.closeSession(session); } System.out.println(&quot;================================&quot;); try { session = HibernateUtils.getSession(); t = session.beginTransaction(); Query query = session.createQuery(&quot;select s from Student s&quot;); //启用查询缓存 query.setCacheable(true); //不会发出查询语句,因为这种情况下,查询过程是这样的： // 在第一次执行list时,会把查询对象的id缓存到查询缓存里 // 第二次执行list时, 会遍历查询缓存里的id到缓存里去找实体对象,由于这里开启了二级缓存,可以找到目标实体对象, //所以就不会再发出n条查询语句. List&lt;Student&gt; students = query.list(); for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { Student s = it.next(); System.out.println(s.getName()); } t.commit(); } catch (Exception e) { e.printStackTrace(); t.rollback(); } finally { HibernateUtils.closeSession(session); } }","comments":true,"tags":[{"name":"hibernate","slug":"hibernate","permalink":"http://jishusuishouji.github.io/tags/hibernate/"}]},{"title":"Layout of Log4j","date":"2017-03-28T07:02:00.000Z","path":"2017/03/28/Log4j/Layout_of_Log4j/","text":"本文档使用Log4j版本为1.2.17 1. Layout介绍Log4j Layout主要用来控制日志的序列化格式，比如时间、线程号、日志消息对齐方式等，是log4j体系结构中的核心组成部分之一。 Layout抽象类声明为:1public abstract class Layout implements OptionHandler Layout实现了OptionHandler接口，OptionHandler仅包含一个方法activateOptions()。对实现了OptionHandler接口的模块，调用属性setter方法后，log4j的配置器类会调用此模块的activateOptions实现以激活配置。OptionHandler存在的原因是有些属性彼此依赖，在它们在全部加载完成之前是无法激活的，这个方法用于在模块变为激活和就绪之前用来执行任何必要任务的机制。比如： 某模块有字符串属性fileName属性，表示log4j用户配置的写出日志文件名，使用前需要创建File对象获取文件写出IO流，具体则是由activateOptions完成文件的打开等，具体可见log4j的FileAppender实现中对文件名和文件IO的操作。 Layout类的方法或接口如下，abstract修饰的需要具体子类实现: //abstract修饰需要具体子类实现，将日志事件渲染为待打印的日志文本字符串，可写出到Appenderabstract public String format(LoggingEvent event )//format函数返回的格式化文本类型，默认返回为”text/plain”public String getContentType()//针对HTMLLayout类的格式化输出，html字符串的头部，默认nullpublic String getHeader()//针对HTMLLayout类的格式化输出，html字符串的尾部，默认nullpublic String getFooter()//对于LayoutEvent中异常的处理模式，true表示忽略异常，异常会到达Appender，由Appender负责渲染为打印持久化字符串信息；false表示由Layout负责渲染异常信息。SimpleLayout、TTCCLayout、PatternLayout实现返回true;XMLLayout实现返回false，由Appender处理渲染异常消息。abstract public boolean ignoresThrowable()Layout是对序列化每一次LoggingEvent的抽象，核心是format方法，format作为抽象方法，由具体子类实现具体的序列化方式。具体子类有： SimpleLayoutTTCCLayoutPatternLayoutXMLLayoutHTMLLayoutDateLayoutLayout继承体系 XMLLayout XMLLayout实现了根据log4j.dtd序列化输出xml格式的日志文本，默认的log4j.dtd文件在/org/apache/log4j/xml/log4j.dtd目录下，注意，XMLLayout打印输出的并非完整XML文件，并不包括&lt;?xml version=”1.0” ?&gt;等XML头部，XMLLayout的目的是输出XML的部分片段，应用可将此片段整合嵌入到其它XML文件中。XMLLayout有成员属性：locationInfo表示是否打印位置信息，即日志事件发生的代码文件名、日志记录点代码行号等信息，log4j配置文件中需要配置为LocationInfoproperties表示是否打印MDC中的Key-Value信息，默认为false，log4j配置文件中需要配置为Properties 注意：log4j的各个模块涉及的成员属性时，如果属性有set方法，一般表示此属性可通过log4j.properties进行配置，具体配置属性值为属性的setXXX方法去掉set前缀。 示例如上面的locationInfo和properties配置: log4j.appender.Console.layout.LocationInfo=truelog4j.appender.Console.layout.Properties=true XMLLayout继承自Layout的方法实现有： //配置激活的接口实现，来自于OptionHandler interface，方法体为空public void activateOptions()//返回false，表示XMLLayout自己处理异常信息public boolean ignoresThrowable()public String format( final LoggingEvent event)2.1 format实现 format按照日志message、NDC、getThrowableStrRep、日志位置信息、MDC的顺序，并按照XML格式序列化LoggingEvent。log4j实现时使用StringBuffer避免字符串拼接的开销（JAVA中String是不可变类），具体使用时设置了StringBuffer的默认长度即DEFAULT_SIZE = 256，最大长度UPPER_LIMIT = 2048。每次format函数调用时，如果当前StringBuffer容量未超过上限，则复用已有的StringBuffer并清空已有内容；如果当前StringBuffer容量超过UPPER_LIMIT上限，则创建一个新的StringBuffer将当前LoggingEvent 序列化到其中，目的是尽量减少内存的占用量。 if(buf.capacity() &gt; UPPER_LIMIT) { buf = new StringBuffer(DEFAULT_SIZE);} else { buf.setLength(0);}xml序列化中，对于属性如 timestamp=”1452874282177” level=“INFO”，为了保持生成的文本符合XML语法，需要对特殊字符进行转义处理。对于属性使用org.apache.log4j.helpers.Transform.escapeTags做转义。对于文本子元素如 &lt;![CDATA[123]]&gt;，使用org.apache.log4j.helpers.Transform.appendEscapingCDATA做转义，将message放在 &lt;![CDATA[ 和 ]] 之间，避免文本破坏XML语法。 处理的XML特殊字符有（简单字符串替换）: -&gt; &gt;&lt; -&gt; &lt;&amp; -&gt; &amp;“ -&gt; &quot;2.2 demo demo java code: Logger logger = Logger.getLogger(LayoutTest.class);NDC.push(“ndc message”);logger.info(“info:123”);logger.warn(“warn:abc”);logger.info(“exception”, new RuntimeException(“run time exception”));demo log4j config: log4j.rootLogger=INFO,Consolelog4j.appender.Console=org.apache.log4j.ConsoleAppenderlog4j.appender.Console.target=System.outlog4j.appender.Console.layout=org.apache.log4j.xml.XMLLayoutlog4j.appender.Console.layout.LocationInfo=truelog4j.appender.Console.layout.Properties=true demo 日志输出: &lt;![CDATA[info:123]]&gt; &lt;![CDATA[ndc message]]&gt; &lt;![CDATA[warn:abc]]&gt; &lt;![CDATA[ndc message]]&gt; &lt;![CDATA[error:xyz]]&gt; &lt;![CDATA[ndc message]]&gt; &lt;![CDATA[exception]]&gt; &lt;![CDATA[ndc message]]&gt; &lt;![CDATA[java.lang.RuntimeException: run time exceptionat com.luohw.log4j.LayoutTest.test(LayoutTest.java:16)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)… …at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)]]&gt; HTMLLayout HTMLLayout用于将每次的LoggingEvent序列化为HTML格式字符串，具体的内容组织为html的表格。生成的HTML文本为完整的一份HTML格式代码（不同于XMLLayout的部分片段），包含html、head、body、具体table信息等。一份HTML日志文档可以包含多条LoggingEvent序列化输出，但header和footer只会输出一次（具体是有Appender打开和关闭相关流时输出）。 注意：如果有Appender使用HTMLLayout，需要设置Appender的字符编码为UTF-8 或者 UTF-16，否则非ASCII字符会产生乱码。 locationInfo表示是否打印位置信息，即日志事件发生的代码文件名、代码行号，log4j配置文件中需要配置为LocationInfo title输出html文档head的title部分，默认为Log4J Log Messages，log4j配置文件中需要配置为Title XMLLayout继承自Layout的方法实现有： //默认返回”text/html”public String getContentType()//配置加载完成后操作，实现为空public void activateOptions()//返回相应HTML头部部分，具体是html、head、title以及body、table的开始部分public String getHeader()//返回相应html尾部，具体是table、body、html的html闭合标签public String getFooter()//返回false，即由HTMLLayout本身处理异常信息格式化，HTMLLayout有成员函数appendThrowableAsHTML，具体是将Throwable对应的字符串做相关转移和替换处理，以符合html语法public boolean ignoresThrowable()//具体序列化LoggingEvent为字符串public String format(LoggingEvent event)3.1 format实现 a. 缓冲StringBuffer更新，判断容量是否超过HTMLLayout的MAX_CAPACITY(1024)，如果超过则创建新的StringBuffer，否则复用原有的StringBuffer，避免内存浪费，具体和XMLLayout原理一致。b. 输出时间、线程、Level等上下文信息，根据locationInfo（如果locationInfo为true）、Level等具体字符串拼接和格式化 0mainINFOcom.luohw.log4j.LayoutTestLayoutTest.java:12info:123 c. 输出NDC信息 NDC: ndc message d. 如果有则输出异常栈信息，一般Logger的日志函数info、warn、error等都有带Throwable型参的重载e. 没有MDC相关信息的格式化输出 3.2 demo demo java code: Logger logger = Logger.getLogger(LayoutTest.class);NDC.push(“ndc message”);logger.info(“info:123”);logger.warn(“warn:abc”);logger.error(“error:xyz”);logger.info(“exception”, new RuntimeException(“run time exception”));demo log4j config: log4j.rootLogger=INFO,Consolelog4j.appender.Console=org.apache.log4j.ConsoleAppenderlog4j.appender.Console.target=System.outlog4j.appender.Console.layout=org.apache.log4j.HTMLLayoutlog4j.appender.Console.layout.LocationInfo=truelog4j.appender.Console.layout.Title=luohw@log4j demo浏览器打开日志输出html: html see more …","comments":true,"tags":[{"name":"Log4j","slug":"Log4j","permalink":"http://jishusuishouji.github.io/tags/Log4j/"}]},{"title":"MongoDB两阶段提交实现事务","date":"2017-03-27T13:12:46.000Z","path":"2017/03/27/mongodb/MongoDB两阶段提交实现事务/","text":"MongoDB数据库中操作单个文档总是原子性的，然而，涉及多个文档的操作，通常被作为一个“事务”，而不是原子性的。因为文档可以是相当复杂并且包含多个嵌套文档，单文档的原子性对许多实际用例提供了支持。尽管单文档操作是原子性的，在某些情况下，需要多文档事务。在这些情况下，使用两阶段提交，提供这些类型的多文档更新支持。因为文档可以表示为Pending数据和状态，可以使用一个两阶段提交确保数据是一致的，在一个错误的情况下，事务前的状态是可恢复的。 事务最常见的例子是以可靠的方式从A账户转账到B账户，在关系型数据库中，此操作将从A账户减掉金额和给B账户增加金额的操作封装在单个原子事务中。在MongoDB中，可以使用两阶段提交达到相同的效果。本文中的所有示例使用mongo shell与数据库进行交互,并假设有两个集合：首先，一个名为accounts的集合存储每个账户的文档数据，另一个名为transactions的集合存储事务本身。 首先创建两个名为A和B的账户，使用下面的命令：12db.accounts.save(&#123;name: &quot;A&quot;, balance: 1000, pendingTransactions: []&#125;)db.accounts.save(&#123;name: &quot;B&quot;, balance: 1000, pendingTransactions: []&#125;) 使用find()方法验证这两个操作已经成功：1db.accounts.find() mongo会返回两个类似下面的文档：12&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc66cb8a04f512696151f&quot;), &quot;name&quot; : &quot;A&quot;, &quot;balance&quot; : 1000, &quot;pendingTransactions&quot; : [ ] &#125;&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc67bb8a04f5126961520&quot;), &quot;name&quot; : &quot;B&quot;, &quot;balance&quot; : 1000, &quot;pendingTransactions&quot; : [ ] &#125; 事务过程：设置事务初始状态initial： 通过插入下面的文档创建transaction集合，transaction文档持有源(source)和目标(destination)，它们引用自accounts集合文档的字段名，以及value字段表示改变balance字段数量的数据。最后，state字段反映事务的当前状态。1db.transactions.save(&#123;source: &quot;A&quot;, destination: &quot;B&quot;, value: 100, state: &quot;initial&quot;&#125;) 验证这个操作已经成功，使用find()：1db.transactions.find() 这个操作会返回一个类似下面的文档：1&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;), &quot;source&quot; : &quot;A&quot;, &quot;destination&quot; : &quot;B&quot;, &quot;value&quot; : 100, &quot;state&quot; : &quot;initial&quot; &#125; 切换事务到Pending状态：在修改accounts集合记录之前，将事务状态从initial设置为pending。使用findOne()方法将transaction文档赋值给shell会话中的局部变量t：1t = db.transactions.findOne(&#123;state: &quot;initial&quot;&#125;) 变量t创建后，shell将返回它的值，将会看到如下的输出：1&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;), &quot;source&quot; : &quot;A&quot;, &quot;destination&quot; : &quot;B&quot;, &quot;value&quot; : 100, &quot;state&quot; : &quot;initial&quot; &#125; 使用update()改变state的值为pending：12db.transactions.update(&#123;_id: t._id&#125;, &#123;$set: &#123;state: &quot;pending&quot;&#125;&#125;)db.transactions.find() find()操作将返回transaction集合的内容，类似下面：1&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;), &quot;source&quot; : &quot;A&quot;, &quot;destination&quot; : &quot;B&quot;, &quot;value&quot; : 100, &quot;state&quot; : &quot;pending&quot; &#125; 将事务应用到两个账户：使用update()方法应用事务到两个账户。在update()查询中，条件pendingTransactions:{$ne:t._id}阻止事务更新账户，如果账户的pendingTransaction字段包含事务t的_id：12345678db.accounts.update( &#123; name: t.source, pendingTransactions: &#123; $ne: t._id &#125; &#125;, &#123; $inc: &#123; balance: -t.value &#125;, $push: &#123; pendingTransactions: t._id &#125; &#125;)db.accounts.update( &#123; name: t.destination, pendingTransactions: &#123; $ne: t._id &#125; &#125;, &#123; $inc: &#123; balance: t.value &#125;, $push: &#123; pendingTransactions: t._id &#125; &#125;) 1db.accounts.find() find()操作将返回accounts集合的内容，现在应该类似于下面的内容：12&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc97fb8a04f5126961523&quot;), &quot;balance&quot; : 900, &quot;name&quot; : &quot;A&quot;, &quot;pendingTransactions&quot; : [ ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;) ] &#125;&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc984b8a04f5126961524&quot;), &quot;balance&quot; : 1100, &quot;name&quot; : &quot;B&quot;, &quot;pendingTransactions&quot; : [ ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;) ] &#125; 设置事务状态为committed：使用下面的update()操作设置事务的状态为committed：12db.transactions.update(&#123;_id: t._id&#125;, &#123;$set: &#123;state: &quot;committed&quot;&#125;&#125;)db.transactions.find() find()操作发回transactions集合的内容，现在应该类似下面的内容：1&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;), &quot;destination&quot; : &quot;B&quot;, &quot;source&quot; : &quot;A&quot;, &quot;state&quot; : &quot;committed&quot;, &quot;value&quot; : 100 &#125; 移除pending事务：使用下面的update()操作从accounts集合中移除pending事务：123db.accounts.update(&#123;name: t.source&#125;, &#123;$pull: &#123;pendingTransactions: t._id&#125;&#125;)db.accounts.update(&#123;name: t.destination&#125;, &#123;$pull: &#123;pendingTransactions: t._id&#125;&#125;)db.accounts.find() find()操作返回accounts集合内容，现在应该类似下面内容： 12&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc97fb8a04f5126961523&quot;), &quot;balance&quot; : 900, &quot;name&quot; : &quot;A&quot;, &quot;pendingTransactions&quot; : [ ] &#125;&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc984b8a04f5126961524&quot;), &quot;balance&quot; : 1100, &quot;name&quot; : &quot;B&quot;, &quot;pendingTransactions&quot; : [ ] &#125; 设置事务状态为done：通过设置transaction文档的state为done完成事务：12db.transactions.update(&#123;_id: t._id&#125;, &#123;$set: &#123;state: &quot;done&quot;&#125;&#125;)db.transactions.find() find()操作返回transaction集合的内容，此时应该类似下面：1&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;), &quot;destination&quot; : &quot;B&quot;, &quot;source&quot; : &quot;A&quot;, &quot;state&quot; : &quot;done&quot;, &quot;value&quot; : 100 &#125; 从失败场景中恢复：最重要的部分不是上面的典型例子，而是从各种失败场景中恢复未完成的事务的可能性。这部分将概述可能的失败，并提供方法从这些事件中恢复事务。这里有两种类型的失败： 1、所有发生在第一步（即设置事务的初始状态initial）之后，但在第三步（即应用事务到两个账户）之前的失败。为了还原事务，应用应该获取一个pending状态的transaction列表并且从第二步（即切换事务到pending状态）中恢复。 2、所有发生在第三步之后（即应用事务到两个账户）但在第五步(即设置事务状态为done)之前的失败。为了还原事务，应用需要获取一个committed状态的事务列表，并且从第四步（即移除pending事务）恢复。 因此应用程序总是能够恢复事务，最终达到一个一致的状态。应用程序开始捕获到每个未完成的事务时运行下面的恢复操作。你可能还希望定期运行恢复操作，以确保数据处于一致状态。达成一致状态所需要的时间取决于应用程序需要多长时间恢复每个事务。 回滚：在某些情况下可能需要“回滚”或“撤消”事务，当应用程序需要“取消”该事务时，或者是因为它永远需要恢复当其中一个帐户不存在的情况下，或停止现有的事务。这里有两种可能的回滚操作： 1、应用事务（即第三步）之后，你已经完全提交事务，你不应该回滚事务。相反，创建一个新的事务，切换源(源)和目标(destination)的值。 2、创建事务（即第一步）之后，在应用事务（即第三步）之前，使用下面的处理过程： 设置事务状态为canceling：首先设置事务状态为canceling，使用下面的update()操作： 1db.transactions.update(&#123;_id: t._id&#125;, &#123;$set: &#123;state: &quot;canceling&quot;&#125;&#125;) ###撤销事务： 使用下面的操作顺序从两个账户中撤销事务： 123db.accounts.update(&#123;name: t.source, pendingTransactions: t._id&#125;, &#123;$inc: &#123;balance: t.value&#125;, $pull: &#123;pendingTransactions: t._id&#125;&#125;)db.accounts.update(&#123;name: t.destination, pendingTransactions: t._id&#125;, &#123;$inc: &#123;balance: -t.value&#125;, $pull: &#123;pendingTransactions: t._id&#125;&#125;)db.accounts.find() find()操作返回acounts集合的内容，应该类似下面：12&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc97fb8a04f5126961523&quot;), &quot;balance&quot; : 1000, &quot;name&quot; : &quot;A&quot;, &quot;pendingTransactions&quot; : [ ] &#125;&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc984b8a04f5126961524&quot;), &quot;balance&quot; : 1000, &quot;name&quot; : &quot;B&quot;, &quot;pendingTransactions&quot; : [ ] &#125; 设置事务状态为canceled：最后，使用下面的update()状态将事务状态设置为canceled：1db.transactions.update(&#123;_id: t._id&#125;, &#123;$set: &#123;state: &quot;canceled&quot;&#125;&#125;)","comments":true,"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://jishusuishouji.github.io/tags/MongoDB/"}]},{"title":"mysql-Innodb事务隔离级别-repeatable read详解","date":"2017-03-27T11:04:08.000Z","path":"2017/03/27/mysql/mysql-Innodb事务隔离级别-repeatable_read详解/","text":"一、事务隔离级别ANSI/ISO SQL标准定义了4中事务隔离级别：未提交读（read uncommitted），提交读（read committed），重复读（repeatable read），串行读（serializable）。 对于不同的事务，采用不同的隔离级别分别有不同的结果。不同的隔离级别有不同的现象。主要有下面3种现在： 1、脏读（dirty read）：一个事务可以读取另一个尚未提交事务的修改数据。 2、非重复读（nonrepeatable read）：在同一个事务中，同一个查询在T1时间读取某一行，在T2时间重新读取这一行时候，这一行的数据已经发生修改(T1和T2都在同一个事务里面)，可能被更新了（update），也可能被删除了（delete）。 3、幻像读（phantom read）：在同一事务中，同一查询多次进行时候，由于其他插入操作（insert）的事务提交，导致每次返回不同的结果集。 不同的隔离级别有不同的现象，并有不同的锁定/并发机制，隔离级别越高，数据库的并发性就越差，4种事务隔离级别分别表现的现象如下表： 隔离级别 脏读 非重复读 幻像读 read uncommitted 允许 允许 允许 read committed 允许 允许 repeatable read 允许 serializable 二、数据库中的默认事务隔离级别在Oracle中默认的事务隔离级别是提交读（read committed）。对于MySQL的Innodb的默认事务隔离级别是重复读（repeatable read）。可以通过下面的命令查看： 12345678910111213mysql&gt; SELECT @@GLOBAL.tx_isolation, @@tx_isolation;+———————–+—————–+| @@GLOBAL.tx_isolation | @@tx_isolation |+———————–+—————–+| REPEATABLE-READ | REPEATABLE-READ |+———————–+—————–+1 row in set (0.00 sec) 下面进行一下测试： 【说明】事务提交，看到最新数据。 上面的结果可以看到Innodb的重复读（repeatable read）不允许脏读，不允许非重复读（即可以重复读，Innodb使用多版本一致性读来实现）和不允许幻象读（这点和ANSI/ISO SQL标准定义的有所区别）。 另外，同样的测试： 1、当session 2进行truncate表的时候，这个时候session 1再次查询就看不到数据。 2、当session 2进行alter表的时候，这个时候session 1再次查询就看不到数据。 造成以上的原因是因为 mysql的持续非锁定读，在repeatable read级别下，读采用的是持续非锁定读。相关介绍见下面： 持续读意味着InnoDB使用它的多版本化来给一个查询展示某个时间点处数据库的快照。查询看到在那个时间点之前被提交的那些确切事务做的更改，并且没有其后的事务或未提交事务做的改变。这个规则的例外是，查询看到发布该查询的事务本身所做的改变。 如果你运行在默认的REPEATABLE READ隔离级别，则在同一事务内的所有持续读读取由该事务中第一个这样的读所确立的快照。你可以通过提交当前事务并在发布新查询的事务之后，为你的查询获得一个更新鲜的快照。 持续读是默认模式，在其中InnoDBzai在READ COMMITTED和REPEATABLE READ隔离级别处理SELECT语句。持续读不在任何它访问的表上设置锁定，因此，其它用户可自由地在持续读在一个表上执行的同一时间修改这些表。 注意，持续读不在DROP TABLE和ALTER TABLE上作用。持续读不在DROP TABLE上作用，因为MySQL不能使用已经被移除的表，并且InnoDB 破坏了该表。持续读不在ALTER TABLE上作用，因为它在某事务内执行，该事务创建一个新表，并且从旧表往新表中插入行。现在，当你重新发出持续读之时，它不能在新表中看见任何行，因为它们被插入到一个在持续读读取的快照中不可见的事务 里。 MySQL官方文档中的多版本一致性读中说明了原因：Consistent read does not work over certain DDL statements。","comments":true,"tags":[{"name":"mysql","slug":"mysql","permalink":"http://jishusuishouji.github.io/tags/mysql/"}]},{"title":"说说MySQL中的事务","date":"2017-03-27T10:27:04.000Z","path":"2017/03/27/mysql/说说MySQL中的事务/","text":"从一个问题开始从ATM机取钱分为以下几个步骤： 1.登陆ATM机，输入密码；2.连接数据库，验证密码；3.验证成功，获得用户信息，比如存款余额等；4.用户输入需要取款的金额，按下确认键；5.从后台数据库中减掉用户账户上的对应金额；6.ATM吐出钱；7.用户把钱拿走。 一个简单的取钱，主要分为以上几步。不知道大家有没有“天真”的想过，如果在第5步中，后台数据库中已经把钱减掉了，但是ATM还就是没有吐出钱（虽然实际也发生过，但是毕竟是低概率事件），这该怎么办？ 关于这个问题，银行系统的开发人员早就想过了，那么他们是怎么来搞定这个问题的呢？这就要说到今天总结的事务这个概念了。 简单说说事务对于上面的取钱这个事情，如果有一步出现了错误，那么就取消整个取钱的动作；简单来说，就是取钱这7步，要么都完成，要么就啥也不做。在数据库中，事务也是这个道理。 事务由一条或者多条sql语句组成，在事务中的操作，这些sql语句要么都执行，要么都不执行，这就是事务的目的。 对于事务而言，它需要满足ACID特性，下面就简要的说说事务的ACID特性。 A，表示原子性；原子性指整个数据库事务是不可分割的工作单位。只有使事务中所有的数据库操作都执行成功，整个事务的执行才算成功。事务中任何一个sql语句执行失败，那么已经执行成功的sql语句也必须撤销，数据库状态应该退回到执行事务前的状态；C，表示一致性；也就是说一致性指事务将数据库从一种状态转变为另一种一致的状态，在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏；I，表示隔离性；隔离性也叫做并发控制、可串行化或者锁。事务的隔离性要求每个读写事务的对象与其它事务的操作对象能相互分离，即该事务提交前对其它事务都不可见，这通常使用锁来实现；D，持久性，表示事务一旦提交了，其结果就是永久性的，也就是数据就已经写入到数据库了，如果发生了宕机等事故，数据库也能将数据恢复。 总结了一些事务的基本概念，在MySQL中，事务还是分为很多中的，下面就来看看到底有哪些事务。 有哪些事务你能想象到吗？就这么个破事务还会分以下这么多种： 扁平事务； 带有保存点的扁平事务； 链事务； 嵌套事务； 分布式事务。 现在就来对这些事务从概念的层面上进行简单的总结一下。 扁平事务扁平事务是最简单的一种，也是实际开发中使用的最多的一种事务。在这种事务中，所有操作都处于同一层次，最常见的方式如下：1234567BEGIN WORK Operation 1 Operation 2 Operation 3 ... Operation NCOMMIT WORK 或者是这种：12345678BEGIN WORK Operation 1 Operation 2 Operation 3 ... Operation N (Error Occured)ROLLBACK WORK 扁平事务的主要缺点是不能提交或回滚事务的某一部分，或者分几个独立的步骤去提交。比如有这样的一个例子，我从呼和浩特去深圳，为了便宜，我可能这么干：1234BEGIN WORK Operation1:呼和浩特---火车---&gt;北京 Operation2:北京---飞机---&gt;深圳ROLLBACK WORK 但是，如果Operation1，从呼和浩特到北京的火车晚点了，错过了航班，怎么办？感觉扁平事务的特性，那我就需要回滚，我再回到呼和浩特，那么这样成本是不是也太高了啊，所以就有了下面的第二种事务——带有保存点的扁平事务。 带有保存点的扁平事务这种事务除了支持扁平事务支持的操作外，允许在事务执行过程中回滚到同一事务中较早的一个状态，这是因为可能某些事务在执行过程中出现的错误并不会对所有的操作都无效，放弃整个事务不合乎要求，开销也太大。保存点用来通知系统应该记住事务当前的状态，以便以后发生错误时，事务能回到该状态。 链事务链事务，就是指回滚时，只能恢复到最近一个保存点；而带有保存点的扁平事务则可以回滚到任意正确的保存点。 嵌套事务看下面这个，你就能明白了，啥是嵌套事务：123456789101112131415BEGIN WORK SubTransaction1: BEGIN WORK SubOperationX COMMIT WORK SubTransaction2: BEGIN WORK SubOperationY COMMIT WORK ... SubTransactionN: BEGIN WORK SubOperationN COMMIT WORKCOMMIT WORK 这就是嵌套事务，在事务中再嵌套事务，位于根节点的事务称为顶层事务。事务的前驱称为父事务，其它事务称为子事务。事务的前驱称为父事务，事务的下一层称为子事务。 子事务既可以提交也可以回滚，但是它的提交操作并不马上生效，除非由其父事务提交。因此就可以确定，任何子事务都在顶层事务提交后才真正的被提交了。同理，任意一个事务的回滚都会引起它的所有子事务一同回滚。 分布式事务分布式事务通常是指在一个分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点，比如：通过建设银行向招商银行转账，建设银行和招商银行肯定用的不是同一个数据库，同时二者的数据库也不在一个网络节点上，那么当用户跨行转账，就是通过分布式事务来保证数据的ACID的。 MySQL中使用事务理论总结的再好，终归都要通过实践来进行理解。下面就来说说MySQL中是如何使用事务的。 在MySQL命令行的默认设置下，事务都是自动提交的，即执行SQL语句后就会马上执行COMMIT操作。因此要显示地开启一个事务须使用命令BEGIN或START TRANSACTION，或者执行命令SET AUTOCOMMIT=0，用来禁止使用当前会话的自动提交。 来看看我们可以使用哪些事务控制语句。 BEGIN或START TRANSACTION；显示地开启一个事务； COMMIT；也可以使用COMMIT WORK，不过二者是等价的。COMMIT会提交事务，并使已对数据库进行的所有修改称为永久性的； ROLLBACK；有可以使用ROLLBACK WORK，不过二者是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改； SAVEPOINT identifier；SAVEPOINT允许在事务中创建一个保存点，一个事务中可以有多个SAVEPOINT； RELEASE SAVEPOINT identifier；删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常； ROLLBACK TO identifier；把事务回滚到标记点； SET RANSACTION；用来设置事务的隔离级别。InnoDB存储引擎提供事务的隔离级别有READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ和SERIALIZABLE。 这些不用你“管”有的时候有些SQL语句会产生一个隐式的提交操作，即执行完成这些语句后，会有一个隐式的COMMIT操作。有以下SQL语句，不用你去“管”： DDL语句，ALTER DATABASE、ALTER EVENT、ALTER PROCEDURE、ALTER TABLE、ALTER VIEW、CREATE TABLE、DROP TABLE、RENAME TABLE、TRUNCATE TABLE等； 修改MYSQL架构的语句，CREATE USER、DROP USER、GRANT、RENAME USER、REVOKE、SET PASSWORD； 管理语句，ANALYZE TABLE、CACHE INDEX、CHECK TABLE、LOAD INDEX INTO CACHE、OPTIMIZE TABLE、REPAIR TABLE等。 以上的这些SQL操作都是隐式的提交操作，不需要手动显式提交。 事务的隔离级别上面也说到了SET TRANSACTION用来设置事务的隔离级别。那事务的隔离级别是什么东东？ 在数据库操作中，为了有效保证并发读取数据的正确性，提出的事务隔离级别。 InnoDB存储引擎提供事务的隔离级别有READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ和SERIALIZABLE。这些隔离级别之间的区别如下： 隔离级别 脏读（Dirty Read） 不可重复读（NonRepeatable Read） 幻读（Phantom Read） 未提交读（Read uncommitted） 可能 可能 可能 已提交读（Read committed） 不可能 可能 可能 可重复读（Repeatable read） 不可能 不可能 可能 可串行化（Serializable ） 不可能 不可能 不可能 脏读：一个事务读取到了另外一个事务没有提交的数据；比如：事务T1更新了一行记录的内容，但是并没有提交所做的修改。事务T2读取到了T1更新后的行，然后T1执行回滚操作，取消了刚才所做的修改。现在T2所读取的行就无效了；不可重复读：在同一事务中，两次读取同一数据，得到内容不同；比如：事务T1读取一行记录，紧接着事务T2修改了T1刚才读取的那一行记录(T2的事务已经提交了)。然后T1又再次读取这行记录，发现与刚才读取的结果不同。这就称为“不可重复”读，因为T1原来读取的那行记录已经发生了变化；幻读：同一事务中，用同样的操作读取两次，得到的记录数不相同；比如：事务T1读取一条指定的WHERE子句所返回的结果集。然后事务T2新插入一行记录，这行记录恰好可以满足T1所使用的查询条件中的WHERE子句的条件。然后T1又使用相同的查询再次对表进行检索，但是此时却看到了事务T2刚才插入的新行。这个新行就称为“幻像”，因为对T1来说这一行就像突然出现的一样。 隔离级别越低，事务请求的锁越少或保持锁的时间就越短。InnoDB存储引擎默认的支持隔离级别是REPEATABLE READ；在这种默认的事务隔离级别下已经能完全保证事务的隔离性要求，即达到SQL标准的SERIALIZABLE级别隔离。 我们可以可以用SET TRANSACTION语句改变单个会话或者所有新进连接的隔离级别。它的语法如下：1SET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL &#123;READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE&#125; 注意：默认的行为（不带session和global）是为下一个（未开始）事务设置隔离级别。如果使用GLOBAL关键字，语句在全局对从那点开始创建的所有新连接（除了不存在的连接）设置默认事务级别。你需要SUPER权限来做这个。使用SESSION 关键字为将来在当前连接上执行的事务设置默认事务级别。 任何客户端都能自由改变会话隔离级别（甚至在事务的中间），或者为下一个事务设置隔离级别。12345678910mysql&gt; set session transaction isolation level repeatable read;Query OK, 0 rows affected (0.00 sec)mysql&gt; select @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set (0.00 sec) 数据库的默认隔离级别mysql的默认隔离级别是可重复读：要是读为主的业务场景，建议RC模式；若是非读为主的业务场景，则建议RR模式，考虑到MySQL5.1及以上版本二进制日志登记格式，建议优先考虑RR模式。 Oracle采用的也是 read committedOracle的RC 跟InnoDB存储引擎的RC不是一样的，属于综合了 RC + RR的折中版本。","comments":true,"tags":[{"name":"mysql","slug":"mysql","permalink":"http://jishusuishouji.github.io/tags/mysql/"}]},{"title":"ORM到底是用还是不用？","date":"2017-03-27T05:22:54.000Z","path":"2017/03/27/ORM/ORM到底是用还是不用？/","text":"ORM即Object/Relation Mapping的简写，一般称作“对象关系映射”，在Web开发中最常出没于和关系型数据库交互的地方。接口、中间件、库、包，你都可以这么称呼它。我们可以结合PHP和MySQL，从ORM的四个核心理念来认识它： 简单：ORM以最基本的形式建模数据。比如ORM会将MySQL的一张表映射成一个PHP类（模型），表的字段就是这个类的成员变量 精确：ORM使所有的MySQL数据表都按照统一的标准精确地映射成PHP类，使系统在代码层面保持准确统一 易懂：ORM使数据库结构文档化。比如MySQL数据库就被ORM转换为了PHP程序员可以读懂的PHP类，PHP程序员可以只把注意力放在他擅长的PHP层面（当然能够熟练掌握MySQL更好） 易用：ORM的避免了不规范、冗余、风格不统一的SQL语句，可以避免很多人为Bug，方便编码风格的统一和后期维护 接下来再通过一个很基本的例子来说明一下ORM的使用，还以PHP和MySQL为例。 user这个数据模型是再普遍不过的了。假设我们有一张user数据表。 在OOP中通常我们需要写一个对应的class User来作为user数据表的数据模型:12345678// 声明class Userclass User&#123; $id; $name; function create()&#123;/*...*/&#125; function load($id)&#123;/*...*/&#125;&#125; 1234// 使用class User$user = new User();$user-&gt;name = &apos;fancy&apos;;$user-&gt;create(); 但是通过ORM，我们可以不用去声明class User，可以直接继承ORM提供的工厂类，比如：1234// 直接使用！对于熟悉MVC的亲知道这个意义之所在！$user = new ORM(&apos;user&apos;); // ORM都有自己的规则，这里直接使用了MySQL的表名$user-&gt;name = &apos;fancy&apos;; // MySQL的表的字段就是$user对象的成员变量$user-&gt;save(); // 掉用ORM提供的接口函数 ORM一般都针对数据模型提供了一下常见的接口函数，比如：create(), update(), save(), load(), find(), find_all(), where()等，也就是讲sql查询全部封装成了编程语言中的函数，通过函数的链式组合生成最终的SQL语句。 所以由这些来看，ORM对于敏捷开发和团队合作开发来说，好处是非常非常大的。这里就罗列一下我想到的ORM显著的优点： 大大缩短了程序员的编码时间，减少甚至免除了对Model的编码 良好的数据库操作接口，使编码难度降低，使团队成员的代码变得简洁易读、风格统一 动态的数据表映射，在数据表结构甚至数据库发生改变时，减少了相应的代码修改 减少了程序员对数据库的学习成本 可以很方便地引入数据缓存之类的附加功能 但是ORM并不是一个完美的东西，它同时也有其自身不可避免的缺点： 自动化进行关系数据库的映射需要消耗系统性能。其实这里的性能消耗还好啦，一般来说都可以忽略之，特别是有cacha存在的时候 在处理多表联查、where条件复杂之类的查询时，ORM的语法会变得复杂且猥琐 越是功能强大的ORM越是消耗内存，因为一个ORM Object会带有很多成员变量和成员函数。有一次修复bug时就遇见，使用ORM查询的时候会占用12MB的内存，而使用SQL的查询时只占用了1.7MB…… ORM就是这么一个让人又爱又恨的东西。回到我们开始的问题：“ORM到底是用还是不用？” Fancy个人的观点是：ORM要用！但关键部位不能用！因为对于一般的Web应用开发来说，使用ORM确实能带来上述的诸多好处，而且在大部分情况下涉及不到ORM的不好的地方。但是在系统里面有大数据量、大运算量、复杂查询的地方，就不要用ORM。ORM的性能问题将给你带来灾难。在这些地方就可以使用纯SQL或者其他简单轻量的DB Helper库了。在详细了解ORM之后，你就可以扬长避短让ORM发挥其最大效用了。","comments":true,"tags":[{"name":"ORM","slug":"ORM","permalink":"http://jishusuishouji.github.io/tags/ORM/"}]},{"title":"maven 多模块项目","date":"2017-03-27T02:16:27.000Z","path":"2017/03/27/maven/maven_多模块项目/","text":"","comments":true,"tags":[]},{"title":"Maven最佳实践：划分模块","date":"2017-03-27T02:00:50.000Z","path":"2017/03/27/maven/Maven最佳实践：划分模块/","text":"“分天下为三十六郡，郡置守，尉，监” —— 《史记·秦始皇本纪》 所有用Maven管理的真实的项目都应该是分模块的，每个模块都对应着一个pom.xml。它们之间通过继承和聚合（也称作多模块，multi-module）相互关联。那么，为什么要这么做呢？我们明明在开发一个项目，划分模块后，导入Eclipse变成了N个项目，这会带来复杂度，给开发带来不便。为了解释原因，假设有这样一个项目，很常见的Java Web应用。在这个应用中，我们分了几层： Dao层负责数据库交互，封装了Hibernate交互的类。 Service层处理业务逻辑，放一些Service接口和实现相关的Bean。 Web层负责与客户端交互，主要有一些Structs的Action类。 对应的，在一个项目中，我们会看到一些包名： org.myorg.app.dao org.myorg.app.service org.myorg.app.web org.myorg.app.util 这样整个项目的框架就清晰了，但随着项目的进行，你可能会遇到如下问题：这个应用可能需要有一个前台和一个后台管理端（web或者swing），你发现大部分dao，一些service，和大部分util是在两个应用中可用的。这样的问题，你一周内遇到了好几次。pom.xml中的依赖列表越来越长以重用的，但是，由于目前只有一个项目（WAR），你不得不新建一个项目依赖这个WAR，这变得非常的恶心，因为在Maven中配置对WAR的依赖远不如依赖JAR那样简单明了，而且你根本不需要org.myorg.app.web。有人修改了dao，提交到svn并且不小心导致build失败了，你在编写service的代码，发现编译不过，只能等那人把dao修复了，你才能继续进行，很多人都在修改，到后来你根本就不清楚哪个依赖是谁需要的，渐渐的，很多不必要的依赖被引入。甚至出现了一个依赖有多个版本存在。build整个项目的时间越来越长，尽管你只是一直在web层工作，但你不得不build整个项目。某个模块，比如util，你只想让一些经验丰富的人来维护，可是，现在这种情况，每个开发者都能修改，这导致关键模块的代码质量不能达到你的要求。我们会发现，其实这里实际上没有遵守一个设计模式原则：“高内聚，低耦合”。虽然我们通过包名划分了层次，并且你还会说，这些包的依赖都是单向的，没有包的环依赖。这很好，但还不够，因为就构建层次来说，所有东西都被耦合在一起了。因此我们需要使用Maven划分模块。 一个简单的Maven模块结构是这样的：1234567891011121314---- app-parent |-- pom.xml (pom) | |-- app-util | |-- pom.xml (jar) | |-- app-dao | |-- pom.xml (jar) | |-- app-service | |-- pom.xml (jar) | |-- app-web |-- pom.xml (war) 上述简单示意图中，有一个父项目(app-parent)聚合很多子项目（app-util, app-dao, app-service, app-web）。每个项目，不管是父子，都含有一个pom.xml文件。而且要注意的是，小括号中标出了每个项目的打包类型。父项目是pom,也只能是pom。子项目有jar，或者war。根据它包含的内容具体考虑。 这些模块的依赖关系如下：123app-dao --&gt; app-utilapp-service --&gt; app-daoapp-web --&gt; app-service 注意依赖的传递性（大部分情况是传递的，除非你配置了特殊的依赖scope），app-dao依赖于app-util，app-service依赖于app-dao，于是app-service也依赖于app-util。同理，app-web依赖于app-dao,app-util。 用项目层次的划分替代包层次的划分能给我们带来如下好处： 方便重用，如果你有一个新的swing项目需要用到app-dao和app-service，添加对它们的依赖即可，你不再需要去依赖一个WAR。而有些模块，如app-util，完全可以渐渐进化成公司的一份基础工具类库，供所有项目使用。这是模块化最重要的一个目的。 由于你现在划分了模块，每个模块的配置都在各自的pom.xml里，不用再到一个混乱的纷繁复杂的总的POM中寻找自己的配置。 如果你只是在app-dao上工作，你不再需要build整个项目，只要在app-dao目录运行mvn命令进行build即可，这样可以节省时间，尤其是当项目越来越复杂，build越来越耗时后。 某些模块，如app-util被所有人依赖，但你不想给所有人修改，现在你完全可以从这个项目结构出来，做成另外一个项目，svn只给特定的人访问，但仍提供jar给别人使用。 多模块的Maven项目结构支持一些Maven的更有趣的特性（如DepencencyManagement），这留作以后讨论。 接下来讨论一下POM配置细节，实际上非常简单，先看app-parent的pom.xml：1234567891011121314&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt; &lt;artifactId&gt;app-parent&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;module&gt;app-util&lt;/module&gt; &lt;module&gt;app-dao&lt;/module&gt; &lt;module&gt;app-service&lt;/module&gt; &lt;module&gt;app-web&lt;/module&gt; &lt;/modules&gt; &lt;/project&gt; Maven的坐标GAV（groupId, artifactId, version）在这里进行配置，这些都是必须的。特殊的地方在于，这里的packaging为pom。所有带有子模块的项目的packaging都为pom。packaging如果不进行配置，它的默认值是jar，代表Maven会将项目打成一个jar包。该配置重要的地方在于modules，例子中包含的子模块有app-util, app-dao, app-service, app-war。在Maven build app-parent的时候，它会根据子模块的相互依赖关系整理一个build顺序，然后依次build。这就是一个父模块大概需要的配置，接下来看一下子模块符合配置继承父模块。1234567891011121314151617&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;app-parent&lt;/artifactId&gt; &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;app-util&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;commons-lang&lt;/groupId&gt; &lt;artifactId&gt;commons-lang&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; app-util模块继承了app-parent父模块，因此这个POM的一开始就声明了对app-parent的引用，该引用是通过Maven坐标GAV实现的。而关于项目app-util本身，它却没有声明完整GAV，这里我们只看到了artifactId。这个POM并没有错，groupId和version默认从父模块继承了。实际上子模块从父模块继承一切东西，包括依赖，插件配置等等。此外app-util配置了一个对于commons-lang的简单依赖，这是最简单的依赖配置形式。大部分情况，也是通过GAV引用的。再看一下app-dao，它也是继承于app-parent，同时依赖于app-util：1234567891011121314151617&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;app-parent&lt;/artifactId&gt; &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;app-dao&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt; &lt;artifactId&gt;app-util&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 该配置和app-util的配置几乎没什么差别，不同的地方在于，依赖变化了，app-dao依赖于app-util。这里要注意的是version的值为${project.version}，这个值是一个属性引用，指向了POM的project/version的值，也就是这个POM对应的version。由于app-dao的version继承于app-parent，因此它的值就是1.0-SNAPSHOT。而app-util也继承了这个值，因此在所有这些项目中，我们做到了保持版本一致。这里还需要注意的是，app-dao依赖于app-util，而app-util又依赖于commons-lang，根据传递性，app-dao也拥有了对于commons-lang的依赖。app-service我们跳过不谈，它依赖于app-dao。我们最后看一下app-web：123456789101112131415161718&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;app-parent&lt;/artifactId&gt; &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;app-web&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt; &lt;artifactId&gt;app-service&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; app-web依赖于app-service，因此配置了对其的依赖。由于app-web是我们最终要部署的应用，因此它的packaging是war。为此，你需要有一个目录src/main/webapp。并在这个目录下拥有web应用需要的文件，如/WEB-INF/web.xml。没有web.xml，Maven会报告build失败，此外你可能还会有这样一些子目录：/js, /img, /css … 。 看看Maven是如何build整个项目的，我们在 app-parent 根目录中运行 mvn clean install ，输出的末尾会有大致这样的内容：12345678910111213141516171819202122232425262728......[INFO] [war:war][INFO] Packaging webapp[INFO] Assembling webapp[app-web] in [/home/juven/workspaces/ws-others/myapp/app-web/target/app-web-1.0-SNAPSHOT][INFO] Processing war project[INFO] Webapp assembled in[50 msecs][INFO] Building war: /home/juven/workspaces/ws-others/myapp/app-web/target/app-web-1.0-SNAPSHOT.war[INFO] [install:install][INFO] Installing /home/juven/workspaces/ws-others/myapp/app-web/target/app-web-1.0-SNAPSHOT.war to /home/juven/.m2/repository/org/myorg/myapp/app-web/1.0-SNAPSHOT/app-web-1.0-SNAPSHOT.war[INFO] [INFO] [INFO] ------------------------------------------------------------------------[INFO] Reactor Summary:[INFO] ------------------------------------------------------------------------[INFO] app-parent ............................................ SUCCESS [1.191s][INFO] app-util .............................................. SUCCESS [1.274s][INFO] app-dao ............................................... SUCCESS [0.583s][INFO] app-service ........................................... SUCCESS [0.593s][INFO] app-web ............................................... SUCCESS [0.976s][INFO] ------------------------------------------------------------------------[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESSFUL[INFO] ------------------------------------------------------------------------[INFO] Total time: 4 seconds[INFO] Finished at: Sat Dec 27 08:20:18 PST 2008[INFO] Final Memory: 3M/17M[INFO] ------------------------------------------------------------------------ 注意Reactor Summary，整个项目根据我们希望的顺序进行build。Maven根据我们的依赖配置，智能的安排了顺序，app-util, app-dao, app-service, app-web。 最后，你可以在 app-web/target 目录下找到文件 app-web-1.0-SNAPSHOT.war ，打开这个war包，在 /WEB-INF/lib 目录看到了 commons-lang-2.4.jar，以及对应的app-util, app-dao, app-service 的jar包。Maven自动帮你处理了打包的事情，并且根据你的依赖配置帮你引入了相应的jar文件。 使用多模块的Maven配置，可以帮助项目划分模块，鼓励重用，防止POM变得过于庞大，方便某个模块的构建，而不用每次都构建整个项目，并且使得针对某个模块的特殊控制更为方便。本文同时给出了一个实际的配置样例，展示了如何使用Maven配置多模块项目。","comments":true,"tags":[{"name":"maven","slug":"maven","permalink":"http://jishusuishouji.github.io/tags/maven/"}]},{"title":"mongodb最大连接数修改","date":"2017-03-26T11:22:25.000Z","path":"2017/03/26/mongodb/mongodb最大连接数修改/","text":"在nodejs启动时一次性开了200个Mongodb连接，目的是为了高并发时减少数据库连接耗时。如果做cluster开10个实例就有2000个连接了，这样就有些节点连接不到数据库的情况。 原因是Mongodb默认最大连接数只有819个，于是通过在启动里面加参数--maxConns=3000来提高最大连接数。然后重启服务，但悲剧的是通过db.serverStatus().connections;查看到最大连接数还是819。原因是linux系统的限制，Linux系统默认一个进程最大文件打开数目为1024。需要在Mongodb开启前修改这个限制。在运行数据前运行ulimit -n命令 。如果已经加入开机脚本，就要在脚本中启动前增加这行了。比如： ulimit -n 20000 /usr/mongodb/bin/mongod --dbpath=/usr/mongodb/data/ --logpath=/usr/mongodb/log/mongodb.log --maxConns=3000 --fork 再查看就可以看到最大连接数增加了。 重启机器后仍有问题解决问题：Invariant failure: ret resulted in status UnknownError 24: Too many open files at src/mongo/db/storage/wiredtiger/wiredtiger_session_cache.cpp 73 按照官方的建议https://docs.mongodb.com/manual/reference/ulimit/#recommended-ulimit-settings， 由于centos 6的最大进程连接数为1024，我们就增加一个限制设定的配置 Red Hat Enterprise Linux and CentOS 6 place a max process limitation of 1024 which overridesulimit settings. Create a file named /etc/security/limits.d/99-mongodb-nproc.conf with new soft nproc and hard nproc values to increase the process limit. See /etc/security/limits.d/90-nproc.conf file as an example. 按照官方推荐的设置123456-f (file size): unlimited-t (cpu time): unlimited-v (virtual memory): unlimited [1]-n (open files): 64000-m (memory size): unlimited [1] [2]-u (processes/threads): 64000 由于服务器只有openfiles不匹配且比推荐的小，另外process/threads比较大， 所以其中99-mongodb-nproc.conf的内容如下：12345678# Default limit for number of user&apos;s processes to prevent# accidental fork bombs.# See rhbz #432903 for reasoning. root soft nproc unlimitedroot hard nproc unlimitedroot soft nofile 64000root hard nofile 64000 设计后重启机器，可用ulimit -a看到值已经更改，问题解决。","comments":true,"tags":[{"name":"mongodb","slug":"mongodb","permalink":"http://jishusuishouji.github.io/tags/mongodb/"}]},{"title":"Spring Cloud Netflix构建微服务入门实践","date":"2017-03-26T09:57:46.000Z","path":"2017/03/26/spring/Spring_Cloud_Netflix构建微服务入门实践/","text":"在使用Spring Cloud Netflix构建微服务之前，我们先了解一下Spring Cloud集成的Netflix OSS的基础组件Eureka，对于Netflix的其他微服务组件，像Hystrix、Zuul、Ribbon等等本文暂不涉及，感兴趣可以参考官网文档。这里，我们用最基础的Eureka来构建一个最基础的微服务应用，来演示如何构建微服务，了解微服务的基本特点。 EurekaEureka是Netflix开源的一个微服务注册组件，提供服务发现特性，它是一个基于REST的服务，主要具有如下功能： 支持服务注册和发现 具有Load Balance和Failover的功能 在进行服务调用过程中，无需知道目标服务的主机（IP）和端口，只要知道服务名就可以实现调用 通过Netfix在Github上的文档，我们看一下Eureka的基本架构，如下图所示：Eureka主要包含如下两个核心组件： Eureka ServerEureka Server是服务注册的服务端组件，负责管理Eureka Client注册的服务，提供服务发现的功能。它支持集群模式部署，集群部署模式中，多个Eureka Server之间会同步服务注册数据，能够保证某一个Eureka Server因为故障挂掉，仍能对外提供注册服务的能力。因为最初在Netflix，Eureka主要用在AWS Cloud上，用作定位服务、Load Balance和Failover，在AWS Cloud上，Eureka支持在多个Region中部署Eureka Server而构建一个注册中心集群，从而实现了服务注册中心的高可用性。 Eureka ClientEureka Client是Eureka Server客户端组件库，可以基于它向Eureka Server注册服务，供服务调用方调用；也可以是一个服务调用方，通过检索服务并调用已经注册的服务。如上图所示，Application Service和Application Client都是基于Eureka Client开发的使用Eureka Server的服务。另外，Eureka Client提供了内置的Load Balancer，实现了基本的Round-robin模式的负载均衡。 Spring Cloud NetflixSpring Cloud Netflix提供了对Netflix OSS的集成，同时还使用了Spring Boot，能够极大地简化微服务程序的开发。使用Spring Cloud提供的基本注解，就能非常方便的使用Netfix OSS基本组件。要想使用Spring Cloud Eureka，只需要在Maven POM文件中加入如下依赖管理配置即可：1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix&lt;/artifactId&gt; &lt;version&gt;1.0.7.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 关于如何使用注解，我们会在下面的实践中，详细说明。 构建微服务实践我们构建一个简单的微服务应用，能够实现服务注册，服务调用的基本功能。计划实现的微服务应用，交互流程如下图所示：上图中，我们假设Eureka Client并没有缓存Eureka Server中注册的服务，而是每次都需要通过Eureka Server来查找并映射目标服务。上图所示的微服务应用，具有如下服务组件： 两个Eureka Server实例组成的服务发现集群通过Spring Cloud实现，只需要使用注解配置即可，代码如下所示： 01package org.shirdrn.springcloud.eureka.server;02 03import org.springframework.boot.autoconfigure.SpringBootApplication;04import org.springframework.boot.builder.SpringApplicationBuilder;05import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;06 07@EnableEurekaServer08@SpringBootApplication09public class MyEurekaServer {10 11 public static void main(String[] args) {12 new SpringApplicationBuilder(MyEurekaServer.class).web(true).run(args);13 }14}部署两个Eureka Server的代码是相同的，其中，对应的配置文件application.yml内容不同，示例如下所示： 01server:02 port: 330003spring:04 application:05 name: my-eureka-server06eureka:07 client:08 serviceUrl:09 defaultZone: http://localhost:3300/eureka/,http://localhost:3301/eureka/10 instance:11 metadataMap:12 instanceId: ${spring.application.name}:${spring.application.instance_id:${random.value}}另一个只需要改一下server.port为3301即可。 具有两个实例的Greeting Service服务该示例服务，只是提供一个接口，能够给调用方返回调用结果，实现代码，如下所示： 01package org.shirdrn.springcloud.eureka.applicationservice.greeting;02 03import org.springframework.boot.autoconfigure.EnableAutoConfiguration;04import org.springframework.boot.autoconfigure.SpringBootApplication;05import org.springframework.boot.builder.SpringApplicationBuilder;06import org.springframework.cloud.netflix.eureka.EnableEurekaClient;07import org.springframework.web.bind.annotation.PathVariable;08import org.springframework.web.bind.annotation.RequestMapping;09import org.springframework.web.bind.annotation.RequestMethod;10import org.springframework.web.bind.annotation.RestController;11 12@SpringBootApplication13@EnableEurekaClient14@RestController15@EnableAutoConfiguration16public class GreeingService {17 18 @RequestMapping(method = RequestMethod.GET, value = “/greeting/{name}”)19 public String greet(@PathVariable(“name”) String name) {20 return “::01:: Hello, “ + name + “!”;21 }22 23 public static void main(String[] args) {24 new SpringApplicationBuilder(GreeingService.class).web(true).run(args);25 }26}为了能够观察，Greeting Service的两个实例，能够在调用的时候实现Round-robin风格的负载均衡，特别在返回的结果中增加了标识来区分。对应的配置文件application.properties内容，除了对应的端口和服务实例名称不同，其它都相同，示例如下所示： 1server.port=99012spring.application.name = greeting.service3eureka.instance.metadataMap.instanceId = ${spring.application.name}:instance-99014eureka.client.serviceUrl.defaultZone = http://localhost:3300/eureka/,http://localhost:3301/eureka/这样就可以在启动时注册到Eureka Server中。 一个名称为Application Caller的服务，需要调用Greeting Service服务该服务和上面的服务类似，只是在其内部实现了对远程服务的调用，我们的实现代码如下所示： 01package org.shirdrn.springcloud.eureka.applicationclient.caller;02 03import org.springframework.beans.factory.annotation.Autowired;04import org.springframework.boot.CommandLineRunner;05import org.springframework.boot.autoconfigure.SpringBootApplication;06import org.springframework.boot.builder.SpringApplicationBuilder;07import org.springframework.cloud.netflix.eureka.EnableEurekaClient;08import org.springframework.cloud.netflix.feign.EnableFeignClients;09import org.springframework.stereotype.Component;10import org.springframework.web.client.RestTemplate;11 12@SpringBootApplication13@EnableEurekaClient14@EnableFeignClients15public class Application {16 17 public static void main(String[] args) {18 new SpringApplicationBuilder(Application.class)19 .web(false)20 .run(args);21 }22}23 24@Component25class RestTemplateExample implements CommandLineRunner {26 27 @Autowired28 private RestTemplate restTemplate;29 private static final String GREETING_SERVICE_URI = “http://greeting.service/greeting/{name}“; // 通过服务名称来调用，而不需要知道目标服务的IP和端口30 31 @Override32 public void run(String… strings) throws Exception {33 while(true) {34 String greetingSentence = this.restTemplate.getForObject(35 GREETING_SERVICE_URI,36 String.class,37 “Dean Shi”); // 透明调用远程服务38 System.out.println(“Response result: “ + greetingSentence);39 40 Thread.sleep(5000);41 }42 }43}对应的配置文件application.properties内容，如下所示： 1server.port=99992spring.application.name = application.client.caller3eureka.instance.metadataMap.instanceId = ${spring.application.name}:instance-99994eureka.client.serviceUrl.defaultZone = http://localhost:3300/eureka/,http://localhost:3301/eureka/启动并验证微服务应用 上面已经实现了该示例微服务应用的全部组件，先可以启动各个服务组件了。启动顺序如下所示： 启动两个Eureka Server启动两个Greeting Service启动服务消费应用Application Call可以通过Web页面查看Eureka Server控制台，如下图所示：eureka-web-console多次启动Application Call应用，就可以通过查看Greeting Service服务的日志，可以看到服务被调用，而且实现了基础的Round-robin负载均衡，日志如下所示： 1Response result: ::02:: Hello, Dean Shi!2Response result: ::01:: Hello, Dean Shi!3Response result: ::02:: Hello, Dean Shi!4Response result: ::01:: Hello, Dean Shi!5Response result: ::02:: Hello, Dean Shi!6Response result: ::01:: Hello, Dean Shi!我们实现示例微服务应用，验证后符合我们的期望。上面微服务应用的实现代码及其配置，可以查看我的Github：https://github.com/shirdrn/springcloud-eureka-demo.git 参考链接 https://github.com/Netflix/eureka/wiki/Eureka-at-a-glancehttp://cloud.spring.io/spring-cloud-netflix/http://cloud.spring.io/spring-cloud-netflix/1.0.x/https://spring.io/blog/2015/01/20/microservice-registration-and-discovery-with-spring-cloud-and-netflix-s-eurekahttp://itmuch.com/spring-cloud-sum-eureka/http://blog.abhijitsarkar.org/technical/netflix-eureka/Creative Commons License本文基于署名-非商业性使用-相同方式共享 4.0许可协议发布，欢迎转载、使用、重新发布，但务必保留文章署名时延军（包含链接：http://shiyanjun.cn），不得用于商业目的，基于本文修改后的作品务必以相同的许可发布。如有任何疑问，请与我联系。","comments":true,"tags":[{"name":"spring","slug":"spring","permalink":"http://jishusuishouji.github.io/tags/spring/"}]},{"title":"ZooKeeper 基础知识、部署和应用程序","date":"2017-03-25T16:07:53.000Z","path":"2017/03/26/zookeeper/ZooKeeper_基础知识、部署和应用程序/","text":"Apache ZooKeeper 是一个面向分布式应用程序的高性能协调服务器。它使用一个简单的接口暴露公共服务（比如命名和配置管理、同步和组服务），让用户不必从头开始编程。它为实现共识、组管理、领导者选举和到场协议（presence protocol）配备了现成的支持。 的示例。 简介ZooKeeper 是一个面向分布式系统的构建块。当设计一个分布式系统时，一般需要设计和开发一些协调服务： 名称服务— 名称服务是将一个名称映射到与该名称有关联的一些信息的服务。电话目录是将人的名字映射到其电话号码的一个名称服务。同样，DNS服务也是一个名称服务，它将一个域名映射到一个 IP 地址。在分布式系统中，您可能想跟踪哪些服务器或服务在运行，并通过名称查看其状态。ZooKeeper暴露了一个简单的接口来完成此工作。也可以将名称服务扩展到组成员服务，这样就可以获得与正在查找其名称的实体有关联的组的信息。 锁定— 为了允许在分布式系统中对共享资源进行有序的访问，可能需要实现分布式互斥（distributed mutexes）。ZooKeeper 提供一种简单的方式来实现它们。 同步— 与互斥同时出现的是同步访问共享资源的需求。无论是实现一个生产者-消费者队列，还是实现一个障碍，ZooKeeper 都提供一个简单的接口来实现该操作。 配置管理— 您可以使用 ZooKeeper 集中存储和管理分布式系统的配置。这意味着，所有新加入的节点都将在加入系统后就可以立即使用来自ZooKeeper的最新集中式配置。这还允许您通过其中一个 ZooKeeper 客户端更改集中式配置，集中地更改分布式系统的状态。 领导者选举— 分布式系统可能必须处理节点停机的问题，您可能想实现一个自动故障转移策略。ZooKeeper 通过领导者选举对此提供现成的支持。 虽然可以从头开始设计和实现所有这些服务，但调试任何问题、竞争条件或死锁都需要执行额外的工作，并且很难实现。就像您不会在代码中随处编写自己的随机数发生器或哈希函数一样，这里有一个要求：人们不应该在每次有需要时就到处从头编写自己的名称服务或领导者选举服务。此外，您可以相对容易地一起解决一个非常简单的组成员服务，但是，要编写它们来提供可靠性、复制和可扩展性，可能需要做更多的工作。这导致了Apache ZooKeeper 的开发和开源，Apache ZooKeeper是一个针对分布式系统的、开箱即用的、可靠的、可扩展的、高性能的协调服务。 ZooKeeper虽然是一个针对分布式系统的协调服务，但它本身也是一个分布式应用程序。ZooKeeper 遵循一个简单的客户端-服务器模型，其中客户端是使用服务的节点（即机器），而服务器是提供服务的节点。ZooKeeper 服务器的集合形成了一个ZooKeeper集合体（ensemble）。在任何给定的时间内，一个 ZooKeeper 客户端可连接到一个 ZooKeeper 服务器。每个 ZooKeeper服务器都可以同时处理大量客户端连接。每个客户端定期发送 ping 到它所连接的 ZooKeeper 服务器，让服务器知道它处于活动和连接状态。被询问的ZooKeeper 服务器通过 ping 确认进行响应，表示服务器也处于活动状态。如果客户端在指定时间内没有收到服务器的确认，那么客户端会连接到集合体中的另一台服务器，而且客户端会话会被透明地转移到新的 ZooKeeper 服务器。 ZooKeeper 有一个类似于文件系统的数据模型，由znodes组成。可以将 znodes（ZooKeeper 数据节点）视为类似 UNIX 的传统系统中的文件，但它们可以有子节点。另一种方式是将它们视为目录，它们可以有与其相关的数据。每个这些目录都被称为一个 znode。图 2 显示的图代表与两个城市中的运动队相同的层次结构。 znode层次结构被存储在每个 ZooKeeper服务器的内存中。这实现了对来自客户端的读取操作的可扩展的快速响应。每个 ZooKeeper服务器还在磁盘上维护了一个事务日志，记录所有的写入请求。因为ZooKeeper 服务器在返回一个成功的响应之前必须将事务同步到磁盘，所以事务日志也是ZooKeeper 中对性能最重要的组成部分。可以存储在 znode 中的数据的默认最大大小为 1 MB。因此，即使 ZooKeeper 的层次结构看起来与文件系统相似，也不应该将它用作一个通用的文件系统。相反，应该只将它用作少量数据的存储机制，以便为分布式应用程序提供可靠性、可用性和协调。当客户端请求读取特定 znode 的内容时，读取操作是在客户端所连接的服务器上进行的。因此，由于只涉及集合体中的一个服务器，所以读取是快速和可扩展的。然而，为了成功完成写入操作，要求 ZooKeeper 集合体的严格意义上的多数节点都是可用的。在启动 ZooKeeper 服务时，集合体中的某个节点被选举为领导者。当客户端发出一个写入请求时，所连接的服务器会将请求传递给领导者。此领导者对集合体的所有节点发出相同的写入请求。如果严格意义上的多数节点（也被称为法定数量（quorum））成功响应该写入请求，那么写入请求被视为已成功完成。然后，一个成功的返回代码会返回给发起写入请求的客户端。如果集合体中的可用节点数量未达到法定数量，那么ZooKeeper服务将不起作用。 法定数量是通过严格意义上的多数节点来表示的。在集合体中，可以包含一个节点，但它不是一个高可用和可靠的系统。如果在集合体中有两个节点，那么这两个节点都必须已经启动并让服务正常运行，因为两个节点中的一个并不是严格意义上的多数。如果在集合体中有三个节点，即使其中一个停机了，您仍然可以获得正常运行的服务（三个中的两个是严格意义上的多数）。出于这个原因，ZooKeeper 的集合体中通常包含奇数数量的节点，因为就容错而言，与三个节点相比，四个节点并不占优势，因为只要有两个节点停机，ZooKeeper 服务就会停止。在有五个节点的集群上，需要三个节点停机才会导致 ZooKeeper 服务停止运作。 现在，我们已经清楚地了解到，节点数量应该是奇数，让我们再来思考一下 ZooKeeper 集合体中需要有多少个节点。读取操作始终从连接到客户端的 ZooKeeper 服务器读取数据，所以它们的性能不会随着集合体中的服务器数量额变化而变化。但是，仅在写入法定数量的节点时，写入操作才是成功的。这意味着，随着在集合体中的节点数量的增加，写入性能会下降，因为必须将写入内容写入到更多的服务器中，并在更多服务器之间进行协调。 ZooKeeper的美妙之处在于，想运行多少服务器完全由您自己决定。如果想运行一台服务器，从 ZooKeeper的角度来看是没问题的；只是您的系统不再是高度可靠或高度可用的。三个节点的 ZooKeeper 集合体支持在一个节点故障的情况下不丢失服务，这对于大多数用户而言，这可能是没问题的，也可以说是最常见的部署拓扑。不过，为了安全起见，可以在您的集合体中使用五个节点。五个节点的集合体让您可以拿出一台服务器进行维护或滚动升级，并能够在不中断服务的情况下承受第二台服务器的意外故障。 因此，在 ZooKeeper 集合体中，三、五或七是最典型的节点数量。请记住，ZooKeeper 集合体的大小与分布式系统中的节点大小没有什么关系。分布式系统中的节点将是 ZooKeeper 集合体的客户端，每个 ZooKeeper服务器都能够以可扩展的方式处理大量客户端。例如，HBase（Hadoop 上的分布式数据库）依赖​​于 ZooKeeper 实现区域服务器的领导者选举和租赁管理。您可以利用一个相对较少（比如说，五个）节点的 ZooKeeper 集合体运行有 50 个节点的大型 HBase 集群。 设置并部署 ZooKeeper 集合体现在让我们设置并部署有三个节点的 ZooKeeper集合体。在这里，我们将使用撰写本文时的最新版的 ZooKeeper：3.4.5。我们用于此演示的节点被命名为zkserver1.mybiz.com、zkserver2.mybiz.com和zk3server3.mybiz.com。必须在每个节点上遵循下面的步骤来启动 ZooKeeper 服务器： 1.如果尚未安装 JDK，请下载安装它。这是必需的，因为 ZooKeeper 服务器在 JVM 上运行。2.下载 ZooKeeper 3.4.5. tar.gz tarball 并将它解压缩到适当的位置。清单 1. 下载 ZooKeeper tarball 并将它解压缩到适当的位置123 wgethttp://www.bizdirusa.com/mirrors/apache/ZooKeeper/stable/zookeeper3.4.5.tar.gz tar xzvf zookeeper3.4.5.tar.gz 3.创建一个目录，用它来存储与 ZooKeeper 服务器有关联的一些状态：mkdir /var/lib/zookeeper。您可能需要将这个目录创建为根目录，并在以后将这个目录的所有者更改为您希望运行ZooKeeper服务器的用户。4.设置配置。创建或编辑zookeeper3.4.5/conf/zoo.cfg文件，使其与 清单 2 相似。清单 2. 设置配置12345678tickTime=2000dataDir=/var/lib/zookeeper clientPort=2181initLimit=5 syncLimit=2server.1=zkserver1.mybiz.com:2888:3888server.2=zkserver2.mybiz.com:2888:3888server.3=zkserver3.mybiz.com:2888:3888 值得重点注意的一点是，所有三个机器都应该打开端口 2181、2888 和 3888。在本例中，端口 2181 由 ZooKeeper 客户端使用，用于连接到 ZooKeeper 服务器；端口 2888 由对等 ZooKeeper 服务器使用，用于互相通信；而端口 3888 用于领导者选举。您可以选择自己喜欢的任何端口。通常建议在所有 ZooKeeper 服务器上使用相同的端口。 5.创建一个 /var/lib/zookeeper/myid文件。此文件的内容将只包含 zkserver1.mybiz.com 上的数字 1、zkserver2.mybiz.com 上的数字 2 和 zkserver3.mybiz.com 上的数字 3。清单 3 显示了来自 zkserver1.mybiz.com 的此文件的 cat 输出。清单 3. cat 输出12mark@zkserver1.mybiz.com:~# cat/var/lib/zookeeper/myid 1 现在，您已经做好了在每台机器上启动 ZooKeeper 服务器的准备。 清单 4. 启动 ZooKeeper 服务器 bin/zkServer.sh start 现在，您可以从其中一台正在运行 ZooKeeper 服务器的机器上启动一个 CLI 客户端。 清单 5. 启动 CLI 客户端12zookeeper3.4.5/ bin/zkCli.sh serverzkserver1.mybiz.com:2181,zkserver2.mybiz.com:2181,zkserver3.mybiz.com:2181 客户端提供一个服务器列表，可以任意选中一个进行连接。如果在连接过程中失去与该服务器的连接，则会选中列表中的另一台服务器，而且客户端会话也会转移到该服务器。一旦启动了客户端，您就可以创建、编辑和删除 znode。让我们在 /mynode 创建一个znode，使用helloworld作为关联的数据。 清单 6. 在 /mynode 上创建一个 znode12[zk:127.0.0.1:2181(CONNECTED) 2] create /mynodehelloworld Created /mynode 现在，让我们在 /mynode 验证和检索数据。 清单 7. 在 /mynode 验证和检索数据1234567[zk:127.0.0.1:2181(CONNECTED) 6] get /mynodehelloworld cZxid = 0x200000005 ctime = Sat Jul 2019:53:52 PDT 2013 mZxid = 0x200000005 mtime = SatJul 20 19:53:52 PDT 2013 pZxid = 0x200000005cversion = 0 dataVersion = 0 aclVersion = 0ephemeralOwner = 0x0 dataLength = 11 numChildren =0 您会发现，在获取一个 znode 数据时，客户端也返回了一些与 znode 有关的元数据。此元数据中的一些重要字段包括，与创建和最后修改 znode 的时间有关的阶段时间戳（ctime 和 mtime）、每次修改数据都会更改的数据版本（dataVersion）、数据长度（dataLength）、这个 znode 的子节点的数量（numChildren）。我们现在可以删除 znode。 清单 8. 删除 znode12 [zk:127.0.0.1:2181(CONNECTED) 7]rmr /mynode 让我们在 /mysecondnode 创建另一个 znode。 清单 9. 创建另一个 znode```[zk:127.0.0.1:2181(CONNECTED) 10] create/mysecondnode hello Created /mysecondnode现在，让我们在 /mysecondnode 验证和检索数据。这一次，我们在最后提供了一个可选参数 1。此参数为 /mysecondnode 上的数据设置了一个一次性的触发器（名称为 watch）。如果另一个客户端在 /mysecondnode 上修改数据，该客户端将会获得一个异步通知。请注意，该通知只发送一次，除非 watch 被重新设置，否则不会因数据发生改变而再次发送通知。 清单 10. 在 /mysecondnode 上验证和检索数据 [zk:127.0.0.1:2181(CONNECTED) 12] get/mysecondnode 1 hello cZxid = 0x200000007 ctime =Sat Jul 20 19:58:27 PDT 2013 mZxid = 0x200000007mtime = Sat Jul 20 19:58:27 PDT 2013 pZxid =0x200000007 cversion = 0 dataVersion = 0aclVersion = 0 ephemeralOwner = 0x0 dataLength = 5numChildren = 0现在，从不同的客户端（比如，从不同的机器）更改与 /mysecondnode 有关联的数据的值。 清单 11. 更改与 /mysecondnode 有关联的数据的值 [zk: localhost:2181(CONNECTED)1] set /mysecondnode hello2 cZxid = 0x200000007ctime = Sat Jul 20 19:58:27 PDT 2013 mZxid =0x200000009 mtime = Sat Jul 20 20:02:37 PDT 2013pZxid = 0x200000007 cversion = 0 dataVersion = 1aclVersion = 0 ephemeralOwner = 0x0 dataLength = 6numChildren = 0您会发现，在第一个客户端上获得了一个 watch 通知。 清单 12. 在第一个客户端上获得了一个 watch 通知 [zk:127.0.0.1:2181(CONNECTED) 13] WATCHER::WatchedEvent state:SyncConnectedtype:NodeDataChanged path:/mysecondnode继续下去，因为 znode 形成了一个分层命名空间，所以您还可以创建子节点。 清单 13. 创建子节点 [zk:localhost:2181(CONNECTED) 2] create /mysecondnode/subnode 123 Created /mysecondnode/ subnode您可以获得关于某个 znode 的其他统计元数据。 清单 14. 获得关于某个 znode 的其他统计元数据 [zk:127.0.0.1:2181(CONNECTED)14] stat /mysecondnode cZxid = 0x200000007 ctime =Sat Jul 20 19:58:27 PDT 2013 mZxid = 0x200000009mtime = Sat Jul 20 20:02:37 PDT 2013 pZxid =0x20000000a cversion = 1 dataVersion = 1aclVersion = 0 ephemeralOwner = 0x0 dataLength = 6numChildren = 1在上面的示例中，我们使用了 ZooKeeper 的 CLI 客户端与 ZooKeeper 服务器进行交互。ZooKeeper 提供了 Java™、C、Python 和其他绑定。您可以通过这些绑定调用客户端 API，将 Java、C 或 Python 应用程序转换为 ZooKeeper 客户端。 ZooKeeper 的应用程序 由于 ZooKeeper 在分布式系统中提供了一些多功能的用例，ZooKeeper 有一组不同的实用应用程序。我们将在这里列出部分这些应用程序。这些应用程序大多取自 Apache ZooKeeper 维基，那里还提供了一个更完整的最新列表。请参阅 参考资料，获得这些技术的链接： Apache Hadoop 依靠 ZooKeeper 来实现 Hadoop HDFS NameNode 的自动故障转移，以及 YARN ResourceManager 的高可用性。 Apache HBase 是构建于 Hadoop 之上的分布式数据库，它使用 ZooKeeper 来实现区域服务器的主选举（master election）、租赁管理以及区域服务器之间的其他通信。 Apache Accumulo 是构建于 Apache ZooKeeper（和 Apache Hadoop）之上的另一个排序分布式键/值存储。 Apache Solr 使用 ZooKeeper 实现领导者选举和集中式配置。 Apache Mesos 是一个集群管理器，提供了分布式应用程序之间高效的资源隔离和共享。Mesos 使用 ZooKeeper 实现了容错的、复制的主选举。 Neo4j 是一个分布式图形数据库，它使用 ZooKeeper 写入主选择和读取从协调（read slave coordination）。 Cloudera Search 使用 ZooKeeper（通过 Apache Solr）集成了搜索功能与 Apache Hadoop，以实现集中式配置管理。 结束语 实现您自己的协议来协调分布式系统，这可能是一个令人感到沮丧的费时的过程。这正是 ZooKeeper 发挥其作用的地方。ZooKeeper 是一个稳定的、简单的、高性能的协调服务，为您提供编写正确的分布式应用程序所需的工具，而无需担心竞争条件、死锁和不一致。在下一次编写分布式应用程序时，您就可以利用 ZooKeeper 支持所有协调需求。","comments":true,"tags":[{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"http://jishusuishouji.github.io/tags/ZooKeeper/"}]},{"title":"Pointfree 编程风格指南","date":"2017-03-25T15:21:00.000Z","path":"2017/03/25/hanshushi/Pointfree_编程风格指南/","text":"函数式编程有什么用？Pointfree就是如何使用函数式编程的答案。 一、程序的本质左侧是数据输入（input），中间是一系列的运算步骤，对数据进行加工，右侧是最后的数据输出（output）。一个或多个这样的任务，就组成了程序。输入和输出（统称为 I/O）与键盘、屏幕、文件、数据库等相关。这里的关键是，中间的运算部分不能有 I/O 操作，应该是纯运算，即通过纯粹的数学运算来求值。否则，就应该拆分出另一个任务。I/O 操作往往有现成命令，大多数时候，编程主要就是写中间的那部分运算逻辑。现在，主流写法是过程式编程和面向对象编程，但是我觉得，最合适纯运算的是函数式编程。 二、函数的拆分与合成上面那张图中，运算过程可以用一个函数fn表示。fn的类型如下。1fn :: a -&gt; b 上面的式子表示，函数fn的输入是数据a，输出是数据b。如果运算比较复杂，通常需要将fn拆分成多个函数。f1、f2、f3的类型如下。123f1 :: a -&gt; mf2 :: m -&gt; nf3 :: n -&gt; b 上面的式子中，输入的数据还是a，输出的数据还是b，但是多了两个中间值m和n。我们可以把整个运算过程，想象成一根水管（pipe），数据从这头进去，那头出来。 函数的拆分，无非就是将一根水管拆成了三根。 进去的数据还是a，出来的数据还是b。fn与f1、f2、f3的关系如下。1fn = R.pipe(f1, f2, f3); 上面代码中，我用到了Ramda函数库的pipe方法，将三个函数合成为一个。 三、Pointfree 的概念1fn = R.pipe(f1, f2, f3); 这个公式说明，如果先定义f1、f2、f3，就可以算出fn。整个过程，根本不需要知道a或b。也就是说，我们完全可以把数据处理的过程，定义成一种与参数无关的合成运算。不需要用到代表数据的那个参数，只要把一些简单的运算步骤合成在一起即可。这就叫做Pointfree：不使用所要处理的值，只合成运算过程。中文可以译作”无值”风格。请看下面的例子。12var addOne = x =&gt; x + 1;var square = x =&gt; x * x; 上面是两个简单函数addOne和square。把它们合成一个运算。123var addOneThenSquare = R.pipe(addOne, square);addOneThenSquare(2) // 9 上面代码中，addOneThenSquare是一个合成函数。定义它的时候，根本不需要提到要处理的值，这就是Pointfree。 四、Pointfree 的本质Pointfree的本质就是使用一些通用的函数，组合出各种复杂运算。上层运算不要直接操作数据，而是通过底层函数去处理。这就要求，将一些常用的操作封装成函数。比如，读取对象的role属性，不要直接写成obj.role，而是要把这个操作封装成函数。12var prop = (p, obj) =&gt; obj[p];var propRole = R.curry(prop)(&apos;role&apos;); 上面代码中，prop函数封装了读取操作。它需要两个参数p（属性名）和obj（对象）。这时，要把数据obj要放在最后一个参数，这是为了方便柯里化。函数propRole则是指定读取role属性。12345678910111213var isWorker = s =&gt; s === &apos;worker&apos;;var getWorkers = R.filter(R.pipe(propRole, isWorker));var data = [ &#123;name: &apos;张三&apos;, role: &apos;worker&apos;&#125;, &#123;name: &apos;李四&apos;, role: &apos;worker&apos;&#125;, &#123;name: &apos;王五&apos;, role: &apos;manager&apos;&#125;,];getWorkers(data)// [// &#123;&quot;name&quot;: &quot;张三&quot;, &quot;role&quot;: &quot;worker&quot;&#125;,// &#123;&quot;name&quot;: &quot;李四&quot;, &quot;role&quot;: &quot;worker&quot;&#125;// ] 上面代码中，data是传入的值，getWorkers是处理这个值的函数。定义getWorkers的时候，完全没有提到data，这就是Pointfree。简单说，Pointfree就是运算过程抽象化，处理一个值，但是不提到这个值。这样做有很多好处，它能够让代码更清晰和简练，更符合语义，更容易复用，测试也变得轻而易举。 五、Pointfree 的示例一下面，我们来看一个示例。1var str = &apos;Lorem ipsum dolor sit amet consectetur adipiscing elit&apos;; 上面是一个字符串，请问其中最长的单词有多少个字符？我们先定义一些基本运算。123456789101112131415// 以空格分割单词var splitBySpace = s =&gt; s.split(&apos; &apos;);// 每个单词的长度var getLength = w =&gt; w.length;// 词的数组转换成长度的数组var getLengthArr = arr =&gt; R.map(getLength, arr); // 返回较大的数字var getBiggerNumber = (a, b) =&gt; a &gt; b ? a : b;// 返回最大的一个数字var findBiggestNumber = arr =&gt; R.reduce(getBiggerNumber, 0, arr); 然后，把基本运算合成为一个函数（查看完整代码）。1234567var getLongestWordLength = R.pipe( splitBySpace, getLengthArr, findBiggestNumber);getLongestWordLength(str) // 11 可以看到，整个运算由三个步骤构成，每个步骤都有语义化的名称，非常的清晰。这就是 Pointfree 风格的优势。Ramda 提供了很多现成的方法，可以直接使用这些方法，省得自己定义一些常用函数。123456// 上面代码的另一种写法var getLongestWordLength = R.pipe( R.split(&apos; &apos;), R.map(R.length), R.reduce(R.max, 0)); 六、Pointfree 示例二下面是一段服务器返回的 JSON 数据。现在要求是，找到用户 Scott 的所有未完成任务，并按到期日期升序排列。 过程式编程的代码如下:上面代码不易读，出错的可能性很大。现在使用 Pointfree 风格改写。12345678var getIncompleteTaskSummaries = function(membername) &#123; return fetchData() .then(R.prop(&apos;tasks&apos;)) .then(R.filter(R.propEq(&apos;username&apos;, membername))) .then(R.reject(R.propEq(&apos;complete&apos;, true))) .then(R.map(R.pick([&apos;id&apos;, &apos;dueDate&apos;, &apos;title&apos;, &apos;priority&apos;]))) .then(R.sortBy(R.prop(&apos;dueDate&apos;)));&#125;; 上面代码已经清晰很多了。另一种写法是，把各个then里面的函数合成起来。12345678910111213141516171819202122232425262728293031// 提取 tasks 属性var SelectTasks = R.prop(&apos;tasks&apos;);// 过滤出指定的用户var filterMember = member =&gt; R.filter( R.propEq(&apos;username&apos;, member));// 排除已经完成的任务var excludeCompletedTasks = R.reject(R.propEq(&apos;complete&apos;, true));// 选取指定属性var selectFields = R.map( R.pick([&apos;id&apos;, &apos;dueDate&apos;, &apos;title&apos;, &apos;priority&apos;]));// 按照到期日期排序var sortByDueDate = R.sortBy(R.prop(&apos;dueDate&apos;));// 合成函数var getIncompleteTaskSummaries = function(membername) &#123; return fetchData().then( R.pipe( SelectTasks, filterMember(membername), excludeCompletedTasks, selectFields, sortByDueDate, ) );&#125;; 上面的代码跟过程式的写法一比较，孰优孰劣一目了然。 函数式编程函数式编程是一种编程的模式，在这种编程模式中最常用的函数和表达式。它强调在编程的时候用函数的方式思考问题，函数也与其他数据类型一样，处于平等地位。可以将函数作为参数传入另一个函数，也可以作为别的函数的返回值。函数式编程倾向于用一系列嵌套的函数来描述运算过程。","comments":true,"tags":[{"name":"函数式编程","slug":"函数式编程","permalink":"http://jishusuishouji.github.io/tags/函数式编程/"}]},{"title":"用Nginx搭建CDN服务器方法-开启Nginx缓存与镜像,自建图片服务器","date":"2017-03-23T15:06:20.000Z","path":"2017/03/23/nginx/用Nginx搭建CDN服务器方法-开启Nginx缓存与镜像,自建图片服务器/","text":"Nginx的proxy_cache和proxy_store很强大，利用proxy_store搭建图片服务器镜像实际上就相当于七牛和又拍的镜像CDN功能了，自动拉取图片保存在CDN服务器上。而proxy_cache作为Nginx缓存，既可以用作负载均衡，也可以反向绑定域名。 用Nginx搭建CDN服务器方法-开启Nginx缓存与镜像,自建图片服务器一、利用Nginx的proxy_cache搭建缓存服务器一：编译ngx_cache_purge1、Nginx的Proxy_cache是根据Key值md5哈希存储缓存，支持任意的Key，例如你可以根据”域名、URI、参数”组合成key，也支持非200状态码，如404/302等。2、要利用Nginx的Proxy_cache，你需要在Nginx编译进ngx_cache_purge 模块，执行：nginx -V，查看有没有ngx_cache_purge字样，没有的话需要自己手动编译。 3、这里以Oneinstack编译ngx_cache_purge模块作为操作演示，如果你用的是其它的LNMP包可以参考，基本过程是差不多的。命令如下：123456789101112131415161718cd /root/oneinstack/src #进入安装包目录nginx -Vtar xzf nginx-1.10.3.tar.gz #根据上面查看到的nginx版本选择解压包 wget http://labs.frickle.com/files/ngx_cache_purge-2.3.tar.gztar zxvf ngx_cache_purge-2.3.tar.gzcd /root/oneinstack/src/nginx-1.10.3 # 下面的./configure 后加的参数，你可以直接复制刚刚用nginx -V得到的参数，然后在最后加上--add-module=../ngx_cache_purge-2.3即可，参考：./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_stub_status_module --with-http_v2_module --with-http_ssl_module --with-http_gzip_static_module --with-http_realip_module --with-http_flv_module --with-http_mp4_module --with-openssl=../openssl-1.0.2k --with-pcre=../pcre-8.39 --with-pcre-jit --with-ld-opt=-ljemalloc --add-module=../ngx_cache_purge-2.3 make mv /usr/local/nginx/sbin/nginx&#123;,$(date +%m%d)&#125;cp objs/nginx /usr/local/nginx/sbin #oneinstack，其它的可以不用这个操作 nginx -tservice nginx restart 4、安装完成后，再次nginx -V你就可以看到Nginx已经成功编译进了ngx_cache_purge 了。 二、利用Nginx的proxy_cache搭建缓存服务器二：修改Nginx配置文件1、先找到你的Nginx配置文件：nginx.conf（路径一般是在/usr/local/nginx/conf/nginx.conf），在配置文件Http中加入以下代码：（注意修改路径为你自己的路径）123456789proxy_connect_timeout 5;proxy_read_timeout 60;proxy_send_timeout 5;proxy_buffer_size 16k;proxy_buffers 4 64k;proxy_busy_buffers_size 128k;proxy_temp_file_write_size 128k;proxy_cache_path /data/wwwroot/pic.test.com levels=1:2 keys_zone=cache_one:200m inactive=30d max_size=5g;proxy_temp_path /data/wwwroot/pic.test.com/temp; 2、操作如下图：Nginx搭建CDN添加代码3、然后在你的虚拟主机的nginx.conf（路径一般是/usr/local/nginx/conf/vhost/pic.freehao123.com.conf），在server listen 80 和 listen 443 ssl http2 都加入下面命令：12345678910111213 location /{ proxy_pass https://www.freehao123.com; proxy_redirect off; proxy_set_header Host www.freehao123.com; proxy_cache cache_one; proxy_cache_valid 200 302 304 365d; proxy_cache_valid 301 1d; proxy_cache_valid any 1m; add_header Images-Cache “$upstream_cache_status from $host”; add_header Pragma public; add_header Cache-Control “public, must-revalidate, proxy-revalidate”; access_log off; log_not_found off; expires max;}4、将配置文件保存重新上传,然后执行:12nginx -tservice nginx restart5、先执行检查Nginx配置是否正确，确认没有问题的就是重启Nginx了。Nginx搭建CDN重启服务器6、如果你想缓存gravatar头像，那么代码就是：12345678910111213 location /avatar{ proxy_pass http://cn.gravatar.com; proxy_redirect off; proxy_set_header Host cn.gravatar.com; proxy_cache cache_one; proxy_cache_valid 200 302 304 365d; proxy_cache_valid 301 1d; proxy_cache_valid any 1m; add_header Images-Cache “$upstream_cache_status from $host”; add_header Pragma public; add_header Cache-Control “public, must-revalidate, proxy-revalidate”; access_log off; log_not_found off; expires max;}7、现在打开你的二级域名：pic.freehao123.com，你就可以看到已经正确缓存了图片了。Nginx搭建CDN缓存头像8、这里再给出另一个Nginx缓存代码，实现效果和上面是一样的。123456789101112131415161718192021222324 #先在Nginx配置中写入以下命令：proxy_temp_file_write_size 128k;proxy_temp_path /data/wwwroot/pic.ucblog.net/temp;proxy_cache_path /data/wwwroot/pic.ucblog.net levels=1:2 keys_zone=cache_one:500m inactive=7d max_size=5g; #再在虚拟主机的Nginx配置中写入以下命令：先在server listen 80 和listen 443代码前面加入：upstream gravatar { server secure.gravatar.com:443;}再在server listen 80 和listen 443 里面加入：location / { proxy_pass_header Server; proxy_set_header Host cn.gravatar.com; proxy_set_header Accept-Encoding ‘’; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_pass https://gravatar; proxy_cache cache_one; proxy_cache_valid 200 304 365d; proxy_cache_key $host$uri$is_args$args; expires max; }9、在VPS主机上，你可以看到proxy_cache生成的哈希文件，就表示缓存已经成功了。Nginx搭建CDN生成缓存文件三、利用Nginx的proxy_store搭建镜像服务器：修改Nginx配置方法1、Nginx的proxy_store作用是直接把静态文件在本地硬盘创建并读取，类似于七牛或者又拍这样的镜像CDN功能，首次访问会自动获取源站的静态图片等文件，之后的访问就是直接从CDN服务器读取，加快了速度。2、直接修改Nginx的虚拟主机配置文件（这里以img.freehao123.com.conf为演示），加入以下代码：1234567891011location / { expires 3d; proxy_set_header Accept-Encoding ‘’; root /data/wwwroot/img.freehao123.com; proxy_store on; proxy_store_access user:rw group:rw all:rw; proxy_temp_path /data/wwwroot/img.freehao123.com/temp; if ( !-e $request_filename) { proxy_pass https://www.freehao123.com; } }3、再次保存配置上传，然后重启Nginx。你可以看到img.freehao123.com请求的图片等静态文件已经成功从源站中获得到了。Nginx搭建CDN图片请求4、在VPS主机上的存目录中也可以看到proxy_store已经完整地将图片等静态文件的目录都保存下来了，相当于一个网站的镜像存储CDN了。Nginx搭建CDN镜像存储5、这里还有一个使用，效果和上面是一样的，记得替换好路径，代码如下：12345678910111213141516upstream http_tornado { server www.freehao123.com:443;} server { # 省略其他配置 location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf|js|html|htm|css)$ { root /opt/data/product/blog/cache; proxy_store on; proxy_store_access user:rw group:rw all:rw; proxy_temp_path /opt/data/product/blog/cache; if ( !-e $request_filename) { proxy_pass http://http_tornado; } } }四、Nginx的proxy_store和proxy_cache有什么区别？1、镜像与缓存的区别。从上面的介绍我们也可以看出来，proxy_store相当于镜像一个网站了，第二次访问图片等静态文件是直接读取CDN服务器上的，大大减轻了源站的负担。proxy_cache相当于缓存，即把请求生成Key，第二次访问就可以加快速度了。Nginx搭建CDN加快速度2、proxy_store适合静态，proxy_cache适合动态。proxy_store是将图片完整保存在CDN服务器上，所以它更适合于图片CDN加速，而proxy_cache是缓存生成Key，更加适合动态网站加速，可用于负载均衡，减轻服务器负担。Nginx搭建CDN减轻负担五、搭建镜像CDN服务器后要做的事情？1、第一，因为搭建镜像CDN服务器是完整地复制了源站的文件和URL，所以为了避免被搜索引擎误认为抄袭重复站，我们可以给CDN站加上Robots.txt，阻止搜索引擎收录。命令如下（允许收录图片，其它不允许爬取）：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192User-agent: BaiduspiderAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: 360SpiderAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: Baiduspider-imageAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: 360Spider-ImageAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: SosospiderAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: sogou spiderAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: YodaoBotAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: GooglebotAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: BingbotAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: SlurpAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: MSNBotAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: googlebot-imageAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: googlebot-mobileAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: yahoo-blogs/v3.9Allow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: psbotAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: Disallow: /2、第二，做好Nginx防盗链。如果你的CDN服务器流量不怎么够的话，建议还是做好防盗链措施，同时还可以帮你减轻服务器负担。在你的虚拟主机配置文件中加入以下代码：12345678location ~ ..(gif|jpg|jpeg|png|bmp|swf)$ { valid_referers none blocked freehao123.com .freehao123.com .google.cn .google.com .google.com.hk image.baidu.com *.baidu.com; if ($invalid_referer) { rewrite ^/ https://www.freehao123.com; #return 403; } } 3、第三，设置好Nginx默认图片。这个主要是针对缓存Gravatar头像的，当源站服务器不存在某一个图片或者文件时，我们可以给Nginx设置一个默认的图片或者链接，这样缓存看起来就完美了。123456789101112 location /avatar { try_files $uri /avatar/set-avatar.png; } #或者使用： location /{ try_files $uri /set-avatar.png; }4、效果见下图：用Nginx搭建CDN默认图片文章出自：免费资源部落 部分内容参考张戈博客\\cheyo.net\\ttt.tt版权所有。本站文章除注明出处外，皆为作者原创文章，可自由引用，但请注明来源。2014年六大免费VPS主机-免费VPS申请、使用和点评您或许对下面这些文章有兴趣: 本月吐槽辛苦排行榜UPyun又拍云CDN安装部署Let’s Encrypt免费SSL证书和配置自定义SSL证书Kloudsec免费CDN加速-提供免费SSL证书支持Https自定义SSL新加坡节点服务器性能管理(APM)：性能魔方mmtrix一站式云评测,云监测,云加速网站UPYUN又拍云动态CDN和静态CDN加速支持自定义域名Https和图片处理阿里百川多媒体-20GB免费存储空间和CDN流量支持图片,视频在线处理2014年十个优秀的免费CDN加速服务-国内和国外免费CDNIncapsula免费CDN服务申请使用:日本,香港,美国CDN加速效果测评Discuz论坛使用七牛,又拍,阿里云OSS CDN加速：CSS,JS,图片,论坛附件","comments":true,"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://jishusuishouji.github.io/tags/Nginx/"}]},{"title":"druid 配置WebStatFilter 网络url统计","date":"2017-03-23T14:54:59.000Z","path":"2017/03/23/druid/druid_配置WebStatFilter_网络url统计/","text":"WebStatFilter用于采集web-jdbc关联监控的数据。 web.xml配置123456789101112&lt;filter&gt; &lt;filter-name&gt;DruidWebStatFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.alibaba.druid.support.http.WebStatFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;exclusions&lt;/param-name&gt; &lt;param-value&gt;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;DruidWebStatFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; exlusions配置经常需要排除一些不必要的url，比如.js,/jslib/等等。配置在init-param中。比如：1234&lt;init-param&gt; &lt;param-name&gt;exclusions&lt;/param-name&gt; &lt;param-value&gt;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&lt;/param-value&gt; &lt;/init-param&gt; sessionStatMaxCount配置缺省sessionStatMaxCount是1000个。你可以按需要进行配置，比如：1234&lt;init-param&gt; &lt;param-name&gt;sessionStatMaxCount&lt;/param-name&gt; &lt;param-value&gt;1000&lt;/param-value&gt; &lt;/init-param&gt; `sessionStatEnable配置你可以关闭session统计功能，比如：1234&lt;init-param&gt; &lt;param-name&gt;sessionStatEnable&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; principalSessionName配置你可以配置principalSessionName，使得druid能够知道当前的session的用户是谁。比如：1234&lt;init-param&gt; &lt;param-name&gt;principalSessionName&lt;/param-name&gt; &lt;param-value&gt;xxx.user&lt;/param-value&gt; &lt;/init-param&gt; 根据需要，把其中的xxx.user修改为你user信息保存在session中的sessionName。 注意：如果你session中保存的是非string类型的对象，需要重载toString方法 principalCookieName如果你的user信息保存在cookie中，你可以配置principalCookieName，使得druid知道当前的user是谁1234&lt;init-param&gt; &lt;param-name&gt;principalCookieName&lt;/param-name&gt; &lt;param-value&gt;xxx.user&lt;/param-value&gt; &lt;/init-param&gt; 根据需要，把其中的xxx.user修改为你user信息保存在cookie中的cookieName profileEnabledruid 0.2.7版本开始支持profile，配置profileEnable能够监控单个url调用的sql列表。1234&lt;init-param&gt; &lt;param-name&gt;profileEnable&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;","comments":true,"tags":[{"name":"druid","slug":"druid","permalink":"http://jishusuishouji.github.io/tags/druid/"}]},{"title":"DRUID连接池的实用 配置详解","date":"2017-03-23T14:03:57.000Z","path":"2017/03/23/druid/DRUID连接池的实用_配置详解/","text":"DRUID介绍DRUID是阿里巴巴开源平台上一个数据库连接池实现，它结合了C3P0、DBCP、PROXOOL等DB池的优点，同时加入了日志监控，可以很好的监控DB池连接和SQL的执行情况，可以说是针对监控而生的DB连接池(据说是目前最好的连接池,不知道速度有没有BoneCP快)。 配置参数和其它连接池一样DRUID的DataSource类为：com.alibaba.druid.pool.DruidDataSource，基本配置参数如下： name 配置这个属性的意义在于，如果存在多个数据源，监控的时候可以通过名字来区分开来。如果没有配置，将会生成一个名字，格式是：”DataSource-“ + System.identityHashCode(this) jdbcUrl连接数据库的url，不同数据库不一样。例如：mysql:jdbc:mysql://10.20.153.104:3306/druid2oracle:jdbc:oracle:thin:@10.20.149.85:1521:ocnauto username连接数据库的用户名 password连接数据库的密码。如果你不希望密码直接写在配置文件中，可以使用ConfigFilter。 driverClassName根据url自动识别这一项可配可不配，如果不配置druid会根据url自动识别dbType，然后选择相应的driverClassName(建议配置下) initialSize默认值0，初始化时建立物理连接的个数。初始化发生在显示调用init方法，或者第一次getConnection时 maxActive默认值8最大连接池数量 maxIdle默认值8已经不再使用，配置了也没效果 minIdle最小连接池数量 maxWait获取连接时最大等待时间，单位毫秒。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降，如果需要可以通过配置useUnfairLock属性为true使用非公平锁。 poolPreparedStatementsfalse是否缓存preparedStatement，也就是PSCache。PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql下建议关闭。 maxOpenPreparedStatements-1要启用PSCache，必须配置大于0，当大于0时，poolPreparedStatements自动触发修改为true。在Druid中，不会存在Oracle下PSCache占用内存过多的问题，可以把这个数值配置大一些，比如说100 validationQuery用来检测连接是否有效的sql，要求是一个查询语句。如果validationQuery为null，testOnBorrow、testOnReturn、testWhileIdle都不会其作用。 testOnBorrowtrue申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。 testOnReturnfalse归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能 testWhileIdlefalse建议配置为true，不影响性能，并且保证安全性。申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效。timeBetweenEvictionRunsMillis有两个含义：1) Destroy线程会检测连接的间隔时间2) testWhileIdle的判断依据，详细看testWhileIdle属性的说明 numTestsPerEvictionRun不再使用，一个DruidDataSource只支持一个EvictionRun minEvictableIdleTimeMillisconnectionInitSqls物理连接初始化的时候执行的sql exceptionSorter根据dbType自动识别当数据库抛出一些不可恢复的异常时，抛弃连接 filters属性类型是字符串，通过别名的方式配置扩展插件，常用的插件有：监控统计用的filter:stat日志用的filter:log4j防御sql注入的filter:wall proxyFilters类型是List&lt;com.alibaba.druid.filter.Filter&gt;，如果同时配置了filters和proxyFilters，是组合关系，并非替换关系 使用方法DB数据源的使用方法也就是2种，一种是在代码中写死通过NEW操作符创建DataSSource，然后set一些连接属性;另外一种是基于SPRING的配置方法，然后让SPRING的Context自动加载配置（以下配置文件默认都在项目根目录下conf文件夹中） 1、属性文件:application.properties(DataSource连接参数) 1234jdbc.driverClassName=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://127.0.0.1:3306/test jdbc.username=root jdbc.password=1qaz!QAZ 2、SPRING配置文件：spring-base.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot; http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot; http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:batch=&quot; http://www.springframework.org/schema/batch&quot; xsi:schemaLocation=&quot; http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd&quot;&gt; &lt;bean id=&quot;propertyConfigure&quot; class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt; &lt;property name=&quot;locations&quot;&gt; &lt;list&gt; &lt;value&gt;./conf/application.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;$&#123;jdbc.driverClassName&#125;&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url&#125;&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot; /&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name=&quot;initialSize&quot; value=&quot;1&quot; /&gt; &lt;property name=&quot;minIdle&quot; value=&quot;1&quot; /&gt; &lt;property name=&quot;maxActive&quot; value=&quot;10&quot; /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name=&quot;maxWait&quot; value=&quot;10000&quot; /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;60000&quot; /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;300000&quot; /&gt; &lt;property name=&quot;testWhileIdle&quot; value=&quot;true&quot; /&gt; &lt;!-- 这里建议配置为TRUE，防止取到的连接不可用 --&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;testOnReturn&quot; value=&quot;false&quot; /&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name=&quot;poolPreparedStatements&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;maxPoolPreparedStatementPerConnectionSize&quot; value=&quot;20&quot; /&gt; &lt;!-- 这里配置提交方式，默认就是TRUE，可以不用配置 --&gt; &lt;property name=&quot;defaultAutoCommit&quot; value=&quot;true&quot; /&gt; &lt;!-- 验证连接有效与否的SQL，不同的数据配置不同 --&gt; &lt;property name=&quot;validationQuery&quot; value=&quot;select 1 &quot; /&gt; &lt;property name=&quot;filters&quot; value=&quot;stat&quot; /&gt; &lt;property name=&quot;proxyFilters&quot;&gt; &lt;list&gt; &lt;ref bean=&quot;logFilter&quot; /&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;logFilter&quot; class=&quot;com.alibaba.druid.filter.logging.Slf4jLogFilter&quot;&gt; &lt;property name=&quot;statementExecutableSqlLogEnable&quot; value=&quot;false&quot; /&gt; &lt;/bean&gt;&lt;/beans&gt; 监控方式1、WEB方式监控配置&lt;servlet&gt; &lt;servlet-name&gt;DruidStatView&lt;/servlet-name&gt; &lt;servlet-class&gt;com.alibaba.druid.support.http.StatViewServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;DruidStatView&lt;/servlet-name&gt; &lt;url-pattern&gt;/druid/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;filter&gt; &lt;filter-name&gt;druidWebStatFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.alibaba.druid.support.http.WebStatFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;exclusions&lt;/param-name&gt; &lt;param-value&gt;/public/*,*.js,*.css,/druid*,*.jsp,*.swf&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;principalSessionName&lt;/param-name&gt; &lt;param-value&gt;sessionInfo&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;profileEnable&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;druidWebStatFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 把上面servlet配置添加到项目web.xml即可。然后运行Tomcat，浏览器输入 http://IP:PROT/druid 就可以打开Druid的监控页面了. 2、日志文件监控Druid提供了多种日志文件监控commons-logging、log4j等，这里我们主要使用slf4j和logback来进行日志监控配置。 首先要引入slf4j和logback相关的jar文件（从Maven公共仓库下载 http://search.maven.org/） 12345678910111213141516171819202122232425&lt;slf4j.version&gt;1.7.7&lt;/slf4j.version&gt; &lt;logback.version&gt;1.1.2&lt;/logback.version&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-access&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; 接下配置logback的配置文件(./conf/logback.xml) 1234567891011121314151617181920212223&lt;configuration&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;Pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n &lt;/Pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt; &lt;file&gt;./logs/druid_info.log&lt;/file&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;Pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/Pattern&gt; &lt;/layout&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;level&gt;debug&lt;/level&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;FILE&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; 最后就是写一个测试类进行测试 12345678910111213141516171819public class TestMain &#123; public static void loadLoggerContext() &#123; System.getProperties().put(&quot;logback.configurationFile&quot;, &quot;./conf/logback.xml&quot;); LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory(); StatusPrinter.setPrintStream(System.err); StatusPrinter.print(lc); &#125; public static void main(String[] args) &#123; try &#123; loadLoggerContext(); FileSystemXmlApplicationContext context = new FileSystemXmlApplicationContext(&quot;./conf/spring-base.xml&quot;); &#125; catch (Exception e) &#123; System.out.println(e); &#125; &#125; &#125;","comments":true,"tags":[{"name":"Druid","slug":"Druid","permalink":"http://jishusuishouji.github.io/tags/Druid/"}]},{"title":"Druid：一个用于大数据实时处理的开源分布式系统","date":"2017-03-23T14:00:02.000Z","path":"2017/03/23/druid/Druid：一个用于大数据实时处理的开源分布式系统/","text":"Druid是一个用于大数据实时查询和分析的高容错、高性能开源分布式系统，旨在快速处理大规模的数据，并能够实现快速查询和分析。尤其是当发生代码部署、机器故障以及其他产品系统遇到宕机等情况时，Druid仍能够保持100%正常运行。创建Druid的最初意图主要是为了解决查询延迟问题，当时试图使用Hadoop来实现交互式查询分析，但是很难满足实时分析的需要。而Druid提供了以交互方式访问数据的能力，并权衡了查询的灵活性和性能而采取了特殊的存储格式。Druid功能介于PowerDrill和Dremel之间，它几乎实现了Dremel的所有功能，并且从PowerDrill吸收一些有趣的数据格式。Druid允许以类似Dremel和PowerDrill的方式进行单表查询，同时还增加了一些新特性，如为局部嵌套数据结构提供列式存储格式、为快速过滤做索引、实时摄取和查询、高容错的分布式体系架构等。从官方得知，Druid的具有以下主要特征： 为分析而设计——Druid是为OLAP工作流的探索性分析而构建，它支持各种过滤、聚合和查询等类； 快速的交互式查询——Druid的低延迟数据摄取架构允许事件在它们创建后毫秒内可被查询到； 高可用性——Druid的数据在系统更新时依然可用，规模的扩大和缩小都不会造成数据丢失； 可扩展——Druid已实现每天能够处理数十亿事件和TB级数据。 Druid应用最多的是类似于广告分析创业公司Metamarkets中的应用场景，如广告分析、互联网广告系统监控以及网络监控等。当业务中出现以下情况时，Druid是一个很好的技术方案选择： 需要交互式聚合和快速探究大量数据时；需要实时查询分析时；具有大量数据时，如每天数亿事件的新增、每天数10T数据的增加；对数据尤其是大数据进行实时分析时；需要一个高可用、高容错、高性能数据库时。一个Druid集群有各种类型的节点（Node）组成，每个节点都可以很好的处理一些的事情，这些节点包括对非实时数据进行处理存储和查询的Historical节点、实时摄取数据、监听输入数据流的Realtime节、监控Historical节点的Coordinator节点、接收来自外部客户端的查询和将查询转发到Realtime和Historical节点的Broker节点、负责索引服务的Indexer节点。 查询操作中数据流和各个节点的关系如下图所示： 如下图是Druid集群的管理层架构，该图展示了相关节点和集群管理所依赖的其他组件（如负责服务发现的ZooKeeper集群）的关系： Druid已基于Apache License 2.0协议开源，代码托管在GitHub，其当前最新稳定版本是0.7.1.1。当前，Druid已有63个代码贡献者和将近2000个关注。Druid的主要贡献者包括广告分析创业公司Metamarkets、电影流媒体网站Netflix、Yahoo等公司。Druid官方还对Druid同Shark、Vertica、Cassandra、Hadoop、Spark、Elasticsearch等在容错能力、灵活性、查询性能等方便进行了对比说明。更多关于Druid的信息，大家还可以参考官方提供的入门教程、白皮书 、设计文档等。 感谢徐川对本文的审校。","comments":true,"tags":[{"name":"Druid","slug":"Druid","permalink":"http://jishusuishouji.github.io/tags/Druid/"}]},{"title":"架构师必看 京东咚咚架构演进","date":"2017-03-21T13:01:44.000Z","path":"2017/03/21/jiagou/架构师必看_京东咚咚架构演进/","text":"技术架构单独拿出来看我认为没有绝对的好与不好，技术架构总是要放在彼时的背景下来看，要考虑业务的时效价值、团队的规模和能力、环境基础设施等等方面。 架构演进的生命周期适时匹配好业务的生命周期，才可能发挥最好的效果。 京东咚咚自从京东开始为第三方卖家提供入驻平台服务后，咚咚也就随之诞生了。 1.0 诞生（2010 – 2011)为了业务的快速上线，1.0 版本的技术架构实现是非常直接且简单粗暴的。 如何简单粗暴法？请看架构图，如下。京东咚咚1.0的功能十分简单，实现了一个IM的基本功能，接入、互通消息和状态。另外还有客服功能，就是顾客接入咨询时的客服分配，按轮询方式把顾客分配给在线的客服接待。 用开源Mina框架实现了TCP的长连接接入，用Tomcat Comet机制实现了HTTP的长轮询服务。而消息投递的实现是一端发送的消息临时存放在 Redis中，另一端拉取的生产消费模型。这个模型的做法导致需要以一种高频率的方式来轮询Redis遍历属于自己连接的关联会话消息。这个模型很简单，简单包括多个层面的意思：理解起来简单；开发起来简单；部署起来也简单。只需要一个Tomcat应用依赖一个共享的Redis，简单的实现核心业务功能，并支持业务快速上线。但这个简单的模型也有些严重的缺陷，主要是效率和扩展问题。轮询的频率间隔大小基本决定了消息的延时，轮询越快延时越低，但轮询越快消耗也越高。这个模型实际上是一个高功耗低效能的模型，因为不活跃的连接在那做高频率的无意义轮询。 高频有多高呢，基本在100ms以内，你不能让轮询太慢，比如超过2秒轮一次，人就会在聊天过程中感受到明显的会话延迟。 随着在线人数增加，轮询的耗时也线性增长，因此这个模型导致了扩展能力和承载能力都不好，一定会随着在线人数的增长碰到性能瓶颈。 1.0的时代背景正是京东技术平台从.NET向Java转型的年代，我也正是在这期间加入京东并参与了京东主站技术转型架构升级的过程。 之后开始接手了京东咚咚，并持续完善这个产品，进行了三次技术架构演进。 2.0 成长（2012）我们刚接手时1.0已在线上运行并支持京东POP（开放平台）业务，之后京东打算组建自营在线客服团队并落地在成都。不管是自营还是POP客服咨询业务当时都起步不久，1.0架构中的性能和效率缺陷问题还没有达到引爆的业务量级。而自营客服当时还处于起步阶段，客服人数不足，服务能力不够，顾客咨询量远远超过客服的服务能力。超出服务能力的顾客咨询，当时我们的系统统一返回提示客服繁忙，请稍后咨询。 这种状况导致高峰期大量顾客无论怎么刷新请求，都很可能无法接入客服，体验很差。所以2.0重点放在了业务功能体验的提升上，如下图所示。京东咚咚针对无法及时提供服务的顾客，可以排队或者留言。 针对纯文字沟通，提供了文件和图片等更丰富的表达方式。 另外支持了客服转接和快捷回复等方式来提升客服的接待效率。总之，整个2.0就是围绕提升客服效率和用户体验。而我们担心的效率问题在2.0高速发展业务的时期还没有出现，但业务量正在逐渐积累，我们知道它快要爆了。到2012年末，度过双十一后开始了3.0的一次重大架构升级。 3.0爆发（2013 – 2014）经历了2.0时代一整年的业务高速发展，实际上代码规模膨胀的很快。与代码一块膨胀的还有团队，从最初的4个人到近30人。 团队大了后，一个系统多人开发，开发人员层次不一，规范难统一，系统模块耦合重，改动沟通和依赖多，上线风险难以控制。一个单独tomcat应用多实例部署模型终于走到头了，这个版本架构升级的主题就是服务化。服务化的第一个问题如何把一个大的应用系统切分成子服务系统。当时的背景是京东的部署还在半自动化年代，自动部署系统刚起步，子服务系统若按业务划分太细太多，部署工作量很大且难管理。所以当时我们不是按业务功能分区服务的，而是按业务重要性级别划分了0、1、2 三个级别不同的子业务服务系统。 另外就是独立了一组接入服务，针对不同渠道和通信方式的接入端，见下图。更细化的应用服务和架构分层方式可见下图。这次大的架构升级，主要考虑了三个方面：稳定性、效率和容量。 做了下面这些事情：1.业务分级、核心、非核心业务隔离2.多机房部署，流量分流、容灾冗余、峰值应对冗余3.读库多源，失败自动转移4.写库主备，短暂有损服务容忍下的快速切换5.外部接口，失败转移或快速断路6.Redis 主备，失败转移7.大表迁移，MongoDB 取代 MySQL 存储消息记录8.改进消息投递模型 前 6 条基本属于考虑系统稳定性、可用性方面的改进升级。 这一块属于陆续迭代完成的，承载很多失败转移的配置和控制功能在上面图中是由管控中心提供的。 第 7 条主要是随着业务量的上升，单日消息量越来越大后，使用了 MongoDB来单独存储量最大的聊天记录。 第 8 条是针对 1.0版本消息轮询效率低的改进，改进后的投递方式如下图所示：不再是轮询了，而是让终端每次建立连接后注册接入点位置，消息投递前定位连接所在接入点位置再推送过去。 这样投递效率就是恒定的了，而且很容易扩展，在线人数越多则连接数越多，只需要扩展接入点即可。 其实，这个模型依然还有些小问题，主要出在离线消息的处理上，可以先思考下，我们最后再讲。3.0 经过了两年的迭代式升级，单纯从业务量上来说还可以继续支撑很长时间的增长。 但实际上到2014年底我们面对的不再是业务量的问题，而是业务模式的变化。 这直接导致了一个全新时代的到来。 4.0 涅槃（2015 至今 )2014年京东的组织架构发生了很大变化，从一个公司变成了一个集团，下设多个子公司。原来的商城成为了其中一个子公司，新成立的子公司包括京东金融、京东智能、京东到家、拍拍、海外事业部等。各自业务范围不同，业务模式也不同，但不管什么业务总是需要客服服务。如何复用原来为商城量身订做的咚咚客服系统并支持其他子公司业务快速接入成为我们新的课题。最早要求接入的是拍拍网，它是从腾讯收购的，所以是完全不同的账户和订单交易体系。由于时间紧迫，我们把为商城订做的部分剥离，基于3.0架构对接拍拍又单独订做了一套，并独立部署，像下面这样。京东咚咚虽然在业务要求的时间点前完成了上线，但这样做也带来了明显的问题：复制工程，定制业务开发，多套源码维护成本高独立部署，至少双机房主备外加一个灰度集群，资源浪费大以前我们都是面向业务去架构系统，如今新的业务变化形势下我们开始考虑面向平台去架构，在统一平台上跑多套业务，统一源码，统一部署，统一维护。 把业务服务继续拆分，剥离出最基础的 IM 服务，IM 通用服务，客服通用服务，而针对不同的业务特殊需求做最小化的定制服务开发。 部署方式则以平台形式部署，不同的业务方的服务跑在同一个平台上，但数据互相隔离。 服务继续被拆分的更微粒化，形成了一组服务矩阵（见下图）。京东咚咚而部署方式，只需要在双机房建立两套对等集群，并另外建一个较小的灰度发布集群即可，所有不同业务都运行在统一平台集群上，如下图。京东咚咚更细粒度的服务意味着每个服务的开发更简单，代码量更小，依赖更少，隔离稳定性更高。 但更细粒度的服务也意味着更繁琐的运维监控管理，直到今年公司内部弹性私有云、缓存云、消息队列、部署、监控、日志等基础系统日趋完善， 使得实施这类细粒度划分的微服务架构成为可能，运维成本可控。 而从当初 1.0 的 1 种应用进程，到 3.0 的 6、7 种应用进程，再到 4.0 的 50+ 更细粒度的不同种应用进程。 每种进程再根据承载业务流量不同分配不同的实例数，真正的实例进程数会过千。 为了更好的监控和管理这些进程，为此专门定制了一套面向服务的运维管理系统，见下图。京东咚咚统一服务运维提供了实用的内部工具和库来帮助开发更健壮的微服务。 包括中心配置管理，流量埋点监控，数据库和缓存访问，运行时隔离，如下图所示是一个运行隔离的图示：京东咚咚细粒度的微服务做到了进程间隔离，严格的开发规范和工具库帮助实现了异步消息和异步 HTTP 来避免多个跨进程的同步长调用链。 进程内部通过切面方式引入了服务增强容器 Armor 来隔离线程， 并支持进程内的单独业务降级和同步转异步化执行。而所有这些工具和库服务都是为了两个目标：让服务进程运行时状态可见让服务进程运行时状态可被管理和改变最后我们回到前文留下的一个悬念，就是关于消息投递模型的缺陷。 一开始我们在接入层检测到终端连接断开后，消息无法投递，再将消息缓存下来，等终端重连接上来再拉取离线消息。 这个模型在移动时代表现的很不好，因为移动网络的不稳定性，导致经常断链后重连。 而准确的检测网络连接断开是依赖一个网络超时的，导致检测可能不准确，引发消息假投递成功。 新的模型如下图所示，它不再依赖准确的网络连接检测，投递前待确认消息 id 被缓存，而消息体被持久存储。 等到终端接收确认返回后，该消息才算投妥，未确认的消息 id 再重新登陆后或重连接后作为离线消息推送。 这个模型不会产生消息假投妥导致的丢失，但可能导致消息重复，只需由客户终端按消息 id 去重即可。京东咚咚京东咚咚诞生之初正是京东技术转型到 Java 之时，经历这些年的发展，取得了很大的进步。 从草根走向专业，从弱小走向规模，从分散走向统一，从杂乱走向规范。 本文主要重心放在了几年来咚咚架构演进的过程，技术架构单独拿出来看我认为没有绝对的好与不好， 技术架构总是要放在彼时的背景下来看，要考虑业务的时效价值、团队的规模和能力、环境基础设施等等方面。 架构演进的生命周期适时匹配好业务的生命周期，才可能发挥最好的效果。 【编辑推荐】58同城沈剑：好的架构不是设计出来的，而是演进出来的架构必备：Rate limiting 的作用和常见方式京东11.11：商品搜索系统架构设计解密京东唐志雄：从技术角度看白条资产证券化关于Java应用相关不同产品的架构中小型网站架构分析及优化友盟吴磊：移动大数据平台的架构、实践与数据增值【责任编辑：wangxueyan TEL：（010）68476606】 点赞 0架构师 京东 架构分享:内容点评已有0条评论,0次赞还可以输入500字 请输入你的评论提交您还没有登录！请先 登录 或 注册还没有评论内容大家都在看猜你喜欢紧急预警！Struts2新漏洞S2-045来袭，多个版本受影响紧急预警！Struts2新漏洞S2-045来袭，多个版本受影响2017年，为何过半的大数据项目不成功?2017年，为何过半的大数据项目不成功?2017年3月编程语言排行榜：Swift首次进入前十2017年3月编程语言排行榜：Swift首次进入前十如何禁掉Windows 10上的所有广告如何禁掉Windows 10上的所有广告编辑推荐外电iOS与Android设备到底是如何被入侵的？头条HTML5游戏开发难点之效率、性能和加载量头条你所不了解的移动支付背后的技术支撑外电我们为何很难对超大规模应用与分布式架构进行备份？头条2017年3月编程语言排行榜：Swift首次进入前十24H热文一周话题本月最赞5个强大的Java分布式缓存框架推荐坐在马桶上看算法：快速排序Java程序员新手老手都离不开八大开发工具2017年3月编程语言排行榜：Swift首次进入前十多图详解Spring框架的设计理念与设计模式2015年十五个热门的 PHP 开发工具Java 中常用缓存Cache机制的实现浅谈Java中的Set、List、Map的区别视频课程+更多技术大咖的旅游梦：同程CTO结缘腾讯云技术大咖的旅游梦：同程CTO结缘腾讯云讲师：腾讯云1人学习过软考网络工程师考试之IP地址计算轻松解决视频课程（攻克要塞系列）软考网络工程师考试之IP地址计算轻松解决视频讲师：朱小平30人学习过大数据培训班4期培训班课程（只针对培训班学员）大数据培训班4期培训班课程（只针对培训班学讲师：徐培成0人学习过热门职位+更多后端开发全职/1-3年/大专5k-15k分享中级Java工程师全职/1-3年/大专6k-10k高达软件诚聘PHP开发师兼职/5-10年/不限15k-25k慧都科技PHP研发工程师全职/1-3年/本科10k-15k动视云科技后端开发(PHP/Go)全职/5-10年/本科30k-50k瓜子二手车最新专题+更多金三银四跳槽季 开发者这样惊呆你的面试官金三银四跳槽季 开发者这样惊呆你的面试官跳槽季你了解AJAX吗？TA不是新编程语言而是WEB应用程序技术你了解AJAX吗？TA不是新编程语言而是WEB应用程序技术AJAXWeb前端知识杂乱 如何分清主次和学习优先级？Web前端知识杂乱 如何分清主次和学习优先级？Web前端/分清主次/学习编程初学者学什么语言好？未来编程趋势预测编程初学者学什么语言好？未来编程趋势预测编程精彩评论和气高尚评论了：【51CTO学院】免费直播课 | 赵海兵–虚拟化与混合云期待中。。。！ lwt1309108评论了：【51CTO学院】免费直播课 | 赵海兵–虚拟化与混合云期待 ashely冰雪雨露评论了：【51CTO学院】免费直播课 | 赵海兵–虚拟化与混合云虚拟化对我目前的工作很要紧 Wanglican评论了：【51CTO学院】团购第二期-低至6折！名师中高级实战进阶项目交了押金了，申请进群了，麻烦通过一下。亲~~精选博文论坛热帖下载排行现阶段为开放式基金赎回良机SecureCRT 使用技巧nagios全攻略(二)—-基本安装和配置关于51CTO合作出书中的职业发展部分利用WINDOWS SERVER 2003路由设置解读 书 +更多点石成金：访客至上的网页设计秘笈（原书第2版）有些网站看起来很清爽； 有些网站看起来很杂乱； 有些网站能让你轻松地找到资料； 有些网站让你犹如置身迷宫…… … 订阅51CTO邮刊点击这里查看样刊订阅51CTO邮刊51CTO旗下网站：领先的IT技术网站 51CTO|领先的中文存储媒体 WatchStor| 中国首个CIO网站 CIOage |中国首家数字医疗网站 HC3iCopyright©2005-2017 51CTO.COM 版权所有 未经许可 请勿转载","comments":true,"tags":[{"name":"架构","slug":"架构","permalink":"http://jishusuishouji.github.io/tags/架构/"}]},{"title":"VAGRANT 和 Docker的使用场景和区别?","date":"2017-01-25T06:20:57.000Z","path":"2017/01/25/xunihua/VAGRANT_和_Docker的使用场景和区别_/","text":"本质区别Vagrant并不提供虚拟化技术，本质上是一个虚拟机外挂，通过虚拟机的管理接口来管理虚拟机，让用户更轻松的进行一些常用配置，比如：CPU/Memory/IP/DISK等分配。并且提供了一些其它的管理操作：比如开机运行指定命令，镜像二次打包，插件编写等等。vagrant官方有介绍: To achieve its magic, Vagrant stands on the shoulders of giants. Machines are provisioned on top of VirtualBox, VMware, AWS, or any other provider. Then, industry-standard provisioning tools such as shell scripts, Chef, or Puppet, can be used to automatically install and configure software on the machine. 而docker是一个容器引擎，每一个实例是一个相对隔离的空间，与宿主机共享操作系统内核，并且共享宿主机资源。相对于披着虚拟机皮的vagrant，docker更加轻量，消耗更少的资源。 应用场景关于应用场景没有绝对，把两个东西都用熟，自己觉得用哪个方便用哪个好管理就用哪个。既然vagrant本质是虚拟机外挂，那么它的应用场景就是，节省你用原生虚拟机管理软件的时间。原来我们新增一台虚拟机需要配置好内存、硬盘、CPU等，然后添加iso，安装。创建用户，等等。一套下来好几十分钟是吧？聪明点你可能会想到复制一个创建好的镜像然后粘贴。但这一切vagrant都帮你想好了,安装vagrant后你只需要6步就能创建一台新的虚拟机，其中两步是创建文件夹和切换文件夹。从安装到创建一台新的虚拟机就成功了。如果你想要再添加一台虚拟机，你只需要执行最后两步，添加一个不同名字的配置就能再新建一台虚拟机。还支持镜像、开机自动运行脚本、插件编写等。dockerdocker主要应用于解决环境依赖以及为应用程序提供一个相对隔离的空间，一个实例像操作系统里运行的一个程序。原来部署一套环境是不是得自己编写自动化部署依赖环境以及程序的脚本？如果有两个依赖同一程序或库的不同版本怎么办？绝对路径？软连接？docker能很好的解决你的烦恼。把需要的依赖环境打包成一个镜像，再把程序放镜像里面运行。 总的来说vagrant更适合给开发大爷们创造一个统一的开发、测试、接近于完全隔离的环境，以及提高对高配机的闲置利用。docker更方便地解决了同一机器上的环境隔离，以及提高运维锅们解决部署时环境依赖的效率。","comments":true,"tags":[{"name":"docker","slug":"docker","permalink":"http://jishusuishouji.github.io/tags/docker/"}]},{"title":"使用 Velocity 模板引擎快速生成代码","date":"2017-01-21T23:35:11.000Z","path":"2017/01/22/java/velocity/使用_Velocity_模板引擎快速生成代码/","text":"Velocity 模板引擎介绍在现今的软件开发过程中，软件开发人员将更多的精力投入在了重复的相似劳动中。特别是在如今特别流行的MVC架构模式中，软件各个层次的功能更加独立，同时代码的相似度也更加高。所以我们需要寻找一种来减少软件开发人员重复劳动的方法，让程序员将更多的精力放在业务逻辑以及其他更加具有创造力的工作上。Velocity这个模板引擎就可以在一定程度上解决这个问题。Velocity是一个基于Java的模板引擎框架，提供的模板语言可以使用在Java中定义的对象和变量上。Velocity是Apache基金会的项目，开发的目标是分离MVC模式中的持久化层和业务层。但是在实际应用过程中，Velocity不仅仅被用在了MVC的架构中，还可以被用在以下一些场景中。 1.Web应用：开发者在不使用JSP的情况下，可以用Velocity让HTML具有动态内容的特性。2.源代码生成：Velocity可以被用来生成Java代码、SQL或者PostScript。有很多开源和商业开发的软件是使用Velocity来开发的。3.自动Email：很多软件的用户注册、密码提醒或者报表都是使用Velocity来自动生成的。使用Velocity可以在文本文件里面生成邮件内容，而不是在Java代码中拼接字符串。4.转换xml：Velocity提供一个叫 Anakia 的ant任务，可以读取XML文件并让它能够被 Velocity模板读取。一个比较普遍的应用是将xdoc文档转换成带样式的HTML文件。 Hello Velocity和学习所有新的语言或者框架的顺序一样，我们从Hello Velocity开始学习。首先在Velocity的官网上下载最新的发布包，之后使用Eclipse建立普通的Java项目。引入解压包中的 velocity-1.7.jar和lib文件夹下面的jar包。这样我们就可以在项目中使用Velocity了。在做完上面的准备工作之后，就可以新建一个叫HelloVelocity的类，代码如下： 清单 1. HelloVelocity.java1234567891011121314151617181920212223242526public class HelloVelocity &#123; public static void main(String[] args) &#123; VelocityEngine ve = new VelocityEngine(); ve.setProperty(RuntimeConstants.RESOURCE_LOADER, &quot;classpath&quot;); ve.setProperty(&quot;classpath.resource.loader.class&quot;, ClasspathResourceLoader.class.getName()); ve.init(); Template t = ve.getTemplate(&quot;hellovelocity.vm&quot;); VelocityContext ctx = new VelocityContext(); ctx.put(&quot;name&quot;, &quot;velocity&quot;); ctx.put(&quot;date&quot;, (new Date()).toString()); List temp = new ArrayList(); temp.add(&quot;1&quot;); temp.add(&quot;2&quot;); ctx.put(&quot;list&quot;, temp); StringWriter sw = new StringWriter(); t.merge(ctx, sw); System.out.println(sw.toString()); &#125;&#125; 在HelloVelocity的代码中，首先new了一个VelocityEngine类，这个类设置了Velocity使用的一些配置，在初始化引擎之后就可以读取hellovelocity.vm这个模板生成的Template这个类。之后的VelocityContext类是配置Velocity模板读取的内容。这个context可以存入任意类型的对象或者变量，让template来读取。这个操作就像是在使用JSP开发时，往request里面放入key-value，让JSP 读取一样。接下来就是写hellovelocity.vm文件了，这个文件实际定义了Velocity的输出内容和格式。hellovelocity.vm的内容如下： 清单 2. Hellovelocity.vm1234567#set( $iAmVariable = &quot;good!&quot; )Welcome $name to velocity.comtoday is $date.#foreach ($i in $list)$i#end$iAmVariable 输出结果如下：Welcome velocity to velocity.comtoday is Sun Mar 23 19:19:04 CST 2014.12good!在输出结果中我们可以看到，$name、$date 都被替换成了在 HelloVelocity.java 里面定义的变量，在 foreach 语句里面遍历了 list 的每一个元素，并打印出来。而$iAmVariable 则是在页面中使用 #set 定义的变量。回页首基本模板语言语法使用在 hellovelocity.vm 里面可以看到很多以 # 和$符开头的内容，这些都是 Velocity 的语法。在 Velocity 中所有的关键字都是以 # 开头的，而所有的变量则是以$开头。Velocity 的语法类似于 JSP 中的 JSTL，甚至可以定义类似于函数的宏，下面来看看具体的语法规则。一、变量和我们所熟知的其他编程语言一样，Velocity 也可以在模板文件中有变量的概念。 变量定义#set($name =“velocity”)等号后面的字符串 Velocity 引擎将重新解析，例如出现以$开始的字符串时，将做变量的替换。#set($hello =“hello $name”)上面的这个等式将会给$hello 赋值为“hello velocity” 变量的使用在模板文件中使用$name 或者${name} 来使用定义的变量。推荐使用${name} 这种格式，因为在模板中同时可能定义了类似$name 和$names 的两个变量，如果不选用大括号的话，引擎就没有办法正确识别$names 这个变量。对于一个复杂对象类型的变量，例如$person，可以使用${person.name} 来访问 person 的 name 属性。值得注意的是，这里的${person.name} 并不是直接访问 person 的 name 属性，而是访问 person 的 getName() 方法，所以${person.name} 和${person.getName()} 是一样的。 变量赋值在第一小点中，定义了一个变量，同时给这个变量赋了值。对于 Velocity 来说，变量是弱数据类型的，可以在赋了一个 String 给变量之后再赋一个数字或者数组给它。可以将以下六种数据类型赋给一个 Velocity 变量：变量引用, 字面字符串, 属性引用, 方法引用, 字面数字, 数组列表。#set($foo = $bar)#set($foo =“hello”)#set($foo.name = $bar.name)#set($foo.name = $bar.getName($arg))#set($foo = 123)#set($foo = [“foo”,$bar])二、循环在 Velocity 中循环语句的语法结构如下：#foreach($element in $list)This is $element$velocityCount#endVelocity 引擎会将 list 中的值循环赋给 element 变量，同时会创建一个$velocityCount 的变量作为计数，从 1 开始，每次循环都会加 1.三、条件语句条件语句的语法如下#if(condition)…#elseif(condition)…#else…#end四、关系操作符Velocity 引擎提供了 AND、OR 和 NOT 操作符，分别对应&amp;&amp;、||和! 例如：#if($foo &amp;&amp; $bar)#end五、宏Velocity 中的宏可以理解为函数定义。定义的语法如下：#macro(macroName arg1 arg2 …)…#end调用这个宏的语法是：#macroName(arg1 arg2 …)这里的参数之间使用空格隔开，下面是定义和使用 Velocity 宏的例子：#macro(sayHello $name)hello $name#end#sayHello(“velocity”)输出的结果为 hello velocity六、#parse 和 #include#parse 和 #include 指令的功能都是在外部引用文件，而两者的区别是，#parse 会将引用的内容当成类似于源码文件，会将内容在引入的地方进行解析，#include 是将引入文件当成资源文件，会将引入内容原封不动地以文本输出。分别看以下例子：foo.vm 文件：#set($name =“velocity”)parse.vm：#parse(“foo.vm”)输出结果为：velocityinclude.vm：#include(“foo.vm”)输出结果为：#set($name =“velocity”)以上内容包含了部分 Velocity 的语法，详细的语法内容可以参考 Velocity 的官方文档。回页首自动生成代码的例子在上个例子中我们可以生成任意的字符串并且打印出来，那为什么我们不能生成一些按照既定格式定义的代码并且写入文件呢。在这里我们以一个实际的 demo 来完成这部分内容。相关内容的源码可以参照附件。这个 demo 的功能是要实现一个学生和老师的管理，实际上都是单张表的维护。我们希望能够只定义 model 层，来生成 MVC 的所有代码。在这个 demo 中，只自动生成 action 和 JSP 的内容，因为现在有很多工具都可以帮助我们自动生成这两个包的代码。首先在 eclipse 中建立一个 Java web 工程，在例子中为了方便管理 jar 包，使用的是 maven 来建立和管理工程。建立好的工程目录结构如下图所示：图 1. 项目目录结构项目目录结构Java Resource 中放的是 Java 源码以及资源文件，Deployed Resources 中放的是 web 相关的文件。在 Java 文件中使用了类似 Spring 的 @Component 和 @Autowired 的注解来实现 IoC，使用 @Action 这样的注解实现 MVC，而在 JSP 中则使用了 JSTL 来输出页面。在上图所示的目录中，annotation、filter、framework 和 util 这四个 package 是作为这个项目框架的，跟业务没有关系，类似于 spring 和 struts 的功能。在实际的项目中我们当然希望能够一开始就编写一个通用的模板文件，然后一下子生成所有的代码，但是很多时候这样做是不可能的，或者说比较困难。为了解决这个问题，我们可以在编写 Velocity 模板文件之前先按照原本的流程编写代码，暂时先忘掉 Velocity。编写的代码应该能够在一个功能上完整的调通涉及 MVC 中所有层次的内容。在这个例子中，先编写好 StudentAction.java 文件，以及上图中 webapp 目录中所示的文件。在写好以上代码，同时也能顺利运行之后，我们可以参照之前编写的代码来写模板文件。这里我们来分别看一个 Java 文件和 JSP 的例子。清单 3. ActionTemplate.vm#parse (“macro.vm”) @Action(“${classNameLowCase}Action”)public class ${classNameUpCase}Action extends BaseAction{ @Autowired public ${classNameUpCase}Dao ${classNameLowCase}Dao; private List&lt;${classNameUpCase}&gt; ${classNameLowCase}s; private ${classNameUpCase} ${classNameLowCase}; #foreach ($attr in ${attrs}) private ${attr[0]} ${attr[1]}; #end public String ${classNameLowCase}List() { ${classNameLowCase}s = ${classNameLowCase}Dao.retrieveAll${classNameUpCase}s(); return “${classNameLowCase}List.jsp”; } …}上面的代码展示了一个 Java 类转换成 vm 模板之后的部分内容，完整内容请参考附件。macro.vm 文件中定义了一些使用的宏。JSP 的改造相对于 Java 文件来说稍微有点复杂，因为 JSP 中使用 JSTL 取 request 中的值也是使用${name} 这样的语法，所以想要输出${name} 这样的字符串而不是被模板引擎所替换，则需要使用转义字符，就像这样：\\${name}。为了能够让这个文件中的 table 得到复用，我们将这个文件中的表格单独拿出来，使用 #parse 命令来包含。下面是 ListJspTemplate.vm 和 ListTableTemplate.vm 的内容：清单 4. ListJspTemplate.vm&lt;%@ page language=”java” contentType=”text/html; charset=UTF-8” pageEncoding=”UTF-8”%&gt;&lt;%@taglib prefix=”c” uri=”http://java.sun.com/jsp/jstl/core“ %&gt;&lt;!DOCTYPE html PUBLIC “-//W3C//DTD HTML 4.01 Transitional//EN” “http://www.w3.org/TR/html4/loose.dtd&quot;&gt; &lt;%@ include file=”includeJS.jsp” %&gt; var pageConfig = { “list” : { “action” : “${classNameLowCase}Action!${classNameLowCase}List.action” } … “idName” : “${classNameLowCase}Id” }; ${classNameUpCase} List ${classNameUpCase} List Add #parse (“ListTableTemplate.vm”) 清单 5. ListTableTemplate.vm #parse (“macro.vm”) #set($plus = “status.index+1”) No.#generateTH($attrs) ${${plus}}#generateTD($classNameLowCase $attrs) Modify Delete 在定义好所有的模板文件之后，需要做的是读取这些文件，然后根据这些文件将 model 的数据类型以及名称设置到 context 中，最后将解析出来的内容写到相应的目录中去。这些工作我们放在了一个叫做 VelocityGenerator 的类中来做，它的源码如下：清单 6. TemplateGenerator.javapublic class VelocityGenerator { public static void main(String[] args) { VelocityEngine ve = new VelocityEngine(); ve.setProperty(RuntimeConstants.RESOURCE_LOADER, “classpath”); ve.setProperty(“classpath.resource.loader.class”, ClasspathResourceLoader.class.getName()); ve.init(); Template actionTpt = ve.getTemplate(“ActionTemplate.vm”); Template listJspTpt = ve.getTemplate(“ListJspTemplate.vm”); Template addTpt = ve.getTemplate(“AddTemplate.vm”); Template modifyTpt = ve.getTemplate(“ModifyTemplate.vm”); VelocityContext ctx = new VelocityContext(); ctx.put(“classNameLowCase”, “teacher”); ctx.put(“classNameUpCase”, “Teacher”); String[][] attrs = { {“Integer”,”id”}, {“String”,”name”}, {“String”,”serializeNo”}, {“String”,”titile”}, {“String”,”subject”} }; ctx.put(“attrs”, attrs); String rootPath = VelocityGenerator.class.getClassLoader().getResource(“”).getFile() + “../../src/main”; merge(actionTpt,ctx,rootPath+”/java/com/liuxiang/velocity/action/TeacherAction.java”); merge(listJspTpt,ctx,rootPath+”/webapp/teacherList.jsp”); merge(addTpt,ctx,rootPath+”/webapp/teacherAdd.jsp”); merge(modifyTpt,ctx,rootPath+”/webapp/teacherModify.jsp”); System.out.println(“success…”); } private static void merge(Template template, VelocityContext ctx, String path) { PrintWriter writer = null; try { writer = new PrintWriter(path); template.merge(ctx, writer); writer.flush(); } catch (FileNotFoundException e) { e.printStackTrace(); } finally { writer.close(); } }}在运行以上代码之后，项目文件夹中将会出现与 Teacher 相关的代码文件。在实际项目中可能不会出现很多这种单张表维护的情况，而且业务逻辑和系统架构会更加复杂，编写模板文件就更加不容易。但是无论多复杂的系统，不同的业务逻辑之间一定或多或少会有相似的代码，特别是在 JSP 和 JS 显示端文件中，因为我们在一个系统中要求显示风格、操作方式一致的时候就免不了会有相似内容的代码出现。在总结这些相似性之后我们还是可以使用 Velocity 来帮助我们生成部分内容的代码，而且即使有一些非共性的内容，我们也可以在生成的代码中继续修改。使用 Velocity 的另外一个好处是生成出来的代码更好维护，风格更加统一。回页首结束语Velocity 可以被应用在各种各样的情景下，本文介绍的只是它的一种用途而已，它还可以被用来做 MVC 结构中的 view 层，或者动态内容静态化等。另外，Velocity 并不是唯一的模板框架，同样很优秀的 Freemarker 也获得了非常广泛的应用，有兴趣的读者可以去深入研究更多的功能和用途。","comments":true,"tags":[{"name":"Velocity","slug":"Velocity","permalink":"http://jishusuishouji.github.io/tags/Velocity/"}]},{"title":"Spring中提示元素 'ref' 中不允许出现属性 'local'","date":"2017-01-17T07:58:44.000Z","path":"2017/01/17/spring/Spring中提示元素__ref__中不允许出现属性__local_/","text":"这个问题在Spring4.X以前的版本不存在。通过查询Spring的官方文档Spring4.X的以上版本不支持该属性了。下面是官方说明： The local attribute on the ref element is no longer supported in the 4.0 beans xsd since it does not provide value over a regular bean reference anymore. Simply change your existing ref local references to ref bean when upgrading to the 4.0 schema. 官方建议使用bean在Spring4.0以上的版本。 案例重现抛错：1234567891011121314151617181920212223242526272829303132333435363738394041Exception in thread &quot;main&quot; org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 37 in XML document from class path resource [application_dependencies.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 37; columnNumber: 27; cvc-complex-type.3.2.2: 元素 &apos;ref&apos; 中不允许出现属性 &apos;local&apos;。 at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304) at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:181) at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:217) at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:188) at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:252) at org.springframework.context.support.AbstractXmlApplicationContext.loadBeanDefinitions(AbstractXmlApplicationContext.java:127) at org.springframework.context.support.AbstractXmlApplicationContext.loadBeanDefinitions(AbstractXmlApplicationContext.java:93) at org.springframework.context.support.AbstractRefreshableApplicationContext.refreshBeanFactory(AbstractRefreshableApplicationContext.java:129) at org.springframework.context.support.AbstractApplicationContext.obtainFreshBeanFactory(AbstractApplicationContext.java:604) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:509) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:139) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:83) at com.mxsm.spring.SpringDependencies.main(SpringDependencies.java:64)Caused by: org.xml.sax.SAXParseException; lineNumber: 37; columnNumber: 27; cvc-complex-type.3.2.2: 元素 &apos;ref&apos; 中不允许出现属性 &apos;local&apos;。 at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198) at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134) at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437) at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368) at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325) at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:453) at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3232) at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2709) at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2051) at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:761) at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:353) at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2717) at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:607) at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:116) at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:489) at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:835) at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:764) at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:123) at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:237) at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:300) at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391) ... 14 more spring xml文件配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;animals&quot; class=&quot;com.mxsm.spring.bean.Animal&quot;&gt; &lt;constructor-arg&gt; &lt;ref bean=&quot;dog&quot;/&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;ref bean=&quot;cat&quot;/&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!--使用type属性--&gt; &lt;bean id=&quot;dog&quot; class=&quot;com.mxsm.spring.bean.Dog&quot;&gt; &lt;constructor-arg type=&quot;java.lang.String&quot; value=&quot;aa&quot;/&gt; &lt;constructor-arg type=&quot;int&quot; value=&quot;1&quot;/&gt; &lt;constructor-arg type=&quot;java.lang.String&quot; value=&quot;meat&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;dog_2&quot; class=&quot;com.mxsm.spring.bean.Dog&quot;&gt; &lt;constructor-arg index=&quot;0&quot; value=&quot;ssss&quot;/&gt; &lt;constructor-arg index=&quot;1&quot; value=&quot;3333&quot;/&gt; &lt;constructor-arg index=&quot;2&quot; value=&quot;8888&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;cat&quot; class=&quot;com.mxsm.spring.bean.Cat&quot;&gt; &lt;constructor-arg name=&quot;a&quot; value=&quot;ssss&quot;/&gt; &lt;constructor-arg name=&quot;b&quot; value=&quot;3333&quot;/&gt; &lt;/bean&gt; &lt;!-- setter 依赖注入bean --&gt; **&lt;bean id=&quot;man&quot; class=&quot;com.mxsm.spring.bean.Man&quot;&gt; &lt;property name=&quot;white&quot;&gt; &lt;ref local=&quot;whiteMan&quot;/&gt; &lt;/property&gt; &lt;property name=&quot;yellow&quot;&gt; &lt;ref local =&quot;yellowMan&quot;/&gt; &lt;/property&gt; &lt;property name=&quot;id&quot; value=&quot;1&quot;/&gt; &lt;/bean&gt;** &lt;bean id=&quot;whiteMan&quot; class=&quot;com.mxsm.spring.bean.WhitePerson&quot;&gt; &lt;constructor-arg name=&quot;age&quot; value=&quot;1&quot;/&gt; &lt;constructor-arg name=&quot;color&quot; value=&quot;white&quot;/&gt; &lt;constructor-arg name=&quot;name&quot; value=&quot;USA&quot;/&gt; &lt;constructor-arg name=&quot;sex&quot; value=&quot;男&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;yellowMan&quot; class=&quot;com.mxsm.spring.bean.YellowPerson&quot;&gt; &lt;constructor-arg name=&quot;age&quot; value=&quot;1&quot;/&gt; &lt;constructor-arg name=&quot;color&quot; value=&quot;yellow&quot;/&gt; &lt;constructor-arg name=&quot;name&quot; value=&quot;China&quot;/&gt; &lt;constructor-arg name=&quot;sex&quot; value=&quot;男&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt;","comments":true,"tags":[{"name":"spring","slug":"spring","permalink":"http://jishusuishouji.github.io/tags/spring/"}]},{"title":"nodejs的require模块及路径","date":"2017-01-13T17:30:53.000Z","path":"2017/01/14/nodejs/nodejs的require模块及路径/","text":"在nodejs中，模块分为核心模块和文件模块。 核心模块是被编译成二进制代码，引用的时候只需require即可，如require(&#39;net&#39;)。文件模块，则是指js文件、json文件或者是.node文件。在引用文件模块的时候要加上文件的路径：如果既不加/.../...、../又不加./的话，则该模块要么是核心模块，要么是从一个node_modules文件夹加载。 如果’/home/ry/projects/foo.js‘ 中的文件调用了`require(‘bar.js’)`` ，node将在下面的位置进行搜索： •/home/ry/projects/node_modules/bar.js•/home/ry/node_modules/bar.js•/home/node_modules/bar.js•/node_modules/bar.js 文件夹作为模块：首先在./some-library文件夹下建立package.json文件，它标识了一个主模块。一个package.json中的内容可能如下：1234&#123; &quot;name&quot; : &quot;some-library&quot;, &quot;main&quot; : &quot;./lib/some-library.js&quot; &#125; require(&#39;./some-library&#39;)(和some-library相同路径的js文件)时将试图加载./some-library/lib/some-library.js如果在这个目录下没有package.json文件，node将试图从这个目录下加载index.js或index.node文件。例如，如果上面没有package.json文件，那么require(&#39;./some-library&#39;)时，将试图加载下面的文件：•./some-library/index.js•./some-library/index.node 分类: javascript,nodejs标签: javascript, nodejs","comments":true,"tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://jishusuishouji.github.io/tags/nodejs/"}]},{"title":"Spring MVC事务配置","date":"2017-01-09T14:36:01.000Z","path":"2017/01/09/java/spring/Spring_MVC事务配置/","text":"","comments":true,"tags":[]},{"title":"是该抛弃Spring HibernateTemplate的时候了","date":"2017-01-09T14:26:48.000Z","path":"2017/01/09/java/spring/是该抛弃Spring_HibernateTemplate的时候了/","text":"在spring2.0之前，我们在使用hibernate和spring的时候，都会被HibernateTemplate为我们提供benefits（资源和事务管理以及把那个“丑陋”的checked exception转换为runtime exception-DataAccessException ）而折服，在项目中不由自主、不假思索地使用它和那个经典的callback方法。而如今，hibernate3.0.1+ 、spring 2.0+版本以后，我们可以在数据访问层直接使用hinberate的session API(例如SessionFactory.getCurrentSession)，不并担心session和transaction management。至于error handling可以通过spring的@Repository annotation和post processor-PersistenceExceptionTranslationPostProcessor来解决。让我们来看一些代码片段：123456789&lt;bean id=&quot;sessionFactory&quot; class=&quot;org.springframework.orm.hibernate3. LocalSessionFactoryBean&quot;&gt; &lt;!-- the properties setting--&gt; &lt;/bean&gt; &lt;bean id=&quot;accountRepo&quot; class=&quot;com.mycompany.HibernateAccountRepository&quot;&gt; &lt;constructor-arg ref=&quot;sessionFactory&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.dao.annotation. PersistenceExceptionTranslationPostProcessor&quot;/&gt; 数据访问层代码片段：123456789101112131415@Repository public class HibernateAccountRepository implements AccountRepository &#123; private SessionFactory factory; public HibernateAccountRepository(SessionFactory factory) &#123; this.factory = factory; &#125; public Account loadAccount(String username) &#123; return (Account)factory.getCurrentSession() .createQuery(&quot;from Account acc where acc.name = :name&quot;) .setParameter(&quot;name&quot;, &quot;thethirdpart&quot;).uniqueResult(); &#125; &#125; 在xml配置文件里面通过配置的post processor会自动检测@Repository标注的bean并为该bean打开exception转换功能。 如果不支持annotations，可以通过AOP来实现，更方便123456&lt;bean id=&quot;persistenceExceptionInterceptor&quot; class=&quot;org.springframework.dao.support.PersistenceExceptionTranslationInterceptor&quot;/&gt; &lt;aop:config&gt; &lt;aop:advisor pointcut=&quot;execution(* *..*Repository+.*(..))&quot; advice-ref=&quot;persistenceExceptionInterceptor&quot; /&gt; &lt;/aop:config&gt; 总结，我们应该选择哪种方式呢？还是那句话，根据不同的情况来做最正确的选择。但我建议是丢弃template，而直接使用hibernate的API，毕竟灵活性更大，更何况遇到复杂的情况我们始终得面对hibernate的API。spring并不强制你做任何事情，记得它是一个非侵入性的framework。","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://jishusuishouji.github.io/tags/spring/"}]},{"title":"So should you still use Spring's HibernateTemplate and/or JpaTemplate??","date":"2017-01-09T14:20:51.000Z","path":"2017/01/09/java/spring/So_should_you_still_use_Spring_s_HibernateTemplate_and_or_JpaTemplate__/","text":"I was reading an article by Vigil Bose on TSS the other day and saw the usage of the HibernateDaoSupport class. Since this is no longer a recommended way of using Hibernate from Spring, I thought I might as well just blog about it another time. 不建议使用HibernateDaoSupport。 With the advent(n. 到来；出现；) of Spring 2.0, it has become possible to start using the Hibernate Session API directly again. The question is whether or not it is wise to abandon the use of the HibernateTemplate when working with Hibernate, or any other template-based approaches Spring features. Using Spring XxxTemplatesIn Spring 1.0, we introduced a revolutionary way of working with data access APIs that threw checked exceptions. The template approach Spring features along with its transaction synchronization manager and the extensive(adj. 广泛的；大量的；广阔的) use of runtime exceptions makes any TCFTC (short for try/catch-finally-try/catch as we coined(杜撰) it back in 2005) often found in data access code entirely obsolete. Below you can see (a simplified version and not entirely precise version of) what Spring’s template approach does for you (with specific code snippets that you would otherwise have to write). Acquisition of connection: If transaction synchronization is active (which it is, if you’re using Spring’s transaction management infrastructure), most of the times any of the Spring templates are using the same connection across the entire thread (things are actually a bit more complicated than that, but that would lead us too much into the gory details). Participation in a transaction Again, when using transaction management features, Spring will automatically associated any new connection with the current transaction. This again, all depends on the current propagations settings and so on, but whichever way you look at it, your core code is not affected by it. Specification of the SQL: This is what you (obviously) have to do yourself. The SQL ideally uses bind parameters, to avoid any chances of SQL injection from happening. Parameters are passed to the JDBC template as arguments. Creation / execution of statement and iterating over result set: After you’ve specified the SQL, Spring is going to create the statement for you, set any parameters you may have specified, execute it and loop over the result set for you. Parse result from result set: You can opt for parsing the result set yourself if you like (or if you have complex parsing requirements), or you can have Spring result a list of primitives, or just one value from the result set. Handling and translation of exceptions: This is where Spring translates any exceptions that might have occurred to Spring’s own DataAccessException hierarchy, automatically insulating calling code from the data access technology in use. Releasing of connection: This is the last piece of the puzzle where Spring releases any resources used. Of course, if transaction synchronization is active, the resources might not be released immediately. Templates are available for several APIs such as: JDBC (JdbcTemplate) Hibernate (HibernateTemplate) iBatis (SqlMapClientTemplate) JDO (JdoTemplate) TopLink (TopLinkTemplate) Messaging (JmsTempate) Transaction management (TransactionTemplate) JNDI (JndiTemplate) Are templates really necessary?The templates add a lot of value when using an API that uses checked exceptions (as opposed to runtime exceptions or unchecked exceptions), but also add a lot of consistency to your code base. People having learnt Spring’s JdbcTemplate can pretty easily start using Spring’s JdoTemplate or Spring’s HibernateTemplate–the approach to using those is similar for each one of them. The most visible impact of the Spring template approach is the code reduction for for example JDBC. This is primarily because the checked exceptions are translated to runtime exceptions inside the template, removing the need to catch the exception in your mainline code. Other reasons are the transparent resource management and automatic synchronization with the currently running transaction. Of course it’s fairly easy to change a framework to use runtime exceptions natively instead of Spring having to do this and this is what for example Hibernate has started to do from version 3.0 onwards. Hibernate is not the only technology to do this–the Java Persistence API is also using runtime exceptions.","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"},{"name":"hibernate","slug":"hibernate","permalink":"http://jishusuishouji.github.io/tags/hibernate/"},{"name":"spring","slug":"spring","permalink":"http://jishusuishouji.github.io/tags/spring/"},{"name":"HibernateTemplate","slug":"HibernateTemplate","permalink":"http://jishusuishouji.github.io/tags/HibernateTemplate/"}]},{"title":"java分布式事务(JTA)实现 jotm和atomikos","date":"2017-01-08T02:03:52.000Z","path":"2017/01/08/java/jta/java分布式事务_JTA_实现 jotm和atomikos/","text":"本地事务：只对单一数据源(单个数据库)事务进行控制。分布式事务：处理多种异构的数据源， 比如某个业务操作中同时包含JDBC和JMS或者某个操作需要访问多个不同的数据库，在不同数据库之间进行事务控制。 在Java中，分布式事务主要的规范是JTA/XA。其中：JTA是Java的事务管理器规范，XA是工业标准的X/Open CAE规范，可被两阶段提交及回滚的事务资源定义。比如某数据库实现了XA规范，则不管是JTA，还是MSDTC，都可以基于同样的行为对该数据库进行事务处理。 JTA全称为Java Transaction API，顾名思义JTA定义了一组统一的事务编程的接口，这些接口如下： XAResource：XAResource接口是对实现了X/Open CAE规范的资源管理器 (Resource Manager，数据库就是典型的资源管理器) 的抽象，它由资源适配器 (Resource Apdater) 提供实现。XAResource是支持事务控制的核心。Transaction：Transaction接口是一个事务实例的抽象，通过它可以控制事务内多个资源的提交或者回滚。二阶段提交过程也是由Transaction接口的实现者来完成的。TransactionManager：托管模式 (managed mode) 下，TransactionManager接口是被应用服务器调用，以控制事务的边界的。UserTransaction：非托管模式 (non-managed mode) 下，应用程序可以通过UserTransaction接口控制事务的边界 在tomcat下是没有分布式事务的，可以借助于第三方Jotm和Automikos实现，在spring中分布式事务是通过jta（jotm，atomikos）来进行实现。即：通过代码的方式来决定是否是分布式事务。 注：推荐用服务器自己的数据源(也就是 lookup JNDI)，这样的话，是不是XA事务就由服务器的配置来定制，代码就不需要任何配置来决定是不是XA了。事务本身是不是XA (分布式的）是服务器的事，服务器来管理“资源” （包括数据源，JMS 连接等，一个资源（JDBC连接）如何参与事务是“资源管理器”（驱动程序）的职责，跟程序无关），服务器提供事务管理并作为“事务协调者”来处理多个“资源管理器”（不同的数据库连接）之间的事务一致性。 jotm和automikos网址：1、http://jotm.objectweb.org/2、http://www.atomikos.com/Main/TransactionsEssentials Spring 通过AOP技术可以让我们在脱离EJB的情况下享受声明式事务的丰盛大餐。此外，通过配合使用ObjectWeb的JOTM开源项目，不需要Java EE应用服务器，Spring也可以提供JTA事务。 正因为AOP让Spring拥有了脱离EJB容器的声明式事务能力，而JOTM让我们在脱离Java EE应用服务器下拥有JTA事务能力。所以，人们将AOP和JOTM称为Java软件开发的两个圣杯。 JTA的实现框架有：GeronimoTM/Jencks 官方文档比较少，不适合学习和维护。SimpleJTA 没有实现JTS (Java Transaction Service)而且不是活跃的。Atomikos 是一个另人钦佩的产品。有丰富的文档，而且有很好的支持。JBossTS 是一个应用在JBOSS服务器上的，肯定是一个成熟的产品，也有好的支持，详细信息可以看这里：http://www.theserverside.com/news/thread.tss?thread_id=37941最常见的二个如下：JOTM JOTM(Java Open Transaction Manager)是ObjectWeb的一个开源JTA实现，它本身也是开源应用程序服务器JOnAS(Java Open Application Server)的一部分，为其提供JTA分布式事务的功能。 存在的问题：使用中不能自动rollback，无论什么情况都commit。注：spring3开始已经不再支持jotm Atomikos 大家推荐最多的。和JOTM相比Atomikos Transactions Essentials更加稳定，它原来是商业项目，现在开源了。象MySQL一样卖服务支持的。而且论坛页比较活跃，有问题很快可以解决。","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"},{"name":"jta","slug":"jta","permalink":"http://jishusuishouji.github.io/tags/jta/"},{"name":"jotm","slug":"jotm","permalink":"http://jishusuishouji.github.io/tags/jotm/"},{"name":"分布式事务","slug":"分布式事务","permalink":"http://jishusuishouji.github.io/tags/分布式事务/"},{"name":"atomikos","slug":"atomikos","permalink":"http://jishusuishouji.github.io/tags/atomikos/"}]},{"title":"java分布式事务:spring+JTA+jotm","date":"2017-01-08T01:23:24.000Z","path":"2017/01/08/java/jta/java分布式事务_spring_JTA_jotm/","text":"业务背景当新建用户时需插入一条用户记录，同时还需在另一个DB中记录日志。因为是不同的DB操作，所以及到分布式事务的处理。 1、代码结构： 2、建表语句：1234567create database log; DROP TABLE IF EXISTS `log`; CREATE TABLE `log` ( `id` varchar(20) NOT NULL, `content` varchar(100) default NULL, PRIMARY KEY (`id`) ); 1234567create database user; DROP TABLE IF EXISTS `user`; CREATE TABLE `user` ( `id` varchar(20) NOT NULL, `name` varchar(40) default NULL, PRIMARY KEY (`id`) ); 3、配置文件application.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;!--?xml version=1.0 encoding=UTF-8?--&gt; &lt;beans aop=&quot;&quot; beans=&quot;&quot; http:=&quot;&quot; schema=&quot;&quot; spring-aop.xsd=&quot;&quot; spring-beans.xsd=&quot;&quot; spring-tx.xsd=&quot;&quot; tx=&quot;&quot; www.springframework.org=&quot;&quot; xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemalocation=&quot;http://www.springframework.org/schema/beans&quot;&gt; &lt;!-- 引用Spring内部所提供的对JOTM支持的工厂类 --&gt; &lt;bean class=&quot;org.springframework.transaction.jta.JotmFactoryBean&quot; id=&quot;jotm&quot;/&gt; &lt;!-- 配置JTA事务管理器, 并在管理器中使用上面所配置的JOTM --&gt; &lt;bean class=&quot;org.springframework.transaction.jta.JtaTransactionManager&quot; id=&quot;txManager&quot;&gt; &lt;property name=&quot;userTransaction&quot; ref=&quot;jotm&quot;/&gt; &lt;/bean&gt; &lt;!-- 配置多个数据源 --&gt; &lt;bean class=&quot;org.enhydra.jdbc.pool.StandardXAPoolDataSource&quot; destroy-method=&quot;shutdown&quot; id=&quot;db1&quot;&gt; &lt;property name=&quot;dataSource&quot;&gt; &lt;bean class=&quot;org.enhydra.jdbc.standard.StandardXADataSource&quot; destroy-method=&quot;shutdown&quot;&gt; &lt;property name=&quot;transactionManager&quot; ref=&quot;jotm&quot;/&gt; &lt;property name=&quot;driverName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:MySQL://localhost:3306/user&quot;/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name=&quot;user&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;org.enhydra.jdbc.pool.StandardXAPoolDataSource&quot; destroy-method=&quot;shutdown&quot; id=&quot;db2&quot;&gt; &lt;property name=&quot;dataSource&quot;&gt; &lt;bean class=&quot;org.enhydra.jdbc.standard.StandardXADataSource&quot; destroy-method=&quot;shutdown&quot;&gt; &lt;property name=&quot;transactionManager&quot; ref=&quot;jotm&quot;/&gt; &lt;property name=&quot;driverName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:MySQL://localhost:3306/log&quot;/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name=&quot;user&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt; &lt;/bean&gt; &lt;!-- 根据不同的数据源配置两个jdbcTemplate --&gt; &lt;bean class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot; id=&quot;jdbcTemplate1&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;db1&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot; id=&quot;jdbcTemplate2&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;db2&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;com.zdp.dao.UserDao&quot; id=&quot;userDao&quot;&gt; &lt;property name=&quot;jdbcTemplate&quot; ref=&quot;jdbcTemplate1&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;com.zdp.dao.LogDao&quot; id=&quot;logDao&quot;&gt; &lt;property name=&quot;jdbcTemplate&quot; ref=&quot;jdbcTemplate2&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;com.zdp.service.UserService&quot; id=&quot;userService&quot;/&gt; &lt;property name=&quot;userDao&quot; ref=&quot;userDao&quot;/&gt; &lt;property name=&quot;logDao&quot; ref=&quot;logDao&quot;/&gt; &lt;/bean&gt; &lt;!-- JTA事务传播特性 --&gt; &lt;tx:advice id=&quot;txAdviceJTA&quot; transaction-manager=&quot;txManager&quot;&gt; &lt;tx:attributes&gt; &lt;tx:method isolation=&quot;DEFAULT&quot; name=&quot;save*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception/&quot;&gt; &lt;tx:method isolation=&quot;DEFAULT&quot; name=&quot;add*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception/&quot;&gt; &lt;tx:method isolation=&quot;DEFAULT&quot; name=&quot;create*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception/&quot;&gt; &lt;tx:method isolation=&quot;DEFAULT&quot; name=&quot;insert*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception/&quot;&gt; &lt;tx:method isolation=&quot;DEFAULT&quot; name=&quot;del*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception/&quot;&gt; &lt;tx:method isolation=&quot;DEFAULT&quot; name=&quot;update*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception/&quot;&gt; &lt;tx:method name=&quot;*&quot; read-only=&quot;true/&quot;&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;/beans&gt; 4、service业务类：1234567891011121314151617181920212223242526public class UserService &#123; private UserDao userDao; private LogDao logDao; public void saveUser(String id, String name) &#123; userDao.insertUser(id, name); // int i = 1 / 0; // 制造异常 logDao.insertLog(id, id + _ + name); &#125; public UserDao getUserDao() &#123; return userDao; &#125; public void setUserDao(UserDao userDao) &#123; this.userDao = userDao; &#125; public LogDao getLogDao() &#123; return logDao; &#125; public void setLogDao(LogDao logDao) &#123; this.logDao = logDao; &#125; &#125; 5、dao类：123456public class UserDao extends JdbcDaoSupport &#123; public void insertUser(String id, String name) &#123; JdbcTemplate template = getJdbcTemplate(); template.execute(insert into user values(&apos; + id + &apos;,&apos; + name + &apos;)); &#125; &#125; 123456public class LogDao extends JdbcDaoSupport &#123; public void insertLog(String id, String content) &#123; JdbcTemplate template = getJdbcTemplate(); template.execute(insert into log values(&apos; + id + &apos;,&apos; + content + &apos;)); &#125; &#125; 6、测试类：12345678public class UserTest &#123; @Test public void testSave() &#123; ApplicationContext cxt = new ClassPathXmlApplicationContext(ApplicationContext.xml); UserService us = (UserService) cxt.getBean(userService); us.saveUser(1, zhangsan); &#125; &#125;","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://jishusuishouji.github.io/tags/spring/"},{"name":"jta","slug":"jta","permalink":"http://jishusuishouji.github.io/tags/jta/"},{"name":"jotm","slug":"jotm","permalink":"http://jishusuishouji.github.io/tags/jotm/"}]}]