[{"title":"Pointfree 编程风格指南","date":"2017-03-25T15:21:00.000Z","path":"2017/03/25/hanshushi/Pointfree_编程风格指南/","text":"函数式编程有什么用？Pointfree就是如何使用函数式编程的答案。 一、程序的本质左侧是数据输入（input），中间是一系列的运算步骤，对数据进行加工，右侧是最后的数据输出（output）。一个或多个这样的任务，就组成了程序。输入和输出（统称为 I/O）与键盘、屏幕、文件、数据库等相关。这里的关键是，中间的运算部分不能有 I/O 操作，应该是纯运算，即通过纯粹的数学运算来求值。否则，就应该拆分出另一个任务。I/O 操作往往有现成命令，大多数时候，编程主要就是写中间的那部分运算逻辑。现在，主流写法是过程式编程和面向对象编程，但是我觉得，最合适纯运算的是函数式编程。 二、函数的拆分与合成上面那张图中，运算过程可以用一个函数fn表示。fn的类型如下。1fn :: a -&gt; b 上面的式子表示，函数fn的输入是数据a，输出是数据b。如果运算比较复杂，通常需要将fn拆分成多个函数。f1、f2、f3的类型如下。123f1 :: a -&gt; mf2 :: m -&gt; nf3 :: n -&gt; b 上面的式子中，输入的数据还是a，输出的数据还是b，但是多了两个中间值m和n。我们可以把整个运算过程，想象成一根水管（pipe），数据从这头进去，那头出来。 函数的拆分，无非就是将一根水管拆成了三根。 进去的数据还是a，出来的数据还是b。fn与f1、f2、f3的关系如下。1fn = R.pipe(f1, f2, f3); 上面代码中，我用到了Ramda函数库的pipe方法，将三个函数合成为一个。 三、Pointfree 的概念1fn = R.pipe(f1, f2, f3); 这个公式说明，如果先定义f1、f2、f3，就可以算出fn。整个过程，根本不需要知道a或b。也就是说，我们完全可以把数据处理的过程，定义成一种与参数无关的合成运算。不需要用到代表数据的那个参数，只要把一些简单的运算步骤合成在一起即可。这就叫做Pointfree：不使用所要处理的值，只合成运算过程。中文可以译作”无值”风格。请看下面的例子。12var addOne = x =&gt; x + 1;var square = x =&gt; x * x; 上面是两个简单函数addOne和square。把它们合成一个运算。123var addOneThenSquare = R.pipe(addOne, square);addOneThenSquare(2) // 9 上面代码中，addOneThenSquare是一个合成函数。定义它的时候，根本不需要提到要处理的值，这就是Pointfree。 四、Pointfree 的本质Pointfree的本质就是使用一些通用的函数，组合出各种复杂运算。上层运算不要直接操作数据，而是通过底层函数去处理。这就要求，将一些常用的操作封装成函数。比如，读取对象的role属性，不要直接写成obj.role，而是要把这个操作封装成函数。12var prop = (p, obj) =&gt; obj[p];var propRole = R.curry(prop)(&apos;role&apos;); 上面代码中，prop函数封装了读取操作。它需要两个参数p（属性名）和obj（对象）。这时，要把数据obj要放在最后一个参数，这是为了方便柯里化。函数propRole则是指定读取role属性。12345678910111213var isWorker = s =&gt; s === &apos;worker&apos;;var getWorkers = R.filter(R.pipe(propRole, isWorker));var data = [ &#123;name: &apos;张三&apos;, role: &apos;worker&apos;&#125;, &#123;name: &apos;李四&apos;, role: &apos;worker&apos;&#125;, &#123;name: &apos;王五&apos;, role: &apos;manager&apos;&#125;,];getWorkers(data)// [// &#123;&quot;name&quot;: &quot;张三&quot;, &quot;role&quot;: &quot;worker&quot;&#125;,// &#123;&quot;name&quot;: &quot;李四&quot;, &quot;role&quot;: &quot;worker&quot;&#125;// ] 上面代码中，data是传入的值，getWorkers是处理这个值的函数。定义getWorkers的时候，完全没有提到data，这就是Pointfree。简单说，Pointfree就是运算过程抽象化，处理一个值，但是不提到这个值。这样做有很多好处，它能够让代码更清晰和简练，更符合语义，更容易复用，测试也变得轻而易举。 五、Pointfree 的示例一下面，我们来看一个示例。1var str = &apos;Lorem ipsum dolor sit amet consectetur adipiscing elit&apos;; 上面是一个字符串，请问其中最长的单词有多少个字符？我们先定义一些基本运算。123456789101112131415// 以空格分割单词var splitBySpace = s =&gt; s.split(&apos; &apos;);// 每个单词的长度var getLength = w =&gt; w.length;// 词的数组转换成长度的数组var getLengthArr = arr =&gt; R.map(getLength, arr); // 返回较大的数字var getBiggerNumber = (a, b) =&gt; a &gt; b ? a : b;// 返回最大的一个数字var findBiggestNumber = arr =&gt; R.reduce(getBiggerNumber, 0, arr); 然后，把基本运算合成为一个函数（查看完整代码）。1234567var getLongestWordLength = R.pipe( splitBySpace, getLengthArr, findBiggestNumber);getLongestWordLength(str) // 11 可以看到，整个运算由三个步骤构成，每个步骤都有语义化的名称，非常的清晰。这就是 Pointfree 风格的优势。Ramda 提供了很多现成的方法，可以直接使用这些方法，省得自己定义一些常用函数。123456// 上面代码的另一种写法var getLongestWordLength = R.pipe( R.split(&apos; &apos;), R.map(R.length), R.reduce(R.max, 0)); 六、Pointfree 示例二下面是一段服务器返回的 JSON 数据。现在要求是，找到用户 Scott 的所有未完成任务，并按到期日期升序排列。 过程式编程的代码如下:上面代码不易读，出错的可能性很大。现在使用 Pointfree 风格改写。12345678var getIncompleteTaskSummaries = function(membername) &#123; return fetchData() .then(R.prop(&apos;tasks&apos;)) .then(R.filter(R.propEq(&apos;username&apos;, membername))) .then(R.reject(R.propEq(&apos;complete&apos;, true))) .then(R.map(R.pick([&apos;id&apos;, &apos;dueDate&apos;, &apos;title&apos;, &apos;priority&apos;]))) .then(R.sortBy(R.prop(&apos;dueDate&apos;)));&#125;; 上面代码已经清晰很多了。另一种写法是，把各个then里面的函数合成起来。12345678910111213141516171819202122232425262728293031// 提取 tasks 属性var SelectTasks = R.prop(&apos;tasks&apos;);// 过滤出指定的用户var filterMember = member =&gt; R.filter( R.propEq(&apos;username&apos;, member));// 排除已经完成的任务var excludeCompletedTasks = R.reject(R.propEq(&apos;complete&apos;, true));// 选取指定属性var selectFields = R.map( R.pick([&apos;id&apos;, &apos;dueDate&apos;, &apos;title&apos;, &apos;priority&apos;]));// 按照到期日期排序var sortByDueDate = R.sortBy(R.prop(&apos;dueDate&apos;));// 合成函数var getIncompleteTaskSummaries = function(membername) &#123; return fetchData().then( R.pipe( SelectTasks, filterMember(membername), excludeCompletedTasks, selectFields, sortByDueDate, ) );&#125;; 上面的代码跟过程式的写法一比较，孰优孰劣一目了然。","tags":[{"name":"函数式编程","slug":"函数式编程","permalink":"http://jishusuishouji.github.io/tags/函数式编程/"}]},{"title":"用Nginx搭建CDN服务器方法-开启Nginx缓存与镜像,自建图片服务器","date":"2017-03-23T15:06:20.000Z","path":"2017/03/23/nginx/用Nginx搭建CDN服务器方法-开启Nginx缓存与镜像,自建图片服务器/","text":"Nginx的proxy_cache和proxy_store很强大，利用proxy_store搭建图片服务器镜像实际上就相当于七牛和又拍的镜像CDN功能了，自动拉取图片保存在CDN服务器上。而proxy_cache作为Nginx缓存，既可以用作负载均衡，也可以反向绑定域名。 用Nginx搭建CDN服务器方法-开启Nginx缓存与镜像,自建图片服务器一、利用Nginx的proxy_cache搭建缓存服务器一：编译ngx_cache_purge1、Nginx的Proxy_cache是根据Key值md5哈希存储缓存，支持任意的Key，例如你可以根据”域名、URI、参数”组合成key，也支持非200状态码，如404/302等。2、要利用Nginx的Proxy_cache，你需要在Nginx编译进ngx_cache_purge 模块，执行：nginx -V，查看有没有ngx_cache_purge字样，没有的话需要自己手动编译。 3、这里以Oneinstack编译ngx_cache_purge模块作为操作演示，如果你用的是其它的LNMP包可以参考，基本过程是差不多的。命令如下：123456789101112131415161718cd /root/oneinstack/src #进入安装包目录nginx -Vtar xzf nginx-1.10.3.tar.gz #根据上面查看到的nginx版本选择解压包 wget http://labs.frickle.com/files/ngx_cache_purge-2.3.tar.gztar zxvf ngx_cache_purge-2.3.tar.gzcd /root/oneinstack/src/nginx-1.10.3 # 下面的./configure 后加的参数，你可以直接复制刚刚用nginx -V得到的参数，然后在最后加上--add-module=../ngx_cache_purge-2.3即可，参考：./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_stub_status_module --with-http_v2_module --with-http_ssl_module --with-http_gzip_static_module --with-http_realip_module --with-http_flv_module --with-http_mp4_module --with-openssl=../openssl-1.0.2k --with-pcre=../pcre-8.39 --with-pcre-jit --with-ld-opt=-ljemalloc --add-module=../ngx_cache_purge-2.3 make mv /usr/local/nginx/sbin/nginx&#123;,$(date +%m%d)&#125;cp objs/nginx /usr/local/nginx/sbin #oneinstack，其它的可以不用这个操作 nginx -tservice nginx restart 4、安装完成后，再次nginx -V你就可以看到Nginx已经成功编译进了ngx_cache_purge 了。 二、利用Nginx的proxy_cache搭建缓存服务器二：修改Nginx配置文件1、先找到你的Nginx配置文件：nginx.conf（路径一般是在/usr/local/nginx/conf/nginx.conf），在配置文件Http中加入以下代码：（注意修改路径为你自己的路径）123456789proxy_connect_timeout 5;proxy_read_timeout 60;proxy_send_timeout 5;proxy_buffer_size 16k;proxy_buffers 4 64k;proxy_busy_buffers_size 128k;proxy_temp_file_write_size 128k;proxy_cache_path /data/wwwroot/pic.test.com levels=1:2 keys_zone=cache_one:200m inactive=30d max_size=5g;proxy_temp_path /data/wwwroot/pic.test.com/temp; 2、操作如下图：Nginx搭建CDN添加代码3、然后在你的虚拟主机的nginx.conf（路径一般是/usr/local/nginx/conf/vhost/pic.freehao123.com.conf），在server listen 80 和 listen 443 ssl http2 都加入下面命令：12345678910111213 location /{ proxy_pass https://www.freehao123.com; proxy_redirect off; proxy_set_header Host www.freehao123.com; proxy_cache cache_one; proxy_cache_valid 200 302 304 365d; proxy_cache_valid 301 1d; proxy_cache_valid any 1m; add_header Images-Cache “$upstream_cache_status from $host”; add_header Pragma public; add_header Cache-Control “public, must-revalidate, proxy-revalidate”; access_log off; log_not_found off; expires max;}4、将配置文件保存重新上传,然后执行:12nginx -tservice nginx restart5、先执行检查Nginx配置是否正确，确认没有问题的就是重启Nginx了。Nginx搭建CDN重启服务器6、如果你想缓存gravatar头像，那么代码就是：12345678910111213 location /avatar{ proxy_pass http://cn.gravatar.com; proxy_redirect off; proxy_set_header Host cn.gravatar.com; proxy_cache cache_one; proxy_cache_valid 200 302 304 365d; proxy_cache_valid 301 1d; proxy_cache_valid any 1m; add_header Images-Cache “$upstream_cache_status from $host”; add_header Pragma public; add_header Cache-Control “public, must-revalidate, proxy-revalidate”; access_log off; log_not_found off; expires max;}7、现在打开你的二级域名：pic.freehao123.com，你就可以看到已经正确缓存了图片了。Nginx搭建CDN缓存头像8、这里再给出另一个Nginx缓存代码，实现效果和上面是一样的。123456789101112131415161718192021222324 #先在Nginx配置中写入以下命令：proxy_temp_file_write_size 128k;proxy_temp_path /data/wwwroot/pic.ucblog.net/temp;proxy_cache_path /data/wwwroot/pic.ucblog.net levels=1:2 keys_zone=cache_one:500m inactive=7d max_size=5g; #再在虚拟主机的Nginx配置中写入以下命令：先在server listen 80 和listen 443代码前面加入：upstream gravatar { server secure.gravatar.com:443;}再在server listen 80 和listen 443 里面加入：location / { proxy_pass_header Server; proxy_set_header Host cn.gravatar.com; proxy_set_header Accept-Encoding ‘’; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_pass https://gravatar; proxy_cache cache_one; proxy_cache_valid 200 304 365d; proxy_cache_key $host$uri$is_args$args; expires max; }9、在VPS主机上，你可以看到proxy_cache生成的哈希文件，就表示缓存已经成功了。Nginx搭建CDN生成缓存文件三、利用Nginx的proxy_store搭建镜像服务器：修改Nginx配置方法1、Nginx的proxy_store作用是直接把静态文件在本地硬盘创建并读取，类似于七牛或者又拍这样的镜像CDN功能，首次访问会自动获取源站的静态图片等文件，之后的访问就是直接从CDN服务器读取，加快了速度。2、直接修改Nginx的虚拟主机配置文件（这里以img.freehao123.com.conf为演示），加入以下代码：1234567891011location / { expires 3d; proxy_set_header Accept-Encoding ‘’; root /data/wwwroot/img.freehao123.com; proxy_store on; proxy_store_access user:rw group:rw all:rw; proxy_temp_path /data/wwwroot/img.freehao123.com/temp; if ( !-e $request_filename) { proxy_pass https://www.freehao123.com; } }3、再次保存配置上传，然后重启Nginx。你可以看到img.freehao123.com请求的图片等静态文件已经成功从源站中获得到了。Nginx搭建CDN图片请求4、在VPS主机上的存目录中也可以看到proxy_store已经完整地将图片等静态文件的目录都保存下来了，相当于一个网站的镜像存储CDN了。Nginx搭建CDN镜像存储5、这里还有一个使用，效果和上面是一样的，记得替换好路径，代码如下：12345678910111213141516upstream http_tornado { server www.freehao123.com:443;} server { # 省略其他配置 location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf|js|html|htm|css)$ { root /opt/data/product/blog/cache; proxy_store on; proxy_store_access user:rw group:rw all:rw; proxy_temp_path /opt/data/product/blog/cache; if ( !-e $request_filename) { proxy_pass http://http_tornado; } } }四、Nginx的proxy_store和proxy_cache有什么区别？1、镜像与缓存的区别。从上面的介绍我们也可以看出来，proxy_store相当于镜像一个网站了，第二次访问图片等静态文件是直接读取CDN服务器上的，大大减轻了源站的负担。proxy_cache相当于缓存，即把请求生成Key，第二次访问就可以加快速度了。Nginx搭建CDN加快速度2、proxy_store适合静态，proxy_cache适合动态。proxy_store是将图片完整保存在CDN服务器上，所以它更适合于图片CDN加速，而proxy_cache是缓存生成Key，更加适合动态网站加速，可用于负载均衡，减轻服务器负担。Nginx搭建CDN减轻负担五、搭建镜像CDN服务器后要做的事情？1、第一，因为搭建镜像CDN服务器是完整地复制了源站的文件和URL，所以为了避免被搜索引擎误认为抄袭重复站，我们可以给CDN站加上Robots.txt，阻止搜索引擎收录。命令如下（允许收录图片，其它不允许爬取）：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192User-agent: BaiduspiderAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: 360SpiderAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: Baiduspider-imageAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: 360Spider-ImageAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: SosospiderAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: sogou spiderAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: YodaoBotAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: GooglebotAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: BingbotAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: SlurpAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: MSNBotAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: googlebot-imageAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: googlebot-mobileAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: yahoo-blogs/v3.9Allow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: psbotAllow: /wp-content/uploads/.jpg$Allow: /wp-content/uploads/.png$Allow: /wp-content/uploads/*.gif$Disallow: / User-agent: Disallow: /2、第二，做好Nginx防盗链。如果你的CDN服务器流量不怎么够的话，建议还是做好防盗链措施，同时还可以帮你减轻服务器负担。在你的虚拟主机配置文件中加入以下代码：12345678location ~ ..(gif|jpg|jpeg|png|bmp|swf)$ { valid_referers none blocked freehao123.com .freehao123.com .google.cn .google.com .google.com.hk image.baidu.com *.baidu.com; if ($invalid_referer) { rewrite ^/ https://www.freehao123.com; #return 403; } } 3、第三，设置好Nginx默认图片。这个主要是针对缓存Gravatar头像的，当源站服务器不存在某一个图片或者文件时，我们可以给Nginx设置一个默认的图片或者链接，这样缓存看起来就完美了。123456789101112 location /avatar { try_files $uri /avatar/set-avatar.png; } #或者使用： location /{ try_files $uri /set-avatar.png; }4、效果见下图：用Nginx搭建CDN默认图片文章出自：免费资源部落 部分内容参考张戈博客\\cheyo.net\\ttt.tt版权所有。本站文章除注明出处外，皆为作者原创文章，可自由引用，但请注明来源。2014年六大免费VPS主机-免费VPS申请、使用和点评您或许对下面这些文章有兴趣: 本月吐槽辛苦排行榜UPyun又拍云CDN安装部署Let’s Encrypt免费SSL证书和配置自定义SSL证书Kloudsec免费CDN加速-提供免费SSL证书支持Https自定义SSL新加坡节点服务器性能管理(APM)：性能魔方mmtrix一站式云评测,云监测,云加速网站UPYUN又拍云动态CDN和静态CDN加速支持自定义域名Https和图片处理阿里百川多媒体-20GB免费存储空间和CDN流量支持图片,视频在线处理2014年十个优秀的免费CDN加速服务-国内和国外免费CDNIncapsula免费CDN服务申请使用:日本,香港,美国CDN加速效果测评Discuz论坛使用七牛,又拍,阿里云OSS CDN加速：CSS,JS,图片,论坛附件","tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://jishusuishouji.github.io/tags/Nginx/"}]},{"title":"druid 配置WebStatFilter 网络url统计","date":"2017-03-23T14:54:59.000Z","path":"2017/03/23/druid/druid_配置WebStatFilter_网络url统计/","text":"WebStatFilter用于采集web-jdbc关联监控的数据。 web.xml配置123456789101112&lt;filter&gt; &lt;filter-name&gt;DruidWebStatFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.alibaba.druid.support.http.WebStatFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;exclusions&lt;/param-name&gt; &lt;param-value&gt;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;DruidWebStatFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; exlusions配置经常需要排除一些不必要的url，比如.js,/jslib/等等。配置在init-param中。比如：1234&lt;init-param&gt; &lt;param-name&gt;exclusions&lt;/param-name&gt; &lt;param-value&gt;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&lt;/param-value&gt; &lt;/init-param&gt; sessionStatMaxCount配置缺省sessionStatMaxCount是1000个。你可以按需要进行配置，比如：1234&lt;init-param&gt; &lt;param-name&gt;sessionStatMaxCount&lt;/param-name&gt; &lt;param-value&gt;1000&lt;/param-value&gt; &lt;/init-param&gt; `sessionStatEnable配置你可以关闭session统计功能，比如：1234&lt;init-param&gt; &lt;param-name&gt;sessionStatEnable&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; principalSessionName配置你可以配置principalSessionName，使得druid能够知道当前的session的用户是谁。比如：1234&lt;init-param&gt; &lt;param-name&gt;principalSessionName&lt;/param-name&gt; &lt;param-value&gt;xxx.user&lt;/param-value&gt; &lt;/init-param&gt; 根据需要，把其中的xxx.user修改为你user信息保存在session中的sessionName。 注意：如果你session中保存的是非string类型的对象，需要重载toString方法 principalCookieName如果你的user信息保存在cookie中，你可以配置principalCookieName，使得druid知道当前的user是谁1234&lt;init-param&gt; &lt;param-name&gt;principalCookieName&lt;/param-name&gt; &lt;param-value&gt;xxx.user&lt;/param-value&gt; &lt;/init-param&gt; 根据需要，把其中的xxx.user修改为你user信息保存在cookie中的cookieName profileEnabledruid 0.2.7版本开始支持profile，配置profileEnable能够监控单个url调用的sql列表。1234&lt;init-param&gt; &lt;param-name&gt;profileEnable&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;","tags":[{"name":"druid","slug":"druid","permalink":"http://jishusuishouji.github.io/tags/druid/"}]},{"title":"DRUID连接池的实用 配置详解","date":"2017-03-23T14:03:57.000Z","path":"2017/03/23/druid/DRUID连接池的实用_配置详解/","text":"DRUID介绍DRUID是阿里巴巴开源平台上一个数据库连接池实现，它结合了C3P0、DBCP、PROXOOL等DB池的优点，同时加入了日志监控，可以很好的监控DB池连接和SQL的执行情况，可以说是针对监控而生的DB连接池(据说是目前最好的连接池,不知道速度有没有BoneCP快)。 配置参数和其它连接池一样DRUID的DataSource类为：com.alibaba.druid.pool.DruidDataSource，基本配置参数如下： name 配置这个属性的意义在于，如果存在多个数据源，监控的时候可以通过名字来区分开来。如果没有配置，将会生成一个名字，格式是：”DataSource-“ + System.identityHashCode(this) jdbcUrl连接数据库的url，不同数据库不一样。例如：mysql:jdbc:mysql://10.20.153.104:3306/druid2oracle:jdbc:oracle:thin:@10.20.149.85:1521:ocnauto username连接数据库的用户名 password连接数据库的密码。如果你不希望密码直接写在配置文件中，可以使用ConfigFilter。 driverClassName根据url自动识别这一项可配可不配，如果不配置druid会根据url自动识别dbType，然后选择相应的driverClassName(建议配置下) initialSize默认值0，初始化时建立物理连接的个数。初始化发生在显示调用init方法，或者第一次getConnection时 maxActive默认值8最大连接池数量 maxIdle默认值8已经不再使用，配置了也没效果 minIdle最小连接池数量 maxWait获取连接时最大等待时间，单位毫秒。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降，如果需要可以通过配置useUnfairLock属性为true使用非公平锁。 poolPreparedStatementsfalse是否缓存preparedStatement，也就是PSCache。PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql下建议关闭。 maxOpenPreparedStatements-1要启用PSCache，必须配置大于0，当大于0时，poolPreparedStatements自动触发修改为true。在Druid中，不会存在Oracle下PSCache占用内存过多的问题，可以把这个数值配置大一些，比如说100 validationQuery用来检测连接是否有效的sql，要求是一个查询语句。如果validationQuery为null，testOnBorrow、testOnReturn、testWhileIdle都不会其作用。 testOnBorrowtrue申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。 testOnReturnfalse归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能 testWhileIdlefalse建议配置为true，不影响性能，并且保证安全性。申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效。timeBetweenEvictionRunsMillis有两个含义：1) Destroy线程会检测连接的间隔时间2) testWhileIdle的判断依据，详细看testWhileIdle属性的说明 numTestsPerEvictionRun不再使用，一个DruidDataSource只支持一个EvictionRun minEvictableIdleTimeMillisconnectionInitSqls物理连接初始化的时候执行的sql exceptionSorter根据dbType自动识别当数据库抛出一些不可恢复的异常时，抛弃连接 filters属性类型是字符串，通过别名的方式配置扩展插件，常用的插件有：监控统计用的filter:stat日志用的filter:log4j防御sql注入的filter:wall proxyFilters类型是List&lt;com.alibaba.druid.filter.Filter&gt;，如果同时配置了filters和proxyFilters，是组合关系，并非替换关系 使用方法DB数据源的使用方法也就是2种，一种是在代码中写死通过NEW操作符创建DataSSource，然后set一些连接属性;另外一种是基于SPRING的配置方法，然后让SPRING的Context自动加载配置（以下配置文件默认都在项目根目录下conf文件夹中） 1、属性文件:application.properties(DataSource连接参数) 1234jdbc.driverClassName=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://127.0.0.1:3306/test jdbc.username=root jdbc.password=1qaz!QAZ 2、SPRING配置文件：spring-base.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot; http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot; http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:batch=&quot; http://www.springframework.org/schema/batch&quot; xsi:schemaLocation=&quot; http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd&quot;&gt; &lt;bean id=&quot;propertyConfigure&quot; class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt; &lt;property name=&quot;locations&quot;&gt; &lt;list&gt; &lt;value&gt;./conf/application.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;$&#123;jdbc.driverClassName&#125;&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url&#125;&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot; /&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name=&quot;initialSize&quot; value=&quot;1&quot; /&gt; &lt;property name=&quot;minIdle&quot; value=&quot;1&quot; /&gt; &lt;property name=&quot;maxActive&quot; value=&quot;10&quot; /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name=&quot;maxWait&quot; value=&quot;10000&quot; /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;60000&quot; /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;300000&quot; /&gt; &lt;property name=&quot;testWhileIdle&quot; value=&quot;true&quot; /&gt; &lt;!-- 这里建议配置为TRUE，防止取到的连接不可用 --&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;testOnReturn&quot; value=&quot;false&quot; /&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name=&quot;poolPreparedStatements&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;maxPoolPreparedStatementPerConnectionSize&quot; value=&quot;20&quot; /&gt; &lt;!-- 这里配置提交方式，默认就是TRUE，可以不用配置 --&gt; &lt;property name=&quot;defaultAutoCommit&quot; value=&quot;true&quot; /&gt; &lt;!-- 验证连接有效与否的SQL，不同的数据配置不同 --&gt; &lt;property name=&quot;validationQuery&quot; value=&quot;select 1 &quot; /&gt; &lt;property name=&quot;filters&quot; value=&quot;stat&quot; /&gt; &lt;property name=&quot;proxyFilters&quot;&gt; &lt;list&gt; &lt;ref bean=&quot;logFilter&quot; /&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;logFilter&quot; class=&quot;com.alibaba.druid.filter.logging.Slf4jLogFilter&quot;&gt; &lt;property name=&quot;statementExecutableSqlLogEnable&quot; value=&quot;false&quot; /&gt; &lt;/bean&gt;&lt;/beans&gt; 监控方式1、WEB方式监控配置&lt;servlet&gt; &lt;servlet-name&gt;DruidStatView&lt;/servlet-name&gt; &lt;servlet-class&gt;com.alibaba.druid.support.http.StatViewServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;DruidStatView&lt;/servlet-name&gt; &lt;url-pattern&gt;/druid/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;filter&gt; &lt;filter-name&gt;druidWebStatFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.alibaba.druid.support.http.WebStatFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;exclusions&lt;/param-name&gt; &lt;param-value&gt;/public/*,*.js,*.css,/druid*,*.jsp,*.swf&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;principalSessionName&lt;/param-name&gt; &lt;param-value&gt;sessionInfo&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;profileEnable&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;druidWebStatFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 把上面servlet配置添加到项目web.xml即可。然后运行Tomcat，浏览器输入 http://IP:PROT/druid 就可以打开Druid的监控页面了. 2、日志文件监控Druid提供了多种日志文件监控commons-logging、log4j等，这里我们主要使用slf4j和logback来进行日志监控配置。 首先要引入slf4j和logback相关的jar文件（从Maven公共仓库下载 http://search.maven.org/） 12345678910111213141516171819202122232425&lt;slf4j.version&gt;1.7.7&lt;/slf4j.version&gt; &lt;logback.version&gt;1.1.2&lt;/logback.version&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-access&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; 接下配置logback的配置文件(./conf/logback.xml) 1234567891011121314151617181920212223&lt;configuration&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;Pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n &lt;/Pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt; &lt;file&gt;./logs/druid_info.log&lt;/file&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;Pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/Pattern&gt; &lt;/layout&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;level&gt;debug&lt;/level&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;FILE&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; 最后就是写一个测试类进行测试 12345678910111213141516171819public class TestMain &#123; public static void loadLoggerContext() &#123; System.getProperties().put(&quot;logback.configurationFile&quot;, &quot;./conf/logback.xml&quot;); LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory(); StatusPrinter.setPrintStream(System.err); StatusPrinter.print(lc); &#125; public static void main(String[] args) &#123; try &#123; loadLoggerContext(); FileSystemXmlApplicationContext context = new FileSystemXmlApplicationContext(&quot;./conf/spring-base.xml&quot;); &#125; catch (Exception e) &#123; System.out.println(e); &#125; &#125; &#125;","tags":[{"name":"Druid","slug":"Druid","permalink":"http://jishusuishouji.github.io/tags/Druid/"}]},{"title":"Druid：一个用于大数据实时处理的开源分布式系统","date":"2017-03-23T14:00:02.000Z","path":"2017/03/23/druid/Druid：一个用于大数据实时处理的开源分布式系统/","text":"Druid是一个用于大数据实时查询和分析的高容错、高性能开源分布式系统，旨在快速处理大规模的数据，并能够实现快速查询和分析。尤其是当发生代码部署、机器故障以及其他产品系统遇到宕机等情况时，Druid仍能够保持100%正常运行。创建Druid的最初意图主要是为了解决查询延迟问题，当时试图使用Hadoop来实现交互式查询分析，但是很难满足实时分析的需要。而Druid提供了以交互方式访问数据的能力，并权衡了查询的灵活性和性能而采取了特殊的存储格式。Druid功能介于PowerDrill和Dremel之间，它几乎实现了Dremel的所有功能，并且从PowerDrill吸收一些有趣的数据格式。Druid允许以类似Dremel和PowerDrill的方式进行单表查询，同时还增加了一些新特性，如为局部嵌套数据结构提供列式存储格式、为快速过滤做索引、实时摄取和查询、高容错的分布式体系架构等。从官方得知，Druid的具有以下主要特征： 为分析而设计——Druid是为OLAP工作流的探索性分析而构建，它支持各种过滤、聚合和查询等类； 快速的交互式查询——Druid的低延迟数据摄取架构允许事件在它们创建后毫秒内可被查询到； 高可用性——Druid的数据在系统更新时依然可用，规模的扩大和缩小都不会造成数据丢失； 可扩展——Druid已实现每天能够处理数十亿事件和TB级数据。 Druid应用最多的是类似于广告分析创业公司Metamarkets中的应用场景，如广告分析、互联网广告系统监控以及网络监控等。当业务中出现以下情况时，Druid是一个很好的技术方案选择： 需要交互式聚合和快速探究大量数据时；需要实时查询分析时；具有大量数据时，如每天数亿事件的新增、每天数10T数据的增加；对数据尤其是大数据进行实时分析时；需要一个高可用、高容错、高性能数据库时。一个Druid集群有各种类型的节点（Node）组成，每个节点都可以很好的处理一些的事情，这些节点包括对非实时数据进行处理存储和查询的Historical节点、实时摄取数据、监听输入数据流的Realtime节、监控Historical节点的Coordinator节点、接收来自外部客户端的查询和将查询转发到Realtime和Historical节点的Broker节点、负责索引服务的Indexer节点。 查询操作中数据流和各个节点的关系如下图所示： 如下图是Druid集群的管理层架构，该图展示了相关节点和集群管理所依赖的其他组件（如负责服务发现的ZooKeeper集群）的关系： Druid已基于Apache License 2.0协议开源，代码托管在GitHub，其当前最新稳定版本是0.7.1.1。当前，Druid已有63个代码贡献者和将近2000个关注。Druid的主要贡献者包括广告分析创业公司Metamarkets、电影流媒体网站Netflix、Yahoo等公司。Druid官方还对Druid同Shark、Vertica、Cassandra、Hadoop、Spark、Elasticsearch等在容错能力、灵活性、查询性能等方便进行了对比说明。更多关于Druid的信息，大家还可以参考官方提供的入门教程、白皮书 、设计文档等。 感谢徐川对本文的审校。","tags":[{"name":"Druid","slug":"Druid","permalink":"http://jishusuishouji.github.io/tags/Druid/"}]},{"title":"架构师必看 京东咚咚架构演进","date":"2017-03-21T13:01:44.000Z","path":"2017/03/21/jiagou/架构师必看_京东咚咚架构演进/","text":"技术架构单独拿出来看我认为没有绝对的好与不好，技术架构总是要放在彼时的背景下来看，要考虑业务的时效价值、团队的规模和能力、环境基础设施等等方面。 架构演进的生命周期适时匹配好业务的生命周期，才可能发挥最好的效果。 京东咚咚自从京东开始为第三方卖家提供入驻平台服务后，咚咚也就随之诞生了。 1.0 诞生（2010 – 2011)为了业务的快速上线，1.0 版本的技术架构实现是非常直接且简单粗暴的。 如何简单粗暴法？请看架构图，如下。京东咚咚1.0的功能十分简单，实现了一个IM的基本功能，接入、互通消息和状态。另外还有客服功能，就是顾客接入咨询时的客服分配，按轮询方式把顾客分配给在线的客服接待。 用开源Mina框架实现了TCP的长连接接入，用Tomcat Comet机制实现了HTTP的长轮询服务。而消息投递的实现是一端发送的消息临时存放在 Redis中，另一端拉取的生产消费模型。这个模型的做法导致需要以一种高频率的方式来轮询Redis遍历属于自己连接的关联会话消息。这个模型很简单，简单包括多个层面的意思：理解起来简单；开发起来简单；部署起来也简单。只需要一个Tomcat应用依赖一个共享的Redis，简单的实现核心业务功能，并支持业务快速上线。但这个简单的模型也有些严重的缺陷，主要是效率和扩展问题。轮询的频率间隔大小基本决定了消息的延时，轮询越快延时越低，但轮询越快消耗也越高。这个模型实际上是一个高功耗低效能的模型，因为不活跃的连接在那做高频率的无意义轮询。 高频有多高呢，基本在100ms以内，你不能让轮询太慢，比如超过2秒轮一次，人就会在聊天过程中感受到明显的会话延迟。 随着在线人数增加，轮询的耗时也线性增长，因此这个模型导致了扩展能力和承载能力都不好，一定会随着在线人数的增长碰到性能瓶颈。 1.0的时代背景正是京东技术平台从.NET向Java转型的年代，我也正是在这期间加入京东并参与了京东主站技术转型架构升级的过程。 之后开始接手了京东咚咚，并持续完善这个产品，进行了三次技术架构演进。 2.0 成长（2012）我们刚接手时1.0已在线上运行并支持京东POP（开放平台）业务，之后京东打算组建自营在线客服团队并落地在成都。不管是自营还是POP客服咨询业务当时都起步不久，1.0架构中的性能和效率缺陷问题还没有达到引爆的业务量级。而自营客服当时还处于起步阶段，客服人数不足，服务能力不够，顾客咨询量远远超过客服的服务能力。超出服务能力的顾客咨询，当时我们的系统统一返回提示客服繁忙，请稍后咨询。 这种状况导致高峰期大量顾客无论怎么刷新请求，都很可能无法接入客服，体验很差。所以2.0重点放在了业务功能体验的提升上，如下图所示。京东咚咚针对无法及时提供服务的顾客，可以排队或者留言。 针对纯文字沟通，提供了文件和图片等更丰富的表达方式。 另外支持了客服转接和快捷回复等方式来提升客服的接待效率。总之，整个2.0就是围绕提升客服效率和用户体验。而我们担心的效率问题在2.0高速发展业务的时期还没有出现，但业务量正在逐渐积累，我们知道它快要爆了。到2012年末，度过双十一后开始了3.0的一次重大架构升级。 3.0爆发（2013 – 2014）经历了2.0时代一整年的业务高速发展，实际上代码规模膨胀的很快。与代码一块膨胀的还有团队，从最初的4个人到近30人。 团队大了后，一个系统多人开发，开发人员层次不一，规范难统一，系统模块耦合重，改动沟通和依赖多，上线风险难以控制。一个单独tomcat应用多实例部署模型终于走到头了，这个版本架构升级的主题就是服务化。服务化的第一个问题如何把一个大的应用系统切分成子服务系统。当时的背景是京东的部署还在半自动化年代，自动部署系统刚起步，子服务系统若按业务划分太细太多，部署工作量很大且难管理。所以当时我们不是按业务功能分区服务的，而是按业务重要性级别划分了0、1、2 三个级别不同的子业务服务系统。 另外就是独立了一组接入服务，针对不同渠道和通信方式的接入端，见下图。更细化的应用服务和架构分层方式可见下图。这次大的架构升级，主要考虑了三个方面：稳定性、效率和容量。 做了下面这些事情：1.业务分级、核心、非核心业务隔离2.多机房部署，流量分流、容灾冗余、峰值应对冗余3.读库多源，失败自动转移4.写库主备，短暂有损服务容忍下的快速切换5.外部接口，失败转移或快速断路6.Redis 主备，失败转移7.大表迁移，MongoDB 取代 MySQL 存储消息记录8.改进消息投递模型 前 6 条基本属于考虑系统稳定性、可用性方面的改进升级。 这一块属于陆续迭代完成的，承载很多失败转移的配置和控制功能在上面图中是由管控中心提供的。 第 7 条主要是随着业务量的上升，单日消息量越来越大后，使用了 MongoDB来单独存储量最大的聊天记录。 第 8 条是针对 1.0版本消息轮询效率低的改进，改进后的投递方式如下图所示：不再是轮询了，而是让终端每次建立连接后注册接入点位置，消息投递前定位连接所在接入点位置再推送过去。 这样投递效率就是恒定的了，而且很容易扩展，在线人数越多则连接数越多，只需要扩展接入点即可。 其实，这个模型依然还有些小问题，主要出在离线消息的处理上，可以先思考下，我们最后再讲。3.0 经过了两年的迭代式升级，单纯从业务量上来说还可以继续支撑很长时间的增长。 但实际上到2014年底我们面对的不再是业务量的问题，而是业务模式的变化。 这直接导致了一个全新时代的到来。 4.0 涅槃（2015 至今 )2014年京东的组织架构发生了很大变化，从一个公司变成了一个集团，下设多个子公司。原来的商城成为了其中一个子公司，新成立的子公司包括京东金融、京东智能、京东到家、拍拍、海外事业部等。各自业务范围不同，业务模式也不同，但不管什么业务总是需要客服服务。如何复用原来为商城量身订做的咚咚客服系统并支持其他子公司业务快速接入成为我们新的课题。最早要求接入的是拍拍网，它是从腾讯收购的，所以是完全不同的账户和订单交易体系。由于时间紧迫，我们把为商城订做的部分剥离，基于3.0架构对接拍拍又单独订做了一套，并独立部署，像下面这样。京东咚咚虽然在业务要求的时间点前完成了上线，但这样做也带来了明显的问题：复制工程，定制业务开发，多套源码维护成本高独立部署，至少双机房主备外加一个灰度集群，资源浪费大以前我们都是面向业务去架构系统，如今新的业务变化形势下我们开始考虑面向平台去架构，在统一平台上跑多套业务，统一源码，统一部署，统一维护。 把业务服务继续拆分，剥离出最基础的 IM 服务，IM 通用服务，客服通用服务，而针对不同的业务特殊需求做最小化的定制服务开发。 部署方式则以平台形式部署，不同的业务方的服务跑在同一个平台上，但数据互相隔离。 服务继续被拆分的更微粒化，形成了一组服务矩阵（见下图）。京东咚咚而部署方式，只需要在双机房建立两套对等集群，并另外建一个较小的灰度发布集群即可，所有不同业务都运行在统一平台集群上，如下图。京东咚咚更细粒度的服务意味着每个服务的开发更简单，代码量更小，依赖更少，隔离稳定性更高。 但更细粒度的服务也意味着更繁琐的运维监控管理，直到今年公司内部弹性私有云、缓存云、消息队列、部署、监控、日志等基础系统日趋完善， 使得实施这类细粒度划分的微服务架构成为可能，运维成本可控。 而从当初 1.0 的 1 种应用进程，到 3.0 的 6、7 种应用进程，再到 4.0 的 50+ 更细粒度的不同种应用进程。 每种进程再根据承载业务流量不同分配不同的实例数，真正的实例进程数会过千。 为了更好的监控和管理这些进程，为此专门定制了一套面向服务的运维管理系统，见下图。京东咚咚统一服务运维提供了实用的内部工具和库来帮助开发更健壮的微服务。 包括中心配置管理，流量埋点监控，数据库和缓存访问，运行时隔离，如下图所示是一个运行隔离的图示：京东咚咚细粒度的微服务做到了进程间隔离，严格的开发规范和工具库帮助实现了异步消息和异步 HTTP 来避免多个跨进程的同步长调用链。 进程内部通过切面方式引入了服务增强容器 Armor 来隔离线程， 并支持进程内的单独业务降级和同步转异步化执行。而所有这些工具和库服务都是为了两个目标：让服务进程运行时状态可见让服务进程运行时状态可被管理和改变最后我们回到前文留下的一个悬念，就是关于消息投递模型的缺陷。 一开始我们在接入层检测到终端连接断开后，消息无法投递，再将消息缓存下来，等终端重连接上来再拉取离线消息。 这个模型在移动时代表现的很不好，因为移动网络的不稳定性，导致经常断链后重连。 而准确的检测网络连接断开是依赖一个网络超时的，导致检测可能不准确，引发消息假投递成功。 新的模型如下图所示，它不再依赖准确的网络连接检测，投递前待确认消息 id 被缓存，而消息体被持久存储。 等到终端接收确认返回后，该消息才算投妥，未确认的消息 id 再重新登陆后或重连接后作为离线消息推送。 这个模型不会产生消息假投妥导致的丢失，但可能导致消息重复，只需由客户终端按消息 id 去重即可。京东咚咚京东咚咚诞生之初正是京东技术转型到 Java 之时，经历这些年的发展，取得了很大的进步。 从草根走向专业，从弱小走向规模，从分散走向统一，从杂乱走向规范。 本文主要重心放在了几年来咚咚架构演进的过程，技术架构单独拿出来看我认为没有绝对的好与不好， 技术架构总是要放在彼时的背景下来看，要考虑业务的时效价值、团队的规模和能力、环境基础设施等等方面。 架构演进的生命周期适时匹配好业务的生命周期，才可能发挥最好的效果。 【编辑推荐】58同城沈剑：好的架构不是设计出来的，而是演进出来的架构必备：Rate limiting 的作用和常见方式京东11.11：商品搜索系统架构设计解密京东唐志雄：从技术角度看白条资产证券化关于Java应用相关不同产品的架构中小型网站架构分析及优化友盟吴磊：移动大数据平台的架构、实践与数据增值【责任编辑：wangxueyan TEL：（010）68476606】 点赞 0架构师 京东 架构分享:内容点评已有0条评论,0次赞还可以输入500字 请输入你的评论提交您还没有登录！请先 登录 或 注册还没有评论内容大家都在看猜你喜欢紧急预警！Struts2新漏洞S2-045来袭，多个版本受影响紧急预警！Struts2新漏洞S2-045来袭，多个版本受影响2017年，为何过半的大数据项目不成功?2017年，为何过半的大数据项目不成功?2017年3月编程语言排行榜：Swift首次进入前十2017年3月编程语言排行榜：Swift首次进入前十如何禁掉Windows 10上的所有广告如何禁掉Windows 10上的所有广告编辑推荐外电iOS与Android设备到底是如何被入侵的？头条HTML5游戏开发难点之效率、性能和加载量头条你所不了解的移动支付背后的技术支撑外电我们为何很难对超大规模应用与分布式架构进行备份？头条2017年3月编程语言排行榜：Swift首次进入前十24H热文一周话题本月最赞5个强大的Java分布式缓存框架推荐坐在马桶上看算法：快速排序Java程序员新手老手都离不开八大开发工具2017年3月编程语言排行榜：Swift首次进入前十多图详解Spring框架的设计理念与设计模式2015年十五个热门的 PHP 开发工具Java 中常用缓存Cache机制的实现浅谈Java中的Set、List、Map的区别视频课程+更多技术大咖的旅游梦：同程CTO结缘腾讯云技术大咖的旅游梦：同程CTO结缘腾讯云讲师：腾讯云1人学习过软考网络工程师考试之IP地址计算轻松解决视频课程（攻克要塞系列）软考网络工程师考试之IP地址计算轻松解决视频讲师：朱小平30人学习过大数据培训班4期培训班课程（只针对培训班学员）大数据培训班4期培训班课程（只针对培训班学讲师：徐培成0人学习过热门职位+更多后端开发全职/1-3年/大专5k-15k分享中级Java工程师全职/1-3年/大专6k-10k高达软件诚聘PHP开发师兼职/5-10年/不限15k-25k慧都科技PHP研发工程师全职/1-3年/本科10k-15k动视云科技后端开发(PHP/Go)全职/5-10年/本科30k-50k瓜子二手车最新专题+更多金三银四跳槽季 开发者这样惊呆你的面试官金三银四跳槽季 开发者这样惊呆你的面试官跳槽季你了解AJAX吗？TA不是新编程语言而是WEB应用程序技术你了解AJAX吗？TA不是新编程语言而是WEB应用程序技术AJAXWeb前端知识杂乱 如何分清主次和学习优先级？Web前端知识杂乱 如何分清主次和学习优先级？Web前端/分清主次/学习编程初学者学什么语言好？未来编程趋势预测编程初学者学什么语言好？未来编程趋势预测编程精彩评论和气高尚评论了：【51CTO学院】免费直播课 | 赵海兵–虚拟化与混合云期待中。。。！ lwt1309108评论了：【51CTO学院】免费直播课 | 赵海兵–虚拟化与混合云期待 ashely冰雪雨露评论了：【51CTO学院】免费直播课 | 赵海兵–虚拟化与混合云虚拟化对我目前的工作很要紧 Wanglican评论了：【51CTO学院】团购第二期-低至6折！名师中高级实战进阶项目交了押金了，申请进群了，麻烦通过一下。亲~~精选博文论坛热帖下载排行现阶段为开放式基金赎回良机SecureCRT 使用技巧nagios全攻略(二)—-基本安装和配置关于51CTO合作出书中的职业发展部分利用WINDOWS SERVER 2003路由设置解读 书 +更多点石成金：访客至上的网页设计秘笈（原书第2版）有些网站看起来很清爽； 有些网站看起来很杂乱； 有些网站能让你轻松地找到资料； 有些网站让你犹如置身迷宫…… … 订阅51CTO邮刊点击这里查看样刊订阅51CTO邮刊51CTO旗下网站：领先的IT技术网站 51CTO|领先的中文存储媒体 WatchStor| 中国首个CIO网站 CIOage |中国首家数字医疗网站 HC3iCopyright©2005-2017 51CTO.COM 版权所有 未经许可 请勿转载","tags":[{"name":"架构","slug":"架构","permalink":"http://jishusuishouji.github.io/tags/架构/"}]},{"title":"VAGRANT 和 Docker的使用场景和区别?","date":"2017-01-25T06:20:57.000Z","path":"2017/01/25/xunihua/VAGRANT_和_Docker的使用场景和区别_/","text":"本质区别Vagrant并不提供虚拟化技术，本质上是一个虚拟机外挂，通过虚拟机的管理接口来管理虚拟机，让用户更轻松的进行一些常用配置，比如：CPU/Memory/IP/DISK等分配。并且提供了一些其它的管理操作：比如开机运行指定命令，镜像二次打包，插件编写等等。vagrant官方有介绍: To achieve its magic, Vagrant stands on the shoulders of giants. Machines are provisioned on top of VirtualBox, VMware, AWS, or any other provider. Then, industry-standard provisioning tools such as shell scripts, Chef, or Puppet, can be used to automatically install and configure software on the machine. 而docker是一个容器引擎，每一个实例是一个相对隔离的空间，与宿主机共享操作系统内核，并且共享宿主机资源。相对于披着虚拟机皮的vagrant，docker更加轻量，消耗更少的资源。 应用场景关于应用场景没有绝对，把两个东西都用熟，自己觉得用哪个方便用哪个好管理就用哪个。既然vagrant本质是虚拟机外挂，那么它的应用场景就是，节省你用原生虚拟机管理软件的时间。原来我们新增一台虚拟机需要配置好内存、硬盘、CPU等，然后添加iso，安装。创建用户，等等。一套下来好几十分钟是吧？聪明点你可能会想到复制一个创建好的镜像然后粘贴。但这一切vagrant都帮你想好了,安装vagrant后你只需要6步就能创建一台新的虚拟机，其中两步是创建文件夹和切换文件夹。从安装到创建一台新的虚拟机就成功了。如果你想要再添加一台虚拟机，你只需要执行最后两步，添加一个不同名字的配置就能再新建一台虚拟机。还支持镜像、开机自动运行脚本、插件编写等。dockerdocker主要应用于解决环境依赖以及为应用程序提供一个相对隔离的空间，一个实例像操作系统里运行的一个程序。原来部署一套环境是不是得自己编写自动化部署依赖环境以及程序的脚本？如果有两个依赖同一程序或库的不同版本怎么办？绝对路径？软连接？docker能很好的解决你的烦恼。把需要的依赖环境打包成一个镜像，再把程序放镜像里面运行。 总的来说vagrant更适合给开发大爷们创造一个统一的开发、测试、接近于完全隔离的环境，以及提高对高配机的闲置利用。docker更方便地解决了同一机器上的环境隔离，以及提高运维锅们解决部署时环境依赖的效率。","tags":[{"name":"docker","slug":"docker","permalink":"http://jishusuishouji.github.io/tags/docker/"}]},{"title":"使用 Velocity 模板引擎快速生成代码","date":"2017-01-21T23:35:11.000Z","path":"2017/01/22/java/velocity/使用_Velocity_模板引擎快速生成代码/","text":"Velocity 模板引擎介绍在现今的软件开发过程中，软件开发人员将更多的精力投入在了重复的相似劳动中。特别是在如今特别流行的MVC架构模式中，软件各个层次的功能更加独立，同时代码的相似度也更加高。所以我们需要寻找一种来减少软件开发人员重复劳动的方法，让程序员将更多的精力放在业务逻辑以及其他更加具有创造力的工作上。Velocity这个模板引擎就可以在一定程度上解决这个问题。Velocity是一个基于Java的模板引擎框架，提供的模板语言可以使用在Java中定义的对象和变量上。Velocity是Apache基金会的项目，开发的目标是分离MVC模式中的持久化层和业务层。但是在实际应用过程中，Velocity不仅仅被用在了MVC的架构中，还可以被用在以下一些场景中。 1.Web应用：开发者在不使用JSP的情况下，可以用Velocity让HTML具有动态内容的特性。2.源代码生成：Velocity可以被用来生成Java代码、SQL或者PostScript。有很多开源和商业开发的软件是使用Velocity来开发的。3.自动Email：很多软件的用户注册、密码提醒或者报表都是使用Velocity来自动生成的。使用Velocity可以在文本文件里面生成邮件内容，而不是在Java代码中拼接字符串。4.转换xml：Velocity提供一个叫 Anakia 的ant任务，可以读取XML文件并让它能够被 Velocity模板读取。一个比较普遍的应用是将xdoc文档转换成带样式的HTML文件。 Hello Velocity和学习所有新的语言或者框架的顺序一样，我们从Hello Velocity开始学习。首先在Velocity的官网上下载最新的发布包，之后使用Eclipse建立普通的Java项目。引入解压包中的 velocity-1.7.jar和lib文件夹下面的jar包。这样我们就可以在项目中使用Velocity了。在做完上面的准备工作之后，就可以新建一个叫HelloVelocity的类，代码如下： 清单 1. HelloVelocity.java1234567891011121314151617181920212223242526public class HelloVelocity &#123; public static void main(String[] args) &#123; VelocityEngine ve = new VelocityEngine(); ve.setProperty(RuntimeConstants.RESOURCE_LOADER, &quot;classpath&quot;); ve.setProperty(&quot;classpath.resource.loader.class&quot;, ClasspathResourceLoader.class.getName()); ve.init(); Template t = ve.getTemplate(&quot;hellovelocity.vm&quot;); VelocityContext ctx = new VelocityContext(); ctx.put(&quot;name&quot;, &quot;velocity&quot;); ctx.put(&quot;date&quot;, (new Date()).toString()); List temp = new ArrayList(); temp.add(&quot;1&quot;); temp.add(&quot;2&quot;); ctx.put(&quot;list&quot;, temp); StringWriter sw = new StringWriter(); t.merge(ctx, sw); System.out.println(sw.toString()); &#125;&#125; 在HelloVelocity的代码中，首先new了一个VelocityEngine类，这个类设置了Velocity使用的一些配置，在初始化引擎之后就可以读取hellovelocity.vm这个模板生成的Template这个类。之后的VelocityContext类是配置Velocity模板读取的内容。这个context可以存入任意类型的对象或者变量，让template来读取。这个操作就像是在使用JSP开发时，往request里面放入key-value，让JSP 读取一样。接下来就是写hellovelocity.vm文件了，这个文件实际定义了Velocity的输出内容和格式。hellovelocity.vm的内容如下： 清单 2. Hellovelocity.vm1234567#set( $iAmVariable = &quot;good!&quot; )Welcome $name to velocity.comtoday is $date.#foreach ($i in $list)$i#end$iAmVariable 输出结果如下：Welcome velocity to velocity.comtoday is Sun Mar 23 19:19:04 CST 2014.12good!在输出结果中我们可以看到，$name、$date 都被替换成了在 HelloVelocity.java 里面定义的变量，在 foreach 语句里面遍历了 list 的每一个元素，并打印出来。而$iAmVariable 则是在页面中使用 #set 定义的变量。回页首基本模板语言语法使用在 hellovelocity.vm 里面可以看到很多以 # 和$符开头的内容，这些都是 Velocity 的语法。在 Velocity 中所有的关键字都是以 # 开头的，而所有的变量则是以$开头。Velocity 的语法类似于 JSP 中的 JSTL，甚至可以定义类似于函数的宏，下面来看看具体的语法规则。一、变量和我们所熟知的其他编程语言一样，Velocity 也可以在模板文件中有变量的概念。 变量定义#set($name =“velocity”)等号后面的字符串 Velocity 引擎将重新解析，例如出现以$开始的字符串时，将做变量的替换。#set($hello =“hello $name”)上面的这个等式将会给$hello 赋值为“hello velocity” 变量的使用在模板文件中使用$name 或者${name} 来使用定义的变量。推荐使用${name} 这种格式，因为在模板中同时可能定义了类似$name 和$names 的两个变量，如果不选用大括号的话，引擎就没有办法正确识别$names 这个变量。对于一个复杂对象类型的变量，例如$person，可以使用${person.name} 来访问 person 的 name 属性。值得注意的是，这里的${person.name} 并不是直接访问 person 的 name 属性，而是访问 person 的 getName() 方法，所以${person.name} 和${person.getName()} 是一样的。 变量赋值在第一小点中，定义了一个变量，同时给这个变量赋了值。对于 Velocity 来说，变量是弱数据类型的，可以在赋了一个 String 给变量之后再赋一个数字或者数组给它。可以将以下六种数据类型赋给一个 Velocity 变量：变量引用, 字面字符串, 属性引用, 方法引用, 字面数字, 数组列表。#set($foo = $bar)#set($foo =“hello”)#set($foo.name = $bar.name)#set($foo.name = $bar.getName($arg))#set($foo = 123)#set($foo = [“foo”,$bar])二、循环在 Velocity 中循环语句的语法结构如下：#foreach($element in $list)This is $element$velocityCount#endVelocity 引擎会将 list 中的值循环赋给 element 变量，同时会创建一个$velocityCount 的变量作为计数，从 1 开始，每次循环都会加 1.三、条件语句条件语句的语法如下#if(condition)…#elseif(condition)…#else…#end四、关系操作符Velocity 引擎提供了 AND、OR 和 NOT 操作符，分别对应&amp;&amp;、||和! 例如：#if($foo &amp;&amp; $bar)#end五、宏Velocity 中的宏可以理解为函数定义。定义的语法如下：#macro(macroName arg1 arg2 …)…#end调用这个宏的语法是：#macroName(arg1 arg2 …)这里的参数之间使用空格隔开，下面是定义和使用 Velocity 宏的例子：#macro(sayHello $name)hello $name#end#sayHello(“velocity”)输出的结果为 hello velocity六、#parse 和 #include#parse 和 #include 指令的功能都是在外部引用文件，而两者的区别是，#parse 会将引用的内容当成类似于源码文件，会将内容在引入的地方进行解析，#include 是将引入文件当成资源文件，会将引入内容原封不动地以文本输出。分别看以下例子：foo.vm 文件：#set($name =“velocity”)parse.vm：#parse(“foo.vm”)输出结果为：velocityinclude.vm：#include(“foo.vm”)输出结果为：#set($name =“velocity”)以上内容包含了部分 Velocity 的语法，详细的语法内容可以参考 Velocity 的官方文档。回页首自动生成代码的例子在上个例子中我们可以生成任意的字符串并且打印出来，那为什么我们不能生成一些按照既定格式定义的代码并且写入文件呢。在这里我们以一个实际的 demo 来完成这部分内容。相关内容的源码可以参照附件。这个 demo 的功能是要实现一个学生和老师的管理，实际上都是单张表的维护。我们希望能够只定义 model 层，来生成 MVC 的所有代码。在这个 demo 中，只自动生成 action 和 JSP 的内容，因为现在有很多工具都可以帮助我们自动生成这两个包的代码。首先在 eclipse 中建立一个 Java web 工程，在例子中为了方便管理 jar 包，使用的是 maven 来建立和管理工程。建立好的工程目录结构如下图所示：图 1. 项目目录结构项目目录结构Java Resource 中放的是 Java 源码以及资源文件，Deployed Resources 中放的是 web 相关的文件。在 Java 文件中使用了类似 Spring 的 @Component 和 @Autowired 的注解来实现 IoC，使用 @Action 这样的注解实现 MVC，而在 JSP 中则使用了 JSTL 来输出页面。在上图所示的目录中，annotation、filter、framework 和 util 这四个 package 是作为这个项目框架的，跟业务没有关系，类似于 spring 和 struts 的功能。在实际的项目中我们当然希望能够一开始就编写一个通用的模板文件，然后一下子生成所有的代码，但是很多时候这样做是不可能的，或者说比较困难。为了解决这个问题，我们可以在编写 Velocity 模板文件之前先按照原本的流程编写代码，暂时先忘掉 Velocity。编写的代码应该能够在一个功能上完整的调通涉及 MVC 中所有层次的内容。在这个例子中，先编写好 StudentAction.java 文件，以及上图中 webapp 目录中所示的文件。在写好以上代码，同时也能顺利运行之后，我们可以参照之前编写的代码来写模板文件。这里我们来分别看一个 Java 文件和 JSP 的例子。清单 3. ActionTemplate.vm#parse (“macro.vm”) @Action(“${classNameLowCase}Action”)public class ${classNameUpCase}Action extends BaseAction{ @Autowired public ${classNameUpCase}Dao ${classNameLowCase}Dao; private List&lt;${classNameUpCase}&gt; ${classNameLowCase}s; private ${classNameUpCase} ${classNameLowCase}; #foreach ($attr in ${attrs}) private ${attr[0]} ${attr[1]}; #end public String ${classNameLowCase}List() { ${classNameLowCase}s = ${classNameLowCase}Dao.retrieveAll${classNameUpCase}s(); return “${classNameLowCase}List.jsp”; } …}上面的代码展示了一个 Java 类转换成 vm 模板之后的部分内容，完整内容请参考附件。macro.vm 文件中定义了一些使用的宏。JSP 的改造相对于 Java 文件来说稍微有点复杂，因为 JSP 中使用 JSTL 取 request 中的值也是使用${name} 这样的语法，所以想要输出${name} 这样的字符串而不是被模板引擎所替换，则需要使用转义字符，就像这样：\\${name}。为了能够让这个文件中的 table 得到复用，我们将这个文件中的表格单独拿出来，使用 #parse 命令来包含。下面是 ListJspTemplate.vm 和 ListTableTemplate.vm 的内容：清单 4. ListJspTemplate.vm&lt;%@ page language=”java” contentType=”text/html; charset=UTF-8” pageEncoding=”UTF-8”%&gt;&lt;%@taglib prefix=”c” uri=”http://java.sun.com/jsp/jstl/core“ %&gt;&lt;!DOCTYPE html PUBLIC “-//W3C//DTD HTML 4.01 Transitional//EN” “http://www.w3.org/TR/html4/loose.dtd&quot;&gt; &lt;%@ include file=”includeJS.jsp” %&gt; var pageConfig = { “list” : { “action” : “${classNameLowCase}Action!${classNameLowCase}List.action” } … “idName” : “${classNameLowCase}Id” }; ${classNameUpCase} List ${classNameUpCase} List Add #parse (“ListTableTemplate.vm”) 清单 5. ListTableTemplate.vm #parse (“macro.vm”) #set($plus = “status.index+1”) No.#generateTH($attrs) ${${plus}}#generateTD($classNameLowCase $attrs) Modify Delete 在定义好所有的模板文件之后，需要做的是读取这些文件，然后根据这些文件将 model 的数据类型以及名称设置到 context 中，最后将解析出来的内容写到相应的目录中去。这些工作我们放在了一个叫做 VelocityGenerator 的类中来做，它的源码如下：清单 6. TemplateGenerator.javapublic class VelocityGenerator { public static void main(String[] args) { VelocityEngine ve = new VelocityEngine(); ve.setProperty(RuntimeConstants.RESOURCE_LOADER, “classpath”); ve.setProperty(“classpath.resource.loader.class”, ClasspathResourceLoader.class.getName()); ve.init(); Template actionTpt = ve.getTemplate(“ActionTemplate.vm”); Template listJspTpt = ve.getTemplate(“ListJspTemplate.vm”); Template addTpt = ve.getTemplate(“AddTemplate.vm”); Template modifyTpt = ve.getTemplate(“ModifyTemplate.vm”); VelocityContext ctx = new VelocityContext(); ctx.put(“classNameLowCase”, “teacher”); ctx.put(“classNameUpCase”, “Teacher”); String[][] attrs = { {“Integer”,”id”}, {“String”,”name”}, {“String”,”serializeNo”}, {“String”,”titile”}, {“String”,”subject”} }; ctx.put(“attrs”, attrs); String rootPath = VelocityGenerator.class.getClassLoader().getResource(“”).getFile() + “../../src/main”; merge(actionTpt,ctx,rootPath+”/java/com/liuxiang/velocity/action/TeacherAction.java”); merge(listJspTpt,ctx,rootPath+”/webapp/teacherList.jsp”); merge(addTpt,ctx,rootPath+”/webapp/teacherAdd.jsp”); merge(modifyTpt,ctx,rootPath+”/webapp/teacherModify.jsp”); System.out.println(“success…”); } private static void merge(Template template, VelocityContext ctx, String path) { PrintWriter writer = null; try { writer = new PrintWriter(path); template.merge(ctx, writer); writer.flush(); } catch (FileNotFoundException e) { e.printStackTrace(); } finally { writer.close(); } }}在运行以上代码之后，项目文件夹中将会出现与 Teacher 相关的代码文件。在实际项目中可能不会出现很多这种单张表维护的情况，而且业务逻辑和系统架构会更加复杂，编写模板文件就更加不容易。但是无论多复杂的系统，不同的业务逻辑之间一定或多或少会有相似的代码，特别是在 JSP 和 JS 显示端文件中，因为我们在一个系统中要求显示风格、操作方式一致的时候就免不了会有相似内容的代码出现。在总结这些相似性之后我们还是可以使用 Velocity 来帮助我们生成部分内容的代码，而且即使有一些非共性的内容，我们也可以在生成的代码中继续修改。使用 Velocity 的另外一个好处是生成出来的代码更好维护，风格更加统一。回页首结束语Velocity 可以被应用在各种各样的情景下，本文介绍的只是它的一种用途而已，它还可以被用来做 MVC 结构中的 view 层，或者动态内容静态化等。另外，Velocity 并不是唯一的模板框架，同样很优秀的 Freemarker 也获得了非常广泛的应用，有兴趣的读者可以去深入研究更多的功能和用途。","tags":[{"name":"Velocity","slug":"Velocity","permalink":"http://jishusuishouji.github.io/tags/Velocity/"}]},{"title":"Spring中提示元素 'ref' 中不允许出现属性 'local'","date":"2017-01-17T07:58:44.000Z","path":"2017/01/17/spring/Spring中提示元素__ref__中不允许出现属性__local_/","text":"这个问题在Spring4.X以前的版本不存在。通过查询Spring的官方文档Spring4.X的以上版本不支持该属性了。下面是官方说明： The local attribute on the ref element is no longer supported in the 4.0 beans xsd since it does not provide value over a regular bean reference anymore. Simply change your existing ref local references to ref bean when upgrading to the 4.0 schema. 官方建议使用bean在Spring4.0以上的版本。 案例重现抛错：1234567891011121314151617181920212223242526272829303132333435363738394041Exception in thread &quot;main&quot; org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 37 in XML document from class path resource [application_dependencies.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 37; columnNumber: 27; cvc-complex-type.3.2.2: 元素 &apos;ref&apos; 中不允许出现属性 &apos;local&apos;。 at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304) at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:181) at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:217) at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:188) at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:252) at org.springframework.context.support.AbstractXmlApplicationContext.loadBeanDefinitions(AbstractXmlApplicationContext.java:127) at org.springframework.context.support.AbstractXmlApplicationContext.loadBeanDefinitions(AbstractXmlApplicationContext.java:93) at org.springframework.context.support.AbstractRefreshableApplicationContext.refreshBeanFactory(AbstractRefreshableApplicationContext.java:129) at org.springframework.context.support.AbstractApplicationContext.obtainFreshBeanFactory(AbstractApplicationContext.java:604) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:509) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:139) at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:83) at com.mxsm.spring.SpringDependencies.main(SpringDependencies.java:64)Caused by: org.xml.sax.SAXParseException; lineNumber: 37; columnNumber: 27; cvc-complex-type.3.2.2: 元素 &apos;ref&apos; 中不允许出现属性 &apos;local&apos;。 at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198) at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134) at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437) at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368) at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325) at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:453) at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3232) at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2709) at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2051) at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:761) at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:353) at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2717) at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:607) at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:116) at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:489) at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:835) at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:764) at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:123) at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:237) at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:300) at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391) ... 14 more spring xml文件配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;animals&quot; class=&quot;com.mxsm.spring.bean.Animal&quot;&gt; &lt;constructor-arg&gt; &lt;ref bean=&quot;dog&quot;/&gt; &lt;/constructor-arg&gt; &lt;constructor-arg&gt; &lt;ref bean=&quot;cat&quot;/&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!--使用type属性--&gt; &lt;bean id=&quot;dog&quot; class=&quot;com.mxsm.spring.bean.Dog&quot;&gt; &lt;constructor-arg type=&quot;java.lang.String&quot; value=&quot;aa&quot;/&gt; &lt;constructor-arg type=&quot;int&quot; value=&quot;1&quot;/&gt; &lt;constructor-arg type=&quot;java.lang.String&quot; value=&quot;meat&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;dog_2&quot; class=&quot;com.mxsm.spring.bean.Dog&quot;&gt; &lt;constructor-arg index=&quot;0&quot; value=&quot;ssss&quot;/&gt; &lt;constructor-arg index=&quot;1&quot; value=&quot;3333&quot;/&gt; &lt;constructor-arg index=&quot;2&quot; value=&quot;8888&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;cat&quot; class=&quot;com.mxsm.spring.bean.Cat&quot;&gt; &lt;constructor-arg name=&quot;a&quot; value=&quot;ssss&quot;/&gt; &lt;constructor-arg name=&quot;b&quot; value=&quot;3333&quot;/&gt; &lt;/bean&gt; &lt;!-- setter 依赖注入bean --&gt; **&lt;bean id=&quot;man&quot; class=&quot;com.mxsm.spring.bean.Man&quot;&gt; &lt;property name=&quot;white&quot;&gt; &lt;ref local=&quot;whiteMan&quot;/&gt; &lt;/property&gt; &lt;property name=&quot;yellow&quot;&gt; &lt;ref local =&quot;yellowMan&quot;/&gt; &lt;/property&gt; &lt;property name=&quot;id&quot; value=&quot;1&quot;/&gt; &lt;/bean&gt;** &lt;bean id=&quot;whiteMan&quot; class=&quot;com.mxsm.spring.bean.WhitePerson&quot;&gt; &lt;constructor-arg name=&quot;age&quot; value=&quot;1&quot;/&gt; &lt;constructor-arg name=&quot;color&quot; value=&quot;white&quot;/&gt; &lt;constructor-arg name=&quot;name&quot; value=&quot;USA&quot;/&gt; &lt;constructor-arg name=&quot;sex&quot; value=&quot;男&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;yellowMan&quot; class=&quot;com.mxsm.spring.bean.YellowPerson&quot;&gt; &lt;constructor-arg name=&quot;age&quot; value=&quot;1&quot;/&gt; &lt;constructor-arg name=&quot;color&quot; value=&quot;yellow&quot;/&gt; &lt;constructor-arg name=&quot;name&quot; value=&quot;China&quot;/&gt; &lt;constructor-arg name=&quot;sex&quot; value=&quot;男&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt;","tags":[{"name":"spring","slug":"spring","permalink":"http://jishusuishouji.github.io/tags/spring/"}]},{"title":"nodejs的require模块及路径","date":"2017-01-13T17:30:53.000Z","path":"2017/01/14/nodejs/nodejs的require模块及路径/","text":"在nodejs中，模块分为核心模块和文件模块。 核心模块是被编译成二进制代码，引用的时候只需require即可，如require(&#39;net&#39;)。文件模块，则是指js文件、json文件或者是.node文件。在引用文件模块的时候要加上文件的路径：如果既不加/.../...、../又不加./的话，则该模块要么是核心模块，要么是从一个node_modules文件夹加载。 如果’/home/ry/projects/foo.js‘ 中的文件调用了`require(‘bar.js’)`` ，node将在下面的位置进行搜索： •/home/ry/projects/node_modules/bar.js•/home/ry/node_modules/bar.js•/home/node_modules/bar.js•/node_modules/bar.js 文件夹作为模块：首先在./some-library文件夹下建立package.json文件，它标识了一个主模块。一个package.json中的内容可能如下：1234&#123; &quot;name&quot; : &quot;some-library&quot;, &quot;main&quot; : &quot;./lib/some-library.js&quot; &#125; require(&#39;./some-library&#39;)(和some-library相同路径的js文件)时将试图加载./some-library/lib/some-library.js如果在这个目录下没有package.json文件，node将试图从这个目录下加载index.js或index.node文件。例如，如果上面没有package.json文件，那么require(&#39;./some-library&#39;)时，将试图加载下面的文件：•./some-library/index.js•./some-library/index.node 分类: javascript,nodejs标签: javascript, nodejs","tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://jishusuishouji.github.io/tags/nodejs/"}]},{"title":"Spring MVC事务配置","date":"2017-01-09T14:36:01.000Z","path":"2017/01/09/java/spring/Spring_MVC事务配置/","text":"","tags":[]},{"title":"是该抛弃Spring HibernateTemplate的时候了","date":"2017-01-09T14:26:48.000Z","path":"2017/01/09/java/spring/是该抛弃Spring_HibernateTemplate的时候了/","text":"在spring2.0之前，我们在使用hibernate和spring的时候，都会被HibernateTemplate为我们提供benefits（资源和事务管理以及把那个“丑陋”的checked exception转换为runtime exception-DataAccessException ）而折服，在项目中不由自主、不假思索地使用它和那个经典的callback方法。而如今，hibernate3.0.1+ 、spring 2.0+版本以后，我们可以在数据访问层直接使用hinberate的session API(例如SessionFactory.getCurrentSession)，不并担心session和transaction management。至于error handling可以通过spring的@Repository annotation和post processor-PersistenceExceptionTranslationPostProcessor来解决。让我们来看一些代码片段：123456789&lt;bean id=&quot;sessionFactory&quot; class=&quot;org.springframework.orm.hibernate3. LocalSessionFactoryBean&quot;&gt; &lt;!-- the properties setting--&gt; &lt;/bean&gt; &lt;bean id=&quot;accountRepo&quot; class=&quot;com.mycompany.HibernateAccountRepository&quot;&gt; &lt;constructor-arg ref=&quot;sessionFactory&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.dao.annotation. PersistenceExceptionTranslationPostProcessor&quot;/&gt; 数据访问层代码片段：123456789101112131415@Repository public class HibernateAccountRepository implements AccountRepository &#123; private SessionFactory factory; public HibernateAccountRepository(SessionFactory factory) &#123; this.factory = factory; &#125; public Account loadAccount(String username) &#123; return (Account)factory.getCurrentSession() .createQuery(&quot;from Account acc where acc.name = :name&quot;) .setParameter(&quot;name&quot;, &quot;thethirdpart&quot;).uniqueResult(); &#125; &#125; 在xml配置文件里面通过配置的post processor会自动检测@Repository标注的bean并为该bean打开exception转换功能。 如果不支持annotations，可以通过AOP来实现，更方便123456&lt;bean id=&quot;persistenceExceptionInterceptor&quot; class=&quot;org.springframework.dao.support.PersistenceExceptionTranslationInterceptor&quot;/&gt; &lt;aop:config&gt; &lt;aop:advisor pointcut=&quot;execution(* *..*Repository+.*(..))&quot; advice-ref=&quot;persistenceExceptionInterceptor&quot; /&gt; &lt;/aop:config&gt; 总结，我们应该选择哪种方式呢？还是那句话，根据不同的情况来做最正确的选择。但我建议是丢弃template，而直接使用hibernate的API，毕竟灵活性更大，更何况遇到复杂的情况我们始终得面对hibernate的API。spring并不强制你做任何事情，记得它是一个非侵入性的framework。","tags":[{"name":"spring","slug":"spring","permalink":"http://jishusuishouji.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"}]},{"title":"So should you still use Spring's HibernateTemplate and/or JpaTemplate??","date":"2017-01-09T14:20:51.000Z","path":"2017/01/09/java/spring/So_should_you_still_use_Spring_s_HibernateTemplate_and_or_JpaTemplate__/","text":"I was reading an article by Vigil Bose on TSS the other day and saw the usage of the HibernateDaoSupport class. Since this is no longer a recommended way of using Hibernate from Spring, I thought I might as well just blog about it another time. 不建议使用HibernateDaoSupport。 With the advent(n. 到来；出现；) of Spring 2.0, it has become possible to start using the Hibernate Session API directly again. The question is whether or not it is wise to abandon the use of the HibernateTemplate when working with Hibernate, or any other template-based approaches Spring features. Using Spring XxxTemplatesIn Spring 1.0, we introduced a revolutionary way of working with data access APIs that threw checked exceptions. The template approach Spring features along with its transaction synchronization manager and the extensive(adj. 广泛的；大量的；广阔的) use of runtime exceptions makes any TCFTC (short for try/catch-finally-try/catch as we coined(杜撰) it back in 2005) often found in data access code entirely obsolete. Below you can see (a simplified version and not entirely precise version of) what Spring’s template approach does for you (with specific code snippets that you would otherwise have to write). Acquisition of connection: If transaction synchronization is active (which it is, if you’re using Spring’s transaction management infrastructure), most of the times any of the Spring templates are using the same connection across the entire thread (things are actually a bit more complicated than that, but that would lead us too much into the gory details). Participation in a transaction Again, when using transaction management features, Spring will automatically associated any new connection with the current transaction. This again, all depends on the current propagations settings and so on, but whichever way you look at it, your core code is not affected by it. Specification of the SQL: This is what you (obviously) have to do yourself. The SQL ideally uses bind parameters, to avoid any chances of SQL injection from happening. Parameters are passed to the JDBC template as arguments. Creation / execution of statement and iterating over result set: After you’ve specified the SQL, Spring is going to create the statement for you, set any parameters you may have specified, execute it and loop over the result set for you. Parse result from result set: You can opt for parsing the result set yourself if you like (or if you have complex parsing requirements), or you can have Spring result a list of primitives, or just one value from the result set. Handling and translation of exceptions: This is where Spring translates any exceptions that might have occurred to Spring’s own DataAccessException hierarchy, automatically insulating calling code from the data access technology in use. Releasing of connection: This is the last piece of the puzzle where Spring releases any resources used. Of course, if transaction synchronization is active, the resources might not be released immediately. Templates are available for several APIs such as: JDBC (JdbcTemplate) Hibernate (HibernateTemplate) iBatis (SqlMapClientTemplate) JDO (JdoTemplate) TopLink (TopLinkTemplate) Messaging (JmsTempate) Transaction management (TransactionTemplate) JNDI (JndiTemplate) Are templates really necessary?The templates add a lot of value when using an API that uses checked exceptions (as opposed to runtime exceptions or unchecked exceptions), but also add a lot of consistency to your code base. People having learnt Spring’s JdbcTemplate can pretty easily start using Spring’s JdoTemplate or Spring’s HibernateTemplate–the approach to using those is similar for each one of them. The most visible impact of the Spring template approach is the code reduction for for example JDBC. This is primarily because the checked exceptions are translated to runtime exceptions inside the template, removing the need to catch the exception in your mainline code. Other reasons are the transparent resource management and automatic synchronization with the currently running transaction. Of course it’s fairly easy to change a framework to use runtime exceptions natively instead of Spring having to do this and this is what for example Hibernate has started to do from version 3.0 onwards. Hibernate is not the only technology to do this–the Java Persistence API is also using runtime exceptions.","tags":[{"name":"spring","slug":"spring","permalink":"http://jishusuishouji.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"},{"name":"hibernate","slug":"hibernate","permalink":"http://jishusuishouji.github.io/tags/hibernate/"},{"name":"HibernateTemplate","slug":"HibernateTemplate","permalink":"http://jishusuishouji.github.io/tags/HibernateTemplate/"}]},{"title":"java分布式事务(JTA)实现 jotm和atomikos","date":"2017-01-08T02:03:52.000Z","path":"2017/01/08/java/jta/java分布式事务_JTA_实现 jotm和atomikos/","text":"本地事务：只对单一数据源(单个数据库)事务进行控制。分布式事务：处理多种异构的数据源， 比如某个业务操作中同时包含JDBC和JMS或者某个操作需要访问多个不同的数据库，在不同数据库之间进行事务控制。 在Java中，分布式事务主要的规范是JTA/XA。其中：JTA是Java的事务管理器规范，XA是工业标准的X/Open CAE规范，可被两阶段提交及回滚的事务资源定义。比如某数据库实现了XA规范，则不管是JTA，还是MSDTC，都可以基于同样的行为对该数据库进行事务处理。 JTA全称为Java Transaction API，顾名思义JTA定义了一组统一的事务编程的接口，这些接口如下： XAResource：XAResource接口是对实现了X/Open CAE规范的资源管理器 (Resource Manager，数据库就是典型的资源管理器) 的抽象，它由资源适配器 (Resource Apdater) 提供实现。XAResource是支持事务控制的核心。Transaction：Transaction接口是一个事务实例的抽象，通过它可以控制事务内多个资源的提交或者回滚。二阶段提交过程也是由Transaction接口的实现者来完成的。TransactionManager：托管模式 (managed mode) 下，TransactionManager接口是被应用服务器调用，以控制事务的边界的。UserTransaction：非托管模式 (non-managed mode) 下，应用程序可以通过UserTransaction接口控制事务的边界 在tomcat下是没有分布式事务的，可以借助于第三方Jotm和Automikos实现，在spring中分布式事务是通过jta（jotm，atomikos）来进行实现。即：通过代码的方式来决定是否是分布式事务。 注：推荐用服务器自己的数据源(也就是 lookup JNDI)，这样的话，是不是XA事务就由服务器的配置来定制，代码就不需要任何配置来决定是不是XA了。事务本身是不是XA (分布式的）是服务器的事，服务器来管理“资源” （包括数据源，JMS 连接等，一个资源（JDBC连接）如何参与事务是“资源管理器”（驱动程序）的职责，跟程序无关），服务器提供事务管理并作为“事务协调者”来处理多个“资源管理器”（不同的数据库连接）之间的事务一致性。 jotm和automikos网址：1、http://jotm.objectweb.org/2、http://www.atomikos.com/Main/TransactionsEssentials Spring 通过AOP技术可以让我们在脱离EJB的情况下享受声明式事务的丰盛大餐。此外，通过配合使用ObjectWeb的JOTM开源项目，不需要Java EE应用服务器，Spring也可以提供JTA事务。 正因为AOP让Spring拥有了脱离EJB容器的声明式事务能力，而JOTM让我们在脱离Java EE应用服务器下拥有JTA事务能力。所以，人们将AOP和JOTM称为Java软件开发的两个圣杯。 JTA的实现框架有：GeronimoTM/Jencks 官方文档比较少，不适合学习和维护。SimpleJTA 没有实现JTS (Java Transaction Service)而且不是活跃的。Atomikos 是一个另人钦佩的产品。有丰富的文档，而且有很好的支持。JBossTS 是一个应用在JBOSS服务器上的，肯定是一个成熟的产品，也有好的支持，详细信息可以看这里：http://www.theserverside.com/news/thread.tss?thread_id=37941最常见的二个如下：JOTM JOTM(Java Open Transaction Manager)是ObjectWeb的一个开源JTA实现，它本身也是开源应用程序服务器JOnAS(Java Open Application Server)的一部分，为其提供JTA分布式事务的功能。 存在的问题：使用中不能自动rollback，无论什么情况都commit。注：spring3开始已经不再支持jotm Atomikos 大家推荐最多的。和JOTM相比Atomikos Transactions Essentials更加稳定，它原来是商业项目，现在开源了。象MySQL一样卖服务支持的。而且论坛页比较活跃，有问题很快可以解决。","tags":[{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"},{"name":"jta","slug":"jta","permalink":"http://jishusuishouji.github.io/tags/jta/"},{"name":"分布式事务","slug":"分布式事务","permalink":"http://jishusuishouji.github.io/tags/分布式事务/"},{"name":"jotm","slug":"jotm","permalink":"http://jishusuishouji.github.io/tags/jotm/"},{"name":"atomikos","slug":"atomikos","permalink":"http://jishusuishouji.github.io/tags/atomikos/"}]},{"title":"java分布式事务:spring+JTA+jotm","date":"2017-01-08T01:23:24.000Z","path":"2017/01/08/java/jta/java分布式事务_spring_JTA_jotm/","text":"业务背景当新建用户时需插入一条用户记录，同时还需在另一个DB中记录日志。因为是不同的DB操作，所以及到分布式事务的处理。 1、代码结构： 2、建表语句：1234567create database log; DROP TABLE IF EXISTS `log`; CREATE TABLE `log` ( `id` varchar(20) NOT NULL, `content` varchar(100) default NULL, PRIMARY KEY (`id`) ); 1234567create database user; DROP TABLE IF EXISTS `user`; CREATE TABLE `user` ( `id` varchar(20) NOT NULL, `name` varchar(40) default NULL, PRIMARY KEY (`id`) ); 3、配置文件application.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;!--?xml version=1.0 encoding=UTF-8?--&gt; &lt;beans aop=&quot;&quot; beans=&quot;&quot; http:=&quot;&quot; schema=&quot;&quot; spring-aop.xsd=&quot;&quot; spring-beans.xsd=&quot;&quot; spring-tx.xsd=&quot;&quot; tx=&quot;&quot; www.springframework.org=&quot;&quot; xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemalocation=&quot;http://www.springframework.org/schema/beans&quot;&gt; &lt;!-- 引用Spring内部所提供的对JOTM支持的工厂类 --&gt; &lt;bean class=&quot;org.springframework.transaction.jta.JotmFactoryBean&quot; id=&quot;jotm&quot;/&gt; &lt;!-- 配置JTA事务管理器, 并在管理器中使用上面所配置的JOTM --&gt; &lt;bean class=&quot;org.springframework.transaction.jta.JtaTransactionManager&quot; id=&quot;txManager&quot;&gt; &lt;property name=&quot;userTransaction&quot; ref=&quot;jotm&quot;/&gt; &lt;/bean&gt; &lt;!-- 配置多个数据源 --&gt; &lt;bean class=&quot;org.enhydra.jdbc.pool.StandardXAPoolDataSource&quot; destroy-method=&quot;shutdown&quot; id=&quot;db1&quot;&gt; &lt;property name=&quot;dataSource&quot;&gt; &lt;bean class=&quot;org.enhydra.jdbc.standard.StandardXADataSource&quot; destroy-method=&quot;shutdown&quot;&gt; &lt;property name=&quot;transactionManager&quot; ref=&quot;jotm&quot;/&gt; &lt;property name=&quot;driverName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:MySQL://localhost:3306/user&quot;/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name=&quot;user&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;org.enhydra.jdbc.pool.StandardXAPoolDataSource&quot; destroy-method=&quot;shutdown&quot; id=&quot;db2&quot;&gt; &lt;property name=&quot;dataSource&quot;&gt; &lt;bean class=&quot;org.enhydra.jdbc.standard.StandardXADataSource&quot; destroy-method=&quot;shutdown&quot;&gt; &lt;property name=&quot;transactionManager&quot; ref=&quot;jotm&quot;/&gt; &lt;property name=&quot;driverName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:MySQL://localhost:3306/log&quot;/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name=&quot;user&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt; &lt;/bean&gt; &lt;!-- 根据不同的数据源配置两个jdbcTemplate --&gt; &lt;bean class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot; id=&quot;jdbcTemplate1&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;db1&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot; id=&quot;jdbcTemplate2&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;db2&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;com.zdp.dao.UserDao&quot; id=&quot;userDao&quot;&gt; &lt;property name=&quot;jdbcTemplate&quot; ref=&quot;jdbcTemplate1&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;com.zdp.dao.LogDao&quot; id=&quot;logDao&quot;&gt; &lt;property name=&quot;jdbcTemplate&quot; ref=&quot;jdbcTemplate2&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;com.zdp.service.UserService&quot; id=&quot;userService&quot;/&gt; &lt;property name=&quot;userDao&quot; ref=&quot;userDao&quot;/&gt; &lt;property name=&quot;logDao&quot; ref=&quot;logDao&quot;/&gt; &lt;/bean&gt; &lt;!-- JTA事务传播特性 --&gt; &lt;tx:advice id=&quot;txAdviceJTA&quot; transaction-manager=&quot;txManager&quot;&gt; &lt;tx:attributes&gt; &lt;tx:method isolation=&quot;DEFAULT&quot; name=&quot;save*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception/&quot;&gt; &lt;tx:method isolation=&quot;DEFAULT&quot; name=&quot;add*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception/&quot;&gt; &lt;tx:method isolation=&quot;DEFAULT&quot; name=&quot;create*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception/&quot;&gt; &lt;tx:method isolation=&quot;DEFAULT&quot; name=&quot;insert*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception/&quot;&gt; &lt;tx:method isolation=&quot;DEFAULT&quot; name=&quot;del*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception/&quot;&gt; &lt;tx:method isolation=&quot;DEFAULT&quot; name=&quot;update*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception/&quot;&gt; &lt;tx:method name=&quot;*&quot; read-only=&quot;true/&quot;&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;/beans&gt; 4、service业务类：1234567891011121314151617181920212223242526public class UserService &#123; private UserDao userDao; private LogDao logDao; public void saveUser(String id, String name) &#123; userDao.insertUser(id, name); // int i = 1 / 0; // 制造异常 logDao.insertLog(id, id + _ + name); &#125; public UserDao getUserDao() &#123; return userDao; &#125; public void setUserDao(UserDao userDao) &#123; this.userDao = userDao; &#125; public LogDao getLogDao() &#123; return logDao; &#125; public void setLogDao(LogDao logDao) &#123; this.logDao = logDao; &#125; &#125; 5、dao类：123456public class UserDao extends JdbcDaoSupport &#123; public void insertUser(String id, String name) &#123; JdbcTemplate template = getJdbcTemplate(); template.execute(insert into user values(&apos; + id + &apos;,&apos; + name + &apos;)); &#125; &#125; 123456public class LogDao extends JdbcDaoSupport &#123; public void insertLog(String id, String content) &#123; JdbcTemplate template = getJdbcTemplate(); template.execute(insert into log values(&apos; + id + &apos;,&apos; + content + &apos;)); &#125; &#125; 6、测试类：12345678public class UserTest &#123; @Test public void testSave() &#123; ApplicationContext cxt = new ClassPathXmlApplicationContext(ApplicationContext.xml); UserService us = (UserService) cxt.getBean(userService); us.saveUser(1, zhangsan); &#125; &#125;","tags":[{"name":"spring","slug":"spring","permalink":"http://jishusuishouji.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"http://jishusuishouji.github.io/tags/java/"},{"name":"jta","slug":"jta","permalink":"http://jishusuishouji.github.io/tags/jta/"},{"name":"jotm","slug":"jotm","permalink":"http://jishusuishouji.github.io/tags/jotm/"}]}]