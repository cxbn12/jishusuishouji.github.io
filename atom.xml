<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>技术随手记</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://jishusuishouji.github.io/"/>
  <updated>2017-04-02T16:04:03.246Z</updated>
  <id>http://jishusuishouji.github.io/</id>
  
  <author>
    <name>技术随手记</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>全面剖析Redis Cluster原理和应用</title>
    <link href="http://jishusuishouji.github.io/2017/04/02/redis/%E5%85%A8%E9%9D%A2%E5%89%96%E6%9E%90Redis_Cluster%E5%8E%9F%E7%90%86%E5%92%8C%E5%BA%94%E7%94%A8/"/>
    <id>http://jishusuishouji.github.io/2017/04/02/redis/全面剖析Redis_Cluster原理和应用/</id>
    <published>2017-04-02T15:57:30.000Z</published>
    <updated>2017-04-02T16:04:03.246Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Redis-Cluster总览"><a href="#1-Redis-Cluster总览" class="headerlink" title="1.Redis Cluster总览"></a>1.Redis Cluster总览</h2><h3 id="1-1-设计原则和初衷"><a href="#1-1-设计原则和初衷" class="headerlink" title="1.1 设计原则和初衷"></a>1.1 设计原则和初衷</h3><p>在官方文档ClusterSpec中，作者详细介绍了Redis集群为什么要设计成现在的样子。最核心的目标有三个：</p>
<ul>
<li>性能：这是Redis赖以生存的看家本领，增加集群功能后当然不能对性能产生太大影响，所以Redis采取了P2P而非Proxy方式、异步复制、客户端重定向等设计，而牺牲了部分的一致性、使用性。</li>
<li>水平扩展：集群的最重要能力当然是扩展，文档中称可以线性扩展到1000结点。</li>
<li>可用性：在Cluster推出之前，可用性要靠Sentinel保证。有了集群之后也自动具有了Sentinel的监控和自动Failover能力。</li>
</ul>
<h3 id="1-2-架构变化与CAP理论"><a href="#1-2-架构变化与CAP理论" class="headerlink" title="1.2 架构变化与CAP理论"></a>1.2 架构变化与CAP理论</h3><p>Redis Cluster集群功能推出已经有一段时间了。在单机版的Redis中，每个Master之间是没有任何通信的，所以我们一般在Jedis客户端或者Codis这样的代理中做Pre-sharding。按照CAP理论来说，单机版的Redis属于保证CP(Consistency &amp; Partition-Tolerancy)而牺牲A(Availability)，也就说Redis能够保证所有用户看到相同的数据（一致性，因为Redis不自动冗余数据）和网络通信出问题时，暂时隔离开的子系统能继续运行（分区容忍性，因为Master之间没有直接关系，不需要通信），但是不保证某些结点故障时，所有请求都能被响应（可用性，某个Master结点挂了的话，那么它上面分片的数据就无法访问了）。</p>
<p>有了Cluster功能后，Redis从一个单纯的NoSQL内存数据库变成了分布式NoSQL数据库，CAP模型也从CP变成了AP。也就是说，通过自动分片和冗余数据，Redis具有了真正的分布式能力，某个结点挂了的话，因为数据在其他结点上有备份，所以其他结点顶上来就可以继续提供服务，保证了Availability。然而，也正因为这一点，Redis无法保证曾经的强一致性了。这也是CAP理论要求的，三者只能取其二。</p>
<p>简单分析了Redis在架构上的变化后，咱们就一起来体验一下Redis Cluster功能吧！</p>
<p>2.Redis集群初探</p>
<p>Redis的安装很简单，以前已经介绍过，就不详细说了。关于Redis Cluster的基础知识之前也有过整理，请参考《Redis集群功能预览》。如果需要全面的了解，那一定要看官方文档Cluster Tutorial，只看这一个就够了！</p>
<p>2.1 集群配置</p>
<p>要想开启Redis Cluster模式，有几项配置是必须的。此外为了方便使用和后续的测试，我还额外做了一些配置：</p>
<p>绑定地址：bind 192.168.XXX.XXX。不能绑定到127.0.0.1或localhost，否则指导客户端重定向时会报”Connection refused”的错误。<br>开启Cluster：cluster-enabled yes<br>集群配置文件：cluster-config-file nodes-7000.conf。这个配置文件不是要我们去配的，而是Redis运行时保存配置的文件，所以我们也不可以修改这个文件。<br>集群超时时间：cluster-node-timeout 15000。结点超时多久则认为它宕机了。<br>槽是否全覆盖：cluster-require-full-coverage no。默认是yes，只要有结点宕机导致16384个槽没全被覆盖，整个集群就全部停止服务，所以一定要改为no<br>后台运行：daemonize yes<br>输出日志：logfile “./redis.log”<br>监听端口：port 7000<br>配置好后，根据我们的集群规模，拷贝出来几份同样的配置文件，唯一不同的就是监听端口，可以依次改为7001、7002… 因为Redis Cluster如果数据冗余是1的话，至少要3个Master和3个Slave，所以我们拷贝出6个实例的配置文件。为了避免相互影响，为6个实例的配置文件建立独立的文件夹。</p>
<p>[root@8gVm redis-3.0.4]# pwd<br>/root/Software/redis-3.0.4<br>[root@8gVm redis-3.0.4]# tree -I “<em>log|nodes</em>“ cfg-cluster/<br>cfg-cluster/<br>├── 7000<br>│   └── redis.conf.7000<br>├── 7001<br>│   └── redis.conf.7001<br>├── 7002<br>│   └── redis.conf.7002<br>├── 7003<br>│   └── redis.conf.7003<br>├── 7004<br>│   └── redis.conf.7004<br>└── 7005<br>    └── redis.conf.7005</p>
<p>6 directories, 6 files<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>2.2 redis-trib管理器</p>
<p>Redis作者应该是个Ruby爱好者，Ruby客户端就是他开发的。这次集群的管理功能没有嵌入到Redis代码中，于是作者又顺手写了个叫做redis-trib的管理脚本。redis-trib依赖Ruby和RubyGems，以及redis扩展。可以先用which命令查看是否已安装ruby和rubygems，用gem list –local查看本地是否已安装redis扩展。</p>
<p>最简便的方法就是用apt或yum包管理器安装RubyGems后执行gem install redis。如果网络或环境受限的话，可以手动安装RubyGems和redis扩展（国外链接可能无法下载，可以从CSDN下载）：</p>
<p>[root@8gVm Software]# wget <a href="https://github.com/rubygems/rubygems/releases/download/v2.2.3/rubygems-2.2.3.tgz" target="_blank" rel="external">https://github.com/rubygems/rubygems/releases/download/v2.2.3/rubygems-2.2.3.tgz</a><br>[root@8gVm Software]# tar xzvf rubygems-2.2.3.tgz<br>[root@8gVm Software]# cd rubygems-2.2.3<br>[root@8gVm rubygems-2.2.3]# ruby setup.rb –no-rdoc –no-ri</p>
<p>[root@8gVm Software]# wget <a href="https://rubygems.org/downloads/redis-3.2.1.gem" target="_blank" rel="external">https://rubygems.org/downloads/redis-3.2.1.gem</a><br>[root@8gVm Software]# gem install redis-3.2.1.gem –local –no-rdoc –no-ri<br>Successfully installed redis-3.2.1<br>1 gem installed<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>2.3 集群建立</p>
<p>首先，启动我们配置好的6个Redis实例。</p>
<p>[root@8gVm redis-3.0.4]# for ((i=0; i&lt;6; ++i))</p>
<blockquote>
<p>do<br>cd cfg-cluster/700$i &amp;&amp; ../../src/redis-server redis.conf.700$i &amp;&amp; cd -<br>done<br>1<br>2<br>3<br>4<br>1<br>2<br>3<br>4<br>此时6个实例还没有形成集群，现在用redis-trb.rb管理脚本建立起集群。可以看到，redis-trib默认用前3个实例作为Master，后3个作为Slave。因为Redis基于Master-Slave做数据备份，而非像Cassandra或Hazelcast一样不区分结点角色，自动复制并分配Slot的位置到各个结点。</p>
</blockquote>
<p>[root@8gVm redis-3.0.4]# src/redis-trib.rb create –replicas 1 192.168.1.100:7000 192.168.1.100:7001 192.168.1.100:7002 192.168.1.100:7003 192.168.1.100:7004 192.168.1.100:7005</p>
<blockquote>
<blockquote>
<blockquote>
<p>Creating cluster<br>Connecting to node 192.168.1.100:7000: OK<br>Connecting to node 192.168.1.100:7001: OK<br>Connecting to node 192.168.1.100:7002: OK<br>Connecting to node 192.168.1.100:7003: OK<br>Connecting to node 192.168.1.100:7004: OK<br>Connecting to node 192.168.1.100:7005: OK<br>Performing hash slots allocation on 6 nodes…<br>Using 3 masters:<br>192.168.1.100:7000<br>192.168.1.100:7001<br>192.168.1.100:7002<br>Adding replica 192.168.1.100:7003 to 192.168.1.100:7000<br>Adding replica 192.168.1.100:7004 to 192.168.1.100:7001<br>Adding replica 192.168.1.100:7005 to 192.168.1.100:7002<br>    …<br>Can I set the above configuration? (type ‘yes’ to accept): yes<br>Nodes configuration updated<br>Assign a different config epoch to each node<br>Sending CLUSTER MEET messages to join the cluster<br>Waiting for the cluster to join….<br>Performing Cluster Check (using node 192.168.1.100:7000)<br>    …<br>[OK] All nodes agree about slots configuration.<br>Check for open slots…<br>Check slots coverage…<br>[OK] All 16384 slots covered.<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>至此，集群就已经建立成功了！“贴心”的Redis还在utils/create-cluster下提供了一个create-cluster脚本，能够创建出一个集群，类似我们上面建立起的3主3从的集群。</p>
</blockquote>
</blockquote>
</blockquote>
<p>2.4 简单测试</p>
<p>我们连接到集群中的任意一个结点，启动redis-cli时要加-c选项，存取两个Key-Value感受一下Redis久违的集群功能。</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000<br>192.168.1.100:7000&gt; set foo bar<br>-&gt; Redirected to slot [12182] located at 192.168.1.100:7002<br>OK<br>192.168.1.100:7002&gt; set hello world<br>-&gt; Redirected to slot [866] located at 192.168.1.100:7000<br>OK<br>192.168.1.100:7000&gt; get foo<br>-&gt; Redirected to slot [12182] located at 192.168.1.100:7002<br>“bar”<br>192.168.1.100:7002&gt; get hello<br>-&gt; Redirected to slot [866] located at 192.168.1.100:7000<br>“world”<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>仔细观察能够注意到，redis-cli根据指示，不断在7000和7002结点之前重定向跳转。如果启动时不加-c选项的话，就能看到以错误形式显示出的MOVED重定向消息。</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -h 192.168.1.100 -p 7000<br>192.168.1.100:7000&gt; get foo<br>(error) MOVED 12182 192.168.1.100:7002<br>1<br>2<br>3<br>1<br>2<br>3<br>2.5 集群重启</p>
<p>目前redis-trib的功能还比较弱，需要重启集群的话先手动kill掉各个进程，然后重新启动就可以了。这也有点太… 网上有人重启后会碰到问题，我还比较幸运，这种“土鳖”的方式重启试了两次还没发现问题。</p>
<p>[root@8gVm redis-3.0.4]# ps -ef | grep redis | awk ‘{print $2}’ | xargs kill<br>1<br>1<br>3.高级功能尝鲜</p>
<p>说是“高级功能”，其实在其他分布式系统中早就都有实现了，只不过在Redis世界里是比较新鲜的。本部分主要试验一下Redis Cluster中的数据迁移(Resharding)和故障转移功能。</p>
<p>3.1 数据迁移</p>
<p>本小节我们体验一下Redis集群的Resharding功能！</p>
<p>3.1.1 创建测试数据</p>
<p>首先保存foo1~10共10个Key-Value作为测试数据。</p>
<p>[root@8gVm redis-3.0.4]# for ((i=0; i&lt;10; ++i))</p>
<blockquote>
<p>do<br>src/redis-cli -c -h 192.168.1.100 -p 7000 set foo$i bar<br>done</p>
</blockquote>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000<br>192.168.1.100:7000&gt; keys <em><br>1) “foo6”<br>2) “foo7”<br>3) “foo3”<br>4) “foo2”<br>192.168.1.100:7000&gt; get foo4<br>-&gt; Redirected to slot [9426] located at 192.168.1.100:7001<br>“bar”<br>192.168.1.100:7001&gt; keys </em><br>1) “foo4”<br>2) “foo8”<br>192.168.1.100:7001&gt; get foo5<br>-&gt; Redirected to slot [13555] located at 192.168.1.100:7002<br>“bar”<br>192.168.1.100:7002&gt; keys *<br>1) “foo5”<br>2) “foo1”<br>3) “foo10”<br>4) “foo9”<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>3.1.2 启动新结点</p>
<p>参照之前的方法新拷贝出两份redis.conf配置文件redis.conf.7010和7011，与之前结点的配置文件做一下区分。启动新的两个Redis实例之后，通过redis-trib.rb脚本添加新的Master和Slave到集群中。</p>
<p>[root@8gVm redis-3.0.4]# cd cfg-cluster/7010 &amp;&amp; ../../src/redis-server redis.conf.7010 &amp;&amp; cd -<br>[root@8gVm redis-3.0.4]# cd cfg-cluster/7011 &amp;&amp; ../../src/redis-server redis.conf.7011 &amp;&amp; cd -<br>1<br>2<br>1<br>2<br>3.1.3 添加到集群</p>
<p>使用redis-trib.rb add-node分别将两个新结点添加到集群中，一个作为Master，一个作为其Slave。</p>
<p>[root@8gVm redis-3.0.4]# src/redis-trib.rb add-node 192.168.1.100:7010 192.168.1.100:7000</p>
<blockquote>
<blockquote>
<blockquote>
<p>Adding node 192.168.1.100:7010 to cluster 192.168.1.100:7000<br>Connecting to node 192.168.1.100:7000: OK<br>Connecting to node 192.168.1.100:7001: OK<br>Connecting to node 192.168.1.100:7002: OK<br>Connecting to node 192.168.1.100:7005: OK<br>Connecting to node 192.168.1.100:7003: OK<br>Connecting to node 192.168.1.100:7004: OK<br>Performing Cluster Check (using node 192.168.1.100:7000)<br>    …<br>[OK] All nodes agree about slots configuration.<br>Check for open slots…<br>Check slots coverage…<br>[OK] All 16384 slots covered.<br>Connecting to node 192.168.1.100:7010: OK<br>Send CLUSTER MEET to node 192.168.1.100:7010 to make it join the cluster.<br>[OK] New node added correctly.</p>
</blockquote>
</blockquote>
</blockquote>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes<br>0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9 192.168.1.100:7010 master - 0 1442452249525 0 connected<br>    …</p>
<p>[root@8gVm redis-3.0.4]# src/redis-trib.rb add-node –slave –master-id 0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9 192.168.1.100:7011 192.168.1.100:7000</p>
<blockquote>
<blockquote>
<blockquote>
<p>Adding node 192.168.1.100:7011 to cluster 192.168.1.100:7000<br>Connecting to node 192.168.1.100:7000: OK<br>Connecting to node 192.168.1.100:7010: OK<br>Connecting to node 192.168.1.100:7001: OK<br>Connecting to node 192.168.1.100:7002: OK<br>Connecting to node 192.168.1.100:7005: OK<br>Connecting to node 192.168.1.100:7003: OK<br>Connecting to node 192.168.1.100:7004: OK<br>Performing Cluster Check (using node 192.168.1.100:7000)<br>    …<br>[OK] All nodes agree about slots configuration.<br>Check for open slots…<br>Check slots coverage…<br>[OK] All 16384 slots covered.<br>Connecting to node 192.168.1.100:7011: OK<br>Send CLUSTER MEET to node 192.168.1.100:7011 to make it join the cluster.<br>Waiting for the cluster to join.<br>Configure node as replica of 192.168.1.100:7010.<br>[OK] New node added correctly.<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>3.1.4 Resharding</p>
</blockquote>
</blockquote>
</blockquote>
<p>通过redis-trib.rb reshard可以交互式地迁移Slot。下面的例子将5000个Slot从7000~7002迁移到7010上。也可以通过./redis-trib.rb reshard <host>:<port> –from <node-id> –to <node-id> –slots –yes在程序中自动完成迁移。</node-id></node-id></port></host></p>
<p>[root@8gVm redis-3.0.4]# src/redis-trib.rb reshard 192.168.1.100:7000<br>Connecting to node 192.168.1.100:7000: OK<br>Connecting to node 192.168.1.100:7010: OK<br>Connecting to node 192.168.1.100:7001: OK<br>Connecting to node 192.168.1.100:7002: OK<br>Connecting to node 192.168.1.100:7005: OK<br>Connecting to node 192.168.1.100:7011: OK<br>Connecting to node 192.168.1.100:7003: OK<br>Connecting to node 192.168.1.100:7004: OK</p>
<blockquote>
<blockquote>
<blockquote>
<p>Performing Cluster Check (using node 192.168.1.100:7000)<br>M: b2036adda128b2eeffa36c3a2056444d23b548a8 192.168.1.100:7000<br>   slots:0-5460 (4128 slots) master<br>   1 additional replica(s)<br>M: 0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9 192.168.1.100:7010<br>   slots:0 (4000 slots) master<br>   1 additional replica(s)<br>   …<br>[OK] All nodes agree about slots configuration.<br>Check for open slots…<br>Check slots coverage…<br>[OK] All 16384 slots covered.<br>How many slots do you want to move (from 1 to 16384)? 5000<br>What is the receiving node ID? 0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9<br>Please enter all the source node IDs.<br>  Type ‘all’ to use all the nodes as source nodes for the hash slots.<br>  Type ‘done’ once you entered all the source nodes IDs.<br>Source node #1:all</p>
</blockquote>
</blockquote>
</blockquote>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes<br>0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9 192.168.1.100:7010 master - 0 1442455872019 7 connected 0-1332 5461-6794 10923-12255<br>b2036adda128b2eeffa36c3a2056444d23b548a8 192.168.1.100:7000 myself,master - 0 0 1 connected 1333-5460<br>b5ab302f5c2395e3c8194c354a85d02f89bace62 192.168.1.100:7001 master - 0 1442455875022 2 connected 6795-10922<br>0c565e207ce3118470fd5ed3c806eb78f1fdfc01 192.168.1.100:7002 master - 0 1442455874521 3 connected 12256-16383<br>    …<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>迁移完成后，查看之前保存的foo1~10的分布情况，可以看到部分Key已经迁移到了新的结点7010上。</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 keys “<em>“<br>1) “foo3”<br>2) “foo7”<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7001 keys “</em>“<br>1) “foo4”<br>2) “foo8”<br>3) “foo0”<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7002 keys “<em>“<br>1) “foo1”<br>2) “foo9”<br>3) “foo5”<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7010 keys “</em>“<br>1) “foo6”<br>2) “foo2”<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>3.2 故障转移</p>
<p>在高可用性方面，Redis可算是能够”Auto”一把了！Redis Cluster重用了Sentinel的代码逻辑，不需要单独启动一个Sentinel集群，Redis Cluster本身就能自动进行Master选举和Failover切换。</p>
<p>下面我们故意kill掉7010结点，之后可以看到结点状态变成了fail，而Slave 7011被选举为新的Master。</p>
<p>[root@8gVm redis-3.0.4]# kill 43637</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes<br>0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9 192.168.1.100:7010 master,fail - 1442456829380 1442456825674 7 disconnected<br>b2036adda128b2eeffa36c3a2056444d23b548a8 192.168.1.100:7000 myself,master - 0 0 1 connected 1333-5460<br>b5ab302f5c2395e3c8194c354a85d02f89bace62 192.168.1.100:7001 master - 0 1442456848722 2 connected 6795-10922<br>0c565e207ce3118470fd5ed3c806eb78f1fdfc01 192.168.1.100:7002 master - 0 1442456846717 3 connected 12256-16383<br>5a3c67248b1df554fbf2c93112ba429f31b1d3d1 192.168.1.100:7005 slave 0c565e207ce3118470fd5ed3c806eb78f1fdfc01 0 1442456847720 6 connected<br>99bff22b97119cf158d225c2b450732a1c0d3c44 192.168.1.100:7011 master - 0 1442456849725 8 connected 0-1332 5461-6794 10923-12255<br>cd305d509c34842a8047e19239b64df94c13cb96 192.168.1.100:7003 slave b2036adda128b2eeffa36c3a2056444d23b548a8 0 1442456848220 4 connected<br>64b544cdd75c1ce395fb9d0af024b7f2b77213a3 192.168.1.100:7004 slave b5ab302f5c2395e3c8194c354a85d02f89bace62 0 1442456845715 5 connected<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>尝试查询之前保存在7010上的Key，可以看到7011顶替上来继续提供服务，整个集群没有受到影响。</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 get foo6<br>“bar”<br>[root@8gVm redis-3.0.4]#<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 get foo2<br>“bar”<br>1<br>2<br>3<br>4<br>5<br>1<br>2<br>3<br>4<br>5<br>4.内部原理剖析</p>
<p>前面我们已经学习过，用Redis提供的redis-trib或create-cluster脚本能几步甚至一步就建立起一个Redis集群。这一部分我们为了深入学习，所以要暂时抛开这些方便的工具，完全手动建立一遍上面的3主3从集群。</p>
<p>4.1 集群发现：MEET</p>
<p>最开始时，每个Redis实例自己是一个集群，我们通过cluster meet让各个结点互相“握手”。这也是Redis Cluster目前的一个欠缺之处：缺少结点的自动发现功能。</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes<br>33c0bd93d7c7403ef0239ff01eb79bfa15d2a32c :7000 myself,master - 0 0 0 connected</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster meet 192.168.1.100 7001<br>OK<br>    …<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster meet 192.168.1.100 7005<br>OK</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes<br>7b953ec26bbdbf67179e5d37e3cf91626774e96f 192.168.1.100:7003 master - 0 1442466369259 4 connected<br>5d9f14cec1f731b6477c1e1055cecd6eff3812d4 192.168.1.100:7005 master - 0 1442466368659 4 connected<br>33c0bd93d7c7403ef0239ff01eb79bfa15d2a32c 192.168.1.100:7000 myself,master - 0 0 1 connected<br>63162ed000db9d5309e622ec319a1dcb29a3304e 192.168.1.100:7001 master - 0 1442466371262 3 connected<br>45baa2cb45435398ba5d559cdb574cfae4083893 192.168.1.100:7002 master - 0 1442466372264 2 connected<br>cdd5b3a244761023f653e08cb14721f70c399b82 192.168.1.100:7004 master - 0 1442466370261 0 connecte<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>4.2 角色设置：REPLICATE</p>
<p>结点全部“握手”成功后，就可以用cluster replicate命令为结点指定角色了，默认每个结点都是Master。</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7003 cluster replicate 33c0bd93d7c7403ef0239ff01eb79bfa15d2a32c<br>OK<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7004 cluster replicate 63162ed000db9d5309e622ec319a1dcb29a3304e<br>OK<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7005 cluster replicate 45baa2cb45435398ba5d559cdb574cfae4083893<br>OK</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes<br>7b953ec26bbdbf67179e5d37e3cf91626774e96f 192.168.1.100:7003 slave 33c0bd93d7c7403ef0239ff01eb79bfa15d2a32c 0 1442466812984 4 connected<br>5d9f14cec1f731b6477c1e1055cecd6eff3812d4 192.168.1.100:7005 slave 45baa2cb45435398ba5d559cdb574cfae4083893 0 1442466813986 5 connected<br>33c0bd93d7c7403ef0239ff01eb79bfa15d2a32c 192.168.1.100:7000 myself,master - 0 0 1 connected<br>63162ed000db9d5309e622ec319a1dcb29a3304e 192.168.1.100:7001 master - 0 1442466814987 3 connected<br>45baa2cb45435398ba5d559cdb574cfae4083893 192.168.1.100:7002 master - 0 1442466811982 2 connected<br>cdd5b3a244761023f653e08cb14721f70c399b82 192.168.1.100:7004 slave 63162ed000db9d5309e622ec319a1dcb29a3304e 0 1442466812483 3 connected<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>4.3 槽指派：ADDSLOTS</p>
<p>设置好主从关系之后，就可以用cluster addslots命令指派16384个槽的位置了。有点恶心的是，ADDSLOTS命令需要在参数中一个个指明槽的ID，而不能指定范围。这里用Bash 3.0的特性简化了，不然就得用Bash的循环来完成了：</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster addslots {0..5000}<br>OK<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7001 cluster addslots {5001..10000}<br>OK<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7001 cluster addslots {10001..16383}<br>OK</p>
<p>[root@8gVm redis-3.0.4]# src/redis-trib.rb check 192.168.1.100:7000<br>Connecting to node 192.168.1.100:7000: OK<br>  …</p>
<blockquote>
<blockquote>
<blockquote>
<p>Performing Cluster Check (using node 192.168.1.100:7000)<br>  …<br>[OK] All nodes agree about slots configuration.<br>Check for open slots…<br>Check slots coverage…<br>[OK] All 16384 slots covered.<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>这样我们就通过手动执行命令得到了与之前一样的集群。</p>
</blockquote>
</blockquote>
</blockquote>
<p>4.4 数据迁移：MIGRATE</p>
<p>真正开始Resharding之前，redis-trib会先在源结点和目的结点上执行cluster setslot <slot> importing和cluster setslot <slot> migrating命令，将要迁移的槽分别标记为迁出中和导入中的状态。然后，执行cluster getkeysinslot获得Slot中的所有Key。最后就可以对每个Key执行migrate命令进行迁移了。槽迁移完成后，执行cluster setslot命令通知整个集群槽的指派已经发生变化。</slot></slot></p>
<p>关于迁移过程中的数据访问，客户端访问源结点时，如果Key还在源结点上就直接操作。如果已经不在源结点了，就向客户端返回一个ASK错误，将客户端重定向到目的结点。</p>
<p>4.5 内部数据结构</p>
<p>Redis Cluster功能涉及三个核心的数据结构clusterState、clusterNode、clusterLink都在cluster.h中定义。这三个数据结构中最重要的属性就是：clusterState.slots、clusterState.slots_to_keys和clusterNode.slots了，它们保存了三种映射关系：</p>
<p>clusterState：集群状态<br>nodes：所有结点<br>migrating_slots_to：迁出中的槽<br>importing_slots_from：导入中的槽<br>slots_to_keys：槽中包含的所有Key，用于迁移Slot时获得其包含的Key<br>slots：Slot所属的结点，用于处理请求时判断Key所在Slot是否自己负责<br>clusterNode：结点信息<br>slots：结点负责的所有Slot，用于发送Gossip消息通知其他结点自己负责的Slot。通过位图方式保存节省空间，16384/8恰好是2048字节，所以槽总数16384不是随意定的。<br>clusterLink：与其他结点通信的连接<br>// 集群状态，每个节点都保存着一个这样的状态，记录了它们眼中的集群的样子。<br>// 另外，虽然这个结构主要用于记录集群的属性，但是为了节约资源，<br>// 有些与节点有关的属性，比如 slots_to_keys 、 failover_auth_count<br>// 也被放到了这个结构里面。<br>typedef struct clusterState {<br>    …<br>    // 指向当前节点的指针<br>    clusterNode <em>myself;  /</em> This node */</p>
<pre><code>// 集群当前的状态：是在线还是下线
int state;            /* REDIS_CLUSTER_OK, REDIS_CLUSTER_FAIL, ... */

// 集群节点名单（包括 myself 节点）
// 字典的键为节点的名字，字典的值为 clusterNode 结构
dict *nodes;          /* Hash table of name -&gt; clusterNode structures */

// 记录要从当前节点迁移到目标节点的槽，以及迁移的目标节点
// migrating_slots_to[i] = NULL 表示槽 i 未被迁移
// migrating_slots_to[i] = clusterNode_A 表示槽 i 要从本节点迁移至节点 A
clusterNode *migrating_slots_to[REDIS_CLUSTER_SLOTS];

// 记录要从源节点迁移到本节点的槽，以及进行迁移的源节点
// importing_slots_from[i] = NULL 表示槽 i 未进行导入
// importing_slots_from[i] = clusterNode_A 表示正从节点 A 中导入槽 i
clusterNode *importing_slots_from[REDIS_CLUSTER_SLOTS];

// 负责处理各个槽的节点
// 例如 slots[i] = clusterNode_A 表示槽 i 由节点 A 处理
clusterNode *slots[REDIS_CLUSTER_SLOTS];

// 跳跃表，表中以槽作为分值，键作为成员，对槽进行有序排序
// 当需要对某些槽进行区间（range）操作时，这个跳跃表可以提供方便
// 具体操作定义在 db.c 里面
zskiplist *slots_to_keys;
...
</code></pre><p>} clusterState;</p>
<p>// 节点状态<br>struct clusterNode {<br>    …<br>    // 节点标识<br>    // 使用各种不同的标识值记录节点的角色（比如主节点或者从节点），<br>    // 以及节点目前所处的状态（比如在线或者下线）。<br>    int flags;      /<em> REDIS<em>NODE</em>… </em>/</p>
<pre><code>// 由这个节点负责处理的槽
// 一共有 REDIS_CLUSTER_SLOTS / 8 个字节长
// 每个字节的每个位记录了一个槽的保存状态
// 位的值为 1 表示槽正由本节点处理，值为 0 则表示槽并非本节点处理
// 比如 slots[0] 的第一个位保存了槽 0 的保存情况
// slots[0] 的第二个位保存了槽 1 的保存情况，以此类推
unsigned char slots[REDIS_CLUSTER_SLOTS/8]; /* slots handled by this node */

// 指针数组，指向各个从节点
struct clusterNode **slaves; /* pointers to slave nodes */

// 如果这是一个从节点，那么指向主节点
struct clusterNode *slaveof; /* pointer to the master node */
...
</code></pre><p>};</p>
<p>/<em> clusterLink encapsulates everything needed to talk with a remote node. </em>/<br>// clusterLink 包含了与其他节点进行通讯所需的全部信息<br>typedef struct clusterLink {<br>    …<br>    // TCP 套接字描述符<br>    int fd;                     /<em> TCP socket file descriptor </em>/</p>
<pre><code>// 与这个连接相关联的节点，如果没有的话就为 NULL
struct clusterNode *node;   /* Node related to this link if any, or NULL */
...
</code></pre><p>} clusterLink;<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58<br>59<br>60<br>61<br>62<br>63<br>64<br>65<br>66<br>67<br>68<br>69<br>70<br>71<br>72<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58<br>59<br>60<br>61<br>62<br>63<br>64<br>65<br>66<br>67<br>68<br>69<br>70<br>71<br>72<br>4.6 处理流程全梳理</p>
<p>在单机模式下，Redis对请求的处理很简单。Key存在的话，就执行请求中的操作；Key不存在的话，就告诉客户端Key不存在。然而在集群模式下，因为涉及到请求重定向和Slot迁移，所以对请求的处理变得很复杂，流程如下：</p>
<p>检查Key所在Slot是否属于当前Node？<br>2.1 计算crc16(key) % 16384得到Slot<br>2.2 查询clusterState.slots负责Slot的结点指针<br>2.3 与myself指针比较<br>若不属于，则响应MOVED错误重定向客户端<br>若属于且Key存在，则直接操作，返回结果给客户端<br>若Key不存在，检查该Slot是否迁出中？(clusterState.migrating_slots_to)<br>若Slot迁出中，返回ASK错误重定向客户端到迁移的目的服务器上<br>若Slot未迁出，检查Slot是否导入中？(clusterState.importing_slots_from)<br>若Slot导入中且有ASKING标记，则直接操作<br>否则响应MOVED错误重定向客户端<br>5.应用案例收集</p>
<p>5.1 有道：Redis Cluster使用经验</p>
<p>详情请参见原文，关键内容摘录如下：</p>
<p>5.1.1 两个缺点</p>
<p>“redis cluster的设计在这块有点奇葩，跟集群相关的操作需要一个外部的ruby脚本来协助（当然可能是为了让主程序的代码足够简洁？），然后那个脚本还只支持填实例的ip不支持host，还不告诉你不支持让你用host之后各种莫名其妙。”</p>
<p>“第一个缺点就是严格依赖客户端driver的成熟度。如果把redis cluster设计成类似Cassandra，请求集群中任何一个节点都可以负责转发请求，client会好写一些。”</p>
<p>“第二个缺点完全是设计问题了，就是一个redis进程既负责读写数据又负责集群交互，虽然设计者已经尽可能简化了代码和逻辑，但还是让redis从一个内存NoSQL变成了一个分布式NoSQL。分布式系统很容易有坑，一旦有坑必须升级redis。”</p>
<p>5.1.2 去中心化 vs. Proxy</p>
<p>“关于redis cluster的设计，Gossip/P2P的去中心化架构本身不是问题，但一旦有了中心节点，能做的事情就多了，比如sharding不均匀是很容易自动rebalance的，而无中心的只能靠外界来搞。然后redis cluster又是slot的形式而非C*式的一致性哈希，新节点分slot又不自动，依赖外界（ruby脚本）来分配显得不方便更不优美和谐。而且因为是master-slave的系统而非W+R&gt;N的那种，master挂掉之后尽快发现是比较重要的，gossip对于节点挂掉的发现终究没有中心节点/zookeeper方便快速。”</p>
<p>“基于proxy做转发意味着屏蔽了下层存储，完全可以根据前缀/tag/冷热程度，来把部分甚至大多数数据放在磁盘从而节约成本又保证一致性，这都是有中心节点所带来的好处。”</p>
<p>5.2 奇虎360：Redis Cluster浅析和Bada对比</p>
<p>详情请参见原文，关键内容摘录如下：</p>
<p>5.2.1 负载均衡问题</p>
<p>“redis cluster的主备是以节点为单位，而bada则是以partition为单位，这样，同样是3个节点，1024个partition的情况下，redis cluster的主节点负责整个1024个partition的服务，而两个从节点则只负责异步备份，导致集群负载不均，再看bada，将1024个partition的主均分到3个节点中，每个节点各有主备，主对外提供服务，这样均分了访问压力，有效的利用了资源。”</p>
<p>5.2.2 一致性的保证</p>
<p>“redis cluster与bada一样，最终一致性，读写都只请求主节点，当一条写请求在对应的主节点写成功后，会立刻返回给客户端成功，然后主节点通过异步的方式将新的数据同步到对应的从节点，这样的方式减少了客户端多个节点写成功等待的时间，不过在某些情况下会造成写丢失：</p>
<p>1）当主节点接受一条写请求，写入并返回给客户端成功后不幸宕掉，此时刚才的写还未同步给其对应的从节点，而从节点在发现主节点挂掉并重新选主后，新的主节点则永久丢失了之前老的主节点向用户确认的写</p>
<p>2）当网络发生割裂，将集群分裂成少数派与多数派，这样在客户端不知情的情况下，会将写继续写入到少数派中的某些主节点中，而当割裂超过一定时长后，集群感知到异常，此时少数派中的所有主节点会停止响应所有的写请求，多数派的其对应的从节点则会发起选举成为新的主节点，假设过了一会后割裂恢复，老的主节点发现有更新的主存在，自动变成其从节点，而新的主节点中则会永久丢失掉网络割裂至集群感知异常进行切主这个阶段老主节点确认的所有写</p>
<p>相对于redis cluster的永久丢失，bada通过binlog merge有效的解决了这一问题。所有partition的主节点在响应客户端的写请求时，都会在本地记录binlog，binlog实质就是带有时间戳的KV对。当老主以从节点的身份重新加入集群时，会触发binlog merge操作，新主会比较并且合并二者的binlog，这样就可以将之前丢失掉得写再补回来。”</p>
<p>5.2.3 请求重定向问题</p>
<p>“bada服务端节点在收到本不该由自己负责的Partition请求后，不会向客户端返回重定向信息，而是通过代理的方式，直接在集群内部向正确节点转发客户端的请求，并将结果同meta信息再转发回客户端。”</p>
<p>“再看multi key操作，redis cluster为了追求高性能，支持multi key的前提是所有的key必须在同一个节点中, 不过这样的处理需要交给用户，对需要进行multi key操作的所有key，在写入前人为的加上hash tags。当redis cluster进行resharding的时候，也就是将某些slot从一个节点迁移到另一个节点时，此时的multi key操作可能会失败，因为在迁移的slot中的key此时存在于两个节点。</p>
<p>bada怎么做呢？用户如果对multi key操作性能很在乎时，可以采用与redis cluster同样的方式，给这些key加上hash tags来让它们落在同一个节点，如果可以接受性能的稍微损耗而解放用户的处理逻辑，则可以像single key操作一样，请求任一bada节点，它会代理所有的key请求并将结果返回给用户。并且在multi key操作在任何时候都可以，即使在进行partition的迁移，bada也会提前进行切主，保证服务的正常提供。”</p>
<p>5.3 芒果TV：Redis服务解决方案</p>
<p>详情请参见原文，关键内容摘录如下：</p>
<p>芒果TV在Redis Cluster基础上进行开发，主要增加了两个组件：</p>
<p>监控管理：以Python为主要开发框架的Web应用程序Redis-ctl<br>请求代理：以C++11为开发语言的轻量数据代理程序cerberus。其作用和优点为：<br>集群代理程序的自动请求分发/重试机制使得应用不必修改自身代码或更新Redis库<br>代理节点为所有Redis节点加上统一管理和状态监测, 可以查阅历史数据, 或在发生任何问题之后快速响应修复<br>代理进程的无状态性使之可在故障后快速恢复, 不影响后端集群数据完整性<br>这两个组件都已开源到GitHub上，大家可以关注一下！</p>
<p>6.Pros &amp; Cons总结</p>
<p>关于Redis Cluster带来的种种优势就不说了，在这里主要是“鸡蛋里挑骨头”，总结一下现阶段集群功能的欠缺之处和可能的“坑”。</p>
<p>6.1 无中心化架构</p>
<p>6.1.1 Gossip消息</p>
<p>Gossip消息的网络开销和时延是决定Redis Cluster能够线性扩展的因素之一。关于这个问题，在《redis cluster百万QPS的挑战》一文中有所提及。</p>
<p>6.1.2 结点粒度备份</p>
<p>此外，Redis Cluster也许是为了简化设计采用了Master-Slave复制的数据备份方案，并没有采取如Cassandra或IMDG等对等分布式系统中常见的Slot粒度（或叫Partition/Bucket等）的自动冗余和指派。</p>
<p>这种设计虽然避免比较复杂的分布式技术，但也带来了一些问题：</p>
<p>Slave完全闲置：即便是读请求也不会被重定向到Slave结点上，Slave属于“冷备”<br>写压力无法分摊：Slave闲置导致的另一个问题就是写压力也都在Master上<br>6.2 客户端的挑战</p>
<p>由于Redis Cluster的设计，客户端要担负起一部分责任：</p>
<p>Cluster协议支持：不管Dummy还是Smart模式，都要具备解析Cluster协议的能力<br>网络开销：Dummy客户端不断重定向的网络开销<br>连接维护：Smart客户端对连接到集群中每个结点Socket的维护<br>缓存路由表：Smart客户端Slot路由表的缓存和更新<br>内存消耗：Smart客户端上述维护的信息都是有内存消耗的<br>MultiOp有限支持：对于MultiOp，由客户端通过KeyTag保证所有Key都在同一Slot。而即便如此，迁移时也会导致MultiOp失败。同理，对Pipeline和Transaction的支持也受限于必须操作同一Slot内的Key。<br>6.3 Redis实现问题</p>
<p>尽管属于无中心化架构一类的分布式系统，但不同产品的细节实现和代码质量还是有不少差异的，就比如Redis Cluster有些地方的设计看起来就有一些“奇葩”和简陋：</p>
<p>不能自动发现：无Auto Discovery功能。集群建立时以及运行中新增结点时，都要通过手动执行MEET命令或redis-trib.rb脚本添加到集群中<br>不能自动Resharding：不仅不自动，连Resharding算法都没有，要自己计算从哪些结点上迁移多少Slot，然后还是得通过redis-trib.rb操作<br>严重依赖外部redis-trib：如上所述，像集群健康状况检查、结点加入、Resharding等等功能全都抽离到一个Ruby脚本中了。还不清楚上面提到的缺失功能未来是要继续加到这个脚本里还是会集成到集群结点中？redis-trib也许要变成Codis中Dashboard的角色<br>无监控管理UI：即便未来加了UI，像迁移进度这种信息在无中心化设计中很难得到<br>只保证最终一致性：写Master成功后立即返回，如需强一致性，自行通过WAIT命令实现。但对于“脑裂”问题，目前Redis没提供网络恢复后的Merge功能，“脑裂”期间的更新可能丢失<br>6.4 性能损耗</p>
<p>由于之前手头没有空闲的物理机资源，所以只在虚拟机上做了简单的单机测试，在单独的一台压力机使用YCSB测试框架向虚拟机产生读写负载。虚拟机的配置为8核Intel Xeon CPU X5650@2.67GHz，16GB内存，分别搭建了4结点的单机版Redis和集群版Redis，测试一下Redis Cluster的性能损耗。由于不是最近做的测试，所以Jedis用的2.6.2版本。注：当然Redis Cluster可以通过多机部署获得水平扩展带来的性能提升，这里只是由于环境有限所以做的简单单机测试。</p>
<p>由于YCSB本身仅支持Redis单机版，所以需要我们自己增加扩展插件，具体方法请参照《YCSB性能测试工具使用》。通过YCSB产生2000w随机数据，Value大约100Byte左右。然后通过YCSB测试Read-Mostly(90% Read)和Read-Write-Mixed(50% Read)两种情况：</p>
<p>数据加载：吞吐量上有约18%的下降。<br>Read-Mostly：吞吐量上有约3.5%~7.9%的下降。<br>Read-Write-Mixed：吞吐量上有约3.3%~5.5%下降。<br>内存占用：Jedis客户端多占用380MB内存。<br>6.5 最后的总结</p>
<p>从现阶段看来，相比Sentinel或Codis等方案，Redis Cluster的优势还真是有限，个人觉得最大的优点有两个：</p>
<p>官方提供的Slot实现而不用像Codis那样去改源码了；<br>不用额外的Sentinel集群或类似的代码实现了。<br>同其他分布式系统，如Cassandra，或内存型的IMDG如Hazelcast和GridGain，除了性能方面外，从功能上Redis Cluster简直被爆得体无完肤… 看看我之前总结过的GridGain介绍《开源IMDG之GridGain》：</p>
<p>结点自动发现和Rebalance<br>分区粒度的备份<br>故障时分区角色自动调整<br>结果聚合（不会重定向客户端）<br>“脑裂”恢复后的Merge（Hazelcast支持多种合并策略）<br>多Primary分区写操作（见Replicated模式）<br>这些都是Redis Cluster没有或者要手动完成的。当然这也不足为奇，因为这与Redis的设计初衷有关，毕竟作者都已经说了，最核心的设计目标就是性能、水平伸缩和可用性。</p>
<p>从Redis Cluster的环境搭建使用到高级功能和内部原理剖析，再到应用案例收集和优缺点的分析罗列，讲了这么多，关于Redis集群到底如何，相信大家根据自己切身和项目的具体情况一定有了自己的结论。不管是评估测试也好，二次开发也好，还是直接上线使用也好，相信随着官方的不断迭代更新和大家的力量，Redis Cluster一定会逐渐完善成熟的！</p>
<p>顶<br>13</p>
<p>踩<br>0</p>
<p>上一篇操作系统内核Hack：(一)实验环境搭建<br>下一篇Redis Cluster架构优化<br>我的同类文章<br>Redis（13）<br>•Redis Cluster架构优化2015-09-25阅读11969<br>•Redis监控工具,命令和调优2015-08-16阅读15729<br>•豌豆夹Redis解决方案Codis安装使用2015-07-25阅读17653<br>•用Netty解析Redis网络协议2015-06-19阅读4886<br>•Redis源码学习：Lua脚本2015-05-22阅读2327<br>•Jedis分片Sentinel连接池实验2015-08-29阅读6353<br>•豌豆夹Redis解决方案Codis源码剖析：Dashboard2015-08-08阅读4675<br>•豌豆夹Redis解决方案Codis源码剖析：Proxy代理2015-07-03阅读8979<br>•Redis源码学习：字符串2015-05-30阅读1772<br>•Redis集群功能预览2015-02-28阅读4059<br>更多文章<br>参考知识库<br>img<br>Python知识库<br>22194关注|1364收录<br>img<br>C++知识库<br>9249关注|1393收录<br>img<br>Redis知识库<br>5139关注|738收录<br>img<br>软件测试知识库<br>4272关注|318收录<br>img<br>MySQL知识库<br>21472关注|1448收录<br>img<br>算法与数据结构知识库<br>15138关注|2320收录<br>img<br>大型网站架构知识库<br>8321关注|708收录<br>猜你在找</p>
]]></content>
    
    <summary type="html">
    
      全面剖析Redis Cluster原理和应用
    
    </summary>
    
      <category term="redis" scheme="http://jishusuishouji.github.io/categories/redis/"/>
    
    
      <category term="redis" scheme="http://jishusuishouji.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>Hibernate缓存 查询缓存</title>
    <link href="http://jishusuishouji.github.io/2017/03/30/hibernate/Hibernate%E7%BC%93%E5%AD%98_%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98/"/>
    <id>http://jishusuishouji.github.io/2017/03/30/hibernate/Hibernate缓存_查询缓存/</id>
    <published>2017-03-30T05:58:14.000Z</published>
    <updated>2017-03-30T05:59:23.196Z</updated>
    
    <content type="html"><![CDATA[<p>网上说<code>query.setCacheable(true)</code>或<code>criteria.setCacheable(true)`` 这两种方式的缓存命中率低，个人认为谈论这个“无卵用”；
我在测试的时候发现，上面的操作会受配置的限制，必须在配置文件中打开</code>hibernate.cache.use_query_cache=true<code>，之后</code>setCacheable`才起作用；</p>
<p>查询缓存可以解决二级缓存的不足；它的作用范围也是<code>SessionFactory</code>；</p>
<p>可以缓存hql语句查询，也可以缓存query和criteria查询；</p>
<p>下面针对query和criteria进行测试：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">/**</div><div class="line"> * 对查询缓存测试 &lt;br&gt;</div><div class="line"> * 1. 只有B处起作用，作用于session; &lt;br&gt;</div><div class="line"> * 2. 配置文件中打开query_cache的前提下，setCacheable 是起作用的</div><div class="line"> */</div><div class="line">@Test</div><div class="line">public void testCriteriaInCache() &#123;</div><div class="line"> System.out.println(&quot;=============&quot;);</div><div class="line"> Session session = hibernateTemplate.getSessionFactory().openSession();</div><div class="line"> Criteria criteria = session.createCriteria(UserModel.class);</div><div class="line"> criteria.setCacheable(true); // 这里仅对B处起作用</div><div class="line"> criteria.add(Restrictions.eq(&quot;name&quot;, &quot;Sucre&quot;));</div><div class="line"> System.out.println(&quot;=============A&quot; + criteria.list());</div><div class="line"> System.out.println(&quot;=============B&quot; + criteria.list()); // B</div><div class="line"> criteria.add(Restrictions.eq(&quot;id&quot;, 1));</div><div class="line"> System.out.println(&quot;=============C&quot; + criteria.list());</div><div class="line"> criteria = session.createCriteria(UserModel.class);</div><div class="line"> criteria.setCacheable(true);</div><div class="line"> criteria.add(Restrictions.eq(&quot;id&quot;, 1));</div><div class="line"> System.out.println(&quot;=============D&quot; + criteria.list());</div><div class="line"> session = hibernateTemplate.getSessionFactory().openSession();</div><div class="line"> criteria = session.createCriteria(UserModel.class);</div><div class="line"> criteria.setCacheable(true);</div><div class="line"> criteria.add(Restrictions.eq(&quot;id&quot;, 1));</div><div class="line"> System.out.println(&quot;=============E&quot; + criteria.list());</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">/**</div><div class="line"> * 测试查询缓存 &lt;br&gt;</div><div class="line"> * 1. BC两处都是使用的A产生的缓存，作用于SessionFactory &lt;br&gt;</div><div class="line"> * 2. 配置文件中打开query_cache的前提下，setCacheable 是起作用的</div><div class="line"> */</div><div class="line">@Test</div><div class="line">public void testQueryInCache() &#123;</div><div class="line"> System.out.println(&quot;=============&quot;);</div><div class="line"> Session session = hibernateTemplate.getSessionFactory().openSession();</div><div class="line"> Query query = session</div><div class="line">   .createQuery(&quot;select u.name from UserModel as u where u.id=?&quot;);</div><div class="line"> query.setParameter(0, 1);</div><div class="line"> query.setCacheable(true);</div><div class="line"> String name = (String) query.list().get(0);</div><div class="line"> System.out.println(&quot;=============A&quot; + name); // A</div><div class="line"> query = session</div><div class="line">   .createQuery(&quot;select u.name from UserModel as u where u.id=?&quot;);</div><div class="line"> query.setParameter(0, 1);</div><div class="line"> query.setCacheable(true);</div><div class="line"> name = (String) query.list().get(0);</div><div class="line"> System.out.println(&quot;=============B&quot; + name); // B</div><div class="line"> session = hibernateTemplate.getSessionFactory().openSession();</div><div class="line"> query = session</div><div class="line">   .createQuery(&quot;select u.name from UserModel as u where u.id=?&quot;);</div><div class="line"> query.setParameter(0, 1);</div><div class="line"> query.setCacheable(true);</div><div class="line"> name = (String) query.list().get(0);</div><div class="line"> System.out.println(&quot;=============C&quot; + name); // C</div><div class="line">&#125;</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      Hibernate缓存 查询缓存
    
    </summary>
    
      <category term="hibernate" scheme="http://jishusuishouji.github.io/categories/hibernate/"/>
    
    
      <category term="hibernate" scheme="http://jishusuishouji.github.io/tags/hibernate/"/>
    
  </entry>
  
  <entry>
    <title>hibernate的查询缓存</title>
    <link href="http://jishusuishouji.github.io/2017/03/30/hibernate/hibernate%E7%9A%84%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98/"/>
    <id>http://jishusuishouji.github.io/2017/03/30/hibernate/hibernate的查询缓存/</id>
    <published>2017-03-30T05:47:52.000Z</published>
    <updated>2017-03-30T05:56:50.612Z</updated>
    
    <content type="html"><![CDATA[<p>hibernate的查询缓存主要是针对普通属性结果集的缓存，而对于实体对象的结果集只缓存id。在一级缓存,二级缓存和查询缓存都打开的情况下做查询操作时这样的：查询普通属性，会先到查询缓存中取，如果没有，则查询数据库；查询实体，会先到查询缓存中取id，如果有，则根据id到缓存(一级/二级)中取实体，如果缓存中取不到实体，再查询数据库。<br> 和一级/二级缓存不同，查询缓存的生命周期是不确定的，当前关联的表发生改变时，查询缓存的生命周期结束。<br><a id="more"></a><br>查询缓存的配置和使用也是很简单的：<br>1&gt;查询缓存的启用不但要在配置文件中进行配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;property name=&quot;hibernate.cache.use_query_cache&quot;&gt;true&lt;/property&gt;</div></pre></td></tr></table></figure></p>
<p>2&gt;还要在程序中显示的进行启用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">query.setCacheable(true);</div></pre></td></tr></table></figure></p>
<p>1&gt;查询缓存的启用不但要在配置文件中进行配置 ——-换成spring配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line">&lt;bean id=&quot;propertyConfigurer&quot; class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt;</div><div class="line">    &lt;property name=&quot;locations&quot;&gt;</div><div class="line">        &lt;list&gt;</div><div class="line">            &lt;value&gt;/WEB-INF/config/jdbc.properties&lt;/value&gt;</div><div class="line">        &lt;/list&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/bean&gt;</div><div class="line">&lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt;</div><div class="line">    &lt;property name=&quot;driverClass&quot; value=&quot;$&#123;jdbc.driverClassName&#125;&quot; /&gt;</div><div class="line">    &lt;property name=&quot;jdbcUrl&quot; value=&quot;$&#123;jdbc.url&#125;&quot; /&gt;</div><div class="line">    &lt;property name=&quot;user&quot; value=&quot;$&#123;jdbc.username&#125;&quot; /&gt;</div><div class="line">    &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot; /&gt;</div><div class="line">    &lt;property name=&quot;autoCommitOnClose&quot; value=&quot;true&quot;/&gt;</div><div class="line">    &lt;property name=&quot;checkoutTimeout&quot; value=&quot;$&#123;cpool.checkoutTimeout&#125;&quot;/&gt;</div><div class="line">    &lt;property name=&quot;initialPoolSize&quot; value=&quot;$&#123;cpool.minPoolSize&#125;&quot;/&gt;</div><div class="line">    &lt;property name=&quot;minPoolSize&quot; value=&quot;$&#123;cpool.minPoolSize&#125;&quot;/&gt;</div><div class="line">    &lt;property name=&quot;maxPoolSize&quot; value=&quot;$&#123;cpool.maxPoolSize&#125;&quot;/&gt;</div><div class="line">    &lt;property name=&quot;maxIdleTime&quot; value=&quot;$&#123;cpool.maxIdleTime&#125;&quot;/&gt;</div><div class="line">    &lt;property name=&quot;acquireIncrement&quot; value=&quot;$&#123;cpool.acquireIncrement&#125;&quot;/&gt;</div><div class="line">    &lt;property name=&quot;maxIdleTimeExcessConnections&quot; value=&quot;$&#123;cpool.maxIdleTimeExcessConnections&#125;&quot;/&gt;</div><div class="line">&lt;/bean&gt;</div><div class="line">&lt;bean id=&quot;sessionFactory&quot; class=&quot;org.springframework.orm.hibernate3.LocalSessionFactoryBean&quot;&gt;</div><div class="line">    &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;    </div><div class="line">    &lt;property name=&quot;mappingLocations&quot;&gt;</div><div class="line">        &lt;list&gt;</div><div class="line">            &lt;value&gt;classpath*:/com/jeecms/core/entity/hbm/*.hbm.xml&lt;/value&gt;</div><div class="line">            &lt;value&gt;classpath*:/com/jeecms/cms/entity/main/hbm/*.hbm.xml&lt;/value&gt;</div><div class="line">            &lt;value&gt;classpath*:/com/jeecms/cms/entity/assist/hbm/*.hbm.xml&lt;/value&gt;</div><div class="line">        &lt;/list&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property name=&quot;hibernateProperties&quot;&gt;</div><div class="line">        &lt;value&gt;</div><div class="line">        hibernate.dialect=org.hibernate.dialect.MySQLInnoDBDialect</div><div class="line">        hibernate.show_sql=false</div><div class="line">        hibernate.format_sql=false</div><div class="line">        hibernate.query.substitutions=true 1, false 0</div><div class="line">        hibernate.jdbc.batch_size=20</div><div class="line">        //查询缓存配置</div><div class="line">        hibernate.cache.use_query_cache=true</div><div class="line">        &lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property name=&quot;entityInterceptor&quot;&gt;   </div><div class="line">        &lt;ref local=&quot;treeInterceptor&quot;/&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property name=&quot;cacheProvider&quot;&gt;</div><div class="line">        &lt;ref local=&quot;cacheProvider&quot;/&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property name=&quot;lobHandler&quot;&gt;</div><div class="line">        &lt;ref bean=&quot;lobHandler&quot; /&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/bean&gt;</div></pre></td></tr></table></figure></p>
<p>2&gt;还要在程序中显示的进行启用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">public List&lt;CmsSite&gt; getList(boolean cacheable) &#123;</div><div class="line">        String hql = &quot;from CmsSite bean order by bean.id asc&quot;;</div><div class="line">        return getSession().createQuery(hql).setCacheable(cacheable).list();</div><div class="line">    &#125;</div></pre></td></tr></table></figure></p>
<h2 id="1-实体类："><a href="#1-实体类：" class="headerlink" title="1.实体类："></a>1.实体类：</h2><pre><code>public class Student { 
  private Integer id; 
  private String name; 
  //一系列的setter.getter方法 
}
</code></pre><p>##2.映射文件</p>
<p>Student.hbm.xml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&lt;class name=&quot;com.sxt.hibernate.cache.entity.Student&quot; table=&quot;sxt_hibernate_student&quot;&gt; </div><div class="line">       </div><div class="line">  &lt;!-- 指定本类的对象使用二级缓存(这也可以放在hibernate.cfg.xml中统一指定) --&gt; </div><div class="line">  &lt;!-- </div><div class="line">  &lt;cache usage=&quot;read-only&quot;/&gt; </div><div class="line">   --&gt; </div><div class="line">  &lt;id name=&quot;id&quot; length=&quot;4&quot;&gt; </div><div class="line">    &lt;generator class=&quot;native&quot;&gt;&lt;/generator&gt; </div><div class="line">  &lt;/id&gt; </div><div class="line">  &lt;property name=&quot;name&quot; length=&quot;10&quot;&gt;&lt;/property&gt; </div><div class="line">&lt;/class&gt;</div></pre></td></tr></table></figure></p>
<h2 id="3-hibernate配置文件："><a href="#3-hibernate配置文件：" class="headerlink" title="3.hibernate配置文件："></a>3.hibernate配置文件：</h2><p>hibernate.cfg.xml</p>
<pre><code>&lt;hibernate-configuration&gt; 
  &lt;session-factory&gt; 
    &lt;property name=&quot;hibernate.connection.url&quot;&gt;jdbc:oracle:thin:@localhost:1521:ORCL10&lt;/property&gt;
    &lt;property name=&quot;hibernate.connection.driver_class&quot;&gt;oracle.jdbc.driver.OracleDriver&lt;/property&gt; 
    &lt;property name=&quot;hibernate.connection.username&quot;&gt;scott&lt;/property&gt; 
    &lt;property name=&quot;hibernate.connection.password&quot;&gt;yf123&lt;/property&gt; 
    &lt;property name=&quot;hibernate.dialect&quot;&gt;org.hibernate.dialect.Oracle9Dialect&lt;/property&gt; 
    &lt;property name=&quot;hibernate.show_sql&quot;&gt;true&lt;/property&gt; 

    &lt;!-- 开启二级缓存,其实hibernate默认就是开启的,这里显示的指定一下 --&gt; 
    &lt;property name=&quot;hibernate.cache.use_second_level_cache&quot;&gt;true&lt;/property&gt; 
    &lt;!-- 指定二级缓存产品的提供商 --&gt; 
    &lt;property name=&quot;hibernate.cache.provider_class&quot;&gt;org.hibernate.cache.EhCacheProvider&lt;/property&gt; 

    &lt;!-- 启用查询缓存 --&gt; 
    &lt;property name=&quot;hibernate.cache.use_query_cache&quot;&gt;true&lt;/property&gt; 

    &lt;mapping resource=&quot;com/sxt/hibernate/cache/entity/Student.hbm.xml&quot;/&gt; 

    &lt;!-- 指定那些类使用二级缓存 --&gt; 
    &lt;class-cache usage=&quot;read-only&quot; class=&quot;com.sxt.hibernate.cache.entity.Student&quot;/&gt; 
  &lt;/session-factory&gt; 
&lt;/hibernate-configuration&gt;
</code></pre><h2 id="4-测试方法："><a href="#4-测试方法：" class="headerlink" title="4.测试方法："></a>4.测试方法：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">public static void main(String[] args) &#123; </div><div class="line">  Session session = null; </div><div class="line">  Transaction t = null; </div><div class="line"></div><div class="line">  *//** </div><div class="line">   * 开启查询缓存,关闭二级缓存, 开启一个session,分别调用query.list </div><div class="line">   */ </div><div class="line">//如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. </div><div class="line">/* </div><div class="line">  try &#123; </div><div class="line">    session = HibernateUtils.getSession(); </div><div class="line">    t = session.beginTransaction(); </div><div class="line">    Query query = session.createQuery(&quot;select s.name from Student s&quot;); </div><div class="line">    //启用查询缓存    </div><div class="line">    query.setCacheable(true); </div><div class="line">    List&lt;String&gt; names = query.list(); </div><div class="line">    for (Iterator&lt;String&gt; it = names.iterator(); it.hasNext();) &#123; </div><div class="line">      String name = it.next(); </div><div class="line">      System.out.println(name); </div><div class="line">    &#125; </div><div class="line">    System.out.println(&quot;================================&quot;); </div><div class="line">    query = session.createQuery(&quot;select s.name from Student s&quot;); </div><div class="line">    //启用查询缓存 </div><div class="line">    query.setCacheable(true); </div><div class="line">    //没有发出查询语句,因为这里使用的查询缓存 </div><div class="line">    names = query.list(); </div><div class="line">    for (Iterator&lt;String&gt; it = names.iterator(); it.hasNext();) &#123; </div><div class="line">      String name = it.next(); </div><div class="line">      System.out.println(name); </div><div class="line">    &#125; </div><div class="line">    t.commit(); </div><div class="line">  &#125; catch (Exception e) &#123; </div><div class="line">    e.printStackTrace(); </div><div class="line">    t.rollback(); </div><div class="line">  &#125; finally &#123; </div><div class="line">    HibernateUtils.closeSession(session); </div><div class="line">  &#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line">@SuppressWarnings(&quot;unchecked&quot;) </div><div class="line">public static void main(String[] args) &#123; </div><div class="line">  Session session = null; </div><div class="line">  Transaction t = null; </div><div class="line"></div><div class="line">  *//** </div><div class="line">   * 开启查询缓存,关闭二级缓存, 开启两个session,分别调用query.list </div><div class="line">   *//* </div><div class="line">  //如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. </div><div class="line">  try &#123; </div><div class="line">    session = HibernateUtils.getSession(); </div><div class="line">    t = session.beginTransaction(); </div><div class="line">    Query query = session.createQuery(&quot;select s.name from Student s&quot;); </div><div class="line">    //启用查询缓存    </div><div class="line">    //query.setCacheable(true); </div><div class="line">    List&lt;String&gt; names = query.list(); </div><div class="line">    for (Iterator&lt;String&gt; it = names.iterator(); it.hasNext();) &#123; </div><div class="line">      String name = it.next(); </div><div class="line">      System.out.println(name); </div><div class="line">    &#125; </div><div class="line"></div><div class="line">    t.commit(); </div><div class="line">  &#125; catch (Exception e) &#123; </div><div class="line">    e.printStackTrace(); </div><div class="line">    t.rollback(); </div><div class="line">  &#125; finally &#123; </div><div class="line">    HibernateUtils.closeSession(session); </div><div class="line">  &#125; </div><div class="line">   </div><div class="line">  System.out.println(&quot;================================&quot;); </div><div class="line">   </div><div class="line">  try &#123; </div><div class="line">    session = HibernateUtils.getSession(); </div><div class="line">    t = session.beginTransaction(); </div><div class="line">    Query query = session.createQuery(&quot;select s.name from Student s&quot;); </div><div class="line">    //启用查询缓存    </div><div class="line">    //query.setCacheable(true); </div><div class="line">    //不会发出查询语句,因为查询缓存和session无关. </div><div class="line">    List&lt;String&gt; names = query.list(); </div><div class="line">    for (Iterator&lt;String&gt; it = names.iterator(); it.hasNext();) &#123; </div><div class="line">      String name = it.next(); </div><div class="line">      System.out.println(name); </div><div class="line">    &#125; </div><div class="line">    t.commit(); </div><div class="line">  &#125; catch (Exception e) &#123; </div><div class="line">    e.printStackTrace(); </div><div class="line">    t.rollback(); </div><div class="line">  &#125; finally &#123; </div><div class="line">    HibernateUtils.closeSession(session); </div><div class="line">  &#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line">@SuppressWarnings(&quot;unchecked&quot;) </div><div class="line">public static void main(String[] args) &#123; </div><div class="line">  Session session = null; </div><div class="line">  Transaction t = null; </div><div class="line"></div><div class="line">  *//** </div><div class="line">   * 开启查询缓存,关闭二级缓存, 开启两个session,分别调用query.iterate </div><div class="line">   *//* </div><div class="line">  //如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. </div><div class="line">  try &#123; </div><div class="line">    session = HibernateUtils.getSession(); </div><div class="line">    t = session.beginTransaction(); </div><div class="line">    Query query = session.createQuery(&quot;select s.name from Student s&quot;); </div><div class="line">    //启用查询缓存    </div><div class="line">    query.setCacheable(true); </div><div class="line">    for (Iterator&lt;String&gt; it = query.iterate(); it.hasNext();) &#123; </div><div class="line">      String name = it.next(); </div><div class="line">      System.out.println(name); </div><div class="line">    &#125; </div><div class="line">    t.commit(); </div><div class="line">  &#125; catch (Exception e) &#123; </div><div class="line">    e.printStackTrace(); </div><div class="line">    t.rollback(); </div><div class="line">  &#125; finally &#123; </div><div class="line">    HibernateUtils.closeSession(session); </div><div class="line">  &#125; </div><div class="line">   </div><div class="line">  System.out.println(&quot;================================&quot;); </div><div class="line">   </div><div class="line">  try &#123; </div><div class="line">    session = HibernateUtils.getSession(); </div><div class="line">    t = session.beginTransaction(); </div><div class="line">    Query query = session.createQuery(&quot;select s.name from Student s&quot;); </div><div class="line">    //启用查询缓存    </div><div class="line">    query.setCacheable(true); </div><div class="line">    //会发出查询语句,因为query.iterate不使用查询缓存 </div><div class="line">    for (Iterator&lt;String&gt; it = query.iterate(); it.hasNext();) &#123; </div><div class="line">      String name = it.next(); </div><div class="line">      System.out.println(name); </div><div class="line">    &#125; </div><div class="line">    t.commit(); </div><div class="line">  &#125; catch (Exception e) &#123; </div><div class="line">    e.printStackTrace(); </div><div class="line">    t.rollback(); </div><div class="line">  &#125; finally &#123; </div><div class="line">    HibernateUtils.closeSession(session); </div><div class="line">  &#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>```<br>  @SuppressWarnings(“unchecked”)<br>  public static void main(String[] args) {<br>    Session session = null;<br>    Transaction t = null; </p>
<pre><code>*//** 
 * 关闭查询缓存,关闭二级缓存, 开启两个session,分别调用query.list查询实体对象 
 *//* 
//如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. 
try { 
  session = HibernateUtils.getSession(); 
  t = session.beginTransaction(); 
  Query query = session.createQuery(&quot;select s from Student s&quot;); 
  //启用查询缓存    
  //query.setCacheable(true); 
  List&lt;Student&gt; students = query.list(); 
  for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { 
    Student s = it.next(); 
    System.out.println(s.getName()); 
  } 
  t.commit(); 
} catch (Exception e) { 
  e.printStackTrace(); 
  t.rollback(); 
} finally { 
  HibernateUtils.closeSession(session); 
} 

System.out.println(&quot;================================&quot;); 

try { 
  session = HibernateUtils.getSession(); 
  t = session.beginTransaction(); 
  Query query = session.createQuery(&quot;select s from Student s&quot;); 
  //启用查询缓存    
  //query.setCacheable(true); 
  //会发出查询语句,因为list默认每次都会发出sql语句 
  List&lt;Student&gt; students = query.list(); 
  for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { 
    Student s = it.next(); 
    System.out.println(s.getName()); 
  } 
  t.commit(); 
} catch (Exception e) { 
  e.printStackTrace(); 
  t.rollback(); 
} finally { 
  HibernateUtils.closeSession(session); 
} 
</code></pre><p>  }*/ </p>
<p>/*  @SuppressWarnings(“unchecked”)<br>  public static void main(String[] args) {<br>    Session session = null;<br>    Transaction t = null; </p>
<pre><code>*//** 
 * 开启查询缓存,关闭二级缓存, 开启两个session,分别调用query.list查询实体对象 
 *//* 
//如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. 
try { 
  session = HibernateUtils.getSession(); 
  t = session.beginTransaction(); 
  Query query = session.createQuery(&quot;select s from Student s&quot;); 
  //启用查询缓存    
  query.setCacheable(true); 
  List&lt;Student&gt; students = query.list(); 
  for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { 
    Student s = it.next(); 
    System.out.println(s.getName()); 
  } 
  t.commit(); 
} catch (Exception e) { 
  e.printStackTrace(); 
  t.rollback(); 
} finally { 
  HibernateUtils.closeSession(session); 
} 

System.out.println(&quot;================================&quot;); 

try { 
  session = HibernateUtils.getSession(); 
  t = session.beginTransaction(); 
  Query query = session.createQuery(&quot;select s from Student s&quot;); 
  //启用查询缓存    
  query.setCacheable(true); 
  //会发出根据id查询实体的n条查询语句,因为这种情况下,查询过程是这样的： 
  // 在第一次执行list时,会把查询对象的id缓存到查询缓存里 
  // 第二次执行list时, 会遍历查询缓存里的id到缓存里去找实体对象,由于这里没找到实体对象, 
  //所以就发出n条查询语句到数据库中查询. 
  List&lt;Student&gt; students = query.list(); 
  for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { 
    Student s = it.next(); 
    System.out.println(s.getName()); 
  } 
  t.commit(); 
} catch (Exception e) { 
  e.printStackTrace(); 
  t.rollback(); 
} finally { 
  HibernateUtils.closeSession(session); 
} 
</code></pre><p>  }*/ </p>
<p>  @SuppressWarnings(“unchecked”)<br>  public static void main(String[] args) {<br>    Session session = null;<br>    Transaction t = null; </p>
<pre><code>/** 
 * 开启查询缓存,开启二级缓存, 开启两个session,分别调用query.list查询实体对象 
 */ 
//如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. 
try { 
  session = HibernateUtils.getSession(); 
  t = session.beginTransaction(); 
  Query query = session.createQuery(&quot;select s from Student s&quot;); 
  //启用查询缓存    
  query.setCacheable(true); 
  List&lt;Student&gt; students = query.list(); 
  for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { 
    Student s = it.next(); 
    System.out.println(s.getName()); 
  } 
  t.commit(); 
} catch (Exception e) { 
  e.printStackTrace(); 
  t.rollback(); 
} finally { 
  HibernateUtils.closeSession(session); 
} 

System.out.println(&quot;================================&quot;); 

try { 
  session = HibernateUtils.getSession(); 
  t = session.beginTransaction(); 
  Query query = session.createQuery(&quot;select s from Student s&quot;); 
  //启用查询缓存    
  query.setCacheable(true); 
  //不会发出查询语句,因为这种情况下,查询过程是这样的： 
  // 在第一次执行list时,会把查询对象的id缓存到查询缓存里 
  // 第二次执行list时, 会遍历查询缓存里的id到缓存里去找实体对象,由于这里开启了二级缓存,可以找到目标实体对象, 
  //所以就不会再发出n条查询语句. 
  List&lt;Student&gt; students = query.list(); 
  for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { 
    Student s = it.next(); 
    System.out.println(s.getName()); 
  } 
  t.commit(); 
} catch (Exception e) { 
  e.printStackTrace(); 
  t.rollback(); 
} finally { 
  HibernateUtils.closeSession(session); 
} 
</code></pre><p>  }</p>
]]></content>
    
    <summary type="html">
    
      hibernate的查询缓存
    
    </summary>
    
      <category term="hibernate" scheme="http://jishusuishouji.github.io/categories/hibernate/"/>
    
    
      <category term="hibernate" scheme="http://jishusuishouji.github.io/tags/hibernate/"/>
    
  </entry>
  
  <entry>
    <title>Layout of Log4j</title>
    <link href="http://jishusuishouji.github.io/2017/03/28/Log4j/Layout_of_Log4j/"/>
    <id>http://jishusuishouji.github.io/2017/03/28/Log4j/Layout_of_Log4j/</id>
    <published>2017-03-28T07:02:00.000Z</published>
    <updated>2017-03-28T07:03:46.667Z</updated>
    
    <content type="html"><![CDATA[<p>本文档使用Log4j版本为1.2.17</p>
<h2 id="1-Layout介绍"><a href="#1-Layout介绍" class="headerlink" title="1. Layout介绍"></a>1. Layout介绍</h2><p>Log4j Layout主要用来控制日志的序列化格式，比如时间、线程号、日志消息对齐方式等，是log4j体系结构中的核心组成部分之一。</p>
<p>Layout抽象类声明为:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">public abstract class Layout implements OptionHandler</div></pre></td></tr></table></figure></p>
<p><code>Layout</code>实现了<code>OptionHandler</code>接口，<code>OptionHandler</code>仅包含一个方法<code>activateOptions()</code>。对实现了<code>OptionHandler</code>接口的模块，调用属性<code>setter</code>方法后，log4j的配置器类会调用此模块的<code>activateOptions</code>实现以激活配置。<code>OptionHandler</code>存在的原因是有些属性彼此依赖，在它们在全部加载完成之前是无法激活的，这个方法用于在模块变为激活和就绪之前用来执行任何必要任务的机制。比如：</p>
<p>某模块有字符串属性fileName属性，表示log4j用户配置的写出日志文件名，使用前需要创建File对象获取文件写出IO流，具体则是由activateOptions完成文件的打开等，具体可见log4j的FileAppender实现中对文件名和文件IO的操作。</p>
<p>Layout类的方法或接口如下，abstract修饰的需要具体子类实现:</p>
<p>//abstract修饰需要具体子类实现，将日志事件渲染为待打印的日志文本字符串，可写出到Appender<br>abstract  public  String format(LoggingEvent event )<br>//format函数返回的格式化文本类型，默认返回为”text/plain”<br>public String getContentType()<br>//针对HTMLLayout类的格式化输出，html字符串的头部，默认null<br>public String getHeader()<br>//针对HTMLLayout类的格式化输出，html字符串的尾部，默认null<br>public String getFooter()<br>//对于LayoutEvent中异常的处理模式，true表示忽略异常，异常会到达Appender，由Appender负责渲染为打印持久化字符串信息；false表示由Layout负责渲染异常信息。SimpleLayout、TTCCLayout、PatternLayout实现返回true;XMLLayout实现返回false，由Appender处理渲染异常消息。<br>abstract public boolean ignoresThrowable()<br>Layout是对序列化每一次LoggingEvent的抽象，核心是format方法，format作为抽象方法，由具体子类实现具体的序列化方式。具体子类有：</p>
<p>SimpleLayout<br>TTCCLayout<br>PatternLayout<br>XMLLayout<br>HTMLLayout<br>DateLayout<br>Layout继承体系</p>
<ol>
<li>XMLLayout</li>
</ol>
<p>XMLLayout实现了根据log4j.dtd序列化输出xml格式的日志文本，默认的log4j.dtd文件在/org/apache/log4j/xml/log4j.dtd目录下，注意，XMLLayout打印输出的并非完整XML文件，并不包括&lt;?xml version=”1.0” ?&gt;等XML头部，XMLLayout的目的是输出XML的部分片段，应用可将此片段整合嵌入到其它XML文件中。XMLLayout有成员属性：<br>locationInfo表示是否打印位置信息，即日志事件发生的代码文件名、日志记录点代码行号等信息，log4j配置文件中需要配置为LocationInfo<br>properties表示是否打印MDC中的Key-Value信息，默认为false，log4j配置文件中需要配置为Properties</p>
<p>注意：log4j的各个模块涉及的成员属性时，如果属性有set方法，一般表示此属性可通过log4j.properties进行配置，具体配置属性值为属性的setXXX方法去掉set前缀。</p>
<p>示例如上面的locationInfo和properties配置:</p>
<p>log4j.appender.Console.layout.LocationInfo=true<br>log4j.appender.Console.layout.Properties=true</p>
<p>XMLLayout继承自Layout的方法实现有：</p>
<p>//配置激活的接口实现，来自于OptionHandler interface，方法体为空<br>public void activateOptions()<br>//返回false，表示XMLLayout自己处理异常信息<br>public boolean ignoresThrowable()<br>public String format( final LoggingEvent event)<br>2.1 format实现</p>
<p>format按照日志message、NDC、getThrowableStrRep、日志位置信息、MDC的顺序，并按照XML格式序列化LoggingEvent。log4j实现时使用StringBuffer避免字符串拼接的开销（JAVA中String是不可变类），具体使用时设置了StringBuffer的默认长度即DEFAULT_SIZE = 256，最大长度UPPER_LIMIT = 2048。每次format函数调用时，如果当前StringBuffer容量未超过上限，则复用已有的StringBuffer并清空已有内容；如果当前StringBuffer容量超过UPPER_LIMIT上限，则创建一个新的StringBuffer将当前LoggingEvent 序列化到其中，目的是尽量减少内存的占用量。</p>
<p>if(buf.capacity() &gt; UPPER_LIMIT) {<br>  buf = new StringBuffer(DEFAULT_SIZE);<br>} else {<br>  buf.setLength(0);<br>}<br>xml序列化中，对于属性如 timestamp=”1452874282177” level=“INFO”，为了保持生成的文本符合XML语法，需要对特殊字符进行转义处理。对于属性使用org.apache.log4j.helpers.Transform.escapeTags做转义。对于文本子元素如 <log4j:message>&lt;![CDATA[123]]&gt;</log4j:message>，使用org.apache.log4j.helpers.Transform.appendEscapingCDATA做转义，将message放在 &lt;![CDATA[ 和 ]] 之间，避免文本破坏XML语法。</p>
<p>处理的XML特殊字符有（简单字符串替换）:</p>
<blockquote>
<p>-&gt; &gt;<br>&lt; -&gt; &lt;<br>&amp; -&gt; &amp;<br>“ -&gt; &quot;<br>2.2 demo</p>
</blockquote>
<p>demo java code:</p>
<p>Logger logger = Logger.getLogger(LayoutTest.class);<br>NDC.push(“ndc message”);<br>logger.info(“info:123”);<br>logger.warn(“warn:abc”);<br>logger.info(“exception”, new RuntimeException(“run time exception”));<br>demo log4j config:</p>
<p>log4j.rootLogger=INFO,Console<br>log4j.appender.Console=org.apache.log4j.ConsoleAppender<br>log4j.appender.Console.target=System.out<br>log4j.appender.Console.layout=org.apache.log4j.xml.XMLLayout<br>log4j.appender.Console.layout.LocationInfo=true<br>log4j.appender.Console.layout.Properties=true</p>
<p>demo 日志输出:</p>
<p><log4j:event logger="com.luohw.log4j.LayoutTest" timestamp="1459227960659" level="INFO" thread="main"></log4j:event></p>
<p><log4j:message>&lt;![CDATA[info:123]]&gt;</log4j:message></p>
<p><log4j:ndc>&lt;![CDATA[ndc message]]&gt;</log4j:ndc></p>
<p><log4j:locationinfo class="com.luohw.log4j.LayoutTest" method="test" file="LayoutTest.java" line="13"><br></log4j:locationinfo></p>
<p><log4j:event logger="com.luohw.log4j.LayoutTest" timestamp="1459227960670" level="WARN" thread="main"></log4j:event></p>
<p><log4j:message>&lt;![CDATA[warn:abc]]&gt;</log4j:message></p>
<p><log4j:ndc>&lt;![CDATA[ndc message]]&gt;</log4j:ndc></p>
<p><log4j:locationinfo class="com.luohw.log4j.LayoutTest" method="test" file="LayoutTest.java" line="14"><br></log4j:locationinfo></p>
<p><log4j:event logger="com.luohw.log4j.LayoutTest" timestamp="1459227960670" level="ERROR" thread="main"></log4j:event></p>
<p><log4j:message>&lt;![CDATA[error:xyz]]&gt;</log4j:message></p>
<p><log4j:ndc>&lt;![CDATA[ndc message]]&gt;</log4j:ndc></p>
<p><log4j:locationinfo class="com.luohw.log4j.LayoutTest" method="test" file="LayoutTest.java" line="15"><br></log4j:locationinfo></p>
<p><log4j:event logger="com.luohw.log4j.LayoutTest" timestamp="1459227960671" level="INFO" thread="main"></log4j:event></p>
<p><log4j:message>&lt;![CDATA[exception]]&gt;</log4j:message></p>
<p><log4j:ndc>&lt;![CDATA[ndc message]]&gt;</log4j:ndc></p>
<p><log4j:throwable>&lt;![CDATA[java.lang.RuntimeException: run time exception<br>at com.luohw.log4j.LayoutTest.test(LayoutTest.java:16)<br>at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<br>at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)<br>… …<br>at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)<br>at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)<br>]]&gt;</log4j:throwable></p>
<p><log4j:locationinfo class="com.luohw.log4j.LayoutTest" method="test" file="LayoutTest.java" line="16"><br></log4j:locationinfo></p>
<ol>
<li>HTMLLayout</li>
</ol>
<p>HTMLLayout用于将每次的LoggingEvent序列化为HTML格式字符串，具体的内容组织为html的表格。生成的HTML文本为完整的一份HTML格式代码（不同于XMLLayout的部分片段），包含html、head、body、具体table信息等。一份HTML日志文档可以包含多条LoggingEvent序列化输出，但header和footer只会输出一次（具体是有Appender打开和关闭相关流时输出）。</p>
<p>注意：如果有Appender使用HTMLLayout，需要设置Appender的字符编码为UTF-8 或者 UTF-16，否则非ASCII字符会产生乱码。</p>
<p>locationInfo表示是否打印位置信息，即日志事件发生的代码文件名、代码行号，log4j配置文件中需要配置为LocationInfo</p>
<p>title输出html文档head的title部分，默认为Log4J Log Messages，log4j配置文件中需要配置为Title</p>
<p>XMLLayout继承自Layout的方法实现有：</p>
<p>//默认返回”text/html”<br>public String getContentType()<br>//配置加载完成后操作，实现为空<br>public void activateOptions()<br>//返回相应HTML头部部分，具体是html、head、title以及body、table的开始部分<br>public String getHeader()<br>//返回相应html尾部，具体是table、body、html的html闭合标签<br>public String getFooter()<br>//返回false，即由HTMLLayout本身处理异常信息格式化，HTMLLayout有成员函数appendThrowableAsHTML，具体是将Throwable对应的字符串做相关转移和替换处理，以符合html语法<br>public boolean ignoresThrowable()<br>//具体序列化LoggingEvent为字符串<br>public String format(LoggingEvent event)<br>3.1 format实现</p>
<p>a.  缓冲StringBuffer更新，判断容量是否超过HTMLLayout的MAX_CAPACITY(1024)，如果超过则创建新的StringBuffer，否则复用原有的StringBuffer，避免内存浪费，具体和XMLLayout原理一致。<br>b.  输出时间、线程、Level等上下文信息，根据locationInfo（如果locationInfo为true）、Level等具体字符串拼接和格式化</p>
<tr><br><td>0</td><br><td title="main thread">main</td><br><td title="Level">INFO</td><br><td title="com.luohw.log4j.LayoutTest category">com.luohw.log4j.LayoutTest</td><br><td>LayoutTest.java:12</td><br><td title="Message">info:123</td><br></tr>

<p>c. 输出NDC信息</p>
<tr><td bgcolor="#EEEEEE" style="font-size : xx-small;" colspan="6" title="Nested Diagnostic Context">NDC: ndc message</td></tr>

<p>d. 如果有则输出异常栈信息，一般Logger的日志函数info、warn、error等都有带Throwable型参的重载<br>e. 没有MDC相关信息的格式化输出</p>
<p>3.2 demo</p>
<p>demo java code:</p>
<p>Logger logger = Logger.getLogger(LayoutTest.class);<br>NDC.push(“ndc message”);<br>logger.info(“info:123”);<br>logger.warn(“warn:abc”);<br>logger.error(“error:xyz”);<br>logger.info(“exception”, new RuntimeException(“run time exception”));<br>demo log4j config:</p>
<p>log4j.rootLogger=INFO,Console<br>log4j.appender.Console=org.apache.log4j.ConsoleAppender<br>log4j.appender.Console.target=System.out<br>log4j.appender.Console.layout=org.apache.log4j.HTMLLayout<br>log4j.appender.Console.layout.LocationInfo=true<br>log4j.appender.Console.layout.Title=luohw@log4j</p>
<p>demo浏览器打开日志输出html:</p>
<p>html</p>
<p>see more …</p>
]]></content>
    
    <summary type="html">
    
      Layout of Log4j
    
    </summary>
    
      <category term="Log4j" scheme="http://jishusuishouji.github.io/categories/Log4j/"/>
    
    
      <category term="Log4j" scheme="http://jishusuishouji.github.io/tags/Log4j/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB两阶段提交实现事务</title>
    <link href="http://jishusuishouji.github.io/2017/03/27/mongodb/MongoDB%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E5%AE%9E%E7%8E%B0%E4%BA%8B%E5%8A%A1/"/>
    <id>http://jishusuishouji.github.io/2017/03/27/mongodb/MongoDB两阶段提交实现事务/</id>
    <published>2017-03-27T13:12:46.000Z</published>
    <updated>2017-03-29T10:15:06.559Z</updated>
    
    <content type="html"><![CDATA[<p> MongoDB数据库中操作单个文档总是原子性的，然而，涉及多个文档的操作，通常被作为一个“事务”，而不是原子性的。因为文档可以是相当复杂并且包含多个嵌套文档，单文档的原子性对许多实际用例提供了支持。尽管单文档操作是原子性的，在某些情况下，需要多文档事务。在这些情况下，使用两阶段提交，提供这些类型的多文档更新支持。因为文档可以表示为<code>Pending</code>数据和状态，可以使用一个两阶段提交确保数据是一致的，在一个错误的情况下，事务前的状态是可恢复的。</p>
<p>事务最常见的例子是以可靠的方式从A账户转账到B账户，在关系型数据库中，此操作将从A账户减掉金额和给B账户增加金额的操作封装在单个原子事务中。在MongoDB中，可以使用两阶段提交达到相同的效果。本文中的所有示例使用mongo shell与数据库进行交互,并假设有两个集合：首先，一个名为<code>accounts</code>的集合存储每个账户的文档数据，另一个名为<code>transactions</code>的集合存储事务本身。</p>
<p>首先创建两个名为A和B的账户，使用下面的命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">db.accounts.save(&#123;name: &quot;A&quot;, balance: 1000, pendingTransactions: []&#125;)</div><div class="line">db.accounts.save(&#123;name: &quot;B&quot;, balance: 1000, pendingTransactions: []&#125;)</div></pre></td></tr></table></figure></p>
<p>使用<code>find()</code>方法验证这两个操作已经成功：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.accounts.find()</div></pre></td></tr></table></figure></p>
<p>mongo会返回两个类似下面的文档：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc66cb8a04f512696151f&quot;), &quot;name&quot; : &quot;A&quot;, &quot;balance&quot; : 1000, &quot;pendingTransactions&quot; : [ ] &#125;</div><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc67bb8a04f5126961520&quot;), &quot;name&quot; : &quot;B&quot;, &quot;balance&quot; : 1000, &quot;pendingTransactions&quot; : [ ] &#125;</div></pre></td></tr></table></figure></p>
<h2 id="事务过程："><a href="#事务过程：" class="headerlink" title="事务过程："></a>事务过程：</h2><p>设置事务初始状态<code>initial</code>：</p>
<p>通过插入下面的文档创建transaction集合，transaction文档持有源(source)和目标(destination)，它们引用自<code>accounts</code>集合文档的字段名，以及<code>value</code>字段表示改变<code>balance</code>字段数量的数据。最后，<code>state</code>字段反映事务的当前状态。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.transactions.save(&#123;source: &quot;A&quot;, destination: &quot;B&quot;, value: 100, state: &quot;initial&quot;&#125;)</div></pre></td></tr></table></figure></p>
<p>验证这个操作已经成功，使用<code>find()</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.transactions.find()</div></pre></td></tr></table></figure></p>
<p>这个操作会返回一个类似下面的文档：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;), &quot;source&quot; : &quot;A&quot;, &quot;destination&quot; : &quot;B&quot;, &quot;value&quot; : 100, &quot;state&quot; : &quot;initial&quot; &#125;</div></pre></td></tr></table></figure></p>
<p>切换事务到Pending状态：<br>在修改accounts集合记录之前，将事务状态从initial设置为pending。使用<code>findOne()</code>方法将transaction文档赋值给shell会话中的局部变量t：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">t = db.transactions.findOne(&#123;state: &quot;initial&quot;&#125;)</div></pre></td></tr></table></figure></p>
<p>变量t创建后，shell将返回它的值，将会看到如下的输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;), &quot;source&quot; : &quot;A&quot;, &quot;destination&quot; : &quot;B&quot;, &quot;value&quot; : 100, &quot;state&quot; : &quot;initial&quot; &#125;</div></pre></td></tr></table></figure></p>
<p>使用<code>update()</code>改变<code>state</code>的值为<code>pending</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">db.transactions.update(&#123;_id: t._id&#125;, &#123;$set: &#123;state: &quot;pending&quot;&#125;&#125;)</div><div class="line">db.transactions.find()</div></pre></td></tr></table></figure></p>
<p><code>find()</code>操作将返回<code>transaction</code>集合的内容，类似下面：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;), &quot;source&quot; : &quot;A&quot;, &quot;destination&quot; : &quot;B&quot;, &quot;value&quot; : 100, &quot;state&quot; : &quot;pending&quot; &#125;</div></pre></td></tr></table></figure></p>
<h3 id="将事务应用到两个账户："><a href="#将事务应用到两个账户：" class="headerlink" title="将事务应用到两个账户："></a>将事务应用到两个账户：</h3><p>使用<code>update()</code>方法应用事务到两个账户。在<code>update()</code>查询中，条件<code>pendingTransactions:{$ne:t._id}</code>阻止事务更新账户，如果账户的pendingTransaction字段包含事务t的<code>_id</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">db.accounts.update(</div><div class="line">    &#123; name: t.source, pendingTransactions: &#123; $ne: t._id &#125; &#125;,</div><div class="line">    &#123; $inc: &#123; balance: -t.value &#125;, $push: &#123; pendingTransactions: t._id &#125; &#125;</div><div class="line">)</div><div class="line">db.accounts.update(</div><div class="line">    &#123; name: t.destination, pendingTransactions: &#123; $ne: t._id &#125; &#125;,</div><div class="line">    &#123; $inc: &#123; balance: t.value &#125;, $push: &#123; pendingTransactions: t._id &#125; &#125;</div><div class="line">)</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.accounts.find()</div></pre></td></tr></table></figure>
<p><code>find()</code>操作将返回accounts集合的内容，现在应该类似于下面的内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc97fb8a04f5126961523&quot;), &quot;balance&quot; : 900, &quot;name&quot; : &quot;A&quot;, &quot;pendingTransactions&quot; : [ ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;) ] &#125;</div><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc984b8a04f5126961524&quot;), &quot;balance&quot; : 1100, &quot;name&quot; : &quot;B&quot;, &quot;pendingTransactions&quot; : [ ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;) ] &#125;</div></pre></td></tr></table></figure></p>
<h3 id="设置事务状态为committed："><a href="#设置事务状态为committed：" class="headerlink" title="设置事务状态为committed："></a>设置事务状态为<code>committed</code>：</h3><p>使用下面的<code>update()</code>操作设置事务的状态为<code>committed</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">db.transactions.update(&#123;_id: t._id&#125;, &#123;$set: &#123;state: &quot;committed&quot;&#125;&#125;)</div><div class="line">db.transactions.find()</div></pre></td></tr></table></figure></p>
<p><code>find()</code>操作发回transactions集合的内容，现在应该类似下面的内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;), &quot;destination&quot; : &quot;B&quot;, &quot;source&quot; : &quot;A&quot;, &quot;state&quot; : &quot;committed&quot;, &quot;value&quot; : 100 &#125;</div></pre></td></tr></table></figure></p>
<h3 id="移除pending事务："><a href="#移除pending事务：" class="headerlink" title="移除pending事务："></a>移除pending事务：</h3><p>使用下面的<code>update()</code>操作从<code>accounts</code>集合中移除<code>pending</code>事务：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">db.accounts.update(&#123;name: t.source&#125;, &#123;$pull: &#123;pendingTransactions: t._id&#125;&#125;)</div><div class="line">db.accounts.update(&#123;name: t.destination&#125;, &#123;$pull: &#123;pendingTransactions: t._id&#125;&#125;)</div><div class="line">db.accounts.find()</div></pre></td></tr></table></figure></p>
<p><code>find()</code>操作返回accounts集合内容，现在应该类似下面内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc97fb8a04f5126961523&quot;), &quot;balance&quot; : 900, &quot;name&quot; : &quot;A&quot;, &quot;pendingTransactions&quot; : [ ] &#125;</div><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc984b8a04f5126961524&quot;), &quot;balance&quot; : 1100, &quot;name&quot; : &quot;B&quot;, &quot;pendingTransactions&quot; : [ ] &#125;</div></pre></td></tr></table></figure>
<h3 id="设置事务状态为done："><a href="#设置事务状态为done：" class="headerlink" title="设置事务状态为done："></a>设置事务状态为done：</h3><p>通过设置transaction文档的<code>state</code>为<code>done</code>完成事务：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">db.transactions.update(&#123;_id: t._id&#125;, &#123;$set: &#123;state: &quot;done&quot;&#125;&#125;)</div><div class="line">db.transactions.find()</div></pre></td></tr></table></figure></p>
<p><code>find()</code>操作返回transaction集合的内容，此时应该类似下面：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;), &quot;destination&quot; : &quot;B&quot;, &quot;source&quot; : &quot;A&quot;, &quot;state&quot; : &quot;done&quot;, &quot;value&quot; : 100 &#125;</div></pre></td></tr></table></figure></p>
<h3 id="从失败场景中恢复："><a href="#从失败场景中恢复：" class="headerlink" title="从失败场景中恢复："></a>从失败场景中恢复：</h3><p>最重要的部分不是上面的典型例子，而是从各种失败场景中恢复未完成的事务的可能性。这部分将概述可能的失败，并提供方法从这些事件中恢复事务。这里有两种类型的失败：</p>
<p>1、所有发生在第一步（即设置事务的初始状态<code>initial</code>）之后，但在第三步（即应用事务到两个账户）之前的失败。为了还原事务，应用应该获取一个<code>pending</code>状态的<code>transaction</code>列表并且从第二步（即切换事务到<code>pending</code>状态）中恢复。</p>
<p>2、所有发生在第三步之后（即应用事务到两个账户）但在第五步(即设置事务状态为<code>done</code>)之前的失败。为了还原事务，应用需要获取一个<code>committed</code>状态的事务列表，并且从第四步（即移除<code>pending</code>事务）恢复。</p>
<p>因此应用程序总是能够恢复事务，最终达到一个一致的状态。应用程序开始捕获到每个未完成的事务时运行下面的恢复操作。你可能还希望定期运行恢复操作，以确保数据处于一致状态。达成一致状态所需要的时间取决于应用程序需要多长时间恢复每个事务。</p>
<h3 id="回滚："><a href="#回滚：" class="headerlink" title="回滚："></a>回滚：</h3><p>在某些情况下可能需要“回滚”或“撤消”事务，当应用程序需要“取消”该事务时，或者是因为它永远需要恢复当其中一个帐户不存在的情况下，或停止现有的事务。这里有两种可能的回滚操作：</p>
<p>1、应用事务（即第三步）之后，你已经完全提交事务，你不应该回滚事务。相反，创建一个新的事务，切换源(源)和目标(destination)的值。</p>
<p>2、创建事务（即第一步）之后，在应用事务（即第三步）之前，使用下面的处理过程：</p>
<h3 id="设置事务状态为canceling："><a href="#设置事务状态为canceling：" class="headerlink" title="设置事务状态为canceling："></a>设置事务状态为canceling：</h3><pre><code>首先设置事务状态为canceling，使用下面的update()操作：
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.transactions.update(&#123;_id: t._id&#125;, &#123;$set: &#123;state: &quot;canceling&quot;&#125;&#125;)</div></pre></td></tr></table></figure>
<p>###撤销事务：</p>
<p>使用下面的操作顺序从两个账户中撤销事务：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">db.accounts.update(&#123;name: t.source, pendingTransactions: t._id&#125;, &#123;$inc: &#123;balance: t.value&#125;, $pull: &#123;pendingTransactions: t._id&#125;&#125;)</div><div class="line">db.accounts.update(&#123;name: t.destination, pendingTransactions: t._id&#125;, &#123;$inc: &#123;balance: -t.value&#125;, $pull: &#123;pendingTransactions: t._id&#125;&#125;)</div><div class="line">db.accounts.find()</div></pre></td></tr></table></figure>
<p><code>find()</code>操作返回acounts集合的内容，应该类似下面：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc97fb8a04f5126961523&quot;), &quot;balance&quot; : 1000, &quot;name&quot; : &quot;A&quot;, &quot;pendingTransactions&quot; : [ ] &#125;</div><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc984b8a04f5126961524&quot;), &quot;balance&quot; : 1000, &quot;name&quot; : &quot;B&quot;, &quot;pendingTransactions&quot; : [ ] &#125;</div></pre></td></tr></table></figure></p>
<h3 id="设置事务状态为canceled："><a href="#设置事务状态为canceled：" class="headerlink" title="设置事务状态为canceled："></a>设置事务状态为<code>canceled</code>：</h3><p>最后，使用下面的update()状态将事务状态设置为canceled：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.transactions.update(&#123;_id: t._id&#125;, &#123;$set: &#123;state: &quot;canceled&quot;&#125;&#125;)</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      MongoDB两阶段提交实现事务
    
    </summary>
    
      <category term="MongoDB" scheme="http://jishusuishouji.github.io/categories/MongoDB/"/>
    
    
      <category term="MongoDB" scheme="http://jishusuishouji.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>mysql-Innodb事务隔离级别-repeatable read详解</title>
    <link href="http://jishusuishouji.github.io/2017/03/27/mysql/mysql-Innodb%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB-repeatable_read%E8%AF%A6%E8%A7%A3/"/>
    <id>http://jishusuishouji.github.io/2017/03/27/mysql/mysql-Innodb事务隔离级别-repeatable_read详解/</id>
    <published>2017-03-27T11:04:08.000Z</published>
    <updated>2017-03-27T11:37:29.144Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、事务隔离级别"><a href="#一、事务隔离级别" class="headerlink" title="一、事务隔离级别"></a>一、事务隔离级别</h2><p>ANSI/ISO SQL标准定义了4中事务隔离级别：未提交读（read uncommitted），提交读（read committed），重复读（repeatable read），串行读（serializable）。</p>
<p>对于不同的事务，采用不同的隔离级别分别有不同的结果。不同的隔离级别有不同的现象。主要有下面3种现在：</p>
<p>1、脏读（dirty read）：一个事务可以读取另一个尚未提交事务的修改数据。</p>
<p>2、非重复读（nonrepeatable read）：在同一个事务中，同一个查询在T1时间读取某一行，在T2时间重新读取这一行时候，这一行的数据已经发生修改(T1和T2都在同一个事务里面)，可能被更新了（update），也可能被删除了（delete）。</p>
<p>3、幻像读（phantom read）：在同一事务中，同一查询多次进行时候，由于其他插入操作（insert）的事务提交，导致每次返回不同的结果集。</p>
<p>不同的隔离级别有不同的现象，并有不同的锁定/并发机制，隔离级别越高，数据库的并发性就越差，4种事务隔离级别分别表现的现象如下表：</p>
<table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读</th>
<th>非重复读</th>
<th>幻像读</th>
</tr>
</thead>
<tbody>
<tr>
<td>read uncommitted</td>
<td>允许</td>
<td>允许</td>
<td>允许</td>
</tr>
<tr>
<td>read committed</td>
<td></td>
<td>允许</td>
<td>允许</td>
</tr>
<tr>
<td>repeatable read</td>
<td></td>
<td></td>
<td>允许</td>
</tr>
<tr>
<td>serializable</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="二、数据库中的默认事务隔离级别"><a href="#二、数据库中的默认事务隔离级别" class="headerlink" title="二、数据库中的默认事务隔离级别"></a>二、数据库中的默认事务隔离级别</h2><p>在Oracle中默认的事务隔离级别是提交读（read committed）。<br>对于MySQL的Innodb的默认事务隔离级别是重复读（repeatable read）。可以通过下面的命令查看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">mysql&gt; SELECT @@GLOBAL.tx_isolation, @@tx_isolation;</div><div class="line"></div><div class="line">+———————–+—————–+</div><div class="line"></div><div class="line">| @@GLOBAL.tx_isolation | @@tx_isolation  |</div><div class="line"></div><div class="line">+———————–+—————–+</div><div class="line"></div><div class="line">| REPEATABLE-READ | REPEATABLE-READ |</div><div class="line"></div><div class="line">+———————–+—————–+</div><div class="line"></div><div class="line">1 row in set (0.00 sec)</div></pre></td></tr></table></figure>
<p>下面进行一下测试：</p>
<p><img src="/img/mysql Innodb repeatable read测试.png" alt=""><br>【说明】<br>事务提交，看到最新数据。</p>
<p>上面的结果可以看到Innodb的重复读（repeatable read）不允许脏读，不允许非重复读（即可以重复读，Innodb使用多版本一致性读来实现）和不允许幻象读（这点和ANSI/ISO SQL标准定义的有所区别）。</p>
<p>另外，同样的测试：</p>
<p>1、当session 2进行truncate表的时候，这个时候session 1再次查询就看不到数据。</p>
<p>2、当session 2进行alter表的时候，这个时候session 1再次查询就看不到数据。</p>
<p>造成以上的原因是因为 mysql的持续非锁定读，在repeatable read级别下，读采用的是持续非锁定读。相关介绍见下面：</p>
<p>持续读意味着InnoDB使用它的多版本化来给一个查询展示某个时间点处数据库的快照。查询看到在那个时间点之前被提交的那些确切事务做的更改，并且没有其后的事务或未提交事务做的改变。这个规则的例外是，查询看到发布该查询的事务本身所做的改变。</p>
<p>如果你运行在默认的REPEATABLE READ隔离级别，则在同一事务内的所有持续读读取由该事务中第一个这样的读所确立的快照。你可以通过提交当前事务并在发布新查询的事务之后，为你的查询获得一个更新鲜的快照。</p>
<p>持续读是默认模式，在其中InnoDBzai在READ COMMITTED和REPEATABLE READ隔离级别处理SELECT语句。持续读不在任何它访问的表上设置锁定，因此，其它用户可自由地在持续读在一个表上执行的同一时间修改这些表。</p>
<p>注意，持续读不在DROP TABLE和ALTER TABLE上作用。持续读不在DROP TABLE上作用，因为MySQL不能使用已经被移除的表，并且InnoDB 破坏了该表。持续读不在ALTER TABLE上作用，因为它在某事务内执行，该事务创建一个新表，并且从旧表往新表中插入行。现在，当你重新发出持续读之时，它不能在新表中看见任何行，因为它们被插入到一个在持续读读取的快照中不可见的事务 里。</p>
<p>MySQL官方文档中的多版本一致性读中说明了原因：Consistent read does not work over certain DDL statements。</p>
]]></content>
    
    <summary type="html">
    
      mysql-Innodb事务隔离级别-repeatable read详解
    
    </summary>
    
      <category term="mysql" scheme="http://jishusuishouji.github.io/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://jishusuishouji.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>说说MySQL中的事务</title>
    <link href="http://jishusuishouji.github.io/2017/03/27/mysql/%E8%AF%B4%E8%AF%B4MySQL%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1/"/>
    <id>http://jishusuishouji.github.io/2017/03/27/mysql/说说MySQL中的事务/</id>
    <published>2017-03-27T10:27:04.000Z</published>
    <updated>2017-03-27T10:58:26.740Z</updated>
    
    <content type="html"><![CDATA[<h2 id="从一个问题开始"><a href="#从一个问题开始" class="headerlink" title="从一个问题开始"></a>从一个问题开始</h2><p>从ATM机取钱分为以下几个步骤：</p>
<p>1.登陆ATM机，输入密码；<br>2.连接数据库，验证密码；<br>3.验证成功，获得用户信息，比如存款余额等；<br>4.用户输入需要取款的金额，按下确认键；<br>5.从后台数据库中减掉用户账户上的对应金额；<br>6.ATM吐出钱；<br>7.用户把钱拿走。</p>
<p>一个简单的取钱，主要分为以上几步。不知道大家有没有“天真”的想过，如果在第5步中，后台数据库中已经把钱减掉了，但是ATM还就是没有吐出钱（虽然实际也发生过，但是毕竟是低概率事件），这该怎么办？</p>
<p>关于这个问题，银行系统的开发人员早就想过了，那么他们是怎么来搞定这个问题的呢？这就要说到今天总结的事务这个概念了。</p>
<h2 id="简单说说事务"><a href="#简单说说事务" class="headerlink" title="简单说说事务"></a>简单说说事务</h2><p>对于上面的取钱这个事情，如果有一步出现了错误，那么就取消整个取钱的动作；简单来说，就是取钱这7步，要么都完成，要么就啥也不做。在数据库中，事务也是这个道理。</p>
<p>事务由一条或者多条sql语句组成，在事务中的操作，这些sql语句要么都执行，要么都不执行，这就是事务的目的。</p>
<p>对于事务而言，它需要满足ACID特性，下面就简要的说说事务的ACID特性。</p>
<p>A，表示原子性；原子性指整个数据库事务是不可分割的工作单位。只有使事务中所有的数据库操作都执行成功，整个事务的执行才算成功。事务中任何一个sql语句执行失败，那么已经执行成功的sql语句也必须撤销，数据库状态应该退回到执行事务前的状态；<br>C，表示一致性；也就是说一致性指事务将数据库从一种状态转变为另一种一致的状态，在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏；<br>I，表示隔离性；隔离性也叫做并发控制、可串行化或者锁。事务的隔离性要求每个读写事务的对象与其它事务的操作对象能相互分离，即该事务提交前对其它事务都不可见，这通常使用锁来实现；<br>D，持久性，表示事务一旦提交了，其结果就是永久性的，也就是数据就已经写入到数据库了，如果发生了宕机等事故，数据库也能将数据恢复。</p>
<p>总结了一些事务的基本概念，在MySQL中，事务还是分为很多中的，下面就来看看到底有哪些事务。</p>
<h2 id="有哪些事务"><a href="#有哪些事务" class="headerlink" title="有哪些事务"></a>有哪些事务</h2><p>你能想象到吗？就这么个破事务还会分以下这么多种：</p>
<ul>
<li>扁平事务；</li>
<li>带有保存点的扁平事务；</li>
<li>链事务；</li>
<li>嵌套事务；</li>
<li>分布式事务。</li>
</ul>
<p>现在就来对这些事务从概念的层面上进行简单的总结一下。</p>
<h3 id="扁平事务"><a href="#扁平事务" class="headerlink" title="扁平事务"></a>扁平事务</h3><p>扁平事务是最简单的一种，也是实际开发中使用的最多的一种事务。在这种事务中，所有操作都处于同一层次，最常见的方式如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">BEGIN WORK</div><div class="line">    Operation 1</div><div class="line">    Operation 2</div><div class="line">    Operation 3</div><div class="line">    ...</div><div class="line">    Operation N</div><div class="line">COMMIT WORK</div></pre></td></tr></table></figure></p>
<p>或者是这种：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">BEGIN WORK</div><div class="line">    Operation 1</div><div class="line">    Operation 2</div><div class="line">    Operation 3</div><div class="line">    ...</div><div class="line">    Operation N</div><div class="line">    (Error Occured)</div><div class="line">ROLLBACK WORK</div></pre></td></tr></table></figure></p>
<p>扁平事务的主要缺点是不能提交或回滚事务的某一部分，或者分几个独立的步骤去提交。比如有这样的一个例子，我从呼和浩特去深圳，为了便宜，我可能这么干：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">BEGIN WORK</div><div class="line">    Operation1:呼和浩特---火车---&gt;北京</div><div class="line">    Operation2:北京---飞机---&gt;深圳</div><div class="line">ROLLBACK WORK</div></pre></td></tr></table></figure></p>
<p>但是，如果Operation1，从呼和浩特到北京的火车晚点了，错过了航班，怎么办？感觉扁平事务的特性，那我就需要回滚，我再回到呼和浩特，那么这样成本是不是也太高了啊，所以就有了下面的第二种事务——带有保存点的扁平事务。</p>
<h3 id="带有保存点的扁平事务"><a href="#带有保存点的扁平事务" class="headerlink" title="带有保存点的扁平事务"></a>带有保存点的扁平事务</h3><p>这种事务除了支持扁平事务支持的操作外，允许在事务执行过程中回滚到同一事务中较早的一个状态，这是因为可能某些事务在执行过程中出现的错误并不会对所有的操作都无效，放弃整个事务不合乎要求，开销也太大。保存点用来通知系统应该记住事务当前的状态，以便以后发生错误时，事务能回到该状态。</p>
<h3 id="链事务"><a href="#链事务" class="headerlink" title="链事务"></a>链事务</h3><p>链事务，就是指回滚时，只能恢复到最近一个保存点；而带有保存点的扁平事务则可以回滚到任意正确的保存点。</p>
<h3 id="嵌套事务"><a href="#嵌套事务" class="headerlink" title="嵌套事务"></a>嵌套事务</h3><p>看下面这个，你就能明白了，啥是嵌套事务：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">BEGIN WORK</div><div class="line">    SubTransaction1:</div><div class="line">            BEGIN WORK</div><div class="line">                SubOperationX</div><div class="line">            COMMIT WORK</div><div class="line">    SubTransaction2:</div><div class="line">            BEGIN WORK</div><div class="line">                SubOperationY</div><div class="line">            COMMIT WORK</div><div class="line">    ...</div><div class="line">    SubTransactionN:</div><div class="line">            BEGIN WORK</div><div class="line">                SubOperationN</div><div class="line">            COMMIT WORK</div><div class="line">COMMIT WORK</div></pre></td></tr></table></figure></p>
<p>这就是嵌套事务，在事务中再嵌套事务，位于根节点的事务称为顶层事务。事务的前驱称为父事务，其它事务称为子事务。事务的前驱称为父事务，事务的下一层称为子事务。</p>
<p>子事务既可以提交也可以回滚，但是它的提交操作并不马上生效，除非由其父事务提交。因此就可以确定，任何子事务都在顶层事务提交后才真正的被提交了。同理，任意一个事务的回滚都会引起它的所有子事务一同回滚。</p>
<h3 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h3><p>分布式事务通常是指在一个分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点，比如：通过建设银行向招商银行转账，建设银行和招商银行肯定用的不是同一个数据库，同时二者的数据库也不在一个网络节点上，那么当用户跨行转账，就是通过分布式事务来保证数据的ACID的。</p>
<h2 id="MySQL中使用事务"><a href="#MySQL中使用事务" class="headerlink" title="MySQL中使用事务"></a>MySQL中使用事务</h2><p>理论总结的再好，终归都要通过实践来进行理解。下面就来说说MySQL中是如何使用事务的。</p>
<p>在MySQL命令行的默认设置下，事务都是自动提交的，即执行SQL语句后就会马上执行COMMIT操作。因此要显示地开启一个事务须使用命令BEGIN或START TRANSACTION，或者执行命令<code>SET AUTOCOMMIT=0</code>，用来禁止使用当前会话的自动提交。</p>
<p>来看看我们可以使用哪些事务控制语句。</p>
<ul>
<li><code>BEGIN</code>或<code>START TRANSACTION</code>；显示地开启一个事务；</li>
<li><code>COMMIT</code>；也可以使用<code>COMMIT WORK</code>，不过二者是等价的。COMMIT会提交事务，并使已对数据库进行的所有修改称为永久性的；</li>
<li>ROLLBACK；有可以使用ROLLBACK WORK，不过二者是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改；</li>
<li><code>SAVEPOINT identifier</code>；SAVEPOINT允许在事务中创建一个保存点，一个事务中可以有多个SAVEPOINT；</li>
<li>RELEASE SAVEPOINT identifier；删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常；</li>
<li><code>ROLLBACK TO identifier</code>；把事务回滚到标记点；</li>
<li><code>SET RANSACTION</code>；用来设置事务的隔离级别。InnoDB存储引擎提供事务的隔离级别有<code>READ UNCOMMITTED</code>、<code>READ COMMITTED</code>、<code>REPEATABLE READ</code>和<code>SERIALIZABLE</code>。</li>
</ul>
<h2 id="这些不用你“管”"><a href="#这些不用你“管”" class="headerlink" title="这些不用你“管”"></a>这些不用你“管”</h2><p>有的时候有些SQL语句会产生一个隐式的提交操作，即执行完成这些语句后，会有一个隐式的<code>COMMIT</code>操作。有以下SQL语句，不用你去“管”：</p>
<ul>
<li>DDL语句，ALTER DATABASE、ALTER EVENT、ALTER PROCEDURE、ALTER TABLE、ALTER VIEW、CREATE TABLE、DROP TABLE、RENAME TABLE、TRUNCATE TABLE等；</li>
<li>修改MYSQL架构的语句，CREATE USER、DROP USER、GRANT、RENAME USER、REVOKE、SET PASSWORD；</li>
<li>管理语句，ANALYZE TABLE、CACHE INDEX、CHECK TABLE、LOAD INDEX INTO CACHE、OPTIMIZE TABLE、REPAIR TABLE等。</li>
</ul>
<p>以上的这些SQL操作都是隐式的提交操作，不需要手动显式提交。</p>
<h2 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h2><p>上面也说到了<code>SET TRANSACTION</code>用来设置事务的隔离级别。那事务的隔离级别是什么东东？</p>
<p>在数据库操作中，为了有效保证并发读取数据的正确性，提出的事务隔离级别。</p>
<p>InnoDB存储引擎提供事务的隔离级别有READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ和SERIALIZABLE。这些隔离级别之间的区别如下：</p>
<table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读（Dirty Read）</th>
<th>不可重复读（NonRepeatable Read）</th>
<th>幻读（Phantom Read）</th>
</tr>
</thead>
<tbody>
<tr>
<td>未提交读（Read uncommitted）</td>
<td>可能</td>
<td>可能</td>
<td>可能</td>
</tr>
<tr>
<td>已提交读（Read committed）</td>
<td>不可能</td>
<td>可能</td>
<td>可能</td>
</tr>
<tr>
<td>可重复读（Repeatable read）</td>
<td>不可能</td>
<td>不可能</td>
<td>可能</td>
</tr>
<tr>
<td>可串行化（Serializable ）</td>
<td>不可能</td>
<td>不可能</td>
<td>不可能</td>
</tr>
</tbody>
</table>
<p>脏读：一个事务读取到了另外一个事务没有提交的数据；比如：事务T1更新了一行记录的内容，但是并没有提交所做的修改。事务T2读取到了T1更新后的行，然后T1执行回滚操作，取消了刚才所做的修改。现在T2所读取的行就无效了；<br>不可重复读：在同一事务中，两次读取同一数据，得到内容不同；比如：事务T1读取一行记录，紧接着事务T2修改了T1刚才读取的那一行记录(T2的事务已经提交了)。然后T1又再次读取这行记录，发现与刚才读取的结果不同。这就称为“不可重复”读，因为T1原来读取的那行记录已经发生了变化；<br>幻读：同一事务中，用同样的操作读取两次，得到的记录数不相同；比如：事务T1读取一条指定的WHERE子句所返回的结果集。然后事务T2新插入一行记录，这行记录恰好可以满足T1所使用的查询条件中的WHERE子句的条件。然后T1又使用相同的查询再次对表进行检索，但是此时却看到了事务T2刚才插入的新行。这个新行就称为“幻像”，因为对T1来说这一行就像突然出现的一样。</p>
<p>隔离级别越低，事务请求的锁越少或保持锁的时间就越短。InnoDB存储引擎默认的支持隔离级别是<code>REPEATABLE READ</code>；在这种默认的事务隔离级别下已经能完全保证事务的隔离性要求，即达到SQL标准的SERIALIZABLE级别隔离。</p>
<p>我们可以可以用<code>SET TRANSACTION</code>语句改变单个会话或者所有新进连接的隔离级别。它的语法如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">SET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL &#123;READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE&#125;</div></pre></td></tr></table></figure></p>
<p>注意：默认的行为（不带session和global）是为下一个（未开始）事务设置隔离级别。如果使用GLOBAL关键字，语句在全局对从那点开始创建的所有新连接（除了不存在的连接）设置默认事务级别。你需要SUPER权限来做这个。使用SESSION 关键字为将来在当前连接上执行的事务设置默认事务级别。 任何客户端都能自由改变会话隔离级别（甚至在事务的中间），或者为下一个事务设置隔离级别。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">mysql&gt; set session transaction isolation level repeatable read;</div><div class="line">Query OK, 0 rows affected (0.00 sec)</div><div class="line"></div><div class="line">mysql&gt; select @@tx_isolation;</div><div class="line">+-----------------+</div><div class="line">| @@tx_isolation  |</div><div class="line">+-----------------+</div><div class="line">| REPEATABLE-READ |</div><div class="line">+-----------------+</div><div class="line">1 row in set (0.00 sec)</div></pre></td></tr></table></figure></p>
<h2 id="数据库的默认隔离级别"><a href="#数据库的默认隔离级别" class="headerlink" title="数据库的默认隔离级别"></a>数据库的默认隔离级别</h2><h3 id="mysql的默认隔离级别是可重复读："><a href="#mysql的默认隔离级别是可重复读：" class="headerlink" title="mysql的默认隔离级别是可重复读："></a>mysql的默认隔离级别是可重复读：</h3><p>要是读为主的业务场景，建议RC模式；若是非读为主的业务场景，则建议RR模式，考虑到MySQL5.1及以上版本二进制日志登记格式，建议优先考虑RR模式。</p>
<h3 id="Oracle采用的也是-read-committed"><a href="#Oracle采用的也是-read-committed" class="headerlink" title="Oracle采用的也是 read committed"></a>Oracle采用的也是 read committed</h3><p>Oracle的RC 跟InnoDB存储引擎的RC不是一样的，属于综合了 RC + RR的折中版本。</p>
]]></content>
    
    <summary type="html">
    
      说说MySQL中的事务
    
    </summary>
    
      <category term="mysql" scheme="http://jishusuishouji.github.io/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://jishusuishouji.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>ORM到底是用还是不用？</title>
    <link href="http://jishusuishouji.github.io/2017/03/27/ORM/ORM%E5%88%B0%E5%BA%95%E6%98%AF%E7%94%A8%E8%BF%98%E6%98%AF%E4%B8%8D%E7%94%A8%EF%BC%9F/"/>
    <id>http://jishusuishouji.github.io/2017/03/27/ORM/ORM到底是用还是不用？/</id>
    <published>2017-03-27T05:22:54.000Z</published>
    <updated>2017-03-27T05:26:18.258Z</updated>
    
    <content type="html"><![CDATA[<p>ORM即Object/Relation Mapping的简写，一般称作“对象关系映射”，在Web开发中最常出没于和关系型数据库交互的地方。接口、中间件、库、包，你都可以这么称呼它。<br><a id="more"></a><br>我们可以结合PHP和MySQL，从ORM的四个核心理念来认识它：</p>
<ul>
<li>简单：ORM以最基本的形式建模数据。比如ORM会将MySQL的一张表映射成一个PHP类（模型），表的字段就是这个类的成员变量</li>
<li>精确：ORM使所有的MySQL数据表都按照统一的标准精确地映射成PHP类，使系统在代码层面保持准确统一</li>
<li>易懂：ORM使数据库结构文档化。比如MySQL数据库就被ORM转换为了PHP程序员可以读懂的PHP类，PHP程序员可以只把注意力放在他擅长的PHP层面（当然能够熟练掌握MySQL更好）</li>
<li>易用：ORM的避免了不规范、冗余、风格不统一的SQL语句，可以避免很多人为Bug，方便编码风格的统一和后期维护</li>
</ul>
<p>接下来再通过一个很基本的例子来说明一下ORM的使用，还以PHP和MySQL为例。</p>
<p>user这个数据模型是再普遍不过的了。假设我们有一张user数据表。</p>
<p>在OOP中通常我们需要写一个对应的class User来作为user数据表的数据模型:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">// 声明class User</div><div class="line">class User&#123;</div><div class="line">    $id;</div><div class="line">    $name;</div><div class="line"></div><div class="line">    function create()&#123;/*...*/&#125;</div><div class="line">    function load($id)&#123;/*...*/&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">// 使用class User</div><div class="line">$user = new User();</div><div class="line">$user-&gt;name = &apos;fancy&apos;;</div><div class="line">$user-&gt;create();</div></pre></td></tr></table></figure>
<p>但是通过ORM，我们可以不用去声明class User，可以直接继承ORM提供的工厂类，比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">// 直接使用！对于熟悉MVC的亲知道这个意义之所在！</div><div class="line">$user = new ORM(&apos;user&apos;);  // ORM都有自己的规则，这里直接使用了MySQL的表名</div><div class="line">$user-&gt;name = &apos;fancy&apos;;    // MySQL的表的字段就是$user对象的成员变量</div><div class="line">$user-&gt;save();            // 掉用ORM提供的接口函数</div></pre></td></tr></table></figure></p>
<p>ORM一般都针对数据模型提供了一下常见的接口函数，比如：<code>create()</code>, <code>update()</code>, <code>save()</code>, <code>load()</code>, <code>find()</code>, <code>find_all()</code>, <code>where()</code>等，也就是讲sql查询全部封装成了编程语言中的函数，通过函数的链式组合生成最终的SQL语句。</p>
<p>所以由这些来看，ORM对于敏捷开发和团队合作开发来说，好处是非常非常大的。这里就罗列一下我想到的ORM显著的优点：</p>
<ul>
<li>大大缩短了程序员的编码时间，减少甚至免除了对Model的编码</li>
<li>良好的数据库操作接口，使编码难度降低，使团队成员的代码变得简洁易读、风格统一</li>
<li>动态的数据表映射，在数据表结构甚至数据库发生改变时，减少了相应的代码修改</li>
<li>减少了程序员对数据库的学习成本</li>
<li>可以很方便地引入数据缓存之类的附加功能</li>
</ul>
<p>但是ORM并不是一个完美的东西，它同时也有其自身不可避免的缺点：</p>
<ul>
<li>自动化进行关系数据库的映射需要消耗系统性能。其实这里的性能消耗还好啦，一般来说都可以忽略之，特别是有cacha存在的时候</li>
<li>在处理多表联查、where条件复杂之类的查询时，ORM的语法会变得复杂且猥琐</li>
<li>越是功能强大的ORM越是消耗内存，因为一个ORM Object会带有很多成员变量和成员函数。有一次修复bug时就遇见，使用ORM查询的时候会占用12MB的内存，而使用SQL的查询时只占用了1.7MB……</li>
</ul>
<p>ORM就是这么一个让人又爱又恨的东西。回到我们开始的问题：“ORM到底是用还是不用？”</p>
<p>Fancy个人的观点是：ORM要用！但关键部位不能用！<br>因为对于一般的Web应用开发来说，使用ORM确实能带来上述的诸多好处，而且在大部分情况下涉及不到ORM的不好的地方。但是在系统里面有大数据量、大运算量、复杂查询的地方，就不要用ORM。ORM的性能问题将给你带来灾难。在这些地方就可以使用纯SQL或者其他简单轻量的DB Helper库了。在详细了解ORM之后，你就可以扬长避短让ORM发挥其最大效用了。</p>
]]></content>
    
    <summary type="html">
    
      ORM到底是用还是不用？
    
    </summary>
    
      <category term="ORM" scheme="http://jishusuishouji.github.io/categories/ORM/"/>
    
    
      <category term="ORM" scheme="http://jishusuishouji.github.io/tags/ORM/"/>
    
  </entry>
  
  <entry>
    <title>maven 多模块项目</title>
    <link href="http://jishusuishouji.github.io/2017/03/27/maven/maven_%E5%A4%9A%E6%A8%A1%E5%9D%97%E9%A1%B9%E7%9B%AE/"/>
    <id>http://jishusuishouji.github.io/2017/03/27/maven/maven_多模块项目/</id>
    <published>2017-03-27T02:16:27.000Z</published>
    <updated>2017-03-27T02:16:27.306Z</updated>
    
    <summary type="html">
    
      maven 多模块项目
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Maven最佳实践：划分模块</title>
    <link href="http://jishusuishouji.github.io/2017/03/27/maven/Maven%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%EF%BC%9A%E5%88%92%E5%88%86%E6%A8%A1%E5%9D%97/"/>
    <id>http://jishusuishouji.github.io/2017/03/27/maven/Maven最佳实践：划分模块/</id>
    <published>2017-03-27T02:00:50.000Z</published>
    <updated>2017-03-27T02:15:42.058Z</updated>
    
    <content type="html"><![CDATA[<p>“分天下为三十六郡，郡置守，尉，监” —— 《史记·秦始皇本纪》</p>
<p>所有用Maven管理的真实的项目都应该是分模块的，每个模块都对应着一个<code>pom.xml</code>。它们之间通过继承和聚合（也称作多模块，multi-module）相互关联。那么，为什么要这么做呢？我们明明在开发一个项目，划分模块后，导入Eclipse变成了N个项目，这会带来复杂度，给开发带来不便。<br><a id="more"></a><br>为了解释原因，假设有这样一个项目，很常见的Java Web应用。在这个应用中，我们分了几层：</p>
<ul>
<li>Dao层负责数据库交互，封装了Hibernate交互的类。</li>
<li>Service层处理业务逻辑，放一些Service接口和实现相关的Bean。</li>
<li>Web层负责与客户端交互，主要有一些Structs的Action类。</li>
</ul>
<p>对应的，在一个项目中，我们会看到一些包名：</p>
<ul>
<li><code>org.myorg.app.dao</code></li>
<li><code>org.myorg.app.service</code></li>
<li><code>org.myorg.app.web</code></li>
<li><code>org.myorg.app.util</code></li>
</ul>
<p>这样整个项目的框架就清晰了，但随着项目的进行，你可能会遇到如下问题：<br>这个应用可能需要有一个前台和一个后台管理端（web或者swing），你发现大部分dao，一些service，和大部分util是在两个应用中可用的。这样的问题，你一周内遇到了好几次。<br><code>pom.xml</code>中的依赖列表越来越长以重用的，但是，由于目前只有一个项目（WAR），你不得不新建一个项目依赖这个WAR，这变得非常的恶心，因为在Maven中配置对WAR的依赖远不如依赖JAR那样简单明了，而且你根本不需要<code>org.myorg.app.web</code>。有人修改了dao，提交到svn并且不小心导致build失败了，你在编写service的代码，发现编译不过，只能等那人把dao修复了，你才能继续进行，很多人都在修改，到后来你根本就不清楚哪个依赖是谁需要的，渐渐的，很多不必要的依赖被引入。甚至出现了一个依赖有多个版本存在。<br>build整个项目的时间越来越长，尽管你只是一直在web层工作，但你不得不build整个项目。<br>某个模块，比如util，你只想让一些经验丰富的人来维护，可是，现在这种情况，每个开发者都能修改，这导致关键模块的代码质量不能达到你的要求。<br>我们会发现，其实这里实际上没有遵守一个设计模式原则：“高内聚，低耦合”。虽然我们通过包名划分了层次，并且你还会说，这些包的依赖都是单向的，没有包的环依赖。这很好，但还不够，因为就构建层次来说，所有东西都被耦合在一起了。因此我们需要使用Maven划分模块。</p>
<p>一个简单的Maven模块结构是这样的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">---- app-parent</div><div class="line">             |-- pom.xml (pom)</div><div class="line">             |</div><div class="line">             |-- app-util</div><div class="line">             |        |-- pom.xml (jar)</div><div class="line">             |</div><div class="line">             |-- app-dao</div><div class="line">             |        |-- pom.xml (jar)</div><div class="line">             |</div><div class="line">             |-- app-service</div><div class="line">             |        |-- pom.xml (jar)</div><div class="line">             |</div><div class="line">             |-- app-web</div><div class="line">                      |-- pom.xml (war)</div></pre></td></tr></table></figure></p>
<p>上述简单示意图中，有一个父项目(app-parent)聚合很多子项目（app-util, app-dao, app-service, app-web）。每个项目，不管是父子，都含有一个<code>pom.xml</code>文件。而且要注意的是，小括号中标出了每个项目的打包类型。父项目是pom,也只能是pom。子项目有jar，或者war。根据它包含的内容具体考虑。</p>
<p>这些模块的依赖关系如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">app-dao      --&gt; app-util</div><div class="line">app-service --&gt; app-dao</div><div class="line">app-web     --&gt; app-service</div></pre></td></tr></table></figure></p>
<p>注意依赖的传递性（大部分情况是传递的，除非你配置了特殊的依赖scope），app-dao依赖于app-util，app-service依赖于app-dao，于是app-service也依赖于app-util。同理，app-web依赖于app-dao,app-util。</p>
<p>用<strong>项目层次的划分</strong>替<strong>代包层次的划分</strong>能给我们带来如下好处：</p>
<ul>
<li>方便重用，如果你有一个新的swing项目需要用到app-dao和app-service，添加对它们的依赖即可，你不再需要去依赖一个WAR。而有些模块，如app-util，完全可以渐渐进化成公司的一份基础工具类库，供所有项目使用。这是模块化最重要的一个目的。</li>
<li>由于你现在划分了模块，每个模块的配置都在各自的<code>pom.xml</code>里，不用再到一个混乱的纷繁复杂的总的POM中寻找自己的配置。</li>
<li>如果你只是在app-dao上工作，你不再需要build整个项目，只要在app-dao目录运行<code>mvn</code>命令进行build即可，这样可以节省时间，尤其是当项目越来越复杂，build越来越耗时后。</li>
<li>某些模块，如app-util被所有人依赖，但你不想给所有人修改，现在你完全可以从这个项目结构出来，做成另外一个项目，svn只给特定的人访问，但仍提供jar给别人使用。</li>
<li>多模块的Maven项目结构支持一些Maven的更有趣的特性（如<code>DepencencyManagement</code>），这留作以后讨论。</li>
<li>接下来讨论一下POM配置细节，实际上非常简单，先看app-parent的<code>pom.xml</code>：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  </div><div class="line">    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;  </div><div class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  </div><div class="line">    &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt;  </div><div class="line">    &lt;artifactId&gt;app-parent&lt;/artifactId&gt;  </div><div class="line">    &lt;packaging&gt;pom&lt;/packaging&gt;  </div><div class="line">    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  </div><div class="line">    &lt;modules&gt;  </div><div class="line">        &lt;module&gt;app-util&lt;/module&gt;  </div><div class="line">        &lt;module&gt;app-dao&lt;/module&gt;  </div><div class="line">        &lt;module&gt;app-service&lt;/module&gt;  </div><div class="line">        &lt;module&gt;app-web&lt;/module&gt;  </div><div class="line">    &lt;/modules&gt;  </div><div class="line">&lt;/project&gt;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>Maven的坐标GAV（<code>groupId</code>, <code>artifactId</code>, <code>version</code>）在这里进行配置，这些都是必须的。特殊的地方在于，这里的<code>packaging</code>为<code>pom</code>。所有带有子模块的项目的<code>packaging</code>都为<code>pom</code>。<code>packaging</code>如果不进行配置，它的默认值是<code>jar</code>，代表Maven会将项目打成一个jar包。<br>该配置重要的地方在于modules，例子中包含的子模块有app-util, app-dao, app-service, app-war。在Maven build app-parent的时候，它会根据子模块的相互依赖关系整理一个build顺序，然后依次build。<br>这就是一个父模块大概需要的配置，接下来看一下子模块符合配置继承父模块。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  </div><div class="line">    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;  </div><div class="line">    &lt;parent&gt;  </div><div class="line">        &lt;artifactId&gt;app-parent&lt;/artifactId&gt;  </div><div class="line">        &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt;  </div><div class="line">        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  </div><div class="line">    &lt;/parent&gt;  </div><div class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  </div><div class="line">    &lt;artifactId&gt;app-util&lt;/artifactId&gt;  </div><div class="line">    &lt;dependencies&gt;  </div><div class="line">        &lt;dependency&gt;  </div><div class="line">            &lt;groupId&gt;commons-lang&lt;/groupId&gt;  </div><div class="line">            &lt;artifactId&gt;commons-lang&lt;/artifactId&gt;  </div><div class="line">            &lt;version&gt;2.4&lt;/version&gt;  </div><div class="line">        &lt;/dependency&gt;  </div><div class="line">    &lt;/dependencies&gt;  </div><div class="line">&lt;/project&gt;</div></pre></td></tr></table></figure></p>
<p>app-util模块继承了app-parent父模块，因此这个POM的一开始就声明了对app-parent的引用，该引用是通过Maven坐标GAV实现的。而关于项目app-util本身，它却没有声明完整GAV，这里我们只看到了artifactId。这个POM并没有错，groupId和version默认从父模块继承了。实际上子模块从父模块继承一切东西，包括依赖，插件配置等等。<br>此外app-util配置了一个对于commons-lang的简单依赖，这是最简单的依赖配置形式。大部分情况，也是通过GAV引用的。<br>再看一下app-dao，它也是继承于app-parent，同时依赖于app-util：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  </div><div class="line">    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;  </div><div class="line">    &lt;parent&gt;  </div><div class="line">        &lt;artifactId&gt;app-parent&lt;/artifactId&gt;  </div><div class="line">        &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt;  </div><div class="line">        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  </div><div class="line">    &lt;/parent&gt;  </div><div class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  </div><div class="line">    &lt;artifactId&gt;app-dao&lt;/artifactId&gt;  </div><div class="line">    &lt;dependencies&gt;  </div><div class="line">        &lt;dependency&gt;  </div><div class="line">            &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt;  </div><div class="line">            &lt;artifactId&gt;app-util&lt;/artifactId&gt;  </div><div class="line">            &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt;  </div><div class="line">        &lt;/dependency&gt;  </div><div class="line">    &lt;/dependencies&gt;  </div><div class="line">&lt;/project&gt;</div></pre></td></tr></table></figure></p>
<p>该配置和app-util的配置几乎没什么差别，不同的地方在于，依赖变化了，app-dao依赖于app-util。这里要注意的是version的值为<code>${project.version}</code>，这个值是一个属性引用，指向了POM的project/version的值，也就是这个POM对应的version。由于app-dao的version继承于app-parent，因此它的值就是<code>1.0-SNAPSHOT</code>。而<code>app-util</code>也继承了这个值，因此在所有这些项目中，我们做到了保持版本一致。<br>这里还需要注意的是，app-dao依赖于app-util，而app-util又依赖于commons-lang，根据传递性，app-dao也拥有了对于commons-lang的依赖。<br>app-service我们跳过不谈，它依赖于app-dao。我们最后看一下app-web：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  </div><div class="line">    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;  </div><div class="line">    &lt;parent&gt;  </div><div class="line">        &lt;artifactId&gt;app-parent&lt;/artifactId&gt;  </div><div class="line">        &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt;  </div><div class="line">        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  </div><div class="line">    &lt;/parent&gt;  </div><div class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  </div><div class="line">    &lt;artifactId&gt;app-web&lt;/artifactId&gt;  </div><div class="line">    &lt;packaging&gt;war&lt;/packaging&gt;  </div><div class="line">    &lt;dependencies&gt;  </div><div class="line">        &lt;dependency&gt;  </div><div class="line">            &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt;  </div><div class="line">            &lt;artifactId&gt;app-service&lt;/artifactId&gt;  </div><div class="line">            &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt;  </div><div class="line">        &lt;/dependency&gt;  </div><div class="line">    &lt;/dependencies&gt;  </div><div class="line">&lt;/project&gt;</div></pre></td></tr></table></figure></p>
<p>app-web依赖于app-service，因此配置了对其的依赖。<br>由于app-web是我们最终要部署的应用，因此它的packaging是war。为此，你需要有一个目录<code>src/main/webapp</code>。并在这个目录下拥有web应用需要的文件，如<code>/WEB-INF/web.xml</code>。没有web.xml，Maven会报告build失败，此外你可能还会有这样一些子目录：/js, /img, /css … 。</p>
<p>看看Maven是如何build整个项目的，我们在 app-parent 根目录中运行 <code>mvn clean install</code> ，输出的末尾会有大致这样的内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line">...</div><div class="line">[INFO] [war:war]</div><div class="line">[INFO] Packaging webapp</div><div class="line">[INFO] Assembling webapp[app-web] in [/home/juven/workspaces/ws-others/myapp/app-web/target/app-web-1.0-SNAPSHOT]</div><div class="line">[INFO] Processing war project</div><div class="line">[INFO] Webapp assembled in[50 msecs]</div><div class="line">[INFO] Building war: /home/juven/workspaces/ws-others/myapp/app-web/target/app-web-1.0-SNAPSHOT.war</div><div class="line">[INFO] [install:install]</div><div class="line">[INFO] Installing /home/juven/workspaces/ws-others/myapp/app-web/target/app-web-1.0-SNAPSHOT.war to /home/juven/.m2/repository/org/myorg/myapp/app-web/1.0-SNAPSHOT/app-web-1.0-SNAPSHOT.war</div><div class="line">[INFO] </div><div class="line">[INFO] </div><div class="line">[INFO] ------------------------------------------------------------------------</div><div class="line">[INFO] Reactor Summary:</div><div class="line">[INFO] ------------------------------------------------------------------------</div><div class="line">[INFO] app-parent ............................................ SUCCESS [1.191s]</div><div class="line">[INFO] app-util .............................................. SUCCESS [1.274s]</div><div class="line">[INFO] app-dao ............................................... SUCCESS [0.583s]</div><div class="line">[INFO] app-service ........................................... SUCCESS [0.593s]</div><div class="line">[INFO] app-web ............................................... SUCCESS [0.976s]</div><div class="line">[INFO] ------------------------------------------------------------------------</div><div class="line">[INFO] ------------------------------------------------------------------------</div><div class="line">[INFO] BUILD SUCCESSFUL</div><div class="line">[INFO] ------------------------------------------------------------------------</div><div class="line">[INFO] Total time: 4 seconds</div><div class="line">[INFO] Finished at: Sat Dec 27 08:20:18 PST 2008</div><div class="line">[INFO] Final Memory: 3M/17M</div><div class="line">[INFO] ------------------------------------------------------------------------</div></pre></td></tr></table></figure></p>
<p>注意Reactor Summary，整个项目根据我们希望的顺序进行build。Maven根据我们的依赖配置，智能的安排了顺序，app-util, app-dao, app-service, app-web。</p>
<p>最后，你可以在 <code>app-web/target</code> 目录下找到文件 <code>app-web-1.0-SNAPSHOT.war</code> ，打开这个war包，在 <code>/WEB-INF/lib</code> 目录看到了 commons-lang-2.4.jar，以及对应的app-util, app-dao, app-service 的jar包。Maven自动帮你处理了打包的事情，并且根据你的依赖配置帮你引入了相应的jar文件。</p>
<p>使用多模块的Maven配置，可以帮助项目划分模块，鼓励重用，防止POM变得过于庞大，方便某个模块的构建，而不用每次都构建整个项目，并且使得针对某个模块的特殊控制更为方便。本文同时给出了一个实际的配置样例，展示了如何使用Maven配置多模块项目。</p>
]]></content>
    
    <summary type="html">
    
      Maven最佳实践：划分模块
    
    </summary>
    
      <category term="maven" scheme="http://jishusuishouji.github.io/categories/maven/"/>
    
    
      <category term="maven" scheme="http://jishusuishouji.github.io/tags/maven/"/>
    
  </entry>
  
  <entry>
    <title>mongodb最大连接数修改</title>
    <link href="http://jishusuishouji.github.io/2017/03/26/mongodb/mongodb%E6%9C%80%E5%A4%A7%E8%BF%9E%E6%8E%A5%E6%95%B0%E4%BF%AE%E6%94%B9/"/>
    <id>http://jishusuishouji.github.io/2017/03/26/mongodb/mongodb最大连接数修改/</id>
    <published>2017-03-26T11:22:25.000Z</published>
    <updated>2017-03-26T11:29:33.693Z</updated>
    
    <content type="html"><![CDATA[<p>在nodejs启动时一次性开了200个Mongodb连接，目的是为了高并发时减少数据库连接耗时。如果做cluster开10个实例就有2000个连接了，这样就有些节点连接不到数据库的情况。</p>
<p>原因是Mongodb默认最大连接数只有819个，于是通过在启动里面加参数<code>--maxConns=3000</code>来提高最大连接数。然后重启服务，但悲剧的是通过<code>db.serverStatus().connections;</code>查看到最大连接数还是<code>819</code>。原因是linux系统的限制，Linux系统默认一个进程最大文件打开数目为1024。需要在Mongodb开启前修改这个限制。在运行数据前运行<code>ulimit -n</code>命令 。如果已经加入开机脚本，就要在脚本中启动前增加这行了。比如：</p>
<pre><code>ulimit -n 20000
/usr/mongodb/bin/mongod --dbpath=/usr/mongodb/data/ --logpath=/usr/mongodb/log/mongodb.log  --maxConns=3000  --fork
</code></pre><p>再查看就可以看到最大连接数增加了。</p>
<h2 id="重启机器后仍有问题"><a href="#重启机器后仍有问题" class="headerlink" title="重启机器后仍有问题"></a>重启机器后仍有问题</h2><p>解决问题：<code>Invariant failure: ret resulted in status UnknownError 24: Too many open files at src/mongo/db/storage/wiredtiger/wiredtiger_session_cache.cpp 73</code></p>
<p>按照官方的建议<a href="https://docs.mongodb.com/manual/reference/ulimit/#recommended-ulimit-settings，" target="_blank" rel="external">https://docs.mongodb.com/manual/reference/ulimit/#recommended-ulimit-settings，</a> 由于centos 6的最大进程连接数为1024，我们就增加一个限制设定的配置</p>
<blockquote>
<p>Red Hat Enterprise Linux and CentOS 6 place a max process limitation of 1024 which overridesulimit settings. Create a file named /etc/security/limits.d/99-mongodb-nproc.conf with new soft nproc and hard nproc values to increase the process limit. See /etc/security/limits.d/90-nproc.conf file as an example.</p>
</blockquote>
<p>按照官方推荐的设置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">-f (file size): unlimited</div><div class="line">-t (cpu time): unlimited</div><div class="line">-v (virtual memory): unlimited [1]</div><div class="line">-n (open files): 64000</div><div class="line">-m (memory size): unlimited [1] [2]</div><div class="line">-u (processes/threads): 64000</div></pre></td></tr></table></figure></p>
<p>由于服务器只有openfiles不匹配且比推荐的小，另外process/threads比较大， 所以其中99-mongodb-nproc.conf的内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># Default limit for number of user&apos;s processes to prevent</div><div class="line"># accidental fork bombs.</div><div class="line"># See rhbz #432903 for reasoning.</div><div class="line"> </div><div class="line">root       soft    nproc     unlimited</div><div class="line">root       hard    nproc     unlimited</div><div class="line">root       soft    nofile    64000</div><div class="line">root       hard    nofile    64000</div></pre></td></tr></table></figure></p>
<p>设计后重启机器，可用<code>ulimit -a</code>看到值已经更改，问题解决。</p>
]]></content>
    
    <summary type="html">
    
      mongodb最大连接数修改
    
    </summary>
    
      <category term="mongodb" scheme="http://jishusuishouji.github.io/categories/mongodb/"/>
    
    
      <category term="mongodb" scheme="http://jishusuishouji.github.io/tags/mongodb/"/>
    
  </entry>
  
  <entry>
    <title>Spring Cloud Netflix构建微服务入门实践</title>
    <link href="http://jishusuishouji.github.io/2017/03/26/spring/Spring_Cloud_Netflix%E6%9E%84%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"/>
    <id>http://jishusuishouji.github.io/2017/03/26/spring/Spring_Cloud_Netflix构建微服务入门实践/</id>
    <published>2017-03-26T09:57:46.000Z</published>
    <updated>2017-03-27T02:15:42.669Z</updated>
    
    <content type="html"><![CDATA[<p>在使用Spring Cloud Netflix构建微服务之前，我们先了解一下Spring Cloud集成的Netflix OSS的基础组件Eureka，对于Netflix的其他微服务组件，像Hystrix、Zuul、Ribbon等等本文暂不涉及，感兴趣可以参考官网文档。这里，我们用最基础的Eureka来构建一个最基础的微服务应用，来演示如何构建微服务，了解微服务的基本特点。</p>
<h2 id="Eureka"><a href="#Eureka" class="headerlink" title="Eureka"></a>Eureka</h2><p>Eureka是Netflix开源的一个微服务注册组件，提供服务发现特性，它是一个基于REST的服务，主要具有如下功能：</p>
<ul>
<li>支持服务注册和发现</li>
<li>具有Load Balance和Failover的功能</li>
<li>在进行服务调用过程中，无需知道目标服务的主机（IP）和端口，只要知道服务名就可以实现调用</li>
</ul>
<p>通过Netfix在Github上的文档，我们看一下Eureka的基本架构，如下图所示：<br><img src="/img/Eureka的基本架构.png" alt="eureka_architecture"><br>Eureka主要包含如下两个核心组件：</p>
<h3 id="Eureka-Server"><a href="#Eureka-Server" class="headerlink" title="Eureka Server"></a>Eureka Server</h3><p>Eureka Server是服务注册的服务端组件，负责管理Eureka Client注册的服务，提供服务发现的功能。它支持集群模式部署，集群部署模式中，多个Eureka Server之间会同步服务注册数据，能够保证某一个Eureka Server因为故障挂掉，仍能对外提供注册服务的能力。因为最初在Netflix，Eureka主要用在AWS Cloud上，用作定位服务、Load Balance和Failover，在AWS Cloud上，Eureka支持在多个Region中部署Eureka Server而构建一个注册中心集群，从而实现了服务注册中心的高可用性。</p>
<h3 id="Eureka-Client"><a href="#Eureka-Client" class="headerlink" title="Eureka Client"></a>Eureka Client</h3><p>Eureka Client是Eureka Server客户端组件库，可以基于它向Eureka Server注册服务，供服务调用方调用；也可以是一个服务调用方，通过检索服务并调用已经注册的服务。如上图所示，Application Service和Application Client都是基于Eureka Client开发的使用Eureka Server的服务。另外，Eureka Client提供了内置的Load Balancer，实现了基本的Round-robin模式的负载均衡。</p>
<h2 id="Spring-Cloud-Netflix"><a href="#Spring-Cloud-Netflix" class="headerlink" title="Spring Cloud Netflix"></a>Spring Cloud Netflix</h2><p>Spring Cloud Netflix提供了对Netflix OSS的集成，同时还使用了Spring Boot，能够极大地简化微服务程序的开发。使用Spring Cloud提供的基本注解，就能非常方便的使用Netfix OSS基本组件。<br>要想使用Spring Cloud Eureka，只需要在Maven POM文件中加入如下依赖管理配置即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&lt;dependencyManagement&gt;</div><div class="line">    &lt;dependencies&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spring-cloud-netflix&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;1.0.7.RELEASE&lt;/version&gt;</div><div class="line">            &lt;type&gt;pom&lt;/type&gt;</div><div class="line">            &lt;scope&gt;import&lt;/scope&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">    &lt;/dependencies&gt;</div><div class="line">&lt;/dependencyManagement&gt;</div></pre></td></tr></table></figure></p>
<p>关于如何使用注解，我们会在下面的实践中，详细说明。</p>
<h2 id="构建微服务实践"><a href="#构建微服务实践" class="headerlink" title="构建微服务实践"></a>构建微服务实践</h2><p>我们构建一个简单的微服务应用，能够实现服务注册，服务调用的基本功能。计划实现的微服务应用，交互流程如下图所示：<br><img src="/img/eureka-service-interaction.png" alt="eureka-service-interaction"><br>上图中，我们假设Eureka Client并没有缓存Eureka Server中注册的服务，而是每次都需要通过Eureka Server来查找并映射目标服务。上图所示的微服务应用，具有如下服务组件：</p>
<p>两个Eureka Server实例组成的服务发现集群<br>通过Spring Cloud实现，只需要使用注解配置即可，代码如下所示：</p>
<p>01<br>package org.shirdrn.springcloud.eureka.server;<br>02</p>
<p>03<br>import org.springframework.boot.autoconfigure.SpringBootApplication;<br>04<br>import org.springframework.boot.builder.SpringApplicationBuilder;<br>05<br>import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;<br>06</p>
<p>07<br>@EnableEurekaServer<br>08<br>@SpringBootApplication<br>09<br>public class MyEurekaServer {<br>10</p>
<p>11<br>    public static void main(String[] args) {<br>12<br>        new SpringApplicationBuilder(MyEurekaServer.class).web(true).run(args);<br>13<br>    }<br>14<br>}<br>部署两个Eureka Server的代码是相同的，其中，对应的配置文件application.yml内容不同，示例如下所示：</p>
<p>01<br>server:<br>02<br>  port: 3300<br>03<br>spring:<br>04<br>  application:<br>05<br>    name: my-eureka-server<br>06<br>eureka:<br>07<br>  client:<br>08<br>    serviceUrl:<br>09<br>      defaultZone: <a href="http://localhost:3300/eureka/,http://localhost:3301/eureka/" target="_blank" rel="external">http://localhost:3300/eureka/,http://localhost:3301/eureka/</a><br>10<br>  instance:<br>11<br>    metadataMap:<br>12<br>      instanceId: ${spring.application.name}:${spring.application.instance_id:${random.value}}<br>另一个只需要改一下server.port为3301即可。</p>
<p>具有两个实例的Greeting Service服务<br>该示例服务，只是提供一个接口，能够给调用方返回调用结果，实现代码，如下所示：</p>
<p>01<br>package org.shirdrn.springcloud.eureka.applicationservice.greeting;<br>02</p>
<p>03<br>import org.springframework.boot.autoconfigure.EnableAutoConfiguration;<br>04<br>import org.springframework.boot.autoconfigure.SpringBootApplication;<br>05<br>import org.springframework.boot.builder.SpringApplicationBuilder;<br>06<br>import org.springframework.cloud.netflix.eureka.EnableEurekaClient;<br>07<br>import org.springframework.web.bind.annotation.PathVariable;<br>08<br>import org.springframework.web.bind.annotation.RequestMapping;<br>09<br>import org.springframework.web.bind.annotation.RequestMethod;<br>10<br>import org.springframework.web.bind.annotation.RestController;<br>11</p>
<p>12<br>@SpringBootApplication<br>13<br>@EnableEurekaClient<br>14<br>@RestController<br>15<br>@EnableAutoConfiguration<br>16<br>public class GreeingService {<br>17</p>
<p>18<br>    @RequestMapping(method = RequestMethod.GET, value = “/greeting/{name}”)<br>19<br>    public String greet(@PathVariable(“name”) String name) {<br>20<br>        return “::01:: Hello, “ + name + “!”;<br>21<br>    }<br>22</p>
<p>23<br>    public static void main(String[] args) {<br>24<br>        new SpringApplicationBuilder(GreeingService.class).web(true).run(args);<br>25<br>    }<br>26<br>}<br>为了能够观察，Greeting Service的两个实例，能够在调用的时候实现Round-robin风格的负载均衡，特别在返回的结果中增加了标识来区分。<br>对应的配置文件application.properties内容，除了对应的端口和服务实例名称不同，其它都相同，示例如下所示：</p>
<p>1<br>server.port=9901<br>2<br>spring.application.name = greeting.service<br>3<br>eureka.instance.metadataMap.instanceId = ${spring.application.name}:instance-9901<br>4<br>eureka.client.serviceUrl.defaultZone = <a href="http://localhost:3300/eureka/,http://localhost:3301/eureka/" target="_blank" rel="external">http://localhost:3300/eureka/,http://localhost:3301/eureka/</a><br>这样就可以在启动时注册到Eureka Server中。</p>
<p>一个名称为Application Caller的服务，需要调用Greeting Service服务<br>该服务和上面的服务类似，只是在其内部实现了对远程服务的调用，我们的实现代码如下所示：</p>
<p>01<br>package org.shirdrn.springcloud.eureka.applicationclient.caller;<br>02</p>
<p>03<br>import org.springframework.beans.factory.annotation.Autowired;<br>04<br>import org.springframework.boot.CommandLineRunner;<br>05<br>import org.springframework.boot.autoconfigure.SpringBootApplication;<br>06<br>import org.springframework.boot.builder.SpringApplicationBuilder;<br>07<br>import org.springframework.cloud.netflix.eureka.EnableEurekaClient;<br>08<br>import org.springframework.cloud.netflix.feign.EnableFeignClients;<br>09<br>import org.springframework.stereotype.Component;<br>10<br>import org.springframework.web.client.RestTemplate;<br>11</p>
<p>12<br>@SpringBootApplication<br>13<br>@EnableEurekaClient<br>14<br>@EnableFeignClients<br>15<br>public class Application {<br>16</p>
<p>17<br>    public static void main(String[] args) {<br>18<br>        new SpringApplicationBuilder(Application.class)<br>19<br>                .web(false)<br>20<br>                .run(args);<br>21<br>    }<br>22<br>}<br>23</p>
<p>24<br>@Component<br>25<br>class RestTemplateExample implements CommandLineRunner {<br>26</p>
<p>27<br>    @Autowired<br>28<br>    private RestTemplate restTemplate;<br>29<br>    private static final String GREETING_SERVICE_URI = “<a href="http://greeting.service/greeting/{name}" target="_blank" rel="external">http://greeting.service/greeting/{name}</a>“;  // 通过服务名称来调用，而不需要知道目标服务的IP和端口<br>30</p>
<p>31<br>    @Override<br>32<br>    public void run(String… strings) throws Exception {<br>33<br>        while(true) {<br>34<br>            String greetingSentence = this.restTemplate.getForObject(<br>35<br>                    GREETING_SERVICE_URI,<br>36<br>                    String.class,<br>37<br>                    “Dean Shi”); // 透明调用远程服务<br>38<br>            System.out.println(“Response result: “ + greetingSentence);<br>39</p>
<p>40<br>            Thread.sleep(5000);<br>41<br>        }<br>42<br>    }<br>43<br>}<br>对应的配置文件application.properties内容，如下所示：</p>
<p>1<br>server.port=9999<br>2<br>spring.application.name = application.client.caller<br>3<br>eureka.instance.metadataMap.instanceId = ${spring.application.name}:instance-9999<br>4<br>eureka.client.serviceUrl.defaultZone = <a href="http://localhost:3300/eureka/,http://localhost:3301/eureka/" target="_blank" rel="external">http://localhost:3300/eureka/,http://localhost:3301/eureka/</a><br>启动并验证微服务应用</p>
<p>上面已经实现了该示例微服务应用的全部组件，先可以启动各个服务组件了。启动顺序如下所示：</p>
<p>启动两个Eureka Server<br>启动两个Greeting Service<br>启动服务消费应用Application Call<br>可以通过Web页面查看Eureka Server控制台，如下图所示：<br>eureka-web-console<br>多次启动Application Call应用，就可以通过查看Greeting Service服务的日志，可以看到服务被调用，而且实现了基础的Round-robin负载均衡，日志如下所示：</p>
<p>1<br>Response result: ::02:: Hello, Dean Shi!<br>2<br>Response result: ::01:: Hello, Dean Shi!<br>3<br>Response result: ::02:: Hello, Dean Shi!<br>4<br>Response result: ::01:: Hello, Dean Shi!<br>5<br>Response result: ::02:: Hello, Dean Shi!<br>6<br>Response result: ::01:: Hello, Dean Shi!<br>我们实现示例微服务应用，验证后符合我们的期望。<br>上面微服务应用的实现代码及其配置，可以查看我的Github：<a href="https://github.com/shirdrn/springcloud-eureka-demo.git" target="_blank" rel="external">https://github.com/shirdrn/springcloud-eureka-demo.git</a></p>
<p>参考链接</p>
<p><a href="https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance" target="_blank" rel="external">https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance</a><br><a href="http://cloud.spring.io/spring-cloud-netflix/" target="_blank" rel="external">http://cloud.spring.io/spring-cloud-netflix/</a><br><a href="http://cloud.spring.io/spring-cloud-netflix/1.0.x/" target="_blank" rel="external">http://cloud.spring.io/spring-cloud-netflix/1.0.x/</a><br><a href="https://spring.io/blog/2015/01/20/microservice-registration-and-discovery-with-spring-cloud-and-netflix-s-eureka" target="_blank" rel="external">https://spring.io/blog/2015/01/20/microservice-registration-and-discovery-with-spring-cloud-and-netflix-s-eureka</a><br><a href="http://itmuch.com/spring-cloud-sum-eureka/" target="_blank" rel="external">http://itmuch.com/spring-cloud-sum-eureka/</a><br><a href="http://blog.abhijitsarkar.org/technical/netflix-eureka/" target="_blank" rel="external">http://blog.abhijitsarkar.org/technical/netflix-eureka/</a><br>Creative Commons License<br>本文基于署名-非商业性使用-相同方式共享 4.0许可协议发布，欢迎转载、使用、重新发布，但务必保留文章署名时延军（包含链接：<a href="http://shiyanjun.cn），不得用于商业目的，基于本文修改后的作品务必以相同的许可发布。如有任何疑问，请与我联系。" target="_blank" rel="external">http://shiyanjun.cn），不得用于商业目的，基于本文修改后的作品务必以相同的许可发布。如有任何疑问，请与我联系。</a></p>
]]></content>
    
    <summary type="html">
    
      Spring Cloud Netflix构建微服务入门实践
    
    </summary>
    
      <category term="spring" scheme="http://jishusuishouji.github.io/categories/spring/"/>
    
    
      <category term="spring" scheme="http://jishusuishouji.github.io/tags/spring/"/>
    
  </entry>
  
  <entry>
    <title>ZooKeeper 基础知识、部署和应用程序</title>
    <link href="http://jishusuishouji.github.io/2017/03/26/zookeeper/ZooKeeper_%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E3%80%81%E9%83%A8%E7%BD%B2%E5%92%8C%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F/"/>
    <id>http://jishusuishouji.github.io/2017/03/26/zookeeper/ZooKeeper_基础知识、部署和应用程序/</id>
    <published>2017-03-25T16:07:53.000Z</published>
    <updated>2017-03-25T16:25:00.412Z</updated>
    
    <content type="html"><![CDATA[<p>Apache ZooKeeper 是一个面向分布式应用程序的高性能<strong>协调服务器</strong>。它使用一个简单的接口暴露公共服务（比如命名和配置管理、同步和组服务），让用户不必从头开始编程。它为实现共识、组管理、领导者选举和到场协议（presence protocol）配备了现成的支持。 的示例。</p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>ZooKeeper 是一个面向分布式系统的构建块。当设计一个分布式系统时，一般需要设计和开发一些协调服务：</p>
<ul>
<li><p>名称服务— 名称服务是将一个名称映射到与该名称有关联的一些信息的服务。电话目录是将人的名字映射到其电话号码的一个名称服务。同样，DNS服务也是一个名称服务，它将一个域名映射到一个 IP 地址。在分布式系统中，您可能想跟踪哪些服务器或服务在运行，并通过名称查看其状态。ZooKeeper暴露了一个简单的接口来完成此工作。也可以将名称服务扩展到组成员服务，这样就可以获得与正在查找其名称的实体有关联的组的信息。</p>
</li>
<li><p>锁定— 为了允许在分布式系统中对共享资源进行有序的访问，可能需要实现分布式互斥（distributed mutexes）。ZooKeeper 提供一种简单的方式来实现它们。</p>
</li>
<li>同步— 与互斥同时出现的是同步访问共享资源的需求。无论是实现一个生产者-消费者队列，还是实现一个障碍，ZooKeeper 都提供一个简单的接口来实现该操作。</li>
<li>配置管理— 您可以使用 ZooKeeper 集中存储和管理分布式系统的配置。这意味着，所有新加入的节点都将在加入系统后就可以立即使用来自ZooKeeper的最新集中式配置。这还允许您通过其中一个 ZooKeeper 客户端更改集中式配置，集中地更改分布式系统的状态。</li>
<li>领导者选举— 分布式系统可能必须处理节点停机的问题，您可能想实现一个自动故障转移策略。ZooKeeper 通过领导者选举对此提供现成的支持。</li>
</ul>
<p>虽然可以从头开始设计和实现所有这些服务，但调试任何问题、竞争条件或死锁都需要执行额外的工作，并且很难实现。就像您不会在代码中随处编写自己的随机数发生器或哈希函数一样，这里有一个要求：人们不应该在每次有需要时就到处从头编写自己的名称服务或领导者选举服务。此外，您可以相对容易地一起解决一个非常简单的组成员服务，但是，要编写它们来提供可靠性、复制和可扩展性，可能需要做更多的工作。这导致了Apache ZooKeeper 的开发和开源，Apache ZooKeeper是一个针对分布式系统的、开箱即用的、可靠的、可扩展的、高性能的协调服务。</p>
<p>ZooKeeper虽然是一个针对分布式系统的协调服务，但它本身也是一个分布式应用程序。ZooKeeper 遵循一个简单的客户端-服务器模型，其中客户端是使用服务的节点（即机器），而服务器是提供服务的节点。ZooKeeper 服务器的集合形成了一个ZooKeeper集合体（ensemble）。在任何给定的时间内，一个 ZooKeeper 客户端可连接到一个 ZooKeeper 服务器。每个 ZooKeeper服务器都可以同时处理大量客户端连接。每个客户端定期发送 ping 到它所连接的 ZooKeeper 服务器，让服务器知道它处于活动和连接状态。被询问的ZooKeeper 服务器通过 ping 确认进行响应，表示服务器也处于活动状态。如果客户端在指定时间内没有收到服务器的确认，那么客户端会连接到集合体中的另一台服务器，而且客户端会话会被透明地转移到新的 ZooKeeper 服务器。</p>
<p><img src="/img/ZooKeeper 的客户端-服务器架构.png" alt="图 1 描述了 ZooKeeper 的客户端-服务器架构。"></p>
<p> ZooKeeper 有一个类似于文件系统的数据模型，由znodes组成。可以将 znodes（ZooKeeper 数据节点）视为类似 UNIX 的传统系统中的文件，但它们可以有子节点。另一种方式是将它们视为目录，它们可以有与其相关的数据。每个这些目录都被称为一个 znode。图 2 显示的图代表与两个城市中的运动队相同的层次结构。</p>
<p><img src="/img/两个城市中的运动队的层次结构.png" alt="图 2. 该图表示了两个城市中的运动队的层次结构"></p>
<p>znode层次结构被存储在每个 ZooKeeper服务器的内存中。这实现了对来自客户端的读取操作的可扩展的快速响应。每个 ZooKeeper服务器还在磁盘上维护了一个事务日志，记录所有的写入请求。因为ZooKeeper 服务器在返回一个成功的响应之前必须将事务同步到磁盘，所以事务日志也是ZooKeeper 中对性能最重要的组成部分。可以存储在 znode 中的数据的默认最大大小为 1 MB。因此，即使 ZooKeeper 的层次结构看起来与文件系统相似，也不应该将它用作一个通用的文件系统。相反，应该只将它用作少量数据的存储机制，以便为分布式应用程序提供可靠性、可用性和协调。<br>当客户端请求读取特定 znode 的内容时，读取操作是在客户端所连接的服务器上进行的。因此，由于只涉及集合体中的一个服务器，所以读取是快速和可扩展的。然而，为了成功完成写入操作，要求 ZooKeeper 集合体的严格意义上的多数节点都是可用的。在启动 ZooKeeper 服务时，集合体中的某个节点被选举为领导者。当客户端发出一个写入请求时，所连接的服务器会将请求传递给领导者。此领导者对集合体的所有节点发出相同的写入请求。如果严格意义上的多数节点（也被称为法定数量（quorum））成功响应该写入请求，那么写入请求被视为已成功完成。然后，一个成功的返回代码会返回给发起写入请求的客户端。如果集合体中的可用节点数量未达到法定数量，那么ZooKeeper服务将不起作用。</p>
<p>法定数量是通过严格意义上的多数节点来表示的。在集合体中，可以包含一个节点，但它不是一个高可用和可靠的系统。如果在集合体中有两个节点，那么这两个节点都必须已经启动并让服务正常运行，因为两个节点中的一个并不是严格意义上的多数。如果在集合体中有三个节点，即使其中一个停机了，您仍然可以获得正常运行的服务（三个中的两个是严格意义上的多数）。出于这个原因，ZooKeeper 的集合体中通常包含奇数数量的节点，因为就容错而言，与三个节点相比，四个节点并不占优势，因为只要有两个节点停机，ZooKeeper 服务就会停止。在有五个节点的集群上，需要三个节点停机才会导致 ZooKeeper 服务停止运作。</p>
<p>现在，我们已经清楚地了解到，节点数量应该是奇数，让我们再来思考一下 ZooKeeper 集合体中需要有多少个节点。读取操作始终从连接到客户端的 ZooKeeper 服务器读取数据，所以它们的性能不会随着集合体中的服务器数量额变化而变化。但是，仅在写入法定数量的节点时，写入操作才是成功的。这意味着，随着在集合体中的节点数量的增加，写入性能会下降，因为必须将写入内容写入到更多的服务器中，并在更多服务器之间进行协调。</p>
<p>ZooKeeper的美妙之处在于，想运行多少服务器完全由您自己决定。如果想运行一台服务器，从 ZooKeeper的角度来看是没问题的；只是您的系统不再是高度可靠或高度可用的。三个节点的 ZooKeeper 集合体支持在一个节点故障的情况下不丢失服务，这对于大多数用户而言，这可能是没问题的，也可以说是最常见的部署拓扑。不过，为了安全起见，可以在您的集合体中使用五个节点。五个节点的集合体让您可以拿出一台服务器进行维护或滚动升级，并能够在不中断服务的情况下承受第二台服务器的意外故障。</p>
<p>因此，在 ZooKeeper 集合体中，三、五或七是最典型的节点数量。请记住，ZooKeeper 集合体的大小与分布式系统中的节点大小没有什么关系。分布式系统中的节点将是 ZooKeeper 集合体的客户端，每个 ZooKeeper服务器都能够以可扩展的方式处理大量客户端。例如，HBase（Hadoop 上的分布式数据库）依赖​​于 ZooKeeper 实现区域服务器的领导者选举和租赁管理。您可以利用一个相对较少（比如说，五个）节点的 ZooKeeper 集合体运行有 50 个节点的大型 HBase 集群。</p>
<h2 id="设置并部署-ZooKeeper-集合体"><a href="#设置并部署-ZooKeeper-集合体" class="headerlink" title="设置并部署 ZooKeeper 集合体"></a>设置并部署 ZooKeeper 集合体</h2><p>现在让我们设置并部署有三个节点的 ZooKeeper集合体。在这里，我们将使用撰写本文时的最新版的 ZooKeeper：3.4.5。我们用于此演示的节点被命名为zkserver1.mybiz.com、zkserver2.mybiz.com和zk3server3.mybiz.com。必须在每个节点上遵循下面的步骤来启动 ZooKeeper 服务器：</p>
<p>1.如果尚未安装 JDK，请下载安装它。这是必需的，因为 ZooKeeper 服务器在 JVM 上运行。<br>2.下载 ZooKeeper 3.4.5. tar.gz tarball 并将它解压缩到适当的位置。<br>清单 1. 下载 ZooKeeper tarball 并将它解压缩到适当的位置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"> wget</div><div class="line">http://www.bizdirusa.com/mirrors/apache/ZooKeeper/stable/zookeeper3.4.5.</div><div class="line">tar.gz tar xzvf zookeeper3.4.5.tar.gz</div></pre></td></tr></table></figure></p>
<p>3.创建一个目录，用它来存储与 ZooKeeper 服务器有关联的一些状态：<code>mkdir /var/lib/zookeeper</code>。您可能需要将这个目录创建为根目录，并在以后将这个目录的所有者更改为您希望运行ZooKeeper服务器的用户。<br>4.设置配置。创建或编辑<code>zookeeper3.4.5/conf/zoo.cfg</code>文件，使其与 清单 2 相似。<br>清单 2. 设置配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">tickTime=2000</div><div class="line">dataDir=/var/lib/zookeeper </div><div class="line">clientPort=2181</div><div class="line">initLimit=5 </div><div class="line">syncLimit=2</div><div class="line">server.1=zkserver1.mybiz.com:2888:3888</div><div class="line">server.2=zkserver2.mybiz.com:2888:3888</div><div class="line">server.3=zkserver3.mybiz.com:2888:3888</div></pre></td></tr></table></figure></p>
<p>值得重点注意的一点是，所有三个机器都应该打开端口 2181、2888 和 3888。在本例中，端口 2181 由 ZooKeeper 客户端使用，用于连接到 ZooKeeper 服务器；端口 2888 由对等 ZooKeeper 服务器使用，用于互相通信；而端口 3888 用于领导者选举。您可以选择自己喜欢的任何端口。通常建议在所有 ZooKeeper 服务器上使用相同的端口。</p>
<p>5.创建一个 <code>/var/lib/zookeeper/myid</code>文件。此文件的内容将只包含 zkserver1.mybiz.com 上的数字 1、zkserver2.mybiz.com 上的数字 2 和 zkserver3.mybiz.com 上的数字 3。清单 3 显示了来自 zkserver1.mybiz.com 的此文件的 cat 输出。<br>清单 3. cat 输出<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mark@zkserver1.mybiz.com:~# cat</div><div class="line">/var/lib/zookeeper/myid 1</div></pre></td></tr></table></figure></p>
<p>现在，您已经做好了在每台机器上启动 ZooKeeper 服务器的准备。</p>
<p>清单 4. 启动 ZooKeeper 服务器</p>
<pre><code>bin/zkServer.sh start
</code></pre><p>现在，您可以从其中一台正在运行 ZooKeeper 服务器的机器上启动一个 CLI 客户端。</p>
<p>清单 5. 启动 CLI 客户端<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">zookeeper3.4.5/ bin/zkCli.sh server</div><div class="line">zkserver1.mybiz.com:2181,zkserver2.mybiz.com:2181,zkserver3.mybiz.com:2181</div></pre></td></tr></table></figure></p>
<p>客户端提供一个服务器列表，可以任意选中一个进行连接。如果在连接过程中失去与该服务器的连接，则会选中列表中的另一台服务器，而且客户端会话也会转移到该服务器。一旦启动了客户端，您就可以创建、编辑和删除 znode。让我们在 <code>/mynode</code> 创建一个znode，使用helloworld作为关联的数据。</p>
<p>清单 6. 在 <code>/mynode</code> 上创建一个 znode<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[zk:127.0.0.1:2181(CONNECTED) 2] create /mynode</div><div class="line">helloworld Created /mynode</div></pre></td></tr></table></figure></p>
<p>现在，让我们在 /mynode 验证和检索数据。</p>
<p>清单 7. 在 /mynode 验证和检索数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[zk:127.0.0.1:2181(CONNECTED) 6] get /mynode</div><div class="line">helloworld cZxid = 0x200000005 ctime = Sat Jul 20</div><div class="line">19:53:52 PDT 2013 mZxid = 0x200000005 mtime = Sat</div><div class="line">Jul 20 19:53:52 PDT 2013 pZxid = 0x200000005</div><div class="line">cversion = 0 dataVersion = 0 aclVersion = 0</div><div class="line">ephemeralOwner = 0x0 dataLength = 11 numChildren =</div><div class="line">0</div></pre></td></tr></table></figure></p>
<p>您会发现，在获取一个 znode 数据时，客户端也返回了一些与 znode 有关的元数据。此元数据中的一些重要字段包括，与创建和最后修改 znode 的时间有关的阶段时间戳（ctime 和 mtime）、每次修改数据都会更改的数据版本（dataVersion）、数据长度（dataLength）、这个 znode 的子节点的数量（numChildren）。我们现在可以删除 znode。</p>
<p>清单 8. 删除 znode<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"> [zk:127.0.0.1:2181(CONNECTED) 7]</div><div class="line">rmr /mynode</div></pre></td></tr></table></figure></p>
<p>让我们在 /mysecondnode 创建另一个 znode。</p>
<p>清单 9. 创建另一个 znode<br>```<br>[zk:127.0.0.1:2181(CONNECTED) 10] create<br>/mysecondnode hello Created /mysecondnode<br>现在，让我们在 /mysecondnode 验证和检索数据。这一次，我们在最后提供了一个可选参数 1。此参数为 /mysecondnode 上的数据设置了一个一次性的触发器（名称为 watch）。如果另一个客户端在 /mysecondnode 上修改数据，该客户端将会获得一个异步通知。请注意，该通知只发送一次，除非 watch 被重新设置，否则不会因数据发生改变而再次发送通知。</p>
<p>清单 10. 在 /mysecondnode 上验证和检索数据</p>
<p>[zk:127.0.0.1:2181(CONNECTED) 12] get<br>/mysecondnode 1 hello cZxid = 0x200000007 ctime =<br>Sat Jul 20 19:58:27 PDT 2013 mZxid = 0x200000007<br>mtime = Sat Jul 20 19:58:27 PDT 2013 pZxid =<br>0x200000007 cversion = 0 dataVersion = 0<br>aclVersion = 0 ephemeralOwner = 0x0 dataLength = 5<br>numChildren = 0<br>现在，从不同的客户端（比如，从不同的机器）更改与 /mysecondnode 有关联的数据的值。</p>
<p>清单 11. 更改与 /mysecondnode 有关联的数据的值</p>
<p> [zk: localhost:2181(CONNECTED)<br>1] set /mysecondnode hello2 cZxid = 0x200000007<br>ctime = Sat Jul 20 19:58:27 PDT 2013 mZxid =<br>0x200000009 mtime = Sat Jul 20 20:02:37 PDT 2013<br>pZxid = 0x200000007 cversion = 0 dataVersion = 1<br>aclVersion = 0 ephemeralOwner = 0x0 dataLength = 6<br>numChildren = 0<br>您会发现，在第一个客户端上获得了一个 watch 通知。</p>
<p>清单 12. 在第一个客户端上获得了一个 watch 通知</p>
<p>[zk:127.0.0.1:2181(CONNECTED) 13] WATCHER::<br>WatchedEvent state:SyncConnected<br>type:NodeDataChanged path:/mysecondnode<br>继续下去，因为 znode 形成了一个分层命名空间，所以您还可以创建子节点。</p>
<p>清单 13. 创建子节点</p>
<p> [zk:<br>localhost:2181(CONNECTED) 2] create /mysecondnode/<br>subnode 123 Created /mysecondnode/ subnode<br>您可以获得关于某个 znode 的其他统计元数据。</p>
<p>清单 14. 获得关于某个 znode 的其他统计元数据</p>
<p> [zk:127.0.0.1:2181(CONNECTED)<br>14] stat /mysecondnode cZxid = 0x200000007 ctime =<br>Sat Jul 20 19:58:27 PDT 2013 mZxid = 0x200000009<br>mtime = Sat Jul 20 20:02:37 PDT 2013 pZxid =<br>0x20000000a cversion = 1 dataVersion = 1<br>aclVersion = 0 ephemeralOwner = 0x0 dataLength = 6<br>numChildren = 1<br>在上面的示例中，我们使用了 ZooKeeper 的 CLI 客户端与 ZooKeeper 服务器进行交互。ZooKeeper 提供了 Java™、C、Python 和其他绑定。您可以通过这些绑定调用客户端 API，将 Java、C 或 Python 应用程序转换为 ZooKeeper 客户端。</p>
<p>ZooKeeper 的应用程序</p>
<p>由于 ZooKeeper 在分布式系统中提供了一些多功能的用例，ZooKeeper 有一组不同的实用应用程序。我们将在这里列出部分这些应用程序。这些应用程序大多取自 Apache ZooKeeper 维基，那里还提供了一个更完整的最新列表。请参阅 参考资料，获得这些技术的链接：</p>
<p>Apache Hadoop 依靠 ZooKeeper 来实现 Hadoop HDFS NameNode 的自动故障转移，以及 YARN ResourceManager 的高可用性。</p>
<p>Apache HBase 是构建于 Hadoop 之上的分布式数据库，它使用 ZooKeeper 来实现区域服务器的主选举（master election）、租赁管理以及区域服务器之间的其他通信。</p>
<p>Apache Accumulo 是构建于 Apache ZooKeeper（和 Apache Hadoop）之上的另一个排序分布式键/值存储。</p>
<p>Apache Solr 使用 ZooKeeper 实现领导者选举和集中式配置。</p>
<p>Apache Mesos 是一个集群管理器，提供了分布式应用程序之间高效的资源隔离和共享。Mesos 使用 ZooKeeper 实现了容错的、复制的主选举。</p>
<p>Neo4j 是一个分布式图形数据库，它使用 ZooKeeper 写入主选择和读取从协调（read slave coordination）。</p>
<p>Cloudera Search 使用 ZooKeeper（通过 Apache Solr）集成了搜索功能与 Apache Hadoop，以实现集中式配置管理。</p>
<p>结束语</p>
<p>实现您自己的协议来协调分布式系统，这可能是一个令人感到沮丧的费时的过程。这正是 ZooKeeper 发挥其作用的地方。ZooKeeper 是一个稳定的、简单的、高性能的协调服务，为您提供编写正确的分布式应用程序所需的工具，而无需担心竞争条件、死锁和不一致。在下一次编写分布式应用程序时，您就可以利用 ZooKeeper 支持所有协调需求。</p>
]]></content>
    
    <summary type="html">
    
      ZooKeeper 基础知识、部署和应用程序
    
    </summary>
    
      <category term="ZooKeeper" scheme="http://jishusuishouji.github.io/categories/ZooKeeper/"/>
    
    
      <category term="ZooKeeper" scheme="http://jishusuishouji.github.io/tags/ZooKeeper/"/>
    
  </entry>
  
  <entry>
    <title>Pointfree 编程风格指南</title>
    <link href="http://jishusuishouji.github.io/2017/03/25/hanshushi/Pointfree_%E7%BC%96%E7%A8%8B%E9%A3%8E%E6%A0%BC%E6%8C%87%E5%8D%97/"/>
    <id>http://jishusuishouji.github.io/2017/03/25/hanshushi/Pointfree_编程风格指南/</id>
    <published>2017-03-25T15:21:00.000Z</published>
    <updated>2017-03-25T15:48:51.593Z</updated>
    
    <content type="html"><![CDATA[<h2 id="函数式编程有什么用？"><a href="#函数式编程有什么用？" class="headerlink" title="函数式编程有什么用？"></a>函数式编程有什么用？</h2><p>Pointfree就是如何使用函数式编程的答案。</p>
<h3 id="一、程序的本质"><a href="#一、程序的本质" class="headerlink" title="一、程序的本质"></a>一、程序的本质</h3><p><img src="/img/程序的本质.png" alt=""><br>左侧是数据输入（input），中间是一系列的运算步骤，对数据进行加工，右侧是最后的数据输出（output）。一个或多个这样的任务，就组成了程序。<br>输入和输出（统称为 I/O）与键盘、屏幕、文件、数据库等相关。这里的关键是，中间的运算部分不能有 I/O 操作，应该是纯运算，即通过纯粹的数学运算来求值。否则，就应该拆分出另一个任务。<br>I/O 操作往往有现成命令，大多数时候，编程主要就是写中间的那部分运算逻辑。现在，主流写法是过程式编程和面向对象编程，但是我觉得，最合适纯运算的是函数式编程。<br><a id="more"></a></p>
<h3 id="二、函数的拆分与合成"><a href="#二、函数的拆分与合成" class="headerlink" title="二、函数的拆分与合成"></a>二、函数的拆分与合成</h3><p>上面那张图中，运算过程可以用一个函数fn表示。<br><img src="/img/函数的拆分与合成.png" alt=""><br><code>fn</code>的类型如下。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fn :: a -&gt; b</div></pre></td></tr></table></figure></p>
<p>上面的式子表示，函数<code>fn</code>的输入是数据<code>a</code>，输出是数据<code>b</code>。<br>如果运算比较复杂，通常需要将<code>fn</code>拆分成多个函数。<br><img src="/img/函数的拆分与合成2.png" alt=""><br>f1、f2、f3的类型如下。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">f1 :: a -&gt; m</div><div class="line">f2 :: m -&gt; n</div><div class="line">f3 :: n -&gt; b</div></pre></td></tr></table></figure></p>
<p>上面的式子中，输入的数据还是<code>a</code>，输出的数据还是<code>b</code>，但是多了两个中间值<code>m</code>和<code>n</code>。<br>我们可以把整个运算过程，想象成一根水管（pipe），数据从这头进去，那头出来。</p>
<p>函数的拆分，无非就是将一根水管拆成了三根。</p>
<p>进去的数据还是<code>a</code>，出来的数据还是<code>b</code>。<code>fn</code>与<code>f1</code>、<code>f2</code>、<code>f3</code>的关系如下。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fn = R.pipe(f1, f2, f3);</div></pre></td></tr></table></figure></p>
<p>上面代码中，我用到了Ramda函数库的<code>pipe</code>方法，将三个函数合成为一个。</p>
<h3 id="三、Pointfree-的概念"><a href="#三、Pointfree-的概念" class="headerlink" title="三、Pointfree 的概念"></a>三、Pointfree 的概念</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fn = R.pipe(f1, f2, f3);</div></pre></td></tr></table></figure>
<p>这个公式说明，如果先定义<code>f1</code>、<code>f2</code>、<code>f3</code>，就可以算出<code>fn</code>。整个过程，根本不需要知道<code>a</code>或<code>b</code>。<br>也就是说，我们完全可以把数据处理的过程，定义成一种与参数无关的合成运算。不需要用到代表数据的那个参数，只要把一些简单的运算步骤合成在一起即可。<br>这就叫做Pointfree：不使用所要处理的值，只合成运算过程。中文可以译作”无值”风格。<br>请看下面的例子。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">var addOne = x =&gt; x + 1;</div><div class="line">var square = x =&gt; x * x;</div></pre></td></tr></table></figure></p>
<p>上面是两个简单函数<code>addOne</code>和<code>square</code>。<br>把它们合成一个运算。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">var addOneThenSquare = R.pipe(addOne, square);</div><div class="line"></div><div class="line">addOneThenSquare(2) //  9</div></pre></td></tr></table></figure></p>
<p>上面代码中，<code>addOneThenSquare</code>是一个合成函数。定义它的时候，根本不需要提到要处理的值，这就是Pointfree。</p>
<h3 id="四、Pointfree-的本质"><a href="#四、Pointfree-的本质" class="headerlink" title="四、Pointfree 的本质"></a>四、Pointfree 的本质</h3><p>Pointfree的本质就是使用一些通用的函数，组合出各种复杂运算。上层运算不要直接操作数据，而是通过底层函数去处理。这就要求，将一些常用的操作封装成函数。<br>比如，读取对象的<code>role</code>属性，不要直接写成<code>obj.role</code>，而是要把这个操作封装成函数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">var prop = (p, obj) =&gt; obj[p];</div><div class="line">var propRole = R.curry(prop)(&apos;role&apos;);</div></pre></td></tr></table></figure></p>
<p>上面代码中，<code>prop</code>函数封装了读取操作。它需要两个参数<code>p</code>（属性名）和<code>obj</code>（对象）。这时，要把数据<code>obj</code>要放在最后一个参数，这是为了方便柯里化。函数<code>propRole</code>则是指定读取<code>role</code>属性。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">var isWorker = s =&gt; s === &apos;worker&apos;;</div><div class="line">var getWorkers = R.filter(R.pipe(propRole, isWorker));</div><div class="line"></div><div class="line">var data = [</div><div class="line">  &#123;name: &apos;张三&apos;, role: &apos;worker&apos;&#125;,</div><div class="line">  &#123;name: &apos;李四&apos;, role: &apos;worker&apos;&#125;,</div><div class="line">  &#123;name: &apos;王五&apos;, role: &apos;manager&apos;&#125;,</div><div class="line">];</div><div class="line">getWorkers(data)</div><div class="line">// [</div><div class="line">//   &#123;&quot;name&quot;: &quot;张三&quot;, &quot;role&quot;: &quot;worker&quot;&#125;,</div><div class="line">//   &#123;&quot;name&quot;: &quot;李四&quot;, &quot;role&quot;: &quot;worker&quot;&#125;</div><div class="line">// ]</div></pre></td></tr></table></figure></p>
<p>上面代码中，<code>data</code>是传入的值，<code>getWorkers</code>是处理这个值的函数。定义<code>getWorkers</code>的时候，完全没有提到<code>data</code>，这就是Pointfree。<br>简单说，Pointfree就是运算过程抽象化，处理一个值，但是不提到这个值。这样做有很多好处，它能够让代码更清晰和简练，更符合语义，更容易复用，测试也变得轻而易举。</p>
<h3 id="五、Pointfree-的示例一"><a href="#五、Pointfree-的示例一" class="headerlink" title="五、Pointfree 的示例一"></a>五、Pointfree 的示例一</h3><p>下面，我们来看一个示例。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">var str = &apos;Lorem ipsum dolor sit amet consectetur adipiscing elit&apos;;</div></pre></td></tr></table></figure></p>
<p>上面是一个字符串，请问其中最长的单词有多少个字符？<br>我们先定义一些基本运算。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">// 以空格分割单词</div><div class="line">var splitBySpace = s =&gt; s.split(&apos; &apos;);</div><div class="line"></div><div class="line">// 每个单词的长度</div><div class="line">var getLength = w =&gt; w.length;</div><div class="line"></div><div class="line">// 词的数组转换成长度的数组</div><div class="line">var getLengthArr = arr =&gt; R.map(getLength, arr); </div><div class="line"></div><div class="line">// 返回较大的数字</div><div class="line">var getBiggerNumber = (a, b) =&gt; a &gt; b ? a : b;</div><div class="line"></div><div class="line">// 返回最大的一个数字</div><div class="line">var findBiggestNumber = </div><div class="line">  arr =&gt; R.reduce(getBiggerNumber, 0, arr);</div></pre></td></tr></table></figure></p>
<p>然后，把基本运算合成为一个函数（查看完整代码）。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">var getLongestWordLength = R.pipe(</div><div class="line">  splitBySpace,</div><div class="line">  getLengthArr,</div><div class="line">  findBiggestNumber</div><div class="line">);</div><div class="line"></div><div class="line">getLongestWordLength(str) // 11</div></pre></td></tr></table></figure></p>
<p>可以看到，整个运算由三个步骤构成，每个步骤都有语义化的名称，非常的清晰。这就是 Pointfree 风格的优势。<br>Ramda 提供了很多现成的方法，可以直接使用这些方法，省得自己定义一些常用函数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">// 上面代码的另一种写法</div><div class="line">var getLongestWordLength = R.pipe(</div><div class="line">  R.split(&apos; &apos;),</div><div class="line">  R.map(R.length),</div><div class="line">  R.reduce(R.max, 0)</div><div class="line">);</div></pre></td></tr></table></figure></p>
<h3 id="六、Pointfree-示例二"><a href="#六、Pointfree-示例二" class="headerlink" title="六、Pointfree 示例二"></a>六、Pointfree 示例二</h3><p>下面是一段服务器返回的 JSON 数据。<br><img src="/img/Pointfree 编程风格指南.png" alt=""><br>现在要求是，找到用户 Scott 的所有未完成任务，并按到期日期升序排列。<br><img src="/img/用户 Scott 的所有未完成任务，并按到期日期升序排列.png" alt=""></p>
<p>过程式编程的代码如下:<br><img src="/img/过程式编程的代码.png" alt=""><br>上面代码不易读，出错的可能性很大。<br>现在使用 Pointfree 风格改写。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">var getIncompleteTaskSummaries = function(membername) &#123;</div><div class="line">  return fetchData()</div><div class="line">    .then(R.prop(&apos;tasks&apos;))</div><div class="line">    .then(R.filter(R.propEq(&apos;username&apos;, membername)))</div><div class="line">    .then(R.reject(R.propEq(&apos;complete&apos;, true)))</div><div class="line">    .then(R.map(R.pick([&apos;id&apos;, &apos;dueDate&apos;, &apos;title&apos;, &apos;priority&apos;])))</div><div class="line">    .then(R.sortBy(R.prop(&apos;dueDate&apos;)));</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>上面代码已经清晰很多了。<br>另一种写法是，把各个then里面的函数合成起来。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">// 提取 tasks 属性</div><div class="line">var SelectTasks = R.prop(&apos;tasks&apos;);</div><div class="line"></div><div class="line">// 过滤出指定的用户</div><div class="line">var filterMember = member =&gt; R.filter(</div><div class="line">  R.propEq(&apos;username&apos;, member)</div><div class="line">);</div><div class="line"></div><div class="line">// 排除已经完成的任务</div><div class="line">var excludeCompletedTasks = R.reject(R.propEq(&apos;complete&apos;, true));</div><div class="line"></div><div class="line">// 选取指定属性</div><div class="line">var selectFields = R.map(</div><div class="line">  R.pick([&apos;id&apos;, &apos;dueDate&apos;, &apos;title&apos;, &apos;priority&apos;])</div><div class="line">);</div><div class="line"></div><div class="line">// 按照到期日期排序</div><div class="line">var sortByDueDate = R.sortBy(R.prop(&apos;dueDate&apos;));</div><div class="line"></div><div class="line">// 合成函数</div><div class="line">var getIncompleteTaskSummaries = function(membername) &#123;</div><div class="line">  return fetchData().then(</div><div class="line">    R.pipe(</div><div class="line">      SelectTasks,</div><div class="line">      filterMember(membername),</div><div class="line">      excludeCompletedTasks,</div><div class="line">      selectFields,</div><div class="line">      sortByDueDate,</div><div class="line">    )</div><div class="line">  );</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>上面的代码跟过程式的写法一比较，孰优孰劣一目了然。</p>
<h2 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h2><p>函数式编程是一种编程的模式，在这种编程模式中最常用的函数和表达式。它强调在编程的时候用函数的方式思考问题，函数也与其他数据类型一样，处于平等地位。可以将函数作为参数传入另一个函数，也可以作为别的函数的返回值。函数式编程倾向于用一系列嵌套的函数来描述运算过程。</p>
]]></content>
    
    <summary type="html">
    
      Pointfree 编程风格指南
    
    </summary>
    
      <category term="函数式编程" scheme="http://jishusuishouji.github.io/categories/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="函数式编程" scheme="http://jishusuishouji.github.io/tags/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>用Nginx搭建CDN服务器方法-开启Nginx缓存与镜像,自建图片服务器</title>
    <link href="http://jishusuishouji.github.io/2017/03/23/nginx/%E7%94%A8Nginx%E6%90%AD%E5%BB%BACDN%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%96%B9%E6%B3%95-%E5%BC%80%E5%90%AFNginx%E7%BC%93%E5%AD%98%E4%B8%8E%E9%95%9C%E5%83%8F,%E8%87%AA%E5%BB%BA%E5%9B%BE%E7%89%87%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    <id>http://jishusuishouji.github.io/2017/03/23/nginx/用Nginx搭建CDN服务器方法-开启Nginx缓存与镜像,自建图片服务器/</id>
    <published>2017-03-23T15:06:20.000Z</published>
    <updated>2017-03-23T15:30:49.116Z</updated>
    
    <content type="html"><![CDATA[<p>Nginx的<code>proxy_cache</code>和<code>proxy_store</code>很强大，利用<code>proxy_store</code>搭建图片服务器镜像实际上就相当于七牛和又拍的镜像CDN功能了，自动拉取图片保存在CDN服务器上。而<code>proxy_cache</code>作为Nginx缓存，既可以用作负载均衡，也可以反向绑定域名。</p>
<h2 id="用Nginx搭建CDN服务器方法-开启Nginx缓存与镜像-自建图片服务器"><a href="#用Nginx搭建CDN服务器方法-开启Nginx缓存与镜像-自建图片服务器" class="headerlink" title="用Nginx搭建CDN服务器方法-开启Nginx缓存与镜像,自建图片服务器"></a>用Nginx搭建CDN服务器方法-开启Nginx缓存与镜像,自建图片服务器</h2><h3 id="一、利用Nginx的proxy-cache搭建缓存服务器一：编译ngx-cache-purge"><a href="#一、利用Nginx的proxy-cache搭建缓存服务器一：编译ngx-cache-purge" class="headerlink" title="一、利用Nginx的proxy_cache搭建缓存服务器一：编译ngx_cache_purge"></a>一、利用Nginx的<code>proxy_cache</code>搭建缓存服务器一：编译n<code>gx_cache_purge</code></h3><p>1、Nginx的<code>Proxy_cache</code>是根据Key值md5哈希存储缓存，支持任意的Key，例如你可以根据”域名、URI、参数”组合成key，也支持非200状态码，如404/302等。<br>2、要利用Nginx的Proxy_cache，你需要在Nginx编译进<code>ngx_cache_purge</code> 模块，执行：<code>nginx -V</code>，查看有没有<code>ngx_cache_purge</code>字样，没有的话需要自己手动编译。<br><img src="/img/nginx -V，查看有没有ngx_cache_purge.gif" alt="Nginx搭建CDN手动编译"></p>
<p>3、这里以Oneinstack编译<code>ngx_cache_purge</code>模块作为操作演示，如果你用的是其它的LNMP包可以参考，基本过程是差不多的。命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">cd /root/oneinstack/src #进入安装包目录</div><div class="line">nginx -V</div><div class="line">tar xzf nginx-1.10.3.tar.gz #根据上面查看到的nginx版本选择解压包</div><div class="line"> </div><div class="line">wget http://labs.frickle.com/files/ngx_cache_purge-2.3.tar.gz</div><div class="line">tar zxvf ngx_cache_purge-2.3.tar.gz</div><div class="line">cd /root/oneinstack/src/nginx-1.10.3</div><div class="line"> </div><div class="line"># 下面的./configure 后加的参数，你可以直接复制刚刚用nginx -V得到的参数，然后在最后加上--add-module=../ngx_cache_purge-2.3即可，参考：</div><div class="line">./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_stub_status_module --with-http_v2_module --with-http_ssl_module --with-http_gzip_static_module --with-http_realip_module --with-http_flv_module --with-http_mp4_module --with-openssl=../openssl-1.0.2k --with-pcre=../pcre-8.39 --with-pcre-jit --with-ld-opt=-ljemalloc --add-module=../ngx_cache_purge-2.3</div><div class="line"> </div><div class="line">make</div><div class="line"> </div><div class="line">mv /usr/local/nginx/sbin/nginx&#123;,$(date +%m%d)&#125;</div><div class="line">cp objs/nginx /usr/local/nginx/sbin #oneinstack，其它的可以不用这个操作</div><div class="line"> </div><div class="line">nginx -t</div><div class="line">service nginx restart</div></pre></td></tr></table></figure></p>
<p>4、安装完成后，再次<code>nginx -V</code>你就可以看到Nginx已经成功编译进了<code>ngx_cache_purge</code> 了。<br><img src="/img/Nginx搭建CDN添加模块.gif" alt="Nginx搭建CDN添加模块"></p>
<h2 id="二、利用Nginx的proxy-cache搭建缓存服务器二：修改Nginx配置文件"><a href="#二、利用Nginx的proxy-cache搭建缓存服务器二：修改Nginx配置文件" class="headerlink" title="二、利用Nginx的proxy_cache搭建缓存服务器二：修改Nginx配置文件"></a>二、利用Nginx的<code>proxy_cache</code>搭建缓存服务器二：修改Nginx配置文件</h2><p>1、先找到你的Nginx配置文件：<code>nginx.conf</code>（路径一般是在<code>/usr/local/nginx/conf/nginx.conf</code>），在配置文件Http中加入以下代码：（注意修改路径为你自己的路径）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">proxy_connect_timeout 5;</div><div class="line">proxy_read_timeout 60;</div><div class="line">proxy_send_timeout 5;</div><div class="line">proxy_buffer_size 16k;</div><div class="line">proxy_buffers 4 64k;</div><div class="line">proxy_busy_buffers_size 128k;</div><div class="line">proxy_temp_file_write_size 128k;</div><div class="line">proxy_cache_path /data/wwwroot/pic.test.com levels=1:2 keys_zone=cache_one:200m inactive=30d max_size=5g;</div><div class="line">proxy_temp_path /data/wwwroot/pic.test.com/temp;</div></pre></td></tr></table></figure></p>
<p>2、操作如下图：<br>Nginx搭建CDN添加代码<br>3、然后在你的虚拟主机的nginx.conf（路径一般是/usr/local/nginx/conf/vhost/pic.freehao123.com.conf），在server listen 80 和  listen 443 ssl http2 都加入下面命令：<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>  location /{<br>    proxy_pass <a href="https://www.freehao123.com" target="_blank" rel="external">https://www.freehao123.com</a>;<br>    proxy_redirect off;<br>    proxy_set_header Host www.freehao123.com;<br>    proxy_cache cache_one;<br>    proxy_cache_valid 200 302 304 365d;<br>    proxy_cache_valid 301 1d;<br>    proxy_cache_valid any 1m;<br>    add_header Images-Cache “$upstream_cache_status from $host”;<br>    add_header Pragma public;<br>    add_header Cache-Control “public, must-revalidate, proxy-revalidate”;<br>    access_log off; log_not_found off; expires max;<br>}<br>4、将配置文件保存重新上传,然后执行:<br>1<br>2<br>nginx -t<br>service nginx restart<br>5、先执行检查Nginx配置是否正确，确认没有问题的就是重启Nginx了。<br>Nginx搭建CDN重启服务器<br>6、如果你想缓存gravatar头像，那么代码就是：<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br> location /avatar{<br>    proxy_pass <a href="http://cn.gravatar.com" target="_blank" rel="external">http://cn.gravatar.com</a>;<br>    proxy_redirect off;<br>    proxy_set_header Host cn.gravatar.com;<br>    proxy_cache cache_one;<br>    proxy_cache_valid 200 302 304 365d;<br>    proxy_cache_valid 301 1d;<br>    proxy_cache_valid any 1m;<br>    add_header Images-Cache “$upstream_cache_status from $host”;<br>    add_header Pragma public;<br>    add_header Cache-Control “public, must-revalidate, proxy-revalidate”;<br>    access_log off; log_not_found off; expires max;<br>}<br>7、现在打开你的二级域名：pic.freehao123.com，你就可以看到已经正确缓存了图片了。<br>Nginx搭建CDN缓存头像<br>8、这里再给出另一个Nginx缓存代码，实现效果和上面是一样的。<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24</p>
<p>#先在Nginx配置中写入以下命令：<br>proxy_temp_file_write_size 128k;<br>proxy_temp_path   /data/wwwroot/pic.ucblog.net/temp;<br>proxy_cache_path  /data/wwwroot/pic.ucblog.net levels=1:2 keys_zone=cache_one:500m inactive=7d max_size=5g;</p>
<p>#再在虚拟主机的Nginx配置中写入以下命令：<br>先在server listen 80 和listen 443代码前面加入：<br>upstream gravatar {<br>    server secure.gravatar.com:443;<br>}<br>再在server listen 80 和listen 443 里面加入：<br>location / {<br>        proxy_pass_header Server;<br>        proxy_set_header Host cn.gravatar.com;<br>        proxy_set_header Accept-Encoding ‘’;<br>        proxy_redirect off;<br>        proxy_set_header X-Real-IP $remote_addr;<br>        proxy_set_header X-Scheme $scheme;<br>        proxy_pass <a href="https://gravatar" target="_blank" rel="external">https://gravatar</a>;<br>        proxy_cache cache_one;<br>        proxy_cache_valid  200 304 365d;<br>        proxy_cache_key $host$uri$is_args$args;<br>        expires max;<br>    }<br>9、在VPS主机上，你可以看到proxy_cache生成的哈希文件，就表示缓存已经成功了。<br>Nginx搭建CDN生成缓存文件<br>三、利用Nginx的proxy_store搭建镜像服务器：修改Nginx配置方法<br>1、Nginx的proxy_store作用是直接把静态文件在本地硬盘创建并读取，类似于七牛或者又拍这样的镜像CDN功能，首次访问会自动获取源站的静态图片等文件，之后的访问就是直接从CDN服务器读取，加快了速度。<br>2、直接修改Nginx的虚拟主机配置文件（这里以img.freehao123.com.conf为演示），加入以下代码：<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>location / {<br>            expires 3d;<br>            proxy_set_header Accept-Encoding ‘’;<br>            root /data/wwwroot/img.freehao123.com;<br>            proxy_store on;<br>            proxy_store_access user:rw group:rw all:rw;<br>            proxy_temp_path /data/wwwroot/img.freehao123.com/temp;<br>            if ( !-e $request_filename)  {<br>                 proxy_pass <a href="https://www.freehao123.com" target="_blank" rel="external">https://www.freehao123.com</a>;<br>            }<br>  }<br>3、再次保存配置上传，然后重启Nginx。你可以看到img.freehao123.com请求的图片等静态文件已经成功从源站中获得到了。<br>Nginx搭建CDN图片请求<br>4、在VPS主机上的存目录中也可以看到proxy_store已经完整地将图片等静态文件的目录都保存下来了，相当于一个网站的镜像存储CDN了。<br>Nginx搭建CDN镜像存储<br>5、这里还有一个使用，效果和上面是一样的，记得替换好路径，代码如下：<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>upstream http_tornado {<br>    server www.freehao123.com:443;<br>}</p>
<p>server {</p>
<pre><code># 省略其他配置
location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|js|html|htm|css)$ {
    root /opt/data/product/blog/cache;
    proxy_store on;
    proxy_store_access user:rw group:rw all:rw;
    proxy_temp_path /opt/data/product/blog/cache;
    if ( !-e $request_filename) {
        proxy_pass  http://http_tornado;
    }
}
</code></pre><p>}<br>四、Nginx的proxy_store和proxy_cache有什么区别？<br>1、镜像与缓存的区别。从上面的介绍我们也可以看出来，proxy_store相当于镜像一个网站了，第二次访问图片等静态文件是直接读取CDN服务器上的，大大减轻了源站的负担。proxy_cache相当于缓存，即把请求生成Key，第二次访问就可以加快速度了。<br>Nginx搭建CDN加快速度<br>2、proxy_store适合静态，proxy_cache适合动态。proxy_store是将图片完整保存在CDN服务器上，所以它更适合于图片CDN加速，而proxy_cache是缓存生成Key，更加适合动态网站加速，可用于负载均衡，减轻服务器负担。<br>Nginx搭建CDN减轻负担<br>五、搭建镜像CDN服务器后要做的事情？<br>1、第一，因为搭建镜像CDN服务器是完整地复制了源站的文件和URL，所以为了避免被搜索引擎误认为抄袭重复站，我们可以给CDN站加上Robots.txt，阻止搜索引擎收录。命令如下（允许收录图片，其它不允许爬取）：<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58<br>59<br>60<br>61<br>62<br>63<br>64<br>65<br>66<br>67<br>68<br>69<br>70<br>71<br>72<br>73<br>74<br>75<br>76<br>77<br>78<br>79<br>80<br>81<br>82<br>83<br>84<br>85<br>86<br>87<br>88<br>89<br>90<br>91<br>92<br>User-agent: Baiduspider<br>Allow: /wp-content/uploads/<em>.jpg$<br>Allow: /wp-content/uploads/</em>.png$<br>Allow: /wp-content/uploads/*.gif$<br>Disallow: /</p>
<p>User-agent: 360Spider<br>Allow: /wp-content/uploads/<em>.jpg$<br>Allow: /wp-content/uploads/</em>.png$<br>Allow: /wp-content/uploads/*.gif$<br>Disallow: /</p>
<p>User-agent: Baiduspider-image<br>Allow: /wp-content/uploads/<em>.jpg$<br>Allow: /wp-content/uploads/</em>.png$<br>Allow: /wp-content/uploads/*.gif$<br>Disallow: /</p>
<p>User-agent: 360Spider-Image<br>Allow: /wp-content/uploads/<em>.jpg$<br>Allow: /wp-content/uploads/</em>.png$<br>Allow: /wp-content/uploads/*.gif$<br>Disallow: /</p>
<p>User-agent: Sosospider<br>Allow: /wp-content/uploads/<em>.jpg$<br>Allow: /wp-content/uploads/</em>.png$<br>Allow: /wp-content/uploads/*.gif$<br>Disallow: /</p>
<p>User-agent: sogou spider<br>Allow: /wp-content/uploads/<em>.jpg$<br>Allow: /wp-content/uploads/</em>.png$<br>Allow: /wp-content/uploads/*.gif$<br>Disallow: /</p>
<p>User-agent: YodaoBot<br>Allow: /wp-content/uploads/<em>.jpg$<br>Allow: /wp-content/uploads/</em>.png$<br>Allow: /wp-content/uploads/*.gif$<br>Disallow: /</p>
<p>User-agent: Googlebot<br>Allow: /wp-content/uploads/<em>.jpg$<br>Allow: /wp-content/uploads/</em>.png$<br>Allow: /wp-content/uploads/*.gif$<br>Disallow: /</p>
<p>User-agent: Bingbot<br>Allow: /wp-content/uploads/<em>.jpg$<br>Allow: /wp-content/uploads/</em>.png$<br>Allow: /wp-content/uploads/*.gif$<br>Disallow: /</p>
<p>User-agent: Slurp<br>Allow: /wp-content/uploads/<em>.jpg$<br>Allow: /wp-content/uploads/</em>.png$<br>Allow: /wp-content/uploads/*.gif$<br>Disallow: /</p>
<p>User-agent: MSNBot<br>Allow: /wp-content/uploads/<em>.jpg$<br>Allow: /wp-content/uploads/</em>.png$<br>Allow: /wp-content/uploads/*.gif$<br>Disallow: /</p>
<p>User-agent: googlebot-image<br>Allow: /wp-content/uploads/<em>.jpg$<br>Allow: /wp-content/uploads/</em>.png$<br>Allow: /wp-content/uploads/*.gif$<br>Disallow: /</p>
<p>User-agent: googlebot-mobile<br>Allow: /wp-content/uploads/<em>.jpg$<br>Allow: /wp-content/uploads/</em>.png$<br>Allow: /wp-content/uploads/*.gif$<br>Disallow: /</p>
<p>User-agent: yahoo-blogs/v3.9<br>Allow: /wp-content/uploads/<em>.jpg$<br>Allow: /wp-content/uploads/</em>.png$<br>Allow: /wp-content/uploads/*.gif$<br>Disallow: /</p>
<p>User-agent: psbot<br>Allow: /wp-content/uploads/<em>.jpg$<br>Allow: /wp-content/uploads/</em>.png$<br>Allow: /wp-content/uploads/*.gif$<br>Disallow: /</p>
<p>User-agent: <em><br>Disallow: /<br>2、第二，做好Nginx防盗链。如果你的CDN服务器流量不怎么够的话，建议还是做好防盗链措施，同时还可以帮你减轻服务器负担。在你的虚拟主机配置文件中加入以下代码：<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>location ~ .</em>.(gif|jpg|jpeg|png|bmp|swf)$<br>          {<br>                  valid_referers none blocked freehao123.com <em>.freehao123.com </em>.google.cn <em>.google.com </em>.google.com.hk image.baidu.com *.baidu.com;<br>                  if ($invalid_referer) {<br>                  rewrite ^/ <a href="https://www.freehao123.com" target="_blank" rel="external">https://www.freehao123.com</a>;</p>
<pre><code>        #return 403;
        }
}
</code></pre><p>3、第三，设置好Nginx默认图片。这个主要是针对缓存Gravatar头像的，当源站服务器不存在某一个图片或者文件时，我们可以给Nginx设置一个默认的图片或者链接，这样缓存看起来就完美了。<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br> location /avatar {</p>
<p> try_files $uri /avatar/set-avatar.png;</p>
<p>}</p>
<p>#或者使用：<br> location /{</p>
<p> try_files $uri /set-avatar.png;</p>
<p>}<br>4、效果见下图：<br>用Nginx搭建CDN默认图片<br>文章出自：免费资源部落 部分内容参考张戈博客\cheyo.net\ttt.tt版权所有。本站文章除注明出处外，皆为作者原创文章，可自由引用，但请注明来源。<br>2014年六大免费VPS主机-免费VPS申请、使用和点评<br>您或许对下面这些文章有兴趣:                    本月吐槽辛苦排行榜<br>UPyun又拍云CDN安装部署Let’s Encrypt免费SSL证书和配置自定义SSL证书<br>Kloudsec免费CDN加速-提供免费SSL证书支持Https自定义SSL新加坡节点<br>服务器性能管理(APM)：性能魔方mmtrix一站式云评测,云监测,云加速网站<br>UPYUN又拍云动态CDN和静态CDN加速支持自定义域名Https和图片处理<br>阿里百川多媒体-20GB免费存储空间和CDN流量支持图片,视频在线处理<br>2014年十个优秀的免费CDN加速服务-国内和国外免费CDN<br>Incapsula免费CDN服务申请使用:日本,香港,美国CDN加速效果测评<br>Discuz论坛使用七牛,又拍,阿里云OSS CDN加速：CSS,JS,图片,论坛附件</p>
]]></content>
    
    <summary type="html">
    
      用Nginx搭建CDN服务器方法-开启Nginx缓存与镜像,自建图片服务器
    
    </summary>
    
      <category term="Nginx" scheme="http://jishusuishouji.github.io/categories/Nginx/"/>
    
    
      <category term="Nginx" scheme="http://jishusuishouji.github.io/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>druid 配置WebStatFilter 网络url统计</title>
    <link href="http://jishusuishouji.github.io/2017/03/23/druid/druid_%E9%85%8D%E7%BD%AEWebStatFilter_%E7%BD%91%E7%BB%9Curl%E7%BB%9F%E8%AE%A1/"/>
    <id>http://jishusuishouji.github.io/2017/03/23/druid/druid_配置WebStatFilter_网络url统计/</id>
    <published>2017-03-23T14:54:59.000Z</published>
    <updated>2017-03-23T15:01:52.687Z</updated>
    
    <content type="html"><![CDATA[<p><code>WebStatFilter</code>用于采集web-jdbc关联监控的数据。<br><a id="more"></a></p>
<h2 id="web-xml配置"><a href="#web-xml配置" class="headerlink" title="web.xml配置"></a><code>web.xml</code>配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">&lt;filter&gt;  </div><div class="line">  &lt;filter-name&gt;DruidWebStatFilter&lt;/filter-name&gt;  </div><div class="line">  &lt;filter-class&gt;com.alibaba.druid.support.http.WebStatFilter&lt;/filter-class&gt;  </div><div class="line">  &lt;init-param&gt;  </div><div class="line">      &lt;param-name&gt;exclusions&lt;/param-name&gt;  </div><div class="line">      &lt;param-value&gt;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&lt;/param-value&gt;  </div><div class="line">  &lt;/init-param&gt;  </div><div class="line">&lt;/filter&gt;  </div><div class="line">&lt;filter-mapping&gt;  </div><div class="line">  &lt;filter-name&gt;DruidWebStatFilter&lt;/filter-name&gt;  </div><div class="line">  &lt;url-pattern&gt;/*&lt;/url-pattern&gt;  </div><div class="line">&lt;/filter-mapping&gt;</div></pre></td></tr></table></figure>
<h3 id="exlusions配置"><a href="#exlusions配置" class="headerlink" title="exlusions配置"></a><code>exlusions</code>配置</h3><p>经常需要排除一些不必要的<code>url</code>，比如<code>.js</code>,<code>/jslib/</code>等等。配置在<code>init-param</code>中。比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&lt;init-param&gt;  </div><div class="line">    &lt;param-name&gt;exclusions&lt;/param-name&gt;  </div><div class="line">    &lt;param-value&gt;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&lt;/param-value&gt;  </div><div class="line">&lt;/init-param&gt;</div></pre></td></tr></table></figure></p>
<h3 id="sessionStatMaxCount配置"><a href="#sessionStatMaxCount配置" class="headerlink" title="sessionStatMaxCount配置"></a><code>sessionStatMaxCount</code>配置</h3><p>缺省<code>sessionStatMaxCount</code>是1000个。你可以按需要进行配置，比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&lt;init-param&gt;  </div><div class="line">    &lt;param-name&gt;sessionStatMaxCount&lt;/param-name&gt;  </div><div class="line">    &lt;param-value&gt;1000&lt;/param-value&gt;  </div><div class="line">&lt;/init-param&gt;</div></pre></td></tr></table></figure></p>
<h3 id="sessionStatEnable配置"><a href="#sessionStatEnable配置" class="headerlink" title="`sessionStatEnable配置"></a><code>`sessionStatEnable</code>配置</h3><p>你可以关闭session统计功能，比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&lt;init-param&gt;  </div><div class="line">    &lt;param-name&gt;sessionStatEnable&lt;/param-name&gt;  </div><div class="line">    &lt;param-value&gt;false&lt;/param-value&gt;  </div><div class="line">&lt;/init-param&gt;</div></pre></td></tr></table></figure></p>
<h3 id="principalSessionName配置"><a href="#principalSessionName配置" class="headerlink" title="principalSessionName配置"></a><code>principalSessionName</code>配置</h3><p>你可以配置<code>principalSessionName</code>，使得druid能够知道当前的session的用户是谁。比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&lt;init-param&gt;  </div><div class="line">    &lt;param-name&gt;principalSessionName&lt;/param-name&gt;  </div><div class="line">    &lt;param-value&gt;xxx.user&lt;/param-value&gt;  </div><div class="line">&lt;/init-param&gt;</div></pre></td></tr></table></figure></p>
<p>根据需要，把其中的<code>xxx.user</code>修改为你<code>user</code>信息保存在session中的<code>sessionName</code>。</p>
<p>注意：如果你session中保存的是非string类型的对象，需要重载toString方法</p>
<h3 id="principalCookieName"><a href="#principalCookieName" class="headerlink" title="principalCookieName"></a><code>principalCookieName</code></h3><p>如果你的user信息保存在cookie中，你可以配置<code>principalCookieName</code>，使得druid知道当前的user是谁<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&lt;init-param&gt;  </div><div class="line">    &lt;param-name&gt;principalCookieName&lt;/param-name&gt;  </div><div class="line">    &lt;param-value&gt;xxx.user&lt;/param-value&gt;  </div><div class="line">&lt;/init-param&gt;</div></pre></td></tr></table></figure></p>
<p>根据需要，把其中的<code>xxx.user</code>修改为你user信息保存在cookie中的<code>cookieName</code></p>
<h3 id="profileEnable"><a href="#profileEnable" class="headerlink" title="profileEnable"></a><code>profileEnable</code></h3><p>druid 0.2.7版本开始支持profile，配置<code>profileEnable</code>能够监控单个url调用的sql列表。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&lt;init-param&gt;  </div><div class="line">    &lt;param-name&gt;profileEnable&lt;/param-name&gt;  </div><div class="line">    &lt;param-value&gt;true&lt;/param-value&gt;  </div><div class="line">&lt;/init-param&gt;</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      druid 配置WebStatFilter 网络url统计
    
    </summary>
    
      <category term="druid" scheme="http://jishusuishouji.github.io/categories/druid/"/>
    
    
      <category term="druid" scheme="http://jishusuishouji.github.io/tags/druid/"/>
    
  </entry>
  
  <entry>
    <title>DRUID连接池的实用 配置详解</title>
    <link href="http://jishusuishouji.github.io/2017/03/23/druid/DRUID%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%9A%84%E5%AE%9E%E7%94%A8_%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/"/>
    <id>http://jishusuishouji.github.io/2017/03/23/druid/DRUID连接池的实用_配置详解/</id>
    <published>2017-03-23T14:03:57.000Z</published>
    <updated>2017-03-23T14:57:31.301Z</updated>
    
    <content type="html"><![CDATA[<h2 id="DRUID介绍"><a href="#DRUID介绍" class="headerlink" title="DRUID介绍"></a>DRUID介绍</h2><p>DRUID是阿里巴巴开源平台上一个数据库连接池实现，它结合了C3P0、DBCP、PROXOOL等DB池的优点，同时加入了日志监控，可以很好的监控DB池连接和SQL的执行情况，可以说是<strong>针对监控而生的DB连接池</strong>(据说是目前最好的连接池,不知道速度有没有BoneCP快)。<br><a id="more"></a></p>
<h2 id="配置参数"><a href="#配置参数" class="headerlink" title="配置参数"></a>配置参数</h2><p>和其它连接池一样DRUID的<code>DataSource</code>类为：<code>com.alibaba.druid.pool.DruidDataSource</code>，基本配置参数如下：</p>
<ul>
<li><code>name</code> 配置这个属性的意义在于，如果存在多个数据源，监控的时候可以通过名字来区分开来。<br>如果没有配置，将会生成一个名字，格式是：”DataSource-“ + <code>System.identityHashCode(this)</code>  </li>
<li><code>jdbcUrl</code><br>连接数据库的url，不同数据库不一样。例如：<br><code>mysql:jdbc:mysql://10.20.153.104:3306/druid2</code><br><code>oracle:jdbc:oracle:thin:@10.20.149.85:1521:ocnauto</code></li>
<li><code>username</code><br>连接数据库的用户名</li>
<li><code>password</code><br>连接数据库的密码。如果你不希望密码直接写在配置文件中，可以使用<code>ConfigFilter</code>。</li>
<li><code>driverClassName</code><br>根据url自动识别<br>这一项可配可不配，如果不配置druid会根据url自动识别dbType，然后选择相应的<code>driverClassName</code>(建议配置下)</li>
<li><code>initialSize</code><br>默认值0，初始化时建立物理连接的个数。初始化发生在显示调用<code>init</code>方法，或者第一次<code>getConnection</code>时</li>
<li><code>maxActive</code><br>默认值8<br>最大连接池数量</li>
<li><code>maxIdle</code><br>默认值8<br>已经不再使用，配置了也没效果</li>
<li><code>minIdle</code><br>最小连接池数量</li>
<li><code>maxWait</code><br>获取连接时最大等待时间，单位毫秒。配置了<code>maxWait</code>之后，缺省启用公平锁，并发效率会有所下降，如果需要可以通过配置<code>useUnfairLock</code>属性为<code>true</code>使用非公平锁。</li>
<li><code>poolPreparedStatements</code><br><code>false</code><br>是否缓存<code>preparedStatement</code>，也就是<code>PSCache</code>。PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql下建议关闭。</li>
<li><code>maxOpenPreparedStatements</code><br><code>-1</code><br>要启用<code>PSCache</code>，必须配置大于0，当大于0时，<code>poolPreparedStatements</code>自动触发修改为<code>true</code>。在Druid中，不会存在Oracle下<code>PSCache</code>占用内存过多的问题，可以把这个数值配置大一些，比如说100</li>
<li><code>validationQuery</code><br>用来检测连接是否有效的sql，要求是一个查询语句。如果<code>validationQuery</code>为<code>null</code>，<code>testOnBorrow</code>、<code>testOnReturn</code>、<code>testWhileIdle</code>都不会其作用。</li>
<li><code>testOnBorrow</code><br><code>true</code><br>申请连接时执行<code>validationQuery</code>检测连接是否有效，做了这个配置会降低性能。</li>
<li><code>testOnReturn</code><br><code>false</code><br>归还连接时执行<code>validationQuery</code>检测连接是否有效，做了这个配置会降低性能</li>
<li><code>testWhileIdle</code><br><code>false</code><br>建议配置为<code>true</code>，不影响性能，并且保证安全性。申请连接的时候检测，如果空闲时间大于<code>timeBetweenEvictionRunsMillis</code>，执行<code>validationQuery</code>检测连接是否有效。<br><code>timeBetweenEvictionRunsMillis</code><br>有两个含义：<br>1) <code>Destroy</code>线程会检测连接的间隔时间<br>2) <code>testWhileIdle</code>的判断依据，详细看<code>testWhileIdle</code>属性的说明</li>
<li><code>numTestsPerEvictionRun</code><br>不再使用，一个DruidDataSource只支持一个<code>EvictionRun</code></li>
<li><code>minEvictableIdleTimeMillis</code><br><code>connectionInitSqls</code><br>物理连接初始化的时候执行的sql</li>
<li><code>exceptionSorter</code><br>根据dbType自动识别<br>当数据库抛出一些不可恢复的异常时，抛弃连接</li>
<li><code>filters</code><br>属性类型是字符串，通过别名的方式配置扩展插件，常用的插件有：<br>监控统计用的filter:stat<br>日志用的filter:log4j<br>防御sql注入的filter:wall</li>
<li><code>proxyFilters</code><br>类型是<code>List&lt;com.alibaba.druid.filter.Filter&gt;</code>，如果同时配置了filters和proxyFilters，是组合关系，并非替换关系</li>
</ul>
<h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><p>DB数据源的使用方法也就是2种，一种是在代码中写死通过NEW操作符创建<code>DataSSource</code>，然后set一些连接属性;另外一种是基于SPRING的配置方法，然后让SPRING的Context自动加载配置（以下配置文件默认都在项目根目录下conf文件夹中）</p>
<p>1、属性文件:<code>application.properties</code>(DataSource连接参数)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">jdbc.driverClassName=com.mysql.jdbc.Driver </div><div class="line">jdbc.url=jdbc:mysql://127.0.0.1:3306/test </div><div class="line">jdbc.username=root </div><div class="line">jdbc.password=1qaz!QAZ</div></pre></td></tr></table></figure>
<p>2、SPRING配置文件：<code>spring-base.xml</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; </div><div class="line">&lt;beans xmlns=&quot; http://www.springframework.org/schema/beans&quot; </div><div class="line"> xmlns:xsi=&quot; http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:batch=&quot; http://www.springframework.org/schema/batch&quot; </div><div class="line"> xsi:schemaLocation=&quot; http://www.springframework.org/schema/beans </div><div class="line">           http://www.springframework.org/schema/beans/spring-beans-4.0.xsd&quot;&gt;</div><div class="line"></div><div class="line"> </div><div class="line"></div><div class="line"> &lt;bean id=&quot;propertyConfigure&quot; </div><div class="line">  class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt; </div><div class="line">  &lt;property name=&quot;locations&quot;&gt; </div><div class="line">   &lt;list&gt; </div><div class="line">    &lt;value&gt;./conf/application.properties&lt;/value&gt; </div><div class="line">   &lt;/list&gt; </div><div class="line">  &lt;/property&gt; </div><div class="line"> &lt;/bean&gt;</div><div class="line"></div><div class="line"> </div><div class="line"></div><div class="line"> &lt;bean id=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; </div><div class="line">  init-method=&quot;init&quot; destroy-method=&quot;close&quot;&gt; </div><div class="line">  &lt;property name=&quot;driverClassName&quot; value=&quot;$&#123;jdbc.driverClassName&#125;&quot; /&gt; </div><div class="line">  &lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url&#125;&quot; /&gt; </div><div class="line">  &lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username&#125;&quot; /&gt; </div><div class="line">  &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot; /&gt; </div><div class="line">  &lt;!-- 配置初始化大小、最小、最大 --&gt; </div><div class="line">  &lt;property name=&quot;initialSize&quot; value=&quot;1&quot; /&gt; </div><div class="line">  &lt;property name=&quot;minIdle&quot; value=&quot;1&quot; /&gt; </div><div class="line">  &lt;property name=&quot;maxActive&quot; value=&quot;10&quot; /&gt;</div><div class="line"></div><div class="line">  &lt;!-- 配置获取连接等待超时的时间 --&gt; </div><div class="line">  &lt;property name=&quot;maxWait&quot; value=&quot;10000&quot; /&gt;</div><div class="line"></div><div class="line">  &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; </div><div class="line">  &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;60000&quot; /&gt;</div><div class="line"></div><div class="line">  &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; </div><div class="line">  &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;300000&quot; /&gt;</div><div class="line"></div><div class="line">  &lt;property name=&quot;testWhileIdle&quot; value=&quot;true&quot; /&gt;</div><div class="line"></div><div class="line">  &lt;!-- 这里建议配置为TRUE，防止取到的连接不可用 --&gt; </div><div class="line">  &lt;property name=&quot;testOnBorrow&quot; value=&quot;true&quot; /&gt; </div><div class="line">  &lt;property name=&quot;testOnReturn&quot; value=&quot;false&quot; /&gt;</div><div class="line"></div><div class="line">  &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; </div><div class="line">  &lt;property name=&quot;poolPreparedStatements&quot; value=&quot;true&quot; /&gt; </div><div class="line">  &lt;property name=&quot;maxPoolPreparedStatementPerConnectionSize&quot; </div><div class="line">   value=&quot;20&quot; /&gt;</div><div class="line"></div><div class="line">  &lt;!-- 这里配置提交方式，默认就是TRUE，可以不用配置 --&gt;</div><div class="line"></div><div class="line">  &lt;property name=&quot;defaultAutoCommit&quot; value=&quot;true&quot; /&gt;</div><div class="line"></div><div class="line">  &lt;!-- 验证连接有效与否的SQL，不同的数据配置不同 --&gt; </div><div class="line">  &lt;property name=&quot;validationQuery&quot; value=&quot;select 1 &quot; /&gt; </div><div class="line">  &lt;property name=&quot;filters&quot; value=&quot;stat&quot; /&gt; </div><div class="line">  &lt;property name=&quot;proxyFilters&quot;&gt; </div><div class="line">   &lt;list&gt; </div><div class="line">    &lt;ref bean=&quot;logFilter&quot; /&gt; </div><div class="line">   &lt;/list&gt; </div><div class="line">  &lt;/property&gt; </div><div class="line"> &lt;/bean&gt;</div><div class="line"></div><div class="line"> </div><div class="line"></div><div class="line"> &lt;bean id=&quot;logFilter&quot; class=&quot;com.alibaba.druid.filter.logging.Slf4jLogFilter&quot;&gt; </div><div class="line">  &lt;property name=&quot;statementExecutableSqlLogEnable&quot; value=&quot;false&quot; /&gt; </div><div class="line"> &lt;/bean&gt;</div><div class="line"></div><div class="line">&lt;/beans&gt;</div></pre></td></tr></table></figure>
<h2 id="监控方式"><a href="#监控方式" class="headerlink" title="监控方式"></a>监控方式</h2><h3 id="1、WEB方式监控配置"><a href="#1、WEB方式监控配置" class="headerlink" title="1、WEB方式监控配置"></a>1、WEB方式监控配置</h3><pre><code>&lt;servlet&gt; 
     &lt;servlet-name&gt;DruidStatView&lt;/servlet-name&gt; 
     &lt;servlet-class&gt;com.alibaba.druid.support.http.StatViewServlet&lt;/servlet-class&gt; 
 &lt;/servlet&gt; 
 &lt;servlet-mapping&gt; 
     &lt;servlet-name&gt;DruidStatView&lt;/servlet-name&gt; 
     &lt;url-pattern&gt;/druid/*&lt;/url-pattern&gt; 
 &lt;/servlet-mapping&gt; 
 &lt;filter&gt; 
  &lt;filter-name&gt;druidWebStatFilter&lt;/filter-name&gt; 
  &lt;filter-class&gt;com.alibaba.druid.support.http.WebStatFilter&lt;/filter-class&gt; 
  &lt;init-param&gt; 
   &lt;param-name&gt;exclusions&lt;/param-name&gt; 
   &lt;param-value&gt;/public/*,*.js,*.css,/druid*,*.jsp,*.swf&lt;/param-value&gt; 
  &lt;/init-param&gt; 
  &lt;init-param&gt; 
   &lt;param-name&gt;principalSessionName&lt;/param-name&gt; 
   &lt;param-value&gt;sessionInfo&lt;/param-value&gt; 
  &lt;/init-param&gt; 
  &lt;init-param&gt; 
   &lt;param-name&gt;profileEnable&lt;/param-name&gt; 
   &lt;param-value&gt;true&lt;/param-value&gt; 
  &lt;/init-param&gt; 
 &lt;/filter&gt; 
 &lt;filter-mapping&gt; 
  &lt;filter-name&gt;druidWebStatFilter&lt;/filter-name&gt; 
  &lt;url-pattern&gt;/*&lt;/url-pattern&gt; 
 &lt;/filter-mapping&gt;
</code></pre><p>把上面servlet配置添加到项目<code>web.xml</code>即可。然后运行Tomcat，浏览器输入 <a href="http://IP:PROT/druid" target="_blank" rel="external">http://IP:PROT/druid</a></p>
<p>就可以打开Druid的监控页面了.</p>
<h3 id="2、日志文件监控"><a href="#2、日志文件监控" class="headerlink" title="2、日志文件监控"></a>2、日志文件监控</h3><p>Druid提供了多种日志文件监控commons-logging、log4j等，这里我们主要使用slf4j和logback来进行日志监控配置。</p>
<p>首先要引入slf4j和logback相关的jar文件（从Maven公共仓库下载 <a href="http://search.maven.org/）" target="_blank" rel="external">http://search.maven.org/）</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">&lt;slf4j.version&gt;1.7.7&lt;/slf4j.version&gt; </div><div class="line">&lt;logback.version&gt;1.1.2&lt;/logback.version&gt;</div><div class="line"></div><div class="line"> </div><div class="line"></div><div class="line">&lt;dependency&gt; </div><div class="line">    &lt;groupId&gt;org.slf4j&lt;/groupId&gt; </div><div class="line">    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; </div><div class="line">    &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; </div><div class="line"> &lt;/dependency&gt; </div><div class="line">&lt;dependency&gt; </div><div class="line">    &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; </div><div class="line">    &lt;artifactId&gt;logback-access&lt;/artifactId&gt; </div><div class="line">    &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; </div><div class="line">&lt;/dependency&gt; </div><div class="line">&lt;dependency&gt; </div><div class="line">    &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; </div><div class="line">    &lt;artifactId&gt;logback-core&lt;/artifactId&gt; </div><div class="line">    &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; </div><div class="line">&lt;/dependency&gt; </div><div class="line">&lt;dependency&gt; </div><div class="line">    &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; </div><div class="line">    &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; </div><div class="line">    &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; </div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p>接下配置logback的配置文件(<code>./conf/logback.xml</code>)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line"></div><div class="line"> &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; </div><div class="line">  &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; </div><div class="line">   &lt;Pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n </div><div class="line">   &lt;/Pattern&gt; </div><div class="line">  &lt;/layout&gt; </div><div class="line"> &lt;/appender&gt;</div><div class="line"></div><div class="line"> &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt; </div><div class="line">  &lt;file&gt;./logs/druid_info.log&lt;/file&gt; </div><div class="line">  &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; </div><div class="line">   &lt;Pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/Pattern&gt; </div><div class="line">  &lt;/layout&gt; </div><div class="line">  &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; </div><div class="line">   &lt;level&gt;debug&lt;/level&gt; </div><div class="line">  &lt;/filter&gt; </div><div class="line"> &lt;/appender&gt;</div><div class="line"></div><div class="line"> &lt;root level=&quot;DEBUG&quot;&gt; </div><div class="line">  &lt;appender-ref ref=&quot;FILE&quot; /&gt; </div><div class="line"> &lt;/root&gt; </div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<p>最后就是写一个测试类进行测试</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">public class TestMain &#123;</div><div class="line"></div><div class="line"> public static void loadLoggerContext() &#123; </div><div class="line">  System.getProperties().put(&quot;logback.configurationFile&quot;, &quot;./conf/logback.xml&quot;); </div><div class="line">  LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory(); </div><div class="line">  StatusPrinter.setPrintStream(System.err); </div><div class="line">  StatusPrinter.print(lc); </div><div class="line"> &#125;</div><div class="line"></div><div class="line"> public static void main(String[] args) &#123; </div><div class="line">  try &#123; </div><div class="line">   loadLoggerContext(); </div><div class="line">   FileSystemXmlApplicationContext context = new FileSystemXmlApplicationContext(&quot;./conf/spring-base.xml&quot;); </div><div class="line"></div><div class="line">  &#125; catch (Exception e) &#123; </div><div class="line">   System.out.println(e); </div><div class="line">  &#125; </div><div class="line"> &#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      DRUID连接池的实用 配置详解
    
    </summary>
    
      <category term="Druid" scheme="http://jishusuishouji.github.io/categories/Druid/"/>
    
    
      <category term="Druid" scheme="http://jishusuishouji.github.io/tags/Druid/"/>
    
  </entry>
  
  <entry>
    <title>Druid：一个用于大数据实时处理的开源分布式系统</title>
    <link href="http://jishusuishouji.github.io/2017/03/23/druid/Druid%EF%BC%9A%E4%B8%80%E4%B8%AA%E7%94%A8%E4%BA%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%97%B6%E5%A4%84%E7%90%86%E7%9A%84%E5%BC%80%E6%BA%90%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    <id>http://jishusuishouji.github.io/2017/03/23/druid/Druid：一个用于大数据实时处理的开源分布式系统/</id>
    <published>2017-03-23T14:00:02.000Z</published>
    <updated>2017-03-23T14:02:58.182Z</updated>
    
    <content type="html"><![CDATA[<p>Druid是一个用于大数据实时查询和分析的高容错、高性能开源分布式系统，旨在快速处理大规模的数据，并能够实现快速查询和分析。尤其是当发生代码部署、机器故障以及其他产品系统遇到宕机等情况时，Druid仍能够保持100%正常运行。创建Druid的最初意图主要是为了解决查询延迟问题，当时试图使用Hadoop来实现交互式查询分析，但是很难满足实时分析的需要。而Druid提供了以交互方式访问数据的能力，并权衡了查询的灵活性和性能而采取了特殊的存储格式。<br><a id="more"></a><br>Druid功能介于PowerDrill和Dremel之间，它几乎实现了Dremel的所有功能，并且从PowerDrill吸收一些有趣的数据格式。Druid允许以类似Dremel和PowerDrill的方式进行单表查询，同时还增加了一些新特性，如为局部嵌套数据结构提供列式存储格式、为快速过滤做索引、实时摄取和查询、高容错的分布式体系架构等。从官方得知，Druid的具有以下主要特征：</p>
<ul>
<li>为分析而设计——Druid是为OLAP工作流的探索性分析而构建，它支持各种过滤、聚合和查询等类；</li>
<li>快速的交互式查询——Druid的低延迟数据摄取架构允许事件在它们创建后毫秒内可被查询到；</li>
<li>高可用性——Druid的数据在系统更新时依然可用，规模的扩大和缩小都不会造成数据丢失；</li>
<li>可扩展——Druid已实现每天能够处理数十亿事件和TB级数据。</li>
<li>Druid应用最多的是类似于广告分析创业公司Metamarkets中的应用场景，如广告分析、互联网广告系统监控以及网络监控等。当业务中出现以下情况时，Druid是一个很好的技术方案选择：</li>
</ul>
<p>需要交互式聚合和快速探究大量数据时；<br>需要实时查询分析时；<br>具有大量数据时，如每天数亿事件的新增、每天数10T数据的增加；<br>对数据尤其是大数据进行实时分析时；<br>需要一个高可用、高容错、高性能数据库时。<br>一个Druid集群有各种类型的节点（Node）组成，每个节点都可以很好的处理一些的事情，这些节点包括对非实时数据进行处理存储和查询的Historical节点、实时摄取数据、监听输入数据流的Realtime节、监控Historical节点的Coordinator节点、接收来自外部客户端的查询和将查询转发到Realtime和Historical节点的Broker节点、负责索引服务的Indexer节点。</p>
<p>查询操作中数据流和各个节点的关系如下图所示：</p>
<p>如下图是Druid集群的管理层架构，该图展示了相关节点和集群管理所依赖的其他组件（如负责服务发现的ZooKeeper集群）的关系：</p>
<p>Druid已基于Apache License 2.0协议开源，代码托管在GitHub，其当前最新稳定版本是0.7.1.1。当前，Druid已有63个代码贡献者和将近2000个关注。Druid的主要贡献者包括广告分析创业公司Metamarkets、电影流媒体网站Netflix、Yahoo等公司。Druid官方还对Druid同Shark、Vertica、Cassandra、Hadoop、Spark、Elasticsearch等在容错能力、灵活性、查询性能等方便进行了对比说明。更多关于Druid的信息，大家还可以参考官方提供的入门教程、白皮书 、设计文档等。</p>
<p>感谢徐川对本文的审校。</p>
]]></content>
    
    <summary type="html">
    
      Druid：一个用于大数据实时处理的开源分布式系统
    
    </summary>
    
      <category term="Druid" scheme="http://jishusuishouji.github.io/categories/Druid/"/>
    
    
      <category term="Druid" scheme="http://jishusuishouji.github.io/tags/Druid/"/>
    
  </entry>
  
  <entry>
    <title>架构师必看 京东咚咚架构演进</title>
    <link href="http://jishusuishouji.github.io/2017/03/21/jiagou/%E6%9E%B6%E6%9E%84%E5%B8%88%E5%BF%85%E7%9C%8B_%E4%BA%AC%E4%B8%9C%E5%92%9A%E5%92%9A%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B/"/>
    <id>http://jishusuishouji.github.io/2017/03/21/jiagou/架构师必看_京东咚咚架构演进/</id>
    <published>2017-03-21T13:01:44.000Z</published>
    <updated>2017-03-25T15:08:34.640Z</updated>
    
    <content type="html"><![CDATA[<p>技术架构单独拿出来看我认为没有绝对的好与不好，技术架构总是要放在彼时的背景下来看，要考虑业务的时效价值、团队的规模和能力、环境基础设施等等方面。 架构演进的生命周期适时匹配好业务的生命周期，才可能发挥最好的效果。</p>
<h2 id="京东咚咚"><a href="#京东咚咚" class="headerlink" title="京东咚咚"></a>京东咚咚</h2><p>自从京东开始为第三方卖家提供入驻平台服务后，咚咚也就随之诞生了。 </p>
<h3 id="1-0-诞生（2010-–-2011"><a href="#1-0-诞生（2010-–-2011" class="headerlink" title="1.0 诞生（2010 – 2011)"></a>1.0 诞生（2010 – 2011)</h3><p>为了业务的快速上线，1.0 版本的技术架构实现是非常直接且简单粗暴的。 如何简单粗暴法？请看架构图，如下。<br><img src="/img/京东咚咚1.0.jpg" alt="京东咚咚1.0"><br>京东咚咚1.0的功能十分简单，实现了一个IM的基本功能，接入、互通消息和状态。另外还有客服功能，就是顾客接入咨询时的客服分配，按轮询方式把顾客分配给在线的客服接待。 用开源Mina框架实现了TCP的长连接接入，用Tomcat Comet机制实现了HTTP的长轮询服务。而消息投递的实现是一端发送的消息临时存放在 Redis中，另一端拉取的生产消费模型。<br>这个模型的做法导致需要以一种高频率的方式来轮询Redis遍历属于自己连接的关联会话消息。这个模型很简单，简单包括多个层面的意思：理解起来简单；开发起来简单；部署起来也简单。只需要一个Tomcat应用依赖一个共享的Redis，简单的实现核心业务功能，并支持业务快速上线。<br>但这个简单的模型也有些严重的缺陷，主要是效率和扩展问题。轮询的频率间隔大小基本决定了消息的延时，轮询越快延时越低，但轮询越快消耗也越高。这个模型实际上是一个高功耗低效能的模型，因为不活跃的连接在那做高频率的无意义轮询。 高频有多高呢，基本在100ms以内，你不能让轮询太慢，比如超过2秒轮一次，人就会在聊天过程中感受到明显的会话延迟。 随着在线人数增加，轮询的耗时也线性增长，因此这个模型导致了扩展能力和承载能力都不好，一定会随着在线人数的增长碰到性能瓶颈。</p>
<p>1.0的时代背景正是京东技术平台从.NET向Java转型的年代，我也正是在这期间加入京东并参与了京东主站技术转型架构升级的过程。 之后开始接手了京东咚咚，并持续完善这个产品，进行了三次技术架构演进。</p>
<h2 id="2-0-成长（2012）"><a href="#2-0-成长（2012）" class="headerlink" title="2.0 成长（2012）"></a>2.0 成长（2012）</h2><p>我们刚接手时1.0已在线上运行并支持京东POP（开放平台）业务，之后京东打算组建自营在线客服团队并落地在成都。不管是自营还是POP客服咨询业务当时都起步不久，1.0架构中的性能和效率缺陷问题还没有达到引爆的业务量级。而自营客服当时还处于起步阶段，客服人数不足，服务能力不够，顾客咨询量远远超过客服的服务能力。超出服务能力的顾客咨询，当时我们的系统统一返回提示客服繁忙，请稍后咨询。 这种状况导致高峰期大量顾客无论怎么刷新请求，都很可能无法接入客服，体验很差。所以2.0重点放在了业务功能体验的提升上，如下图所示。<br><img src="/img/京东咚咚2.0.jpg" alt="京东咚咚"><br>京东咚咚针对无法及时提供服务的顾客，可以排队或者留言。 针对纯文字沟通，提供了文件和图片等更丰富的表达方式。 另外支持了客服转接和快捷回复等方式来提升客服的接待效率。总之，整个2.0就是围绕提升客服效率和用户体验。而我们担心的效率问题在2.0高速发展业务的时期还没有出现，但业务量正在逐渐积累，我们知道它快要爆了。到2012年末，度过双十一后开始了3.0的一次重大架构升级。</p>
<h2 id="3-0爆发（2013-–-2014）"><a href="#3-0爆发（2013-–-2014）" class="headerlink" title="3.0爆发（2013 – 2014）"></a>3.0爆发（2013 – 2014）</h2><p>经历了2.0时代一整年的业务高速发展，实际上代码规模膨胀的很快。与代码一块膨胀的还有团队，从最初的4个人到近30人。 团队大了后，一个系统多人开发，开发人员层次不一，规范难统一，系统模块耦合重，改动沟通和依赖多，上线风险难以控制。一个单独tomcat应用多实例部署模型终于走到头了，这个版本架构升级的主题就是服务化。服务化的第一个问题如何把一个大的应用系统切分成子服务系统。当时的背景是京东的部署还在半自动化年代，自动部署系统刚起步，子服务系统若按业务划分太细太多，部署工作量很大且难管理。所以当时我们不是按业务功能分区服务的，而是按业务重要性级别划分了0、1、2 三个级别不同的子业务服务系统。 另外就是独立了一组接入服务，针对不同渠道和通信方式的接入端，见下图。<br><img src="/img/京东咚咚3.0服务化.jpg" alt="京东咚咚"><br>更细化的应用服务和架构分层方式可见下图。<br><img src="/img/京东咚咚3.0细化服务化.jpg" alt="京东咚咚"><br>这次大的架构升级，主要考虑了三个方面：稳定性、效率和容量。 做了下面这些事情：<br>1.业务分级、核心、非核心业务隔离<br>2.多机房部署，流量分流、容灾冗余、峰值应对冗余<br>3.读库多源，失败自动转移<br>4.写库主备，短暂有损服务容忍下的快速切换<br>5.外部接口，失败转移或快速断路<br>6.Redis 主备，失败转移<br>7.大表迁移，MongoDB 取代 MySQL 存储消息记录<br>8.改进消息投递模型</p>
<p>前 6 条基本属于考虑系统稳定性、可用性方面的改进升级。 这一块属于陆续迭代完成的，承载很多失败转移的配置和控制功能在上面图中是由管控中心提供的。 第 7 条主要是随着业务量的上升，单日消息量越来越大后，使用了 MongoDB来单独存储量最大的聊天记录。 第 8 条是针对 1.0版本消息轮询效率低的改进，改进后的投递方式如下图所示：<br><img src="/img/京东咚咚3.0优化轮训服务.jpg" alt="京东咚咚"><br>不再是轮询了，而是让终端每次建立连接后注册接入点位置，消息投递前定位连接所在接入点位置再推送过去。 这样投递效率就是恒定的了，而且很容易扩展，在线人数越多则连接数越多，只需要扩展接入点即可。 其实，这个模型依然还有些小问题，主要出在离线消息的处理上，可以先思考下，我们最后再讲。<br>3.0 经过了两年的迭代式升级，单纯从业务量上来说还可以继续支撑很长时间的增长。 但实际上到2014年底我们面对的不再是业务量的问题，而是业务模式的变化。 这直接导致了一个全新时代的到来。</p>
<h2 id="4-0-涅槃（2015-至今"><a href="#4-0-涅槃（2015-至今" class="headerlink" title="4.0 涅槃（2015 至今 )"></a>4.0 涅槃（2015 至今 )</h2><p>2014年京东的组织架构发生了很大变化，从一个公司变成了一个集团，下设多个子公司。原来的商城成为了其中一个子公司，新成立的子公司包括京东金融、京东智能、京东到家、拍拍、海外事业部等。各自业务范围不同，业务模式也不同，但不管什么业务总是需要客服服务。如何复用原来为商城量身订做的咚咚客服系统并支持其他子公司业务快速接入成为我们新的课题。<br>最早要求接入的是拍拍网，它是从腾讯收购的，所以是完全不同的账户和订单交易体系。由于时间紧迫，我们把为商城订做的部分剥离，基于3.0架构对接拍拍又单独订做了一套，并独立部署，像下面这样。<br>京东咚咚<br>虽然在业务要求的时间点前完成了上线，但这样做也带来了明显的问题：<br>复制工程，定制业务开发，多套源码维护成本高<br>独立部署，至少双机房主备外加一个灰度集群，资源浪费大<br>以前我们都是面向业务去架构系统，如今新的业务变化形势下我们开始考虑面向平台去架构，在统一平台上跑多套业务，统一源码，统一部署，统一维护。 把业务服务继续拆分，剥离出最基础的 IM 服务，IM 通用服务，客服通用服务，而针对不同的业务特殊需求做最小化的定制服务开发。 部署方式则以平台形式部署，不同的业务方的服务跑在同一个平台上，但数据互相隔离。 服务继续被拆分的更微粒化，形成了一组服务矩阵（见下图）。<br>京东咚咚<br>而部署方式，只需要在双机房建立两套对等集群，并另外建一个较小的灰度发布集群即可，所有不同业务都运行在统一平台集群上，如下图。<br>京东咚咚<br>更细粒度的服务意味着每个服务的开发更简单，代码量更小，依赖更少，隔离稳定性更高。 但更细粒度的服务也意味着更繁琐的运维监控管理，直到今年公司内部弹性私有云、缓存云、消息队列、部署、监控、日志等基础系统日趋完善， 使得实施这类细粒度划分的微服务架构成为可能，运维成本可控。 而从当初 1.0 的 1 种应用进程，到 3.0 的 6、7 种应用进程，再到 4.0 的 50+ 更细粒度的不同种应用进程。 每种进程再根据承载业务流量不同分配不同的实例数，真正的实例进程数会过千。 为了更好的监控和管理这些进程，为此专门定制了一套面向服务的运维管理系统，见下图。<br>京东咚咚<br>统一服务运维提供了实用的内部工具和库来帮助开发更健壮的微服务。 包括中心配置管理，流量埋点监控，数据库和缓存访问，运行时隔离，如下图所示是一个运行隔离的图示：<br>京东咚咚<br>细粒度的微服务做到了进程间隔离，严格的开发规范和工具库帮助实现了异步消息和异步 HTTP 来避免多个跨进程的同步长调用链。 进程内部通过切面方式引入了服务增强容器 Armor 来隔离线程， 并支持进程内的单独业务降级和同步转异步化执行。而所有这些工具和库服务都是为了两个目标：<br>让服务进程运行时状态可见<br>让服务进程运行时状态可被管理和改变<br>最后我们回到前文留下的一个悬念，就是关于消息投递模型的缺陷。 一开始我们在接入层检测到终端连接断开后，消息无法投递，再将消息缓存下来，等终端重连接上来再拉取离线消息。 这个模型在移动时代表现的很不好，因为移动网络的不稳定性，导致经常断链后重连。 而准确的检测网络连接断开是依赖一个网络超时的，导致检测可能不准确，引发消息假投递成功。 新的模型如下图所示，它不再依赖准确的网络连接检测，投递前待确认消息 id 被缓存，而消息体被持久存储。 等到终端接收确认返回后，该消息才算投妥，未确认的消息 id 再重新登陆后或重连接后作为离线消息推送。 这个模型不会产生消息假投妥导致的丢失，但可能导致消息重复，只需由客户终端按消息 id 去重即可。<br>京东咚咚<br>京东咚咚诞生之初正是京东技术转型到 Java 之时，经历这些年的发展，取得了很大的进步。 从草根走向专业，从弱小走向规模，从分散走向统一，从杂乱走向规范。 本文主要重心放在了几年来咚咚架构演进的过程，技术架构单独拿出来看我认为没有绝对的好与不好， 技术架构总是要放在彼时的背景下来看，要考虑业务的时效价值、团队的规模和能力、环境基础设施等等方面。 架构演进的生命周期适时匹配好业务的生命周期，才可能发挥最好的效果。</p>
<p>【编辑推荐】<br>58同城沈剑：好的架构不是设计出来的，而是演进出来的<br>架构必备：Rate limiting 的作用和常见方式<br>京东11.11：商品搜索系统架构设计解密<br>京东唐志雄：从技术角度看白条资产证券化<br>关于Java应用相关不同产品的架构<br>中小型网站架构分析及优化<br>友盟吴磊：移动大数据平台的架构、实践与数据增值<br>【责任编辑：wangxueyan TEL：（010）68476606】</p>
<p>点赞 0<br>架构师  京东  架构分享:<br>内容点评已有0条评论,0次赞还可以输入500字</p>
<p>请输入你的评论<br>提交您还没有登录！请先 登录 或 注册<br>还没有评论内容<br>大家都在看猜你喜欢<br>紧急预警！Struts2新漏洞S2-045来袭，多个版本受影响紧急预警！Struts2新漏洞S2-045来袭，多个版本受影响2017年，为何过半的大数据项目不成功?2017年，为何过半的大数据项目不成功?2017年3月编程语言排行榜：Swift首次进入前十2017年3月编程语言排行榜：Swift首次进入前十如何禁掉Windows 10上的所有广告如何禁掉Windows 10上的所有广告<br>编辑推荐外电iOS与Android设备到底是如何被入侵的？头条HTML5游戏开发难点之效率、性能和加载量头条你所不了解的移动支付背后的技术支撑外电我们为何很难对超大规模应用与分布式架构进行备份？头条2017年3月编程语言排行榜：Swift首次进入前十<br>24H热文一周话题本月最赞<br>5个强大的Java分布式缓存框架推荐<br>坐在马桶上看算法：快速排序<br>Java程序员新手老手都离不开八大开发工具<br>2017年3月编程语言排行榜：Swift首次进入前十<br>多图详解Spring框架的设计理念与设计模式<br>2015年十五个热门的 PHP 开发工具<br>Java 中常用缓存Cache机制的实现<br>浅谈Java中的Set、List、Map的区别<br>视频课程+更多技术大咖的旅游梦：同程CTO结缘腾讯云<br>技术大咖的旅游梦：同程CTO结缘腾讯云<br>讲师：腾讯云1人学习过<br>软考网络工程师考试之IP地址计算轻松解决视频课程（攻克要塞系列）<br>软考网络工程师考试之IP地址计算轻松解决视频<br>讲师：朱小平30人学习过<br>大数据培训班4期培训班课程（只针对培训班学员）<br>大数据培训班4期培训班课程（只针对培训班学<br>讲师：徐培成0人学习过<br>热门职位+更多<br>后端开发<br>全职/1-3年/大专5k-15k分享<br>中级Java工程师<br>全职/1-3年/大专6k-10k高达软件<br>诚聘PHP开发师<br>兼职/5-10年/不限15k-25k慧都科技<br>PHP研发工程师<br>全职/1-3年/本科10k-15k动视云科技<br>后端开发(PHP/Go)<br>全职/5-10年/本科30k-50k瓜子二手车<br>最新专题+更多金三银四跳槽季 开发者这样惊呆你的面试官金三银四跳槽季 开发者这样惊呆你的面试官<br>跳槽季<br>你了解AJAX吗？TA不是新编程语言而是WEB应用程序技术你了解AJAX吗？TA不是新编程语言而是WEB应用程序技术<br>AJAX<br>Web前端知识杂乱 如何分清主次和学习优先级？Web前端知识杂乱 如何分清主次和学习优先级？<br>Web前端/分清主次/学习<br>编程初学者学什么语言好？未来编程趋势预测编程初学者学什么语言好？未来编程趋势预测<br>编程<br>精彩评论<br>和气高尚评论了：【51CTO学院】免费直播课 | 赵海兵–虚拟化与混合云<br>期待中。。。！</p>
<p>lwt1309108评论了：【51CTO学院】免费直播课 | 赵海兵–虚拟化与混合云<br>期待</p>
<p>ashely冰雪雨露评论了：【51CTO学院】免费直播课 | 赵海兵–虚拟化与混合云<br>虚拟化对我目前的工作很要紧</p>
<p>Wanglican评论了：【51CTO学院】团购第二期-低至6折！名师中高级实战进阶项目<br>交了押金了，申请进群了，麻烦通过一下。亲~~<br>精选博文论坛热帖下载排行<br>现阶段为开放式基金赎回良机<br>SecureCRT 使用技巧<br>nagios全攻略(二)—-基本安装和配置<br>关于51CTO合作出书中的职业发展部分<br>利用WINDOWS SERVER 2003路由设置解<br>读 书 +更多<br>点石成金：访客至上的网页设计秘笈（原书第2版）<br>有些网站看起来很清爽； 有些网站看起来很杂乱； 有些网站能让你轻松地找到资料； 有些网站让你犹如置身迷宫…… …</p>
<p>订阅51CTO邮刊<br>点击这里查看样刊<br>订阅51CTO邮刊<br>51CTO旗下网站：领先的IT技术网站 51CTO|领先的中文存储媒体 WatchStor| 中国首个CIO网站 CIOage |中国首家数字医疗网站 HC3i<br>Copyright©2005-2017 51CTO.COM 版权所有 未经许可 请勿转载</p>
]]></content>
    
    <summary type="html">
    
      架构师必看 京东咚咚架构演进
    
    </summary>
    
      <category term="架构" scheme="http://jishusuishouji.github.io/categories/%E6%9E%B6%E6%9E%84/"/>
    
    
      <category term="架构" scheme="http://jishusuishouji.github.io/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>VAGRANT 和 Docker的使用场景和区别?</title>
    <link href="http://jishusuishouji.github.io/2017/01/25/xunihua/VAGRANT_%E5%92%8C_Docker%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E5%92%8C%E5%8C%BA%E5%88%AB_/"/>
    <id>http://jishusuishouji.github.io/2017/01/25/xunihua/VAGRANT_和_Docker的使用场景和区别_/</id>
    <published>2017-01-25T06:20:57.000Z</published>
    <updated>2017-01-25T06:25:44.037Z</updated>
    
    <content type="html"><![CDATA[<p>本质区别<br>Vagrant并不提供虚拟化技术，本质上是一个虚拟机外挂，通过虚拟机的管理接口来管理虚拟机，让用户更轻松的进行一些常用配置，比如：CPU/Memory/IP/DISK等分配。并且提供了一些其它的管理操作：比如开机运行指定命令，镜像二次打包，插件编写等等。<br>vagrant官方有介绍:</p>
<blockquote>
<p>To achieve its magic, Vagrant stands on the shoulders of giants. Machines are provisioned on top of VirtualBox, VMware, AWS, or any other provider. Then, industry-standard provisioning tools such as shell scripts, Chef, or Puppet, can be used to automatically install and configure software on the machine.</p>
</blockquote>
<p>而docker是一个容器引擎，每一个实例是一个相对隔离的空间，与宿主机共享操作系统内核，并且共享宿主机资源。相对于披着虚拟机皮的vagrant，docker更加轻量，消耗更少的资源。</p>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>关于应用场景没有绝对，把两个东西都用熟，自己觉得用哪个方便用哪个好管理就用哪个。既然vagrant本质是虚拟机外挂，那么它的应用场景就是，节省你用原生虚拟机管理软件的时间。原来我们新增一台虚拟机需要配置好内存、硬盘、CPU等，然后添加iso，安装。创建用户，等等。一套下来好几十分钟是吧？聪明点你可能会想到复制一个创建好的镜像然后粘贴。但这一切vagrant都帮你想好了,安装vagrant后你只需要6步就能创建一台新的虚拟机，其中两步是创建文件夹和切换文件夹。<br>从安装到创建一台新的虚拟机就成功了。如果你想要再添加一台虚拟机，你只需要执行最后两步，添加一个不同名字的配置就能再新建一台虚拟机。还支持镜像、开机自动运行脚本、插件编写等。dockerdocker主要应用于解决环境依赖以及为应用程序提供一个相对隔离的空间，一个实例像操作系统里运行的一个程序。原来部署一套环境是不是得自己编写自动化部署依赖环境以及程序的脚本？如果有两个依赖同一程序或库的不同版本怎么办？绝对路径？软连接？docker能很好的解决你的烦恼。把需要的依赖环境打包成一个镜像，再把程序放镜像里面运行。</p>
<p>总的来说vagrant更适合给开发大爷们创造一个统一的开发、测试、接近于完全隔离的环境，以及提高对高配机的闲置利用。docker更方便地解决了同一机器上的环境隔离，以及提高运维锅们解决部署时环境依赖的效率。</p>
]]></content>
    
    <summary type="html">
    
      VAGRANT 和 Docker的使用场景和区别?
    
    </summary>
    
      <category term="docker" scheme="http://jishusuishouji.github.io/categories/docker/"/>
    
    
      <category term="docker" scheme="http://jishusuishouji.github.io/tags/docker/"/>
    
  </entry>
  
</feed>
