<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>技术随手记</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://jishusuishouji.github.io/"/>
  <updated>2017-04-05T05:14:59.913Z</updated>
  <id>http://jishusuishouji.github.io/</id>
  
  <author>
    <name>技术随手记</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ActiveMQ入门实例</title>
    <link href="http://jishusuishouji.github.io/2017/04/05/activemq/ActiveMQ%E5%85%A5%E9%97%A8%E5%AE%9E%E4%BE%8B/"/>
    <id>http://jishusuishouji.github.io/2017/04/05/activemq/ActiveMQ入门实例/</id>
    <published>2017-04-05T05:08:11.000Z</published>
    <updated>2017-04-05T05:14:59.913Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-下载ActiveMQ"><a href="#1-下载ActiveMQ" class="headerlink" title="1.下载ActiveMQ"></a>1.下载ActiveMQ</h2><p>去官方网站下载：<a href="http://activemq.apache.org/" target="_blank" rel="external">http://activemq.apache.org/</a></p>
<h2 id="2-运行ActiveMQ"><a href="#2-运行ActiveMQ" class="headerlink" title="2.运行ActiveMQ"></a>2.运行ActiveMQ</h2><p>解压缩<code>apache-activemq-5.5.1-bin.zip</code>，然后双击<code>apache-activemq-5.5.1\bin\activemq.bat</code>运行ActiveMQ程序。</p>
<p>启动ActiveMQ以后，登陆：<code>http://localhost:8161/admin/</code>，创建一个<code>Queue</code>，命名为<code>FirstQueue</code>。</p>
<h2 id="3-创建Eclipse项目并运行"><a href="#3-创建Eclipse项目并运行" class="headerlink" title="3.创建Eclipse项目并运行"></a>3.创建Eclipse项目并运行</h2><p>创建project：<code>ActiveMQ-5.5</code>，并导入<code>apache-activemq-5.5.1\lib</code>目录下需要用到的jar文件，项目结构如下图所示：</p>
<p><img src="/img/ActiveMQ的Eclipse项目.jpg" alt="ActiveMQ的Eclipse项目"></p>
<h3 id="3-1-Sender-java"><a href="#3-1-Sender-java" class="headerlink" title="3.1.Sender.java"></a>3.1.<code>Sender.java</code></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line">package com.xuwei.activemq;</div><div class="line"></div><div class="line">import javax.jms.Connection;</div><div class="line">import javax.jms.ConnectionFactory;</div><div class="line">import javax.jms.DeliveryMode;</div><div class="line">import javax.jms.Destination;</div><div class="line">import javax.jms.MessageProducer;</div><div class="line">import javax.jms.Session;</div><div class="line">import javax.jms.TextMessage;</div><div class="line">import org.apache.activemq.ActiveMQConnection;</div><div class="line">import org.apache.activemq.ActiveMQConnectionFactory;</div><div class="line"></div><div class="line">public class Sender &#123;</div><div class="line">    private static final int SEND_NUMBER = 5;</div><div class="line"></div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        // ConnectionFactory ：连接工厂，JMS 用它创建连接</div><div class="line">        ConnectionFactory connectionFactory;</div><div class="line">        // Connection ：JMS 客户端到JMS Provider 的连接</div><div class="line">        Connection connection = null;</div><div class="line">        // Session： 一个发送或接收消息的线程</div><div class="line">        Session session;</div><div class="line">        // Destination ：消息的目的地;消息发送给谁.</div><div class="line">        Destination destination;</div><div class="line">        // MessageProducer：消息发送者</div><div class="line">        MessageProducer producer;</div><div class="line">        // TextMessage message;</div><div class="line">        // 构造ConnectionFactory实例对象，此处采用ActiveMq的实现jar</div><div class="line">        connectionFactory = new ActiveMQConnectionFactory(</div><div class="line">                ActiveMQConnection.DEFAULT_USER,</div><div class="line">                ActiveMQConnection.DEFAULT_PASSWORD,</div><div class="line">                &quot;tcp://localhost:61616&quot;);</div><div class="line">        try &#123;</div><div class="line">            // 构造从工厂得到连接对象</div><div class="line">            connection = connectionFactory.createConnection();</div><div class="line">            // 启动</div><div class="line">            connection.start();</div><div class="line">            // 获取操作连接</div><div class="line">            session = connection.createSession(Boolean.TRUE,</div><div class="line">                    Session.AUTO_ACKNOWLEDGE);</div><div class="line">            destination = session.createQueue(&quot;FirstQueue&quot;);</div><div class="line">            // 得到消息生成者【发送者】</div><div class="line">            producer = session.createProducer(destination);</div><div class="line">            // 设置不持久化，此处学习，实际根据项目决定</div><div class="line">            producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT);</div><div class="line">            // 构造消息，此处写死</div><div class="line">            sendMessage(session, producer);</div><div class="line">            session.commit();</div><div class="line">        &#125; catch (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125; finally &#123;</div><div class="line">            try &#123;</div><div class="line">                if (null != connection)</div><div class="line">                    connection.close();</div><div class="line">            &#125; catch (Throwable ignore) &#123;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public static void sendMessage(Session session, MessageProducer producer)</div><div class="line">            throws Exception &#123;</div><div class="line">        for (int i = 1; i &lt;= SEND_NUMBER; i++) &#123;</div><div class="line">            TextMessage message = session</div><div class="line">                    .createTextMessage(&quot;ActiveMq 发送的消息&quot; + i);</div><div class="line">            // 发送消息到目的地方</div><div class="line">            System.out.println(&quot;发送消息：&quot; + &quot;ActiveMq 发送的消息&quot; + i);</div><div class="line">            producer.send(message);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="3-2-Receiver-java"><a href="#3-2-Receiver-java" class="headerlink" title="3.2.Receiver.java"></a>3.2.Receiver.java</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div></pre></td><td class="code"><pre><div class="line">package com.xuwei.activemq;</div><div class="line"></div><div class="line">import javax.jms.Connection;</div><div class="line">import javax.jms.ConnectionFactory;</div><div class="line">import javax.jms.Destination;</div><div class="line">import javax.jms.MessageConsumer;</div><div class="line">import javax.jms.Session;</div><div class="line">import javax.jms.TextMessage;</div><div class="line">import org.apache.activemq.ActiveMQConnection;</div><div class="line">import org.apache.activemq.ActiveMQConnectionFactory;</div><div class="line"></div><div class="line">public class Receiver &#123;</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        // ConnectionFactory ：连接工厂，JMS 用它创建连接</div><div class="line">        ConnectionFactory connectionFactory;</div><div class="line">        // Connection ：JMS 客户端到JMS Provider 的连接</div><div class="line">        Connection connection = null;</div><div class="line">        // Session： 一个发送或接收消息的线程</div><div class="line">        Session session;</div><div class="line">        // Destination ：消息的目的地;消息发送给谁.</div><div class="line">        Destination destination;</div><div class="line">        // 消费者，消息接收者</div><div class="line">        MessageConsumer consumer;</div><div class="line">        connectionFactory = new ActiveMQConnectionFactory(</div><div class="line">                ActiveMQConnection.DEFAULT_USER,</div><div class="line">                ActiveMQConnection.DEFAULT_PASSWORD,</div><div class="line">                &quot;tcp://localhost:61616&quot;);</div><div class="line">        try &#123;</div><div class="line">            // 构造从工厂得到连接对象</div><div class="line">            connection = connectionFactory.createConnection();</div><div class="line">            // 启动</div><div class="line">            connection.start();</div><div class="line">            // 获取操作连接</div><div class="line">            session = connection.createSession(Boolean.FALSE,</div><div class="line">                    Session.AUTO_ACKNOWLEDGE);</div><div class="line">   </div><div class="line">            destination = session.createQueue(&quot;FirstQueue&quot;);</div><div class="line">            consumer = session.createConsumer(destination);</div><div class="line">            while (true) &#123;</div><div class="line">                //设置接收者接收消息的时间，为了便于测试，这里谁定为100s</div><div class="line">                TextMessage message = (TextMessage) consumer.receive(100000);</div><div class="line">                if (null != message) &#123;</div><div class="line">                    System.out.println(&quot;收到消息&quot; + message.getText());</div><div class="line">                &#125; else &#123;</div><div class="line">                    break;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125; catch (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125; finally &#123;</div><div class="line">            try &#123;</div><div class="line">                if (null != connection)</div><div class="line">                    connection.close();</div><div class="line">            &#125; catch (Throwable ignore) &#123;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="4-注意事项"><a href="#4-注意事项" class="headerlink" title="4.注意事项"></a>4.注意事项</h2><p>最后接收者跟发送者在不同的机器上测试</p>
<h2 id="5-测试过程"><a href="#5-测试过程" class="headerlink" title="5.测试过程"></a>5.测试过程</h2><p>运行<code>Receiver</code>后没有任何信息，运行Sender以后，显示如下信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">发送消息：ActiveMq 发送的消息1</div><div class="line">发送消息：ActiveMq 发送的消息2</div><div class="line">发送消息：ActiveMq 发送的消息3</div><div class="line">发送消息：ActiveMq 发送的消息4</div><div class="line">发送消息：ActiveMq 发送的消息5</div></pre></td></tr></table></figure></p>
<p>而<code>Receiver</code>现如下信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">收到消息ActiveMq 发送的消息1</div><div class="line">收到消息ActiveMq 发送的消息2</div><div class="line">收到消息ActiveMq 发送的消息3</div><div class="line">收到消息ActiveMq 发送的消息4</div><div class="line">收到消息ActiveMq 发送的消息5</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      ActiveMQ入门实例
    
    </summary>
    
      <category term="java" scheme="http://jishusuishouji.github.io/categories/java/"/>
    
      <category term="JMS" scheme="http://jishusuishouji.github.io/categories/java/JMS/"/>
    
      <category term="ActiveMQ" scheme="http://jishusuishouji.github.io/categories/java/JMS/ActiveMQ/"/>
    
    
      <category term="ActiveMQ" scheme="http://jishusuishouji.github.io/tags/ActiveMQ/"/>
    
  </entry>
  
  <entry>
    <title>activemq的几种基本通信方式总结</title>
    <link href="http://jishusuishouji.github.io/2017/04/05/activemq/activemq%E7%9A%84%E5%87%A0%E7%A7%8D%E5%9F%BA%E6%9C%AC%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93/"/>
    <id>http://jishusuishouji.github.io/2017/04/05/activemq/activemq的几种基本通信方式总结/</id>
    <published>2017-04-05T03:09:12.000Z</published>
    <updated>2017-04-05T05:07:35.171Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>面向消息队列是一个总体比较合理的应用系统集成方案。<br>ActiveMQ是JMS消息通信规范的一个实现。消息通信模式主要有发布-订阅、点对点。</p>
<h2 id="基础流程"><a href="#基础流程" class="headerlink" title="基础流程"></a>基础流程</h2><p>ActiveMQ启动服务的过程:</p>
<ol>
<li>获得JMS connection factory，通过提供特定环境的连接信息来构造factory。</li>
<li>利用factory构造JMS connection.</li>
<li>启动connection</li>
<li>通过connection创建JMS session.</li>
<li>指定JMS destination.</li>
<li>创建JMS producer和JMS message并提供destination.</li>
<li>创建JMS consumer和注册JMS message listener.</li>
<li>发送和接收JMS message.</li>
<li>关闭所有JMS资源，包括connection, session, producer, consumer等。</li>
</ol>
<h2 id="publish-subscribe"><a href="#publish-subscribe" class="headerlink" title="publish-subscribe"></a>publish-subscribe</h2><p>发布订阅模式类似于订阅报纸。</p>
<p><img src="/img/JMS发布订阅模式示意图.jpg" alt="JMS发布订阅模式示意图"></p>
<h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><h4 id="publisher"><a href="#publisher" class="headerlink" title="publisher"></a>publisher</h4><p>publisher是属于发布信息的一方，它通过定义一个或者多个topic，然后给这些topic发送消息。<br>publisher的构造函数如下：</p>
<pre><code>public Publisher() throws JMSException {  
    factory = new ActiveMQConnectionFactory(brokerURL);  
    connection = factory.createConnection();  
    try {  
        connection.start();  
    } catch (JMSException jmse) {  
        connection.close();  
        throw jmse;  
    }  
    session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);  
    producer = session.createProducer(null);  
}
</code></pre><p>按照前面说的流程定义了基本的<code>connectionFactory</code>, <code>connection</code>,<code>session</code>,<code>producer</code>。。</p>
<h4 id="接着定义一系列的topic让所有的consumer来订阅"><a href="#接着定义一系列的topic让所有的consumer来订阅" class="headerlink" title="接着定义一系列的topic让所有的consumer来订阅"></a>接着定义一系列的topic让所有的consumer来订阅</h4><pre><code>protected void setTopics(String[] stocks) throws JMSException {  
    destinations = new Destination[stocks.length];  
    for(int i = 0; i &lt; stocks.length; i++) {  
        destinations[i] = session.createTopic(&quot;STOCKS.&quot; + stocks[i]);  
    }  
}  
</code></pre><h4 id="定义好topic之后要给这些指定的topic发消息："><a href="#定义好topic之后要给这些指定的topic发消息：" class="headerlink" title="定义好topic之后要给这些指定的topic发消息："></a>定义好topic之后要给这些指定的topic发消息：</h4><pre><code>protected void sendMessage(String[] stocks) throws JMSException {  
    for(int i = 0; i &lt; stocks.length; i++) {  
        Message message = createStockMessage(stocks[i], session);  
        System.out.println(&quot;Sending: &quot; + ((ActiveMQMapMessage)message).getContentMap() + &quot; on destination: &quot; + destinations[i]);  
        producer.send(destinations[i], message);  
    }  
}  

protected Message createStockMessage(String stock, Session session) throws JMSException {  
    MapMessage message = session.createMapMessage();  
    message.setString(&quot;stock&quot;, stock);  
    message.setDouble(&quot;price&quot;, 1.00);  
    message.setDouble(&quot;offer&quot;, 0.01);  
    message.setBoolean(&quot;up&quot;, true);          
    return message;  
}  
</code></pre><p>在<code>sendMessage</code>方法里遍历每个<code>topic</code>，然后给每个<code>topic</code>发送定义的<code>Message</code>消息。</p>
<h4 id="publisher发布消息"><a href="#publisher发布消息" class="headerlink" title="publisher发布消息"></a>publisher发布消息</h4><pre><code>public static void main(String[] args) throws JMSException {  
    if(args.length &lt; 1)  
        throw new IllegalArgumentException();  

    // Create publisher       
    Publisher publisher = new Publisher();  

    // Set topics  
    publisher.setTopics(args);  

    for(int i = 0; i &lt; 10; i++) {  
        publisher.sendMessage(args);  
        System.out.println(&quot;Publisher &apos;&quot; + i + &quot; price messages&quot;);  
        try {  
            Thread.sleep(1000);  
        } catch(InterruptedException e) {  
            e.printStackTrace();  
        }  
    }  
    // Close all resources  
    publisher.close();  
}  
</code></pre><h4 id="close方法关闭资源："><a href="#close方法关闭资源：" class="headerlink" title="close方法关闭资源："></a><code>close</code>方法关闭资源：</h4><pre><code>public void close() throws JMSException {  
    if (connection != null) {  
        connection.close();  
    }  
}  
</code></pre><h3 id="consumer"><a href="#consumer" class="headerlink" title="consumer"></a>consumer</h3><p>具体的步骤:<br>1.初始化资源。 </p>
<ol>
<li>接收消息。 </li>
<li>必要的时候关闭资源。</li>
</ol>
<h4 id="初始化资源放到构造函数里面："><a href="#初始化资源放到构造函数里面：" class="headerlink" title="初始化资源放到构造函数里面："></a>初始化资源放到构造函数里面：</h4><pre><code>public Consumer() throws JMSException {  
    factory = new ActiveMQConnectionFactory(brokerURL);  
    connection = factory.createConnection();  
    connection.start();  
    session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);  
}  
</code></pre><h4 id="接收和处理消息的方法"><a href="#接收和处理消息的方法" class="headerlink" title="接收和处理消息的方法"></a>接收和处理消息的方法</h4><p>分为同步和异步的：</p>
<ul>
<li>同步  <code>MessageConsumer.receive()</code>方法</li>
<li><p>异步  注册<code>MessageListener</code>，使用<code>MessageConsumer.setMessageListener()</code>。</p>
<p>  public static void main(String[] args) throws JMSException {  </p>
<pre><code>Consumer consumer = new Consumer();  
for (String stock : args) {  
    Destination destination = consumer.getSession().createTopic(&quot;STOCKS.&quot; + stock);  
    MessageConsumer messageConsumer = consumer.getSession().createConsumer(destination);  
    messageConsumer.setMessageListener(new Listener());  
}  
</code></pre><p>  }  </p>
<p>  public Session getSession() {  </p>
<pre><code>return session;  
</code></pre><p>  }  </p>
</li>
</ul>
<blockquote>
<p>这里的代码不要当真了，写得很烂</p>
</blockquote>
<h4 id="Listener负责处理接收到的消息："><a href="#Listener负责处理接收到的消息：" class="headerlink" title="Listener负责处理接收到的消息："></a><code>Listener</code>负责处理接收到的消息：</h4><pre><code>public class Listener implements MessageListener {  
    public void onMessage(Message message) {  
        try {  
            MapMessage map = (MapMessage)message;  
            String stock = map.getString(&quot;stock&quot;);  
            double price = map.getDouble(&quot;price&quot;);  
            double offer = map.getDouble(&quot;offer&quot;);  
            boolean up = map.getBoolean(&quot;up&quot;);  
            DecimalFormat df = new DecimalFormat( &quot;#,###,###,##0.00&quot; );  
            System.out.println(stock + &quot;\t&quot; + df.format(price) + &quot;\t&quot; + df.format(offer) + &quot;\t&quot; + (up?&quot;up&quot;:&quot;down&quot;));  
        } catch (Exception e) {  
            e.printStackTrace();  
        }  
    }  
}  
</code></pre><p>实现了<code>MessageListener</code>接口，里面的<code>onMessage</code>方法在接收到消息之后会被调用的方法。</p>
<h3 id="实现pub-sub模式的步骤"><a href="#实现pub-sub模式的步骤" class="headerlink" title="实现pub-sub模式的步骤"></a>实现pub-sub模式的步骤</h3><p>两者设定一个共同的topic。</p>
<p>在publisher端通过<code>session</code>创建<code>producer</code>，根据指定的参数创建<code>destination</code>，然后将消息和<code>destination</code>作为<code>producer.send()</code>方法的参数。</p>
<p>在consumer端也要创建类似的<code>connection</code>,<code>session</code>。通过<code>session</code>得到<code>destination</code>，再通过<code>session.createConsumer(destination)</code>来得到一个<code>MessageConsumer</code>对象。有了这个<code>MessageConsumer</code>就可以自行选择是直接同步的<code>receive</code>消息还是注册listener了。</p>
<h2 id="p2p"><a href="#p2p" class="headerlink" title="p2p"></a>p2p</h2><p><img src="/img/JMS点对点模式示意图.jpg" alt="JMS点对点模式示意图"></p>
<p>在p2p的场景里，相互通信的双方是通过一个类似于队列的方式来进行交流。和pub-sub的区别在于一个消息会发送给订阅此topic的多个订阅者，而在p2p里queue的消息只能被一个接受者接受。</p>
<h3 id="发送者"><a href="#发送者" class="headerlink" title="发送者"></a>发送者</h3><pre><code>public Publisher() throws JMSException {  
    factory = new ActiveMQConnectionFactory(brokerURL);  
    connection = factory.createConnection();  
    connection.start();  
    session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);  
    producer = session.createProducer(null);  
}
</code></pre><h4 id="发送消息："><a href="#发送消息：" class="headerlink" title="发送消息："></a>发送消息：</h4><pre><code>public void sendMessage() throws JMSException {  
    for(int i = 0; i &lt; jobs.length; i++)  
    {  
        String job = jobs[i];  
        Destination destination = session.createQueue(&quot;JOBS.&quot; + job);  
        Message message = session.createObjectMessage(i);  
        System.out.println(&quot;Sending: id: &quot; + ((ObjectMessage)message).getObject() + &quot; on queue: &quot; + destination);  
        producer.send(destination, message);  
    }  
}  
</code></pre><h4 id="消息发送者的启动代码："><a href="#消息发送者的启动代码：" class="headerlink" title="消息发送者的启动代码："></a>消息发送者的启动代码：</h4><pre><code>public static void main(String[] args) throws JMSException {  
    Publisher publisher = new Publisher();  
    for(int i = 0; i &lt; 10; i++) {  
        publisher.sendMessage();  
        System.out.println(&quot;Published &quot; + i + &quot; job messages&quot;);  
    try {  
            Thread.sleep(1000);  
        } catch (InterruptedException x) {  
            e.printStackTrace();  
        }  
    }  
    publisher.close();  
}  
</code></pre><p>在这里发送10条消息，在每个<code>sendMessage</code>的方法里实际上是针对每个<code>queue</code>发送了10条。</p>
<h3 id="接收者"><a href="#接收者" class="headerlink" title="接收者"></a>接收者</h3><pre><code>public Consumer() throws JMSException {  
    factory = new ActiveMQConnectionFactory(brokerURL);  
    connection = factory.createConnection();  
    connection.start();  
    session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);  
}  


public static void main(String[] args) throws JMSException {  
        Consumer consumer = new Consumer();  
        for (String job : consumer.jobs) {  
            Destination destination = consumer.getSession().createQueue(&quot;JOBS.&quot; + job);  
            MessageConsumer messageConsumer = consumer.getSession().createConsumer(destination);  
            messageConsumer.setMessageListener(new Listener(job));  
        }  
    }  

    public Session getSession() {  
        return session;  
    }
</code></pre><h4 id="MessageListener接口实现类"><a href="#MessageListener接口实现类" class="headerlink" title="MessageListener接口实现类"></a><code>MessageListener</code>接口实现类</h4><pre><code>import javax.jms.Message;  
import javax.jms.MessageListener;  
import javax.jms.ObjectMessage;  

public class Listener implements MessageListener {        
    private String job;  

    public Listener(String job) {  
        this.job = job;  
    }  

    public void onMessage(Message message) {  
        try {  
            //do something here  
            System.out.println(job + &quot; id:&quot; + ((ObjectMessage)message).getObject());  
        } catch (Exception e) {  
            e.printStackTrace();  
        }  
    }        
}
</code></pre><h2 id="比较pub-sub和p2p模式"><a href="#比较pub-sub和p2p模式" class="headerlink" title="比较pub-sub和p2p模式"></a>比较pub-sub和p2p模式</h2><p>基本的处理流程都是类似的，除了在pub-sub中要通过<code>createTopic</code>来设置topic，而在p2p中要通过<code>createQueue</code>来创建通信队列。</p>
<h2 id="request-response"><a href="#request-response" class="headerlink" title="request-response"></a>request-response</h2><p>和前面两种方式比较起来，request-response的通信方式很常见，但是不是默认提供的一种模式。在前面的两种模式中都是一方负责发送消息而另外一方负责处理。而实际中的很多应用需要双方都能给对方发送消息。<br>请求-应答方式并不是JMS规范系统默认提供的一种通信方式，而是通过在现有通信方式的基础上稍微运用一点技巧实现的。</p>
<blockquote>
<p>以下这种方式只能说是很差，并不是什么高明的做法</p>
</blockquote>
<p><img src="/img/JMS实际应用中产生的应答方式示意图.jpg" alt="JMS实际应用中产生的应答方式示意图"><br>在JMS里面，如果要实现请求/应答的方式，可以利用<code>JMSReplyTo</code>和<code>JMSCorrelationID</code>消息头来将通信的双方关联起来。另外，<code>QueueRequestor</code>和<code>TopicRequestor</code>能够支持简单的请求/应答过程。</p>
<pre><code>// client side  
Destination tempDest = session.createTemporaryQueue();  
MessageConsumer responseConsumer = session.createConsumer(tempDest);  
...  

// send a request..  
message.setJMSReplyTo(tempDest)  
message.setJMSCorrelationID(myCorrelationID);  

producer.send(message);  
</code></pre><p>client端创建一个临时队列并在发送的消息里指定了发送返回消息的<code>destination</code>以及<code>correlationID</code>。那么在处理消息的server端得到这个消息后就知道该发送给谁了。Server端的大致流程如下：</p>
<pre><code>public void onMessage(Message request) {  

  Message response = session.createMessage();  
  response.setJMSCorrelationID(request.getJMSCorrelationID())  

  producer.send(request.getJMSReplyTo(), response)  
}  
</code></pre><p>这里是在server端注册<code>MessageListener</code>，通过设置返回信息的<code>CorrelationID</code>和<code>JMSReplyTo</code>将信息返回。</p>
<h3 id="Client"><a href="#Client" class="headerlink" title="Client:"></a>Client:</h3><pre><code>public Client() {  
    ActiveMQConnectionFactory connectionFactory = new ActiveMQConnectionFactory(&quot;tcp://localhost:61616&quot;);  
    Connection connection;  
    try {  
        connection = connectionFactory.createConnection();  
        connection.start();  
        Session session = connection.createSession(transacted, ackMode);  
        Destination adminQueue = session.createQueue(clientQueueName);  

        //Setup a message producer to send message to the queue the server is consuming from  
        this.producer = session.createProducer(adminQueue);  
        this.producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT);  

        //Create a temporary queue that this client will listen for responses on then create a consumer  
        //that consumes message from this temporary queue...for a real application a client should reuse  
        //the same temp queue for each message to the server...one temp queue per client  
        Destination tempDest = session.createTemporaryQueue();  
        MessageConsumer responseConsumer = session.createConsumer(tempDest);  

        //This class will handle the messages to the temp queue as well  
        responseConsumer.setMessageListener(this);  

        //Now create the actual message you want to send  
        TextMessage txtMessage = session.createTextMessage();  
        txtMessage.setText(&quot;MyProtocolMessage&quot;);  

        //Set the reply to field to the temp queue you created above, this is the queue the server  
        //will respond to  
        txtMessage.setJMSReplyTo(tempDest);  

        //Set a correlation ID so when you get a response you know which sent message the response is for  
        //If there is never more than one outstanding message to the server then the  
        //same correlation ID can be used for all the messages...if there is more than one outstanding  
        //message to the server you would presumably want to associate the correlation ID with this  
        //message somehow...a Map works good  
        String correlationId = this.createRandomString();  
        txtMessage.setJMSCorrelationID(correlationId);  
        this.producer.send(txtMessage);  
    } catch (JMSException e) {  
        //Handle the exception appropriately  
    }  
}  
</code></pre><p>这里的代码除了初始化构造函数里的参数还同时设置了两个destination，一个是自己要发送消息出去的destination，在<code>session.createProducer(adminQueue);</code>这一句设置。另外一个是自己要接收的消息destination, 通过<code>Destination tempDest = session.createTemporaryQueue(); responseConsumer = session.createConsumer(tempDest);</code> 这两句指定了要接收消息的目的地。这里是用的一个临时队列。在前面指定了返回消息的通信队列之后，需要通知server端知道发送返回消息给哪个队列。于是<code>txtMessage.setJMSReplyTo(tempDest);</code>指定了这一部分，同时<code>txtMessage.setJMSCorrelationID(correlationId);</code>方法主要是为了保证每次发送回来请求的server端能够知道对应的是哪个请求。这里一个请求和一个应答是相当于对应一个相同的序列号一样。</p>
<p>同时，因为client端在发送消息之后还要接收server端返回的消息，所以它也要实现一个消息receiver的功能。这里采用实现<code>MessageListener</code>接口的方式：</p>
<pre><code>public void onMessage(Message message) {  
    String messageText = null;  
    try {  
        if (message instanceof TextMessage) {  
            TextMessage textMessage = (TextMessage) message;  
            messageText = textMessage.getText();  
            System.out.println(&quot;messageText = &quot; + messageText);  
        }  
    } catch (JMSException e) {  
        //Handle the exception appropriately  
    }  
}  
</code></pre><h3 id="Server"><a href="#Server" class="headerlink" title="Server:"></a>Server:</h3><p>这里server端要执行的过程和client端相反，它是先接收消息，在接收到消息后根据提供的<code>JMSCorelationID</code>来发送返回的消息：</p>
<pre><code>public void onMessage(Message message) {  
    try {  
        TextMessage response = this.session.createTextMessage();  
        if (message instanceof TextMessage) {  
            TextMessage txtMsg = (TextMessage) message;  
            String messageText = txtMsg.getText();  
            response.setText(this.messageProtocol.handleProtocolMessage(messageText));  
        }  

        //Set the correlation ID from the received message to be the correlation id of the response message  
        //this lets the client identify which message this is a response to if it has more than  
        //one outstanding message to the server  
        response.setJMSCorrelationID(message.getJMSCorrelationID());  

        //Send the response to the Destination specified by the JMSReplyTo field of the received message,  
        //this is presumably a temporary queue created by the client  
        this.replyProducer.send(message.getJMSReplyTo(), response);  
    } catch (JMSException e) {  
        //Handle the exception appropriately  
    }  
}
</code></pre><p>前面，在<code>replyProducer.send()</code>方法里，<code>message.getJMSReplyTo()</code>就得到了要发送消息回去的destination。<br>另外，设置这些发送返回信息的replyProducer的信息主要在构造函数相关的方法里实现了：</p>
<pre><code>public Server() {  
    try {  
        //This message broker is embedded  
        BrokerService broker = new BrokerService();  
        broker.setPersistent(false);  
        broker.setUseJmx(false);  
        broker.addConnector(messageBrokerUrl);  
        broker.start();  
    } catch (Exception e) {  
        //Handle the exception appropriately  
    }  

    //Delegating the handling of messages to another class, instantiate it before setting up JMS so it  
    //is ready to handle messages  
    this.messageProtocol = new MessageProtocol();  
    this.setupMessageQueueConsumer();  
}  

private void setupMessageQueueConsumer() {  
    ActiveMQConnectionFactory connectionFactory = new ActiveMQConnectionFactory(messageBrokerUrl);  
    Connection connection;  
    try {  
        connection = connectionFactory.createConnection();  
        connection.start();  
        this.session = connection.createSession(this.transacted, ackMode);  
        Destination adminQueue = this.session.createQueue(messageQueueName);  

        //Setup a message producer to respond to messages from clients, we will get the destination  
        //to send to from the JMSReplyTo header field from a Message  
        this.replyProducer = this.session.createProducer(null);  
        this.replyProducer.setDeliveryMode(DeliveryMode.NON_PERSISTENT);  

        //Set up a consumer to consume messages off of the admin queue  
        MessageConsumer consumer = this.session.createConsumer(adminQueue);  
        consumer.setMessageListener(this);  
    } catch (JMSException e) {  
        //Handle the exception appropriately  
    }  
}
</code></pre><p>对于请求/应答的方式来说，这种典型交互的过程就是Client端在设定正常发送请求的Queue同时也设定一个临时的Queue。同时在要发送的message里头指定要返回消息的destination以及CorelationID，这些就好比是一封信里面所带的回执。根据这个信息人家才知道怎么给你回信。对于Server端来说则要额外创建一个producer，在处理接收到消息的方法里再利用producer将消息发回去。这一系列的过程看起来很像http协议里面请求-应答的方式，都是一问一答。</p>
<h2 id="一些应用和改进"><a href="#一些应用和改进" class="headerlink" title="一些应用和改进"></a>一些应用和改进</h2><p>回顾前面三种基本的通信方式，发现它们都存在着一定的共同点，比如说都要初始化<code>ConnectionFactory</code>, <code>Connection</code>, <code>Session</code>等。在使用完之后都要将这些资源关闭。如果每一个实现它的通信端都这么写一通的话，其实是一种简单的重复。从工程的角度来看是完全没有必要的。</p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>通过工厂方法封装这些对象的创建和销毁，然后简单的通过调用工厂方法的方式得到它们。<br>既然基本的流程都是在开头创建资源在结尾销毁，也可以采用Template Method模式的思路。通过继承一个抽象类，在抽象类里提供了资源的封装。所有继承的类只要实现怎么去使用这些资源的方法就可以了。</p>
]]></content>
    
    <summary type="html">
    
      activemq的几种基本通信方式总结
    
    </summary>
    
      <category term="java" scheme="http://jishusuishouji.github.io/categories/java/"/>
    
      <category term="JMS，ActiveMQ" scheme="http://jishusuishouji.github.io/categories/java/JMS%EF%BC%8CActiveMQ/"/>
    
    
      <category term="activeMQ" scheme="http://jishusuishouji.github.io/tags/activeMQ/"/>
    
  </entry>
  
  <entry>
    <title>基于ZooKeeper和Thrift构建动态RPC调用</title>
    <link href="http://jishusuishouji.github.io/2017/04/03/thrift/%E5%9F%BA%E4%BA%8EZooKeeper%E5%92%8CThrift%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81RPC%E8%B0%83%E7%94%A8/"/>
    <id>http://jishusuishouji.github.io/2017/04/03/thrift/基于ZooKeeper和Thrift构建动态RPC调用/</id>
    <published>2017-04-03T10:49:07.000Z</published>
    <updated>2017-04-03T14:57:53.850Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、基本功能"><a href="#一、基本功能" class="headerlink" title="一、基本功能"></a>一、基本功能</h2><p>实现服务端向ZooKeeper集群注册自己提供的服务，并且把自己的IP地址和服务端口创建到具体的服务目录下。客户端向ZooKeeper集群监听自己关注的RPC服务（例如：<code>sayHello</code>和天气服务）， 监听服务目录下的IP地址列表变化。若要在自己的项目中使用，可以采用阿里的Dubbo分布式服务框架。<br>在WEB端展示可以访问的RPC服务，WEB端可以通过RPC客户端向指定IP地址的RPC服务器发出调用RPC服务，RPC服务端向客户端反馈提供的服务内容，WEB客户端展示内容。<br>只是展示动态RPC基本原理，真正的调用一般都不是web端触发的，应该是RPC的客户端根据监听到的多个IP服务提供者，根据每个IP的负载情况，动态选择最优可用的RPC服务端并且调用服务。 </p>
<p>我们提供2个基本RPC服务，网络及应用部署如图:<br><img src="/img/基本RPC服务网络及应用部署" alt="基本RPC服务网络及应用部署"></p>
<h2 id="二、ZooKeeper介绍"><a href="#二、ZooKeeper介绍" class="headerlink" title="二、ZooKeeper介绍"></a>二、ZooKeeper介绍</h2><p>ZooKeeper是一个开放源代码的分布式应用程序协调服务，由知名互联网公司雅虎创建，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。<br>ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。它是一个为分布式应用提供一致性服务的软件，以下是ZooKeeper典型的应用场景</p>
<ul>
<li>数据发布和订阅：就是发布者将数据发布到ZooKeeper的一个或一系列节点上，供订阅者进行数据订阅，进而达到动态获取数据的目的，实现配置信息的集中管理和数据的动态更新。</li>
<li>负载均衡：用来对多个计算机、网络连接、CPU、磁盘驱动或其他资源进分配负载，已达到优化资源使用、最大化吞吐率、最下化响应和避免过载。</li>
<li>命名服务：命名服务是分布式系统最基本的公共服务之一。在分布式系统中，被命名的实体通常可以就是集群中的机器、提供的服务地址或远程对象等–这些我们都可以统称它们的名称（Name），其中较常见的就是一些分布式服务框架（如RPC、RMI）中的服务地址列表，通过使用命名服务，客户端应用能够指定名字来获取资源的实体、服务地址和提供者的信息。</li>
<li>集群管理：随着分布式系统规模的日益扩大，集群中的机器规模也随之变大、因此集群监控与集群控制就变得很重要。</li>
<li>分布式锁：分布式锁就是控制分布式系统之间同步访问共享资源的一种方式。在分布式系统中，常常需要协调他们的动作。如果不同的系统或是同一个系统的不同主机之间共享了一个或一组资源，那么访问这些资源的时候，往往需要互斥来防止彼此干扰来保证一致性，在这种情况下，便需要使用到分布式锁。</li>
<li>分布式队列：利用Zookeeper的功能我们也可以实现类似于ActiveMQ、Kafka和HornetQ等的消息中间件。</li>
</ul>
<h2 id="三、构建ZooKeeper集群机及RPC服务机"><a href="#三、构建ZooKeeper集群机及RPC服务机" class="headerlink" title="三、构建ZooKeeper集群机及RPC服务机"></a>三、构建ZooKeeper集群机及RPC服务机</h2><p>在Ubuntu桌面系统下完成，利用Oracle下的虚拟机软件VirtualBox。虚拟出了５个Ubuntu 操作系统，３个ZooKeeper机，分别是ZooKeeper-1,ZooKeeper-2,ZooKeeper-3个构建出一个ZooKeeper集群。２个RPC服务机，把在宿主机编写好的程序，通过打包的方式，发布到RPC服务机的jetty下，提供RPC服务 。</p>
<h2 id="四、配置ZooKeeper"><a href="#四、配置ZooKeeper" class="headerlink" title="四、配置ZooKeeper"></a>四、配置ZooKeeper</h2><p>从官方网站下载后，解压到了虚拟机的<code>/work/</code>目录下，将<code>/work/zookeeper-3.4.8/conf/</code>目录下的<code>zoo_sample.cfg</code>重新复制一份命名为<code>zoo.cfg</code>,打开<code>zoo.cfg</code>文件。　<br>修改配置文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">tickTime=2000    </div><div class="line">ddataDir=/work/data/zookeeper   </div><div class="line">clientPort=2181 </div><div class="line">　   Server.1=192.168.0.3:2888:3888</div><div class="line">Server.2=192.168.0.4:2888:3888</div><div class="line">Server.3=192.168.0.5:2888:3888</div></pre></td></tr></table></figure></p>
<p>参数说明:<br><code>tickTime</code>: zookeeper中使用的基本时间单位, 毫秒值.<br><code>dataDir</code>: 数据和日志的目录. 可以是任意目录.此处我们配置到了<code>/work/data/zookeeper</code>目录下<br><code>clientPort</code>: 监听client连接的端口号.<br><code>Server.X=HOST/IP:port:port</code>　<br>     <code>Server.X</code> ：X是我们配置zookeeper集群服务每台机子的编号，需要在每台机子的<code>/work/data/zookeeper/</code>下创建<code>myid</code>文件，内容就是机子的编号。</p>
<h2 id="五、启动、关闭"><a href="#五、启动、关闭" class="headerlink" title="五、启动、关闭"></a>五、启动、关闭</h2><p>切换到<code>/work/zookeeper-3.4.8/bin</code>目录下 </p>
<h3 id="1-启动"><a href="#1-启动" class="headerlink" title="1. 启动"></a>1. 启动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">./zkServer.sh start</div><div class="line">ZooKeeper JMX enabled by default</div><div class="line">Using config: /work/zookeeper-3.4.8/bin/../conf/zoo.cfg</div><div class="line">Starting zookeeper ... STARTED</div></pre></td></tr></table></figure>
<h4 id="2-验证"><a href="#2-验证" class="headerlink" title="2.验证"></a>2.验证</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">./zkCli.sh</div><div class="line">[zk: localhost:2181(CONNECTED) 0]</div></pre></td></tr></table></figure>
<p>进入ZooKeeper 客户端终端命令就说明ZooKeeper启动成功了。 </p>
<h3 id="3-关闭"><a href="#3-关闭" class="headerlink" title="3. 关闭"></a>3. 关闭</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">./zkServer.sh stop</div><div class="line"></div><div class="line">ZooKeeper JMX enabled by default</div><div class="line">Using config: /work/tool/zookeeper-3.4.8/bin/../conf/zoo.cfg</div><div class="line">Stopping zookeeper ... STOPPED</div></pre></td></tr></table></figure>
<h2 id="六、利用Thrift提供RPC服务"><a href="#六、利用Thrift提供RPC服务" class="headerlink" title="六、利用Thrift提供RPC服务"></a>六、利用Thrift提供RPC服务</h2><h3 id="定义Weather-thrift文件"><a href="#定义Weather-thrift文件" class="headerlink" title="定义Weather.thrift文件"></a>定义<code>Weather.thrift</code>文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">namespace java com.rpc.weather</div><div class="line">　　　　 　　service weather&#123; </div><div class="line">    　　string getWeather(1:string city) </div><div class="line"> 　　&#125;</div></pre></td></tr></table></figure>
<h3 id="生成JAVA文件接口"><a href="#生成JAVA文件接口" class="headerlink" title="生成JAVA文件接口"></a>生成JAVA文件接口</h3><p>在windows环境下使用Thrift工具编译<code>.thrift</code>文件，就会生成相应的<code>.java</code> 文件。该文件包含了在<code>.thrift</code>文件中描述的服务类的接口定义，即<code>.Iface</code>接口，以及服务调用的底层通信细节。命令如下:　<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">thrift.exe -r -gen java 　weather.thrift</div></pre></td></tr></table></figure></p>
<p>该命令会自动生产相应的JAVA文件</p>
<p><code>gen-java</code>目录就是生成好代码的地方</p>
<h3 id="实现RPC接口功能"><a href="#实现RPC接口功能" class="headerlink" title="实现RPC接口功能"></a>实现RPC接口功能</h3><p>weather的接口实现比较复杂，在这里我们用简单些Hello来说明，道理是一样的。Hello接口的实现： hello只是一个简单的反馈功能，它把客户端传递过来的参数经过简单的组合一起反馈给ＲＰＣ的客户端，本例只是简单展示了一下ＲＰＣ服务处理能力，实现上面已经生产好的Hello.Iface 接口。代码如下：<br>public class HelloServiceImpl implements com.rpc.sayhello.Hello.Iface {<br>    public String helloString(String para) throws TException {<br>        System.out.println(“helloString be calling”);<br>        return “你好:” + para + “,欢迎来到”+GetIP.IP()+”服务器!”;<br>    }<br>}<br>1<br>2<br>3<br>4<br>5<br>6<br>1<br>2<br>3<br>4<br>5<br>6</p>
<h2 id="七、RPC服务注册"><a href="#七、RPC服务注册" class="headerlink" title="七、RPC服务注册"></a>七、RPC服务注册</h2><p>我们在ZooKeeper注册了2个服务（2个ZNode节点），分别是sayHello及Weather。用2个IP提供RPC的服务。目录结构如图-：<br>这里写图片描述<br>在Zookeeper的每个节点，都可以分为持久节点和临时节点　持久节点是指一旦这个节点被创建了，除非主动进行删除操作，否则这个节点将一直保存在ＺooKeeper中.而临时节点就不一样了，它的生命周期和客户端回话绑定，一旦客户端回话失效，那么这个客户端创建的所有临时节点都会被移除。ZooKeeper主要是利用了“心跳检测”功能，它会定时向各个服务提供者发送一个请求，如果长期没有响应，服务中心就认为该服务提供者已经“挂了”，并将其剔除。注意临时节点下不可以在创建任何节点。</p>
<p>注册天气服务的主要代码：</p>
<p>private void createServerHost()  {<br>        Stat stat = zookeeper.exists(WeatherConstants.RPCNAME + “/“ + GetIP.IP() + “:” + WeatherConstants.WeahterPort,false);//检查节点是否存在<br>        if (stat == null) {<br>　　　　　　// 这里是临时的节点，会因服务器的宕机、网络失效而消失<br>    path = zookeeper.create(WeatherConstants.RPCNAME + “/“ + GetIP.IP() + “:” + 　　WeatherConstants.WeahterPort, “”.getBytes(),Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);//创建节点　<br>        }<br>    }<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>1<br>2<br>3<br>4<br>5<br>6<br>7</p>
<h2 id="八、RPC客戶端服务监听"><a href="#八、RPC客戶端服务监听" class="headerlink" title="八、RPC客戶端服务监听"></a>八、RPC客戶端服务监听</h2><p>Watcher(事件监听器)，是ZooKeeper的一个很重要的特性。ZooKeeper允许用户在指定的节点上注册一些Watcher，并且在一些特定的事件触发的时候，ZooKeeper服务器会将事件通知到感兴趣的客户端。利用Watcher监听2个服务节点下的IP变化，一旦我们监听的服务下的节点有变化（增加或减少）ZooKeeper就会向我们注册的监听类发送“NodeChildrenChanged”事件，我们就可以在此时更新地址列表变化，从而进行更新。<br>需要注意的是ZooKeeper服务器在向客户端发送Watcher的通知的时候，仅仅只会发出一个通知，而不会把节点的变化情况发送给客户端，客户端需要自己重新获取。另外，由于Watcher通知是一次性的，一旦触发一次通知后，该Watcher就失效了，因此客户端需要反复注册Watcher。</p>
<p>监听服务列表的变化<br>在监听WatchWeather类内我们定义了一个weatherlist的数组列表，用来存储提供天气的所有ＲＰＣ服务的地址和端口。<br>通过zookeeper.getChildren获取在zookeeper注册的所有提供天气的ＩＰ地址。并且注册了在这个节点下的监听类。</p>
<p>　　　　weatherlist = zookeeper.getChildren(WeatherConstants.RPCNAME, this);<br>　　　 //在监听的WatchWeather实现Watcher接口的process方法：<br>　　　　public void process(WatchedEvent event) {<br>        if (EventType.NodeChildrenChanged == event.getType()) { 　<br>        　　weatherlist = zookeeper.getChildren(WeatherConstants.RPCNAME, this);<br>　　　　　}  　<br>    }<br>　　<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>只要我们监听的节点下有变动就会接受到NodeChildrenChanged 事件，在这里我们再次获取了节点下的最新ＩＰ地址列表，并且重新注册了监听类。</p>
<h2 id="九、调用RPC服务"><a href="#九、调用RPC服务" class="headerlink" title="九、调用RPC服务"></a>九、调用RPC服务</h2><p>public class CallWeatherRPC {<br>    public String callWeather(String ip, int port, String city) {<br>        String retString = null;<br>        TTransport transport = new TSocket(ip, port);<br>        transport.open();<br>        TProtocol protocol = new TBinaryProtocol(transport);<br>        weather.Client client = new weather.Client(protocol);//weather为定义接口实现的文件<br>        retString = client.getWeather(city);//调用ＲＰＣ服务<br>        transport.close();<br>        return retString;<br>    }<br>}<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>此处是使用了Thrift的客户端调用RPC服务端的相应程序，主要特点是IP地址不固定，可以有多地址可以调用。</p>
]]></content>
    
    <summary type="html">
    
      基于ZooKeeper和Thrift构建动态RPC调用
    
    </summary>
    
      <category term="分布式" scheme="http://jishusuishouji.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="RPC" scheme="http://jishusuishouji.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/RPC/"/>
    
      <category term="Thrift" scheme="http://jishusuishouji.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/RPC/Thrift/"/>
    
    
      <category term="Thrift" scheme="http://jishusuishouji.github.io/tags/Thrift/"/>
    
      <category term="RPC" scheme="http://jishusuishouji.github.io/tags/RPC/"/>
    
      <category term="ZoopKeeper" scheme="http://jishusuishouji.github.io/tags/ZoopKeeper/"/>
    
  </entry>
  
  <entry>
    <title>Apache Thrift学习之一（入门及Java实例演示）</title>
    <link href="http://jishusuishouji.github.io/2017/04/03/thrift/Apache_Thrift%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%B8%80%EF%BC%88%E5%85%A5%E9%97%A8%E5%8F%8AJava%E5%AE%9E%E4%BE%8B%E6%BC%94%E7%A4%BA%EF%BC%89/"/>
    <id>http://jishusuishouji.github.io/2017/04/03/thrift/Apache_Thrift学习之一（入门及Java实例演示）/</id>
    <published>2017-04-03T09:58:39.000Z</published>
    <updated>2017-04-04T14:33:34.955Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><p>Apache Thrift是Facebook实现的一种高效的、支持多种编程语言的远程服务调用的框架。Thrift是由Facebook开发的，并在2008年捐给了Apache基金会，成为了一个孵化器项目。</p>
<p>Thrift是一个软件框架，用来进行可扩展且跨语言的服务开发。它结合了功能强大的软件堆栈和代码生成引擎，</p>
<p>Thrift是一个驱动层接口，它提供了用于客户端使用多种语言实现的API。<br>Thrift是个代码生成库，支持的客户端语言包括C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, and OCaml 。它的目标是为了各种流行的语言提供便利的RPC调用机制，而不需要使用那些开销巨大的方式，比如SOAP。</p>
<p>要使用Thrift，就要使用一个语言中立的服务定义文件，描述数据类型和服务接口。这个文件会被用作引擎的输入，编译器为每种支持的语言生成代码。这种静态生成的设计让它非常容易被开发者所使用，而且因为类型验证都发生在编译期而非运行期，所以代码可以很有效率地运行。</p>
<p>Thrift的设计提供了以下这些特性：<br>1、语言无关的类型<br>因为类型是使用定义文件按照语言中立的方式规定的，所以它们可以被不同的语言分享。比如，C++的结构可以和Python的字典类型相互交换数据。<br>2、通用传输接口<br>不论你使用的是磁盘文件、内存数据还是socket流，都可以使用同一段应用代码。<br>3、协议无关<br>Thrift会对数据类型进行编码和解码，可以跨协议使用。<br>4、支持版本<br>数据类型可以加入版本信息，来支持客户端API的更新。</p>
<h2 id="二、下载配置"><a href="#二、下载配置" class="headerlink" title="二、下载配置"></a>二、下载配置</h2><h3 id="1）安装thrift：到thrift官网下载exe文件，然后将文件重命名为thrift-exe-拷贝到D-EBOOK-thrift目录下-或者任何目录下-，然后就可以在dos环境下使用了"><a href="#1）安装thrift：到thrift官网下载exe文件，然后将文件重命名为thrift-exe-拷贝到D-EBOOK-thrift目录下-或者任何目录下-，然后就可以在dos环境下使用了" class="headerlink" title="1）安装thrift：到thrift官网下载exe文件，然后将文件重命名为thrift.exe,拷贝到D:\EBOOK\thrift目录下(或者任何目录下)，然后就可以在dos环境下使用了"></a>1）安装thrift：到thrift官网下载exe文件，然后将文件重命名为<code>thrift.exe</code>,拷贝到<code>D:\EBOOK\thrift</code>目录下(或者任何目录下)，然后就可以在dos环境下使用了</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">D:\EBOOK\thrift&gt;thrift -gen java D:\work\workspace\thriftworkspace\demo1\demoHello.thrift</div></pre></td></tr></table></figure>
<p>输出的java文件默认输出到当前目录下<code>D:\EBOOK\thrift\gen-java</code>，也可以使用<code>-o</code>参数指定输出路径;</p>
<h3 id="2）下载相关依赖包"><a href="#2）下载相关依赖包" class="headerlink" title="2）下载相关依赖包"></a>2）下载相关依赖包</h3><h4 id="2-1）libthrift-jar-，下载地址：http-repo1-maven-org-maven2-org-apache-thrift-libthrift-0-9-0"><a href="#2-1）libthrift-jar-，下载地址：http-repo1-maven-org-maven2-org-apache-thrift-libthrift-0-9-0" class="headerlink" title="2.1）libthrift.jar ，下载地址：http://repo1.maven.org/maven2/org/apache/thrift/libthrift/0.9.0/"></a>2.1）<code>libthrift.jar</code> ，下载地址：<a href="http://repo1.maven.org/maven2/org/apache/thrift/libthrift/0.9.0/" target="_blank" rel="external">http://repo1.maven.org/maven2/org/apache/thrift/libthrift/0.9.0/</a></h4><h4 id="2-2）slf4j-api-jar"><a href="#2-2）slf4j-api-jar" class="headerlink" title="2.2）slf4j-api.jar"></a>2.2）<code>slf4j-api.jar</code></h4><h4 id="2-3）slf4j-simple-jar"><a href="#2-3）slf4j-simple-jar" class="headerlink" title="2.3）slf4j-simple.jar"></a>2.3）<code>slf4j-simple.jar</code></h4><p>到官网<a href="http://thrift.apache.org/download" target="_blank" rel="external">http://thrift.apache.org/download</a> 下载最新版本，截止今日（2016-05-23）最新版本为0.9.3</p>
<h3 id="3-Maven项目设置依赖包"><a href="#3-Maven项目设置依赖包" class="headerlink" title="3) Maven项目设置依赖包"></a>3) Maven项目设置依赖包</h3><p>如果是Maven构建项目的，直接在<code>pom.xml</code>中添加如下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">  &lt;groupId&gt;org.apache.thrift&lt;/groupId&gt;</div><div class="line">  &lt;artifactId&gt;libthrift&lt;/artifactId&gt;</div><div class="line">  &lt;version&gt;0.8.0&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure></p>
<h3 id="4-手动编译"><a href="#4-手动编译" class="headerlink" title="4).手动编译"></a>4).手动编译</h3><p>如果自己编译lib包，把下载的压缩包解压到<code>X</code>盘，然后在<code>X:\thrift-0.8.0\lib\java</code> 目录下运行<code>ant</code>进行自动编译，会在<code>X:\thrift-0.8.0\lib\java\build\</code> 目录下看到编译好的lib包：<code>libthrift-0.8.0.jar</code></p>
<h2 id="三、基本概念"><a href="#三、基本概念" class="headerlink" title="三、基本概念"></a>三、基本概念</h2><h3 id="1-数据类型"><a href="#1-数据类型" class="headerlink" title="1.数据类型"></a>1.数据类型</h3><h4 id="基本类型："><a href="#基本类型：" class="headerlink" title="基本类型："></a>基本类型：</h4><p><code>bool</code>：布尔值，<code>true</code>或<code>false</code>，对应Java的<code>boolean</code><br><code>byte</code>：8位有符号整数，对应Java的<code>byte</code><br><code>i16</code>：16位有符号整数，对应Java的<code>short</code><br><code>i32</code>：32位有符号整数，对应Java的<code>int</code><br><code>i64</code>：64位有符号整数，对应Java的<code>long</code><br><code>double</code>：64 位浮点数，对应Java的<code>double</code><br><code>string</code>：utf-8编码的字符串，对应Java的<code>String</code></p>
<h4 id="结构体类型："><a href="#结构体类型：" class="headerlink" title="结构体类型："></a>结构体类型：</h4><p><code>struct</code>：定义公共的对象，类似于C语言中的结构体定义，在Java中是一个JavaBean</p>
<h4 id="容器类型："><a href="#容器类型：" class="headerlink" title="容器类型："></a>容器类型：</h4><p><code>list</code>：对应Java的<code>ArrayList</code><br><code>set</code>：对应Java的<code>HashSet</code><br><code>map</code>：对应Java的<code>HashMap</code></p>
<h4 id="异常类型："><a href="#异常类型：" class="headerlink" title="异常类型："></a>异常类型：</h4><p><code>exception</code>：对应Java的<code>Exception</code></p>
<h4 id="服务类型："><a href="#服务类型：" class="headerlink" title="服务类型："></a>服务类型：</h4><p><code>service</code>：对应服务的类</p>
<h3 id="2-服务端编码基本步骤："><a href="#2-服务端编码基本步骤：" class="headerlink" title="2.服务端编码基本步骤："></a>2.服务端编码基本步骤：</h3><ul>
<li>实现服务处理接口impl</li>
<li>创建<code>TProcessor</code>(业务处理器)</li>
<li>创建<code>TServerTransport</code>()</li>
<li>创建<code>TProtocol</code>(传输协议)</li>
<li>创建<code>TServer</code></li>
<li>启动<code>Server</code></li>
</ul>
<h3 id="3-客户端编码基本步骤："><a href="#3-客户端编码基本步骤：" class="headerlink" title="3.客户端编码基本步骤："></a>3.客户端编码基本步骤：</h3><ul>
<li>创建<code>Transport</code></li>
<li>创建<code>TProtocol</code></li>
<li>基于<code>TTransport</code>和<code>TProtocol</code>创建<code>Client</code></li>
<li>调用<code>Client</code>的相应方法</li>
</ul>
<h3 id="4-数据传输协议"><a href="#4-数据传输协议" class="headerlink" title="4.数据传输协议"></a>4.数据传输协议</h3><p><code>TBinaryProtocol</code>: 二进制格式.<br><code>TCompactProtocol</code>: 压缩格式<br><code>TJSONProtocol</code>: JSON格式<br><code>TSimpleJSONProtocol</code>: 提供JSON只写协议, 生成的文件很容易通过脚本语言解析</p>
<blockquote>
<p>客户端和服务端的协议要一致</p>
</blockquote>
<p>##四、实例演示</p>
<h3 id="1-thrift生成代码"><a href="#1-thrift生成代码" class="headerlink" title="1. thrift生成代码"></a>1. thrift生成代码</h3><p>创建Thrift文件：<code>D:\work\workspace\thriftworkspace\demo1\demoHello.thrift</code> ,内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">namespace java com.dxz.thrift.demo</div><div class="line"> </div><div class="line">service  HelloWorldService &#123;</div><div class="line">  string sayHello(1:string username)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>thrift-0.8.0.exe是官网提供的windows下编译工具，运用这个工具生成相关代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">D:\EBOOK\thrift&gt;thrift-0.9.3.exe -r -gen java D:\work\workspace\thriftworkspace\demo1\demoHello.thrift</div></pre></td></tr></table></figure></p>
<p>将生成的<code>HelloWorldService.java</code>文件copy到自己测试的工程中，我的工程是用maven构建的，故在<code>pom.xml</code>中增加如下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.apache.thrift&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;libthrift&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;0.8.0&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;1.5.8&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure></p>
<p>如果是ant构建的工程，将<code>libthrift-0.9.3.jar</code>加入到工程中</p>
<h3 id="2-实现接口Iface"><a href="#2-实现接口Iface" class="headerlink" title="2. 实现接口Iface"></a>2. 实现接口Iface</h3><p>java代码：<code>HelloWorldImpl.java</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">package com.dxz.thrift.demo;</div><div class="line">import org.apache.thrift.TException;</div><div class="line">public class HelloWorldImpl implements HelloWorldService.Iface &#123;</div><div class="line">    public HelloWorldImpl() &#123;</div><div class="line">    &#125;</div><div class="line">    @Override</div><div class="line">    public String sayHello(String username) throws TException &#123;</div><div class="line">        return &quot;Hi,&quot; + username + &quot; welcome to thrift world&quot;;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="3-TSimpleServer服务端"><a href="#3-TSimpleServer服务端" class="headerlink" title="3.TSimpleServer服务端"></a>3.<code>TSimpleServer</code>服务端</h3><h4 id="简单的单线程服务模型，一般用于测试。"><a href="#简单的单线程服务模型，一般用于测试。" class="headerlink" title="简单的单线程服务模型，一般用于测试。"></a>简单的单线程服务模型，一般用于测试。</h4><p>编写服务端server代码：<code>HelloServerDemo.java</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">package com.dxz.thrift.demo;</div><div class="line"></div><div class="line">import org.apache.thrift.TProcessor;</div><div class="line">import org.apache.thrift.protocol.TBinaryProtocol;</div><div class="line">import org.apache.thrift.protocol.TCompactProtocol;</div><div class="line">import org.apache.thrift.protocol.TJSONProtocol;</div><div class="line">import org.apache.thrift.protocol.TSimpleJSONProtocol;</div><div class="line">import org.apache.thrift.server.TServer;</div><div class="line">import org.apache.thrift.server.TSimpleServer;</div><div class="line">import org.apache.thrift.transport.TServerSocket;</div><div class="line"></div><div class="line">public class HelloServerDemo &#123;</div><div class="line">    public static final int SERVER_PORT = 8090;</div><div class="line"></div><div class="line">    public void startServer() &#123;</div><div class="line">        try &#123;</div><div class="line">            System.out.println(&quot;HelloWorld TSimpleServer start ....&quot;);</div><div class="line"></div><div class="line">            TProcessor tprocessor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldImpl());</div><div class="line">            //HelloWorldService.Processor&lt;HelloWorldService.Iface&gt; tprocessor =</div><div class="line">            new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldImpl());</div><div class="line"></div><div class="line">            // 简单的单线程服务模型，一般用于测试</div><div class="line">            TServerSocket serverTransport = new TServerSocket(SERVER_PORT);</div><div class="line">            TServer.Args tArgs = new TServer.Args(serverTransport);</div><div class="line">            tArgs.processor(tprocessor);</div><div class="line">            tArgs.protocolFactory(new TBinaryProtocol.Factory());</div><div class="line">            // tArgs.protocolFactory(new TCompactProtocol.Factory());</div><div class="line">            // tArgs.protocolFactory(new TJSONProtocol.Factory());</div><div class="line">            TServer server = new TSimpleServer(tArgs);</div><div class="line">            server.serve();</div><div class="line"></div><div class="line">        &#125; catch (Exception e) &#123;</div><div class="line">            System.out.println(&quot;Server start error!!!&quot;);</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        HelloServerDemo server = new HelloServerDemo();</div><div class="line">        server.startServer();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h4 id="编写客户端Client代码：HelloClientDemo-java"><a href="#编写客户端Client代码：HelloClientDemo-java" class="headerlink" title="编写客户端Client代码：HelloClientDemo.java"></a>编写客户端Client代码：<code>HelloClientDemo.java</code></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">package com.dxz.thrift.demo;</div><div class="line"></div><div class="line">import org.apache.thrift.TException;</div><div class="line">import org.apache.thrift.protocol.TBinaryProtocol;</div><div class="line">import org.apache.thrift.protocol.TCompactProtocol;</div><div class="line">import org.apache.thrift.protocol.TJSONProtocol;</div><div class="line">import org.apache.thrift.protocol.TProtocol;</div><div class="line">import org.apache.thrift.transport.TSocket;</div><div class="line">import org.apache.thrift.transport.TTransport;</div><div class="line">import org.apache.thrift.transport.TTransportException;</div><div class="line"></div><div class="line">public class HelloClientDemo &#123;</div><div class="line"></div><div class="line">    public static final String SERVER_IP = &quot;localhost&quot;;</div><div class="line">    public static final int SERVER_PORT = 8090;</div><div class="line">    public static final int TIMEOUT = 30000;</div><div class="line"></div><div class="line">    public void startClient(String userName) &#123;</div><div class="line">        TTransport transport = null;</div><div class="line">        try &#123;</div><div class="line">            transport = new TSocket(SERVER_IP, SERVER_PORT, TIMEOUT);</div><div class="line">            // 协议要和服务端一致</div><div class="line">            TProtocol protocol = new TBinaryProtocol(transport);</div><div class="line">            // TProtocol protocol = new TCompactProtocol(transport);</div><div class="line">            // TProtocol protocol = new TJSONProtocol(transport);</div><div class="line">            HelloWorldService.Client client = new HelloWorldService.Client(protocol);</div><div class="line">            transport.open();</div><div class="line">            String result = client.sayHello(userName);</div><div class="line">            System.out.println(&quot;Thrify client result =: &quot; + result);</div><div class="line">        &#125; catch (TTransportException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125; catch (TException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125; finally &#123;</div><div class="line">            if (null != transport) &#123;</div><div class="line">                transport.close();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        HelloClientDemo client = new HelloClientDemo();</div><div class="line">        client.startClient(&quot;china&quot;);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>先运行服务端程序，日志如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">HelloWorld TSimpleServer start ....</div></pre></td></tr></table></figure></p>
<p>再运行客户端调用程序，日志如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Thrify client result =: Hi,china welcome to thrift world.</div></pre></td></tr></table></figure></p>
<p>测试成功，和预期的返回信息一致。</p>
<h3 id="4-TThreadPoolServer-服务模型"><a href="#4-TThreadPoolServer-服务模型" class="headerlink" title="4.TThreadPoolServer 服务模型"></a>4.TThreadPoolServer 服务模型</h3><p>线程池服务模型，使用标准的阻塞式IO，预先创建一组线程处理请求。</p>
<h4 id="编写服务端代码：HelloServerDemo2-java"><a href="#编写服务端代码：HelloServerDemo2-java" class="headerlink" title="编写服务端代码：HelloServerDemo2.java"></a>编写服务端代码：<code>HelloServerDemo2.java</code></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">package com.dxz.thrift.demo;</div><div class="line"></div><div class="line">import org.apache.thrift.TProcessor;</div><div class="line">import org.apache.thrift.protocol.TBinaryProtocol;</div><div class="line">import org.apache.thrift.server.TServer;</div><div class="line">import org.apache.thrift.server.TThreadPoolServer;</div><div class="line">import org.apache.thrift.transport.TServerSocket;</div><div class="line"></div><div class="line">public class HelloServerDemo2 &#123;</div><div class="line">    public static final int SERVER_PORT = 8090;</div><div class="line"></div><div class="line">    public void startServer() &#123;</div><div class="line">        try &#123;</div><div class="line">            System.out.println(&quot;HelloWorld TThreadPoolServer start ....&quot;);</div><div class="line"></div><div class="line">            TProcessor tprocessor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldImpl());</div><div class="line"></div><div class="line">            TServerSocket serverTransport = new TServerSocket(SERVER_PORT);</div><div class="line">            TThreadPoolServer.Args ttpsArgs = new TThreadPoolServer.Args(serverTransport);</div><div class="line">            ttpsArgs.processor(tprocessor);</div><div class="line">            ttpsArgs.protocolFactory(new TBinaryProtocol.Factory());</div><div class="line"></div><div class="line">            // 线程池服务模型，使用标准的阻塞式IO，预先创建一组线程处理请求。</div><div class="line">            TServer server = new TThreadPoolServer(ttpsArgs);</div><div class="line">            server.serve();</div><div class="line"></div><div class="line">        &#125; catch (Exception e) &#123;</div><div class="line">            System.out.println(&quot;Server start error!!!&quot;);</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        HelloServerDemo2 server = new HelloServerDemo2();</div><div class="line">        server.startServer();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>客户端Client代码和之前的一样，只要数据传输的协议一致即可，客户端测试成功，结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Thrify client result =: Hi,china welcome to thrift world.</div></pre></td></tr></table></figure></p>
<h3 id="5-TNonblockingServer-服务模型"><a href="#5-TNonblockingServer-服务模型" class="headerlink" title="5.TNonblockingServer 服务模型"></a>5.TNonblockingServer 服务模型</h3><p>使用非阻塞式IO，服务端和客户端需要指定<code>TFramedTransport</code>数据传输的方式。</p>
<h4 id="编写服务端代码：HelloServerDemo3-java"><a href="#编写服务端代码：HelloServerDemo3-java" class="headerlink" title="编写服务端代码：HelloServerDemo3.java"></a>编写服务端代码：<code>HelloServerDemo3.java</code></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">package com.dxz.thrift.demo;</div><div class="line"></div><div class="line">import org.apache.thrift.TProcessor;</div><div class="line">import org.apache.thrift.protocol.TBinaryProtocol;</div><div class="line">import org.apache.thrift.protocol.TCompactProtocol;</div><div class="line">import org.apache.thrift.server.TNonblockingServer;</div><div class="line">import org.apache.thrift.server.TServer;</div><div class="line">import org.apache.thrift.server.TThreadPoolServer;</div><div class="line">import org.apache.thrift.transport.TFramedTransport;</div><div class="line">import org.apache.thrift.transport.TNonblockingServerSocket;</div><div class="line">import org.apache.thrift.transport.TServerSocket;</div><div class="line"></div><div class="line">public class HelloServerDemo3 &#123;</div><div class="line">    public static final int SERVER_PORT = 8090;</div><div class="line"></div><div class="line">    public void startServer() &#123;</div><div class="line">        try &#123;</div><div class="line">            System.out.println(&quot;HelloWorld TNonblockingServer start ....&quot;);</div><div class="line"></div><div class="line">            TProcessor tprocessor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldImpl());</div><div class="line"></div><div class="line">            TNonblockingServerSocket tnbSocketTransport = new TNonblockingServerSocket(SERVER_PORT);</div><div class="line">            TNonblockingServer.Args tnbArgs = new TNonblockingServer.Args(tnbSocketTransport);</div><div class="line">            tnbArgs.processor(tprocessor);</div><div class="line">            tnbArgs.transportFactory(new TFramedTransport.Factory());</div><div class="line">            tnbArgs.protocolFactory(new TCompactProtocol.Factory());</div><div class="line"></div><div class="line">            // 使用非阻塞式IO，服务端和客户端需要指定TFramedTransport数据传输的方式</div><div class="line">            TServer server = new TNonblockingServer(tnbArgs);</div><div class="line">            server.serve();</div><div class="line"></div><div class="line">        &#125; catch (Exception e) &#123;</div><div class="line">            System.out.println(&quot;Server start error!!!&quot;);</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /**</div><div class="line">     * @param args</div><div class="line">     */</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        HelloServerDemo3 server = new HelloServerDemo3();</div><div class="line">        server.startServer();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="编写客户端代码：HelloClientDemo3-java"><a href="#编写客户端代码：HelloClientDemo3-java" class="headerlink" title="编写客户端代码：HelloClientDemo3.java"></a>编写客户端代码：<code>HelloClientDemo3.java</code></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line">package com.dxz.thrift.demo;</div><div class="line"></div><div class="line">import org.apache.thrift.TException;</div><div class="line">import org.apache.thrift.protocol.TBinaryProtocol;</div><div class="line">import org.apache.thrift.protocol.TCompactProtocol;</div><div class="line">import org.apache.thrift.protocol.TJSONProtocol;</div><div class="line">import org.apache.thrift.protocol.TProtocol;</div><div class="line">import org.apache.thrift.transport.TSocket;</div><div class="line">import org.apache.thrift.transport.TTransport;</div><div class="line">import org.apache.thrift.transport.TTransportException;</div><div class="line">import org.apache.thrift.TException;</div><div class="line">import org.apache.thrift.protocol.TCompactProtocol;</div><div class="line">import org.apache.thrift.protocol.TProtocol;</div><div class="line">import org.apache.thrift.transport.TFramedTransport;</div><div class="line">import org.apache.thrift.transport.TSocket;</div><div class="line">import org.apache.thrift.transport.TTransport;</div><div class="line">import org.apache.thrift.transport.TTransportException;</div><div class="line"></div><div class="line">public class HelloClientDemo3 &#123;</div><div class="line"></div><div class="line">    public static final String SERVER_IP = &quot;localhost&quot;;</div><div class="line">    public static final int SERVER_PORT = 8090;</div><div class="line">    public static final int TIMEOUT = 30000;</div><div class="line"></div><div class="line">    public void startClient(String userName) &#123;</div><div class="line">        TTransport transport = null;</div><div class="line">        try &#123;</div><div class="line">            transport = new TFramedTransport(new TSocket(SERVER_IP, SERVER_PORT, TIMEOUT));</div><div class="line">            // 协议要和服务端一致</div><div class="line">            TProtocol protocol = new TCompactProtocol(transport);</div><div class="line">            HelloWorldService.Client client = new HelloWorldService.Client(protocol);</div><div class="line">            transport.open();</div><div class="line">            String result = client.sayHello(userName);</div><div class="line">            System.out.println(&quot;Thrify client result =: &quot; + result);</div><div class="line">        &#125; catch (TTransportException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125; catch (TException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125; finally &#123;</div><div class="line">            if (null != transport) &#123;</div><div class="line">                transport.close();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /**</div><div class="line">     * @param args</div><div class="line">     */</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        HelloClientDemo3 client = new HelloClientDemo3();</div><div class="line">        client.startClient(&quot;HelloClientDemo3&quot;);</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>客户端的测试成功，结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Thrify client result =: Hi,HelloClientDemo3 welcome to thrift world.</div></pre></td></tr></table></figure></p>
<h3 id="6-THsHaServer服务模型"><a href="#6-THsHaServer服务模型" class="headerlink" title="6.THsHaServer服务模型"></a>6.THsHaServer服务模型</h3><p>半同步半异步的服务端模型，需要指定为：<code>TFramedTransport</code>数据传输的方式。</p>
<h4 id="编写服务端代码：HelloServerDemo4-java"><a href="#编写服务端代码：HelloServerDemo4-java" class="headerlink" title="编写服务端代码：HelloServerDemo4.java"></a>编写服务端代码：<code>HelloServerDemo4.java</code></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line">package com.dxz.thrift.demo;</div><div class="line"></div><div class="line">import org.apache.thrift.TProcessor;</div><div class="line">import org.apache.thrift.protocol.TBinaryProtocol;</div><div class="line">import org.apache.thrift.protocol.TCompactProtocol;</div><div class="line">import org.apache.thrift.server.THsHaServer;</div><div class="line">import org.apache.thrift.server.TNonblockingServer;</div><div class="line">import org.apache.thrift.server.TServer;</div><div class="line">import org.apache.thrift.server.TSimpleServer;</div><div class="line">import org.apache.thrift.server.TThreadPoolServer;</div><div class="line">import org.apache.thrift.transport.TFramedTransport;</div><div class="line">import org.apache.thrift.transport.TNonblockingServerSocket;</div><div class="line">import org.apache.thrift.transport.TServerSocket;</div><div class="line"></div><div class="line">public class HelloServerDemo4 &#123;</div><div class="line">    public static final int SERVER_PORT = 8090;</div><div class="line"></div><div class="line">    public void startServer() &#123;</div><div class="line">        try &#123;</div><div class="line">            System.out.println(&quot;HelloWorld THsHaServer start ....&quot;);</div><div class="line"></div><div class="line">            TProcessor tprocessor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldImpl());</div><div class="line"></div><div class="line">            TNonblockingServerSocket tnbSocketTransport = new TNonblockingServerSocket(SERVER_PORT);</div><div class="line">            THsHaServer.Args thhsArgs = new THsHaServer.Args(tnbSocketTransport);</div><div class="line">            thhsArgs.processor(tprocessor);</div><div class="line">            thhsArgs.transportFactory(new TFramedTransport.Factory());</div><div class="line">            thhsArgs.protocolFactory(new TBinaryProtocol.Factory());</div><div class="line"></div><div class="line">            // 半同步半异步的服务模型</div><div class="line">            TServer server = new THsHaServer(thhsArgs);</div><div class="line">            server.serve();</div><div class="line"></div><div class="line">        &#125; catch (Exception e) &#123;</div><div class="line">            System.out.println(&quot;Server start error!!!&quot;);</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /**</div><div class="line">     * @param args</div><div class="line">     */</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        HelloServerDemo4 server = new HelloServerDemo4();</div><div class="line">        server.startServer();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="客户端代码HelloClientDemo4-java"><a href="#客户端代码HelloClientDemo4-java" class="headerlink" title="客户端代码HelloClientDemo4.java"></a>客户端代码<code>HelloClientDemo4.java</code></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line">package com.dxz.thrift.demo;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line"></div><div class="line">import org.apache.thrift.TException;</div><div class="line">import org.apache.thrift.protocol.TBinaryProtocol;</div><div class="line">import org.apache.thrift.protocol.TCompactProtocol;</div><div class="line">import org.apache.thrift.protocol.TProtocol;</div><div class="line">import org.apache.thrift.transport.TSocket;</div><div class="line">import org.apache.thrift.transport.TTransport;</div><div class="line">import org.apache.thrift.transport.TTransportException;</div><div class="line"></div><div class="line">public class HelloClientDemo4 &#123;</div><div class="line"></div><div class="line">    public static final String SERVER_IP = &quot;localhost&quot;;</div><div class="line">    public static final int SERVER_PORT = 8090;</div><div class="line">    public static final int TIMEOUT = 30000;</div><div class="line"></div><div class="line">    public void startClient(String userName) &#123;</div><div class="line">        TTransport transport = null;</div><div class="line">        try &#123;</div><div class="line">            transport = new TFramedTransport(new TSocket(SERVER_IP, SERVER_PORT, TIMEOUT));</div><div class="line">            // 协议要和服务端一致</div><div class="line">            TProtocol protocol = new TBinaryProtocol(transport);</div><div class="line">            // TProtocol protocol = new TCompactProtocol(transport);</div><div class="line">            // TProtocol protocol = new TJSONProtocol(transport);</div><div class="line">            HelloWorldService.Client client = new HelloWorldService.Client(protocol);</div><div class="line">            transport.open();</div><div class="line">            String result = client.sayHello(userName);</div><div class="line">            System.out.println(&quot;Thrify client result =: &quot; + result);</div><div class="line">        &#125; catch (TTransportException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125; catch (TException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125; finally &#123;</div><div class="line">            if (null != transport) &#123;</div><div class="line">                transport.close();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /**</div><div class="line">     * @param args</div><div class="line">     */</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        HelloClientDemo4 client = new HelloClientDemo4();</div><div class="line">        client.startClient(&quot;HelloClientDemo4&quot;);</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>结果：Thrify client result =: Hi,HelloClientDemo4 welcome to thrift world.</p>
<h3 id="7-异步客户端"><a href="#7-异步客户端" class="headerlink" title="7.异步客户端"></a>7.异步客户端</h3><p>编写服务端代码：HelloServerDemo5.java</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line">package com.dxz.thrift.demo;</div><div class="line"></div><div class="line">import org.apache.thrift.TProcessor;</div><div class="line">import org.apache.thrift.protocol.TCompactProtocol;</div><div class="line">import org.apache.thrift.server.TNonblockingServer;</div><div class="line">import org.apache.thrift.server.TServer;</div><div class="line">import org.apache.thrift.transport.TFramedTransport;</div><div class="line">import org.apache.thrift.transport.TNonblockingServerSocket;</div><div class="line"></div><div class="line">public class HelloServerDemo5 &#123;</div><div class="line">    public static final int SERVER_PORT = 8090;</div><div class="line"></div><div class="line">    public void startServer() &#123;</div><div class="line">        try &#123;</div><div class="line">            System.out.println(&quot;HelloWorld TNonblockingServer start ....&quot;);</div><div class="line"></div><div class="line">            TProcessor tprocessor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldImpl());</div><div class="line"></div><div class="line">            TNonblockingServerSocket tnbSocketTransport = new TNonblockingServerSocket(SERVER_PORT);</div><div class="line">            TNonblockingServer.Args tnbArgs = new TNonblockingServer.Args(tnbSocketTransport);</div><div class="line">            tnbArgs.processor(tprocessor);</div><div class="line">            tnbArgs.transportFactory(new TFramedTransport.Factory());</div><div class="line">            tnbArgs.protocolFactory(new TCompactProtocol.Factory());</div><div class="line"></div><div class="line">            // 使用非阻塞式IO，服务端和客户端需要指定TFramedTransport数据传输的方式</div><div class="line">            TServer server = new TNonblockingServer(tnbArgs);</div><div class="line">            server.serve();</div><div class="line"></div><div class="line">        &#125; catch (Exception e) &#123;</div><div class="line">            System.out.println(&quot;Server start error!!!&quot;);</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /**</div><div class="line">     * @param args</div><div class="line">     */</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        HelloServerDemo5 server = new HelloServerDemo5();</div><div class="line">        server.startServer();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>编写客户端Client代码：<code>HelloAsynClientDemo.java</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div></pre></td><td class="code"><pre><div class="line">package com.dxz.thrift.demo;</div><div class="line"></div><div class="line">import java.util.concurrent.CountDownLatch;</div><div class="line">import java.util.concurrent.TimeUnit;</div><div class="line"></div><div class="line">import org.apache.thrift.TException;</div><div class="line">import org.apache.thrift.async.AsyncMethodCallback;</div><div class="line">import org.apache.thrift.async.TAsyncClientManager;</div><div class="line">import org.apache.thrift.protocol.TCompactProtocol;</div><div class="line">import org.apache.thrift.protocol.TProtocolFactory;</div><div class="line">import org.apache.thrift.transport.TNonblockingSocket;</div><div class="line">import org.apache.thrift.transport.TNonblockingTransport;</div><div class="line">import com.dxz.thrift.demo.HelloWorldService.AsyncClient.sayHello_call;</div><div class="line"></div><div class="line">public class HelloAsynClientDemo &#123;</div><div class="line"></div><div class="line">    public static final String SERVER_IP = &quot;localhost&quot;;</div><div class="line">    public static final int SERVER_PORT = 8090;</div><div class="line">    public static final int TIMEOUT = 30000;</div><div class="line"></div><div class="line">    public void startClient(String userName) &#123;</div><div class="line">        try &#123;</div><div class="line">            TAsyncClientManager clientManager = new TAsyncClientManager();</div><div class="line">            TNonblockingTransport transport = new TNonblockingSocket(SERVER_IP, SERVER_PORT, TIMEOUT);</div><div class="line"></div><div class="line">            TProtocolFactory tprotocol = new TCompactProtocol.Factory();</div><div class="line">            HelloWorldService.AsyncClient asyncClient = new HelloWorldService.AsyncClient(tprotocol, clientManager,</div><div class="line">                    transport);</div><div class="line">            System.out.println(&quot;Client start .....&quot;);</div><div class="line"></div><div class="line">            CountDownLatch latch = new CountDownLatch(1);</div><div class="line">            AsynCallback callBack = new AsynCallback(latch);</div><div class="line">            System.out.println(&quot;call method sayHello start ...&quot;);</div><div class="line">            asyncClient.sayHello(userName, callBack);</div><div class="line">            System.out.println(&quot;call method sayHello .... end&quot;);</div><div class="line">            boolean wait = latch.await(30, TimeUnit.SECONDS);</div><div class="line">            System.out.println(&quot;latch.await =:&quot; + wait);</div><div class="line">        &#125; catch (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">        System.out.println(&quot;startClient end.&quot;);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public class AsynCallback implements AsyncMethodCallback&lt;sayHello_call&gt; &#123;</div><div class="line">        private CountDownLatch latch;</div><div class="line"></div><div class="line">        public AsynCallback(CountDownLatch latch) &#123;</div><div class="line">            this.latch = latch;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        @Override</div><div class="line">        public void onComplete(sayHello_call response) &#123;</div><div class="line">            System.out.println(&quot;onComplete&quot;);</div><div class="line">            try &#123;</div><div class="line">                // Thread.sleep(1000L * 1);</div><div class="line">                System.out.println(&quot;AsynCall result =:&quot; + response.getResult().toString());</div><div class="line">            &#125; catch (TException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125; catch (Exception e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125; finally &#123;</div><div class="line">                latch.countDown();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        @Override</div><div class="line">        public void onError(Exception exception) &#123;</div><div class="line">            System.out.println(&quot;onError :&quot; + exception.getMessage());</div><div class="line">            latch.countDown();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /**</div><div class="line">     * @param args</div><div class="line">     */</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        HelloAsynClientDemo client = new HelloAsynClientDemo();</div><div class="line">        client.startClient(&quot;HelloAsynClientDemo&quot;);</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>先运行服务程序，再运行客户端程序，测试结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Client start .....</div><div class="line">call method sayHello start ...</div><div class="line">call method sayHello .... end</div><div class="line">onComplete</div><div class="line">AsynCall result =:Hi,HelloAsynClientDemo welcome to thrift world.</div><div class="line">latch.await =:true</div><div class="line">startClient end.</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      Apache Thrift学习之一（入门及Java实例演示）
    
    </summary>
    
      <category term="RPC" scheme="http://jishusuishouji.github.io/categories/RPC/"/>
    
      <category term="Thrift" scheme="http://jishusuishouji.github.io/categories/RPC/Thrift/"/>
    
    
      <category term="facebook" scheme="http://jishusuishouji.github.io/tags/facebook/"/>
    
      <category term="Thrift" scheme="http://jishusuishouji.github.io/tags/Thrift/"/>
    
      <category term="RPC" scheme="http://jishusuishouji.github.io/tags/RPC/"/>
    
  </entry>
  
  <entry>
    <title>facebook的thriff 基于rpc的远程调用实现</title>
    <link href="http://jishusuishouji.github.io/2017/04/03/thriff/facebook%E7%9A%84thriff_%E5%9F%BA%E4%BA%8Erpc%E7%9A%84%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8%E5%AE%9E%E7%8E%B0/"/>
    <id>http://jishusuishouji.github.io/2017/04/03/thriff/facebook的thriff_基于rpc的远程调用实现/</id>
    <published>2017-04-03T09:05:33.000Z</published>
    <updated>2017-04-03T09:28:52.804Z</updated>
    
    <content type="html"><![CDATA[<h2 id="RPC、RMI、JMS概念："><a href="#RPC、RMI、JMS概念：" class="headerlink" title="RPC、RMI、JMS概念："></a>RPC、RMI、JMS概念：</h2><h3 id="RPC与RMI的对比"><a href="#RPC与RMI的对比" class="headerlink" title="RPC与RMI的对比"></a>RPC与RMI的对比</h3><p>-远程过程调用 (RPC)是平台中立的，它不理会操作系统之间以及编程语言之间的差异。即RPC支持多种语言，而RMI只支持Java写的应用程序。<br>另外RMI调用远程对象方法，允许方法返回Java对象以及基本数据类型。而RPC不支持对象的概念，传送到RPC服务的消息由外部数据表示 (External Data Representation, XDR) 语言表示，这种语言抽象了字节序类和数据类型结构之间的差异。只有由XDR定义的数据类型才能被传递，RPC不允许传递对象。可以说RMI是面向对象方式的Java RPC。</p>
<h3 id="JMS"><a href="#JMS" class="headerlink" title="JMS"></a>JMS</h3><p>Java消息服务(Java Messaging Service, JMS) 是一种允许应用程序创建、发送、接受和读取消息的Java API。JMS与RMI的区别在于，采用JMS服务，对象是在物理上被异步从网络的某个JVM上直接移动到另一个JVM上。(严重怀疑)</p>
<p>而RMI对象是绑定在本地JVM中，只有函数参数和返回值是通过网络传送的。</p>
<h2 id="thrift概念"><a href="#thrift概念" class="headerlink" title="thrift概念"></a>thrift概念</h2><p>是facebook提供的一种跨平台远程通信框架，效率比较高。</p>
<h2 id="thirift用法"><a href="#thirift用法" class="headerlink" title="thirift用法"></a>thirift用法</h2><h3 id="1-编写一个thrift文件Test-thrift，用于确定连接双方的接口。"><a href="#1-编写一个thrift文件Test-thrift，用于确定连接双方的接口。" class="headerlink" title="1.编写一个thrift文件Test.thrift，用于确定连接双方的接口。"></a>1.编写一个thrift文件<code>Test.thrift</code>，用于确定连接双方的接口。</h3><p>简单例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">service Test &#123;</div><div class="line">  void  ping(1: i32 length)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="2-使用thrift编译"><a href="#2-使用thrift编译" class="headerlink" title="2.使用thrift编译"></a>2.使用thrift编译</h3><p>thrift可以用不同命令生成不同文件：</p>
<h4 id="a-生成java文件"><a href="#a-生成java文件" class="headerlink" title="a.生成java文件"></a>a.生成java文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">thrift  -gen java Test.thrift</div></pre></td></tr></table></figure>
<p>完成后生成一个java文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">public class Test &#123;                                   </div><div class="line">  public interfaceIface &#123;                   </div><div class="line">    public void ping(int length)throws org.apache.thrift.TException;             </div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h4 id="b-生成node-js文件："><a href="#b-生成node-js文件：" class="headerlink" title="b.生成node.js文件："></a>b.生成node.js文件：</h4><p>thrift原生支持<code>node.js</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">thrift  -gen js:node Test.thrift</div></pre></td></tr></table></figure></p>
<p>完成后生成<code>Test.js</code>和<code>Test_types.js</code>两个文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">var Thrift = require(&apos;thrift&apos;).Thrift;</div><div class="line">                                </div><div class="line">var ttypes = require(&apos;./Test_types&apos;);</div><div class="line">//HELPER FUNCTIONS AND STRUCTURES</div><div class="line">                                </div><div class="line">var Test_ping_args =function(args) &#123;</div><div class="line">  this.length = null;</div><div class="line">  if(args) &#123;</div><div class="line">    if(args.length !== undefined) &#123;</div><div class="line">      this.length = args.length;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>不过需要在node.js里加载thrift库：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm intall thrift</div></pre></td></tr></table></figure></p>
<p>准备工作到此结束！</p>
<h3 id="3-实战："><a href="#3-实战：" class="headerlink" title="3.实战："></a>3.实战：</h3><p>使用java当客户端,Node.js当服务端。<br>java客户端代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">package apache.thrift;</div><div class="line">              </div><div class="line">import org.apache.thrift.TException;</div><div class="line">import org.apache.thrift.protocol.TBinaryProtocol;</div><div class="line">import org.apache.thrift.protocol.TProtocol;</div><div class="line">import org.apache.thrift.transport.TFramedTransport;</div><div class="line">import org.apache.thrift.transport.TSocket;</div><div class="line">import org.apache.thrift.transport.TTransport;</div><div class="line">import org.apache.thrift.transport.TTransportException;</div><div class="line">              </div><div class="line"></div><div class="line">public class TestUserStorage &#123;</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        TTransport transport =new TFramedTransport(new TSocket(&quot;localhost&quot;,9799));</div><div class="line">        try&#123;</div><div class="line">            transport.open();</div><div class="line">        &#125;catch(TTransportException e1) &#123;</div><div class="line">            e1.printStackTrace();</div><div class="line">        &#125;</div><div class="line">        TProtocol protocol =new TBinaryProtocol(transport);</div><div class="line">              </div><div class="line">        UserStorage.Client client =new UserStorage.Client(protocol);</div><div class="line">        try&#123;</div><div class="line">            client.store(new UserProfile(1,&quot;&quot;,&quot;&quot;));</div><div class="line">            System.out.println(client.retrieve(1));</div><div class="line">        &#125;catch(TException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;     </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>注意两个地方：thrift在java中的实现很多，但是node-thrift模块目前只支持<code>TFramedTransport</code>，<code>TBinaryProtocol</code>，所以使用其他实现时server会出错。另外transport是需要先open进行连接的。</p>
<p>node服务端代码：</p>
<pre><code>var thrift = require(&apos;thrift&apos;);

var UserStorage = require(&apos;./gen-nodejs/UserStorage.js&apos;),
    ttypes = require(&apos;./gen-nodejs/user_types&apos;);

var users = {};

var server = thrift.createServer(UserStorage, {
  store:function(user, success) {
    console.log(&quot;server stored:&quot;, user.uid);
    users[user.uid] = user;
    success();
  },

  retrieve:function(uid, success) {
    console.log(&quot;server retrieved:&quot;, uid);
    success(users[uid]);
  },
});

server.listen(9799);
</code></pre><h4 id="输出结果："><a href="#输出结果：" class="headerlink" title="输出结果："></a>输出结果：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">client: UserProfile(uid:1, name:, blurb:)</div><div class="line">server: server stored: 1</div><div class="line">server retrieved: 1</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      facebook的thriff 基于rpc的远程调用实现
    
    </summary>
    
      <category term="RPC" scheme="http://jishusuishouji.github.io/categories/RPC/"/>
    
      <category term="thriff" scheme="http://jishusuishouji.github.io/categories/RPC/thriff/"/>
    
    
      <category term="thriff" scheme="http://jishusuishouji.github.io/tags/thriff/"/>
    
      <category term="rpc" scheme="http://jishusuishouji.github.io/tags/rpc/"/>
    
      <category term="facebook" scheme="http://jishusuishouji.github.io/tags/facebook/"/>
    
  </entry>
  
  <entry>
    <title>hexo安装部署</title>
    <link href="http://jishusuishouji.github.io/2017/04/03/hexo/hexo%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://jishusuishouji.github.io/2017/04/03/hexo/hexo安装部署/</id>
    <published>2017-04-03T02:39:14.000Z</published>
    <updated>2017-04-03T04:00:31.737Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Hexo安装"><a href="#Hexo安装" class="headerlink" title="Hexo安装"></a>Hexo安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install hexo -g  #-g表示全局安装, npm默认为当前项目安装</div></pre></td></tr></table></figure>
<a id="more"></a>
<h2 id="Hexo博客的初始化"><a href="#Hexo博客的初始化" class="headerlink" title="Hexo博客的初始化"></a>Hexo博客的初始化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">cd ~/git</div><div class="line">hexo init hexo  #执行init命令初始化到你指定的hexo目录</div><div class="line">cd hexo</div><div class="line">npm install    #install before start blogging</div><div class="line">hexo generate       #自动根据当前目录下文件,生成静态网页</div><div class="line">hexo server         #运行本地服务</div></pre></td></tr></table></figure>
<p>浏览器输入<code>http://localhost:4000</code>就可以看到效果。</p>
<h2 id="Hexo博客目录结构"><a href="#Hexo博客目录结构" class="headerlink" title="Hexo博客目录结构"></a>Hexo博客目录结构</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">.</div><div class="line">├── .deploy       #需要部署的文件</div><div class="line">├── node_modules  #Hexo插件</div><div class="line">├── public        #生成的静态网页文件</div><div class="line">├── scaffolds     #模板</div><div class="line">├── source        #博客正文和其他源文件, 404 favicon CNAME 等都应该放在这里</div><div class="line">|   ├── _drafts   #草稿</div><div class="line">|   └── _posts    #文章</div><div class="line">├── themes        #主题</div><div class="line">├── _config.yml   #全局配置文件</div><div class="line">└── package.json</div></pre></td></tr></table></figure>
<h2 id="安装git插件"><a href="#安装git插件" class="headerlink" title="安装git插件"></a>安装git插件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install hexo-deployer-git --save</div></pre></td></tr></table></figure>
<h2 id="自动生成分类和标签的index-html"><a href="#自动生成分类和标签的index-html" class="headerlink" title="自动生成分类和标签的index.html"></a>自动生成分类和标签的<code>index.html</code></h2><h3 id="分类页"><a href="#分类页" class="headerlink" title="分类页"></a>分类页</h3><ul>
<li>go to your hexo folder</li>
<li><code>hexo new page categories</code></li>
<li>in the <code>source\categories\index.md</code>, add <code>type: &quot;tags&quot;</code></li>
<li>if you don’t want to have comments on that page, also add <code>comments: false</code></li>
</ul>
<h3 id="标签页"><a href="#标签页" class="headerlink" title="标签页"></a>标签页</h3><ul>
<li>go to your hexo folder</li>
<li><code>hexo new page tags</code></li>
<li>in the <code>source\tags\index.md</code>, add <code>type: &quot;tags&quot;</code></li>
<li>if you don’t want to have comments on that page, also add <code>comments: false</code></li>
</ul>
]]></content>
    
    <summary type="html">
    
      hexo安装部署
    
    </summary>
    
      <category term="hexo" scheme="http://jishusuishouji.github.io/categories/hexo/"/>
    
    
      <category term="hexo" scheme="http://jishusuishouji.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>Redis Cluster实现原理</title>
    <link href="http://jishusuishouji.github.io/2017/04/03/redis/Redis_Cluster%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
    <id>http://jishusuishouji.github.io/2017/04/03/redis/Redis_Cluster实现原理/</id>
    <published>2017-04-03T00:56:20.000Z</published>
    <updated>2017-04-05T03:07:43.744Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Redis-Cluster主要特性和设计"><a href="#一、Redis-Cluster主要特性和设计" class="headerlink" title="一、Redis Cluster主要特性和设计"></a>一、Redis Cluster主要特性和设计</h2><h3 id="集群目标"><a href="#集群目标" class="headerlink" title="集群目标"></a>集群目标</h3><p>1）高性能和线性扩展，最大可以支撑到1000个节点；<br>Cluster架构中无Proxy层，Master与slave之间使用异步replication，且不存在操作的merge。（即操作不能跨多个nodes，不存在merge层）</p>
<p>2）一定程度上保证writes的安全性，需要客户端容忍一定程度的数据丢失;<br>集群将会尽可能（best-effort）保存客户端write操作的数据；<br>通常在<code>failover</code>期间，会有短暂时间内的数据丢失（因为异步replication引起）；<br>当客户端与少数派的节点处于网络分区时（network partition），丢失数据的可能性会更高。（因为节点有效性检测、<code>failover</code>需要更长的时间）</p>
<p>3）可用性：只要集群中大多数<code>master</code>可达、且失效的<code>master</code>至少有一个<code>slave</code>可达时，集群都可以继续提供服务；<br>同时“<code>replicas migration</code>”可以将那些拥有多个<code>slaves</code>的<code>master</code>的某个<code>slave</code>，迁移到没有<code>slave</code>的<code>master</code>下，即将整个集群相对<code>slaves</code>的分布更加平衡，尽力确保每个<code>master</code>都有一定数量的<code>slave</code>备份。</p>
<p>（Redis Cluster集群由多个shard组成，每个shard可以由一个master和多个slaves构成，数据根据hash slots配额分布在多个<code>shard</code>节点上，节点之间建立双向TCP链接用于有效性检测、<code>Failover</code>等，Client直接与<code>shard</code>节点进行通讯；<br>Cluster集群没有Proxy层，也没有中央式的Master用于协调集群状态或者state存储；<br>集群暂不提供动态reblance(再平衡)策略）</p>
<p>备注：下文中提到的query、查询等语义，泛指redis的读写操作。</p>
<h3 id="Mutli-key操作"><a href="#Mutli-key操作" class="headerlink" title="Mutli-key操作"></a>Mutli-key操作</h3><p>Redis单实例支持的命令，Cluster也都支持，但是对于“multi-key”操作（即一次RPC调用中需要进行多个key的操作）比如<code>Set</code>类型的交集、并集等，则要求这些key必须属于同一个node。Cluster不能进行跨Nodes操作，也没有nodes提供merge层代理。</p>
<p>Cluster中实现了一个称为“hash tags”的概念，每个key都可以包含一个自定义的“<code>tags</code>”，那么在存储时将根据tags计算此key应该分布在哪个nodes上（而不是使用key计算，但是存储层面仍然是key）；此特性，可以强制某些keys被保存在同一个节点上，以便于进行“multikey”操作，比如“<code>foo</code>”和“<code>{foo}.student</code>”将会被保存在同一个node上。不过在人工对slots进行resharding期间，multikey操作可能不可用。</p>
<p>我们在Redis单例中，偶尔会用到“SELECT”指令，即可以将key保存在特定的database中（默认database索引号为0）；但是在Cluster环境下，将不支持<code>SELECT</code>命令，所有的key都将保存在默认的database中。</p>
<h3 id="客户端与Server角色"><a href="#客户端与Server角色" class="headerlink" title="客户端与Server角色"></a>客户端与Server角色</h3><p>集群中nodes负责存储数据，保持集群的状态，包括keys与nodes的对应关系（内部其实为slots与nodes对应关系）。nodes也能够自动发现其他的nodes，检测失效的节点，当某个master失效时还应该能将合适的slave提升为master。</p>
<p>为了达成这些行为，集群中的每个节点都通过TCP与其他所有nodes建立连接，它们之间的通信协议和方式称为“Redis Cluster Bus”。Nodes之间使用gossip协议向其他nodes传播集群信息，以达到自动发现的特性，通过发送ping来确认其他nodes工作是否正常，也会在合适的时机发送集群的信息。当然在Failover时（包括人为failover）也会使用Bus来传播消息。<br>（gossip：最终一致性，分布式服务数据同步算法，node首先需要知道（可以读取配置）集群中至少一个seed node，此node向seed发送ping请求，此时seed节点pong返回自己已知的所有nodes列表，然后node解析nodes列表并与它们都建立tcp连接，同时也会向每个nodes发送ping，并从它们的pong结果中merge出全局nodes列表，并逐步与所有的nodes建立连接…….数据传输的方式也是类似，网络拓扑结构为full mesh）</p>
<p>因为Node并不提供Proxy机制，当Client将请求发给错误的nodes时（此node上不存在此key所属的slot），node将会反馈“MOVED”或者“ASK”错误信息，以便Client重新定向到合适的node。理论上，Client可以将请求发送给任意一个nodes，然后根据再根据错误信息转发给合适的node，客户端可以不用保存集群的状态信息，当然这种情况下性能比较低效，因为Client可能需要2次TCP调用才能获取key的结果，通常客户端会缓存集群中nodes与slots的映射关系，并在遇到“Redirected”错误反馈时，才会更新本地的缓存。</p>
<h3 id="安全写入（write-safety）"><a href="#安全写入（write-safety）" class="headerlink" title="安全写入（write safety）"></a>安全写入（write safety）</h3><p>在Master-slaves之间使用异步replication机制，在failover之后，新的Master将会最终替代其他的replicas（即slave）。在出现网络分区时（network partition），总会有一个窗口期（node timeout）可能会导致数据丢失；不过，Client与多数派的Master、少数派Master处于一个分区（网络分区，因为网络阻断问题，导致Clients与Nodes被隔离成2部分）时，这两种情况下影响并不相同。</p>
<p>1）write提交到master，master执行完毕后向Client反馈“OK”，不过此时可能数据还没有传播给slaves（异步replication）；如果此时master不可达的时间超过阀值（node timeout，参见配置参数），那么将触发slave被选举为新的Master（即Failover），这意味着那些没有replication到slaves的writes将永远丢失了！<br>2）还有一种情况导致数据丢失：<br>A）因为网络分区，此时master不可达，且Master与Client处于一个分区，且是少数派分区。<br>B）Failover机制，将其中一个slave提升为新Master。<br>C）此后网络分区消除，旧的Master再次可达，此时它将被切换成slave。<br>D）那么在网络分区期间，处于少数派分区的Client仍然将write提交到旧的Master，因为它们觉得Master仍然有效；当旧的Master再次加入集群，切换成slave之后，这些数据将永远丢失。</p>
<p>在第二种情况下，如果Master无法与其他大多数Masters通讯的时间超过阀值后，此Master也将不再接收Writes，自动切换为readonly状态。当网络分区消除后，仍然会有一小段时间，客户端的write请求被拒绝，因为此时旧的Master需要更新本地的集群状态、与其他节点建立连接、角色切换为slave等等，同时Client端的路由信息也需要更新。<br>只有当此master被大多数其他master不可达的时间达到阀值时，才会触发Failover，这个时间称为<code>NODE_TIMEOUT</code>，可以通过配置设定。所以当网络分区在此时间被消除的话，writes不会有任何丢失。反之，如果网络分区持续时间超过此值，处于“小分区”（minority）端的Master将会切换为<code>readonly</code>状态，拒绝客户端继续提交writes请求，那么“大分区”端将会进行<code>failover</code>，这意味着<code>NODE_TIMEOUT</code>期间发生在“小分区”端的writes操作将丢失（因为新的Master上没有同步到那些数据）。 </p>
<h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h3><p>处于“小分区”的集群节点是不可用的；“大分区”端必须持有大多数Masters，同时每个不可达的Master至少有一个slave也在“大分区”端，当<code>NODE_TIMEOUT</code>时，触发<code>failover</code>，此后集群才是可用的。Redis Cluster在小部分nodes失效后仍然可以恢复有效性，如果application希望大面积节点失效仍然有效，那么Cluster不适合这种情况。</p>
<p>比如集群有N个Master，且每个Master都有一个slave，那么集群的有效性只能容忍一个节点（master）被分区隔离（即一个master处于小分区端，其他处于大分区端），当第二个节点被分区隔离之前仍保持可用性的概率为1 - (1/(N <em> 2 - 1))（解释：当第一个节点失效后，剩余N </em> 2 -1个节点，此时没有slave的Master失效的概率为1/(N <em> 2 -1)）。比如有5个Master，每个Master有一个slave，当2个nodes被隔离出去（或者失效）后，集群可用性的概率只有1/(5 </em> 2 - 1) = 11.11%。<br>幸好Redis Cluster提供了“replicas migration”机制，在实际应用方面，可以有效的提高集群的可用性，当每次failover发生后，集群都会重新配置、平衡slaves的分布，以更好的抵御下一次失效情况的发生。</p>
<h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p>Redis Cluster并没有提供Proxy层，而是告知客户端将key的请求转发给合适的nodes。Client保存集群中nodes与keys的映射关系（slots），并保持此数据的更新，所以通常Client总能够将请求直接发送到正确的nodes上。因为采用异步replication，所以master不会等待slaves也保存成功后才向客户端反馈结果，除非显式的指定了<code>WAIT</code>指令。multi-key指令仅限于单个节点内，除了resharding操作外，节点的数据不会在节点间迁移。每个操作只会在特定的一个节点上执行，所以集群的性能为master节点的线性扩展。同时，Clients与每个nodes保持链接，所以请求的延迟等同于单个节点，即请求的延迟并不会因为Cluster的规模增大而受到影响。高性能和扩展性，同时保持合理的数据安全性，是Redis Cluster的设计目标。</p>
<p>Redis Cluster没有Proxy层，Client请求的数据也无法在nodes间merge；因为Redis核心就是K-V数据存储，没有scan类型（<code>sort</code>，<code>limit</code>，<code>group by</code>）的操作，因此merge操作并不被Redis Cluster所接受，而且这种特性会极大增加了Cluster的设计复杂度。</p>
<h2 id="二、Cluster主要组件"><a href="#二、Cluster主要组件" class="headerlink" title="二、Cluster主要组件"></a>二、Cluster主要组件</h2><h3 id="keys分布模型"><a href="#keys分布模型" class="headerlink" title="keys分布模型"></a>keys分布模型</h3><p>集群将key分成16384个slots（hash 槽），slot是数据映射的单位，言外之意，Redis Cluster最多支持16384个nodes（每个nodes持有一个slot）。集群中的每个master持有16384个slots中的一部分，处于“stable”状态时，集群中没有任何slots在节点间迁移，即任意一个hash slot只会被单个node所服务（master，当然可以有多个slave用于replicas，slave也可以用来扩展read请求）。keys与slot的映射关系，是按照如下算法计算的：<code>HASH_SLOT = CRC16(key) mod 16384</code>。其中<code>CRC16</code>是一种冗余码校验和，可以将字符串转换成16位的数字。</p>
<h3 id="hash-tags"><a href="#hash-tags" class="headerlink" title="hash tags"></a>hash tags</h3><p>在计算hash slots时有一个意外的情况，用于支持“hash tags”；hash tags用于确保多个keys能够被分配在同一个hash slot中，用于支持multi-key操作。hash tags的实现比较简单，key中“<code>{}</code>”之间的字符串就是当前key的hash tags，如果存在多个“<code>{}</code>”，首个符合规则的字符串作为<code>hash tags</code>，如果“<code>{}</code>”存在多级嵌套，那么最内层首个完整的字符串作为<code>hash tags</code>，比如“<code>{foo}.student</code>”，那么“<code>foo</code>”是hash tags。如果key中存在合法的hash tags，那么在计算hash slots时，将使用hash tags，而不再使用原始的key。即“<code>foo</code>”与“<code>{foo}.student</code>”将得到相同的slot值，不过“<code>{foo}.student</code>”仍作为key来保存数据，即redis中数据的key仍为“<code>{foo}.student</code>”。</p>
<h3 id="集群节点的属性"><a href="#集群节点的属性" class="headerlink" title="集群节点的属性"></a>集群节点的属性</h3><p>集群中每个节点都有唯一的名字，称之为node ID，一个160位随机数字的16进制表示，在每个节点首次启动时创建。每个节点都将各自的ID保存在实例的配置文件中，此后将一直使用此ID，或者说只要配置文件不被删除，或者没有使用“CLUSTER RESET”指令重置集群，那么此ID将永不会修改。</p>
<p>集群通过node ID来标识节点，而不是使用IP + port，因为node可以修改它的IP和port，不过如果ID不变，我们仍然认定它是集群中合法一员。集群可以在cluster Bus中通过gossip协议来探测IP、port的变更，并重新配置。</p>
<p>node ID并不是与node相关的唯一信息，不过是唯一一个全局一致的。每个node还持有如下相关的信息，有些信息是关系集群配置的，其他的信息比如最后ping时间等。每个node也保存其他节点的IP、Port、flags（比如flags表示它是master还是slave）、最近ping的时间、最近pong接收时间、当前配置的epoch、链接的状态，最重要的是还包含此node上持有的hash slots。这些信息均可通过“CLUSTER NODES”指令开查看。</p>
<h3 id="Cluster-Bus"><a href="#Cluster-Bus" class="headerlink" title="Cluster Bus"></a>Cluster Bus</h3><p>每个Node都有一个特定的TCP端口，用来接收其他nodes的链接；此端口号为面向Client的端口号+10000，比如客户端端口号为<code>6379</code>，那么此node的BUS端口号为<code>16379</code>，客户端端口号可以在配置文件中声明。由此可见，nodes之间的交互通讯是通过Bus端口进行，使用了特定的二进制协议，此端口通常应该只对nodes可用，可以借助防火墙技术来屏蔽其他非法访问。</p>
<h3 id="集群拓扑"><a href="#集群拓扑" class="headerlink" title="集群拓扑"></a>集群拓扑</h3><p>Redis Cluster中每个node都与其他nodes的Bus端口建立TCP链接（full mesh，全网）。比如在由N个节点组成的集群中，每个node有N-1个向外发出的TCP链接，以及N-1个其他nodes发过来的TCP链接；这些TCP链接总是keepalive，不是按需创建的。如果ping发出之后，node在足够长的时间内仍然没有pong响应，那么此node将会被标记为“不可达”，那么与此node的链接将会被刷新或者重建。Nodes之间通过gossip协议和配置更新的机制，来避免每次都交互大量的消息，最终确保在nodes之间的信息传送量是可控的。</p>
<h3 id="节点间handshake"><a href="#节点间handshake" class="headerlink" title="节点间handshake"></a>节点间handshake</h3><p>Nodes通过Bus端口发送ping、pong；如果一个节点不属于集群，那么它的消息将会被其他nodes全部丢弃。一个节点被认为是集群成员的方式有2种：<br>1）如果此node在“Cluster meet”指令中引入，此命令的主要意义就是将指定node加入集群。那么对于当前节点，将认为指定的node为“可信任的”。（此后将会通过gossip协议传播给其他nodes）<br>2）当其他nodes通过gossip引入了新的nodes，这些nodes也是被认为是“可信任的”。</p>
<p>只要我们将一个节点加入集群，最终此节点将会与其他节点建立链接，即cluster可以通过信息交换来自动发现新的节点，链接拓扑仍然是full mesh。</p>
<h2 id="三、重定向与resharding"><a href="#三、重定向与resharding" class="headerlink" title="三、重定向与resharding"></a>三、重定向与resharding</h2><h3 id="MOVED重定向"><a href="#MOVED重定向" class="headerlink" title="MOVED重定向"></a>MOVED重定向</h3><p>理论上，Client可以将请求随意发给任何一个node，包括slaves，此node解析query，如果可以执行（比如语法正确，multiple keys都应该在一个node slots上），它会查看key应该属于哪个slot、以及此slot所在的nodes，如果当前node持有此slot，那么query直接执行即可，否则当前node将会向Client反馈“MOVED”错误：</p>
<pre><code>GET X  
-MOVED 3999 127.0.0.1:6381  
</code></pre><p>错误信息中包括此<code>key</code>对应的slot（3999），以及此slot所在node的ip和port，对于Client 而言，收到<code>MOVED</code>信息后，它需要将请求重新发给指定的node。不过，当node向Client返回<code>MOVED</code>之前，集群的配置也在变更（节点调整、resharding、failover等，可能会导致slot的位置发生变更），此时Client可能需要等待更长的时间，不过最终node会反馈<code>MOVED</code>信息，且信息中包含指定的新的node位置。虽然Cluster使用ID标识node，但是在<code>MOVED</code>信息中尽可能地暴露给客户端便于使用的ip + port。</p>
<p>当Client遇到“<code>MOVED</code>”错误时，将会使用“<code>CLUSTER NODES</code>”或者“<code>CLUSTER SLOTS</code>”指令获取集群的最新信息，主要是nodes与slots的映射关系；因为遇到<code>MOVED</code>，一般也不会仅仅一个slot发生的变更，通常是一个或者多个节点的slots发生了变化，所以进行一次全局刷新是有必要的；我们还应该明白，Client将会把集群的这些信息在被缓存，以便提高query的性能。</p>
<p>还有一个错误信息：“<code>ASK</code>”，它与“<code>MOVED</code>”都属于重定向错误，客户端的处理机制基本相同，只是<code>ASK</code>不会触发Client刷新本地的集群信息。</p>
<h3 id="集群运行时重新配置（live-reconfiguration）"><a href="#集群运行时重新配置（live-reconfiguration）" class="headerlink" title="集群运行时重新配置（live reconfiguration）"></a>集群运行时重新配置（live reconfiguration）</h3><p>我们可以在Cluster运行时增加、删除nodes，这两种操作都会导致：slots在nodes的迁移；当然这种机制也可用来集群数据的rebalance等等。</p>
<p>1）集群中新增一个node，我们需要将其他nodes上的部分slots迁移到此新nodes上，以实现数据负载的均衡分配。<br>2）集群中移除一个node，那么在移除节点之前，必须将此节点上（如果此节点没有任何<code>slaves</code>）的slots迁移到其他nodes。<br>3）如果数据负载不均衡，比如某些slots数据集较大、负载较大时，我们需要它们迁移到负载较小的nodes上（即手动resharding），以实现集群的负载平衡。</p>
<p>Cluster支持slots在nodes间移动；从实际的角度来看，一个slot只是一序列keys的逻辑标识，所以Cluster中slot的迁移，其实就是一序列keys的迁移，不过resharding操作只能以slot为单位（而不能仅仅迁移某些keys）。Redis提供了如下几个操作：</p>
<p>1）<code>CLUSTER ADDSLOTS [slot]</code> ….<br>2）<code>CLUSTER DELSLOTS [slot]</code> …<br>3）<code>CLUSTER SETSLOT [slot] NODE [node]</code><br>4）<code>CLUSTER SETSLOT [slot] MIGRATING [destination-node]</code><br>5）<code>CLUSTER SETSLOT [slot] IMPORTING [source-node]</code></p>
<p>前两个指令：<code>ADDSLOTS</code>和<code>DELSLOTS</code>，用于向当前node分配或者移除slots，指令可以接受多个slot值。分配slots的意思是告知指定的master（即此指令需要在某个master节点执行）此后由它接管相应slots的服务；slots分配后，这些信息将会通过gossip发给集群的其他nodes。<br><code>ADDSLOTS</code>指令通常在创建一个新的Cluster时使用，一个新的Cluster有多个空的Masters构成，此后管理员需要手动为每个master分配slots，并将16384个slots分配完毕，集群才能正常服务。简而言之，<code>ADDSLOTS</code>只能操作那些尚未分配的（即不被任何nodes持有）slots，我们通常在创建新的集群或者修复一个broken的集群（集群中某些slots因为nodes的永久失效而丢失）时使用。为了避免出错，Redis Cluster提供了一个redis-trib辅助工具，方便我们做这些事情。</p>
<p><code>DELSLOTS</code>就是将指定的slots删除，前提是这些slots必须在当前node上，被删除的slots处于“未分配”状态（当然其对应的keys数据也被clear），即尚未被任何nodes覆盖，这种情况可能导致集群处于不可用状态，此指令通常用于debug，在实际环境中很少使用。那些被删除的slots，可以通过<code>ADDSLOTS</code>重新分配。</p>
<p><code>SETSLOT</code>是个很重要的指令，对集群slots进行reshard的最重要手段；它用来将单个slot在两个nodes间迁移。根据slot的操作方式，它有两种状态“<code>MIGRATING</code>”、“<code>IMPORTING</code>”（或者说迁移的方式）<br>1）<code>MIGRATING</code>：将slot的状态设置为“<code>MIGRATING</code>”，并迁移到destination-node上，需要注意当前node必须是slot的持有者。在迁移期间，Client的查询操作仍在当前node上执行，如果key不存在，则会向Client反馈“-<code>ASK</code>”重定向信息，此后Client将会把请求重新提交给迁移的目标node。<br>2）<code>IMPORTING</code>：将slot的状态设置为“IMPORTING”，并将其从source-node迁移到当前node上，前提是source-node必须是slot的持有者。Client交互机制同上。</p>
<p>假如我们有两个节点A、B，其中slot 8在A上，我们希望将8从A迁移到B，可以使用如下方式：<br>1）在B上：<code>CLUSTER SETSLOT 8 IMPORTING A</code><br>2）在A上：<code>CLUSTER SETSLOT 8 MIGRATING B</code><br>在迁移期间，集群中其他的nodes的集群信息不会改变，即slot 8仍对应A，即此期间，Client查询仍在A上：<br>1）如果key在A上存在，则由A执行。<br>2）否则，将向客户端返回ASK，客户端将请求重定向到B。<br>这种方式下，新key的创建就不会在A上执行，而是在B上执行，这也就是ASK重定向的原因（迁移之前的keys在A，迁移期间created的keys在B上）；当上述<code>SETSLOT</code>执行完毕后，slot的状态也会被自动清除，同时将slot迁移信息传播给其他nodes，至此集群中slot的映射关系将会变更，此后slot 8的数据请求将会直接提交到B上。</p>
<h3 id="ASK重定向"><a href="#ASK重定向" class="headerlink" title="ASK重定向"></a>ASK重定向</h3><p>在上文中，我们已经介绍了<code>MOVED</code>重定向，<code>ASK</code>与其非常相似。在resharding期间，为什么不能用<code>MOVED</code>？MOVED意思为hash slots已经永久被另一个node接管、接下来的相应的查询应该与它交互，<code>ASK</code>的意思是当前query暂时与指定的node交互；在迁移期间，slot 8的keys有可能仍在A上，所以Client的请求仍然需要首先经由A，对于A上不存在的，我们才需要到B上进行尝试。迁移期间，Redis Cluster并没有粗暴的将slot 8的请求全部阻塞、直到迁移结束，这种方式尽管不再需要<code>ASK</code>，但是会影响集群的可用性。<br>1）当Client接收到<code>ASK</code>重定向，它仅仅将当前query重定向到指定的node；此后的请求仍然交付给旧的节点。<br>2）客户端并不会更新本地的slots映射，仍然保持slot 8与A的映射；直到集群迁移完毕，且遇到<code>MOVED</code>重定向。</p>
<p>一旦slot 8迁移完毕之后（集群的映射信息也已更新），如果Client再次在A上访问slot 8时，将会得到<code>MOVED</code>重定向信息，此后客户端也更新本地的集群映射信息。</p>
<h3 id="客户端首次链接以及重定向处理"><a href="#客户端首次链接以及重定向处理" class="headerlink" title="客户端首次链接以及重定向处理"></a>客户端首次链接以及重定向处理</h3><p>可能有些Cluster客户端的实现，不会在内存中保存slots映射关系（即nodes与slots的关系），每次请求都从声明的、已知的nodes中，随机访问一个node，并根据重定向（<code>MOVED</code>）信息来寻找合适的node，这种访问模式，通常是非常低效的。<br>当然，Client应该尽可能的将slots配置信息缓存在本地，不过配置信息也不需要绝对的实时更新，因为在请求时偶尔出现“重定向”，Client也能兼容此次请求的正确转发，此时再更新slots配置。（所以Client通常不需要间歇性的检测Cluster中配置信息是否已经更新）客户端通常是全量更新slots配置：<br>1）首次链接到集群的某个节点<br>2）当遇到<code>MOVED</code>重定向消息时<br>遇到<code>MOVED</code>时，客户端仅仅更新特定的slot是不够的，因为集群中的reshard通常会影响到多个slots。客户端通过向任意一个nodes发送“<code>CLUSTER NODES</code>”或者“<code>CLUSTER SLOTS</code>”指令均可以获得当前集群最新的slots映射信息；“<code>CLUSTER SLOTS</code>”指令返回的信息更易于Client解析。如果集群处于broken状态，即某些slots尚未被任何nodes覆盖，指令返回的结果可能是不完整的。</p>
<h3 id="Multikeys操作"><a href="#Multikeys操作" class="headerlink" title="Multikeys操作"></a>Multikeys操作</h3><p>前文已经介绍，基于hash tags机制，我们可以在集群中使用<code>Multikeys</code>操作。不过，在resharding期间，Multikeys操作将可能不可用，比如这些keys不存在于同一个slot（迁移会导致keys被分离）；比如<code>Multikeys</code>逻辑上属于同一个slot，但是因为resharding，它们可能暂时不处于同一个nodes，有些可能在迁移的目标节点上（比如<code>Multikeys</code>包含a、b、c三个keys，逻辑上它们都属于slot 8，但是其中c在迁移期间创建，它被存储在节点B上，a、b仍然在节点A），此时将会向客户端返回“<code>-TRYAGAIN</code>”错误，那么客户端此后将需要重试一次，或者直接返回错误（如果迁移操作被中断），无论如何最终<code>Multikeys</code>的访问逻辑是一致的，slots的状态也是最终确定的。</p>
<h3 id="slaves扩展reads请求"><a href="#slaves扩展reads请求" class="headerlink" title="slaves扩展reads请求"></a>slaves扩展reads请求</h3><p>通常情况下，read、write请求都将有持有slots的master节点处理；因为redis的slaves可以支持read操作（前提是application能够容忍stale数据），所以客户端可以使用“<code>READONLY</code>”指令来扩展read请求。<br>“<code>READONLY</code>”表明其可以访问集群的slaves节点，能够容忍stale数据，而且此次链接不会执行writes操作。当链接设定为<code>readonly</code>模式后，Cluster只有当keys不被slave的master节点持有时才会发送重定向消息（即Client的read请求总是发给slave，只有当此slave的master不持有slots时才会重定向，很好理解）：<br>1）此slave的master节点不持有相应的slots<br>2）集群重新配置，比如reshard或者slave迁移到了其他master上，此slave本身也不持有此slot。</p>
<p>此时Client更新本地的slot配置信息，同上文所述。（目前很多Client实现均基于连接池，所以不能非常便捷的设置<code>READLONLY</code>选项，非常遗憾）</p>
<h2 id="四、容错（Fault-Tolerance）"><a href="#四、容错（Fault-Tolerance）" class="headerlink" title="四、容错（Fault Tolerance）"></a>四、容错（Fault Tolerance）</h2><h3 id="心跳与gossip消息"><a href="#心跳与gossip消息" class="headerlink" title="心跳与gossip消息"></a>心跳与gossip消息</h3><p>集群中的nodes持续的交换ping、pong数据，这两种数据包的结构一样，同样都能携带集群的配置信息，唯一不同的就是<code>message</code>中的<code>type</code>字段。<br>通常，一个node发送ping消息，那么接收者将会反馈pong消息；不过有时候并非如此，或许接收者将pong信息发给其他的nodes，而不是直接反馈给发送者，比如当集群中添加新的node时。<br>通常一个node每秒都会随机向几个nodes发送ping，所以无论集群规模多大，每个nodes发送的ping数据包的总量是恒定的。每个node都确保尽可能的向那些在半个NODE_TIMEOUT时间内，尚未发送过ping或者接收到它们的pong消息的nodes发送ping。在NODE_TIMEOUT逾期之前，nodes也会尝试与那些通讯异常的nodes重新建立TCP链接，确保不能仅仅因为当前链接异常而认为它们就是不可达的。</p>
<p>当NODE_TIMEOUT值较小、集群中nodes规模较大时，那么全局交换的信息量也会非常庞大，因为每个node都尽力在半个NODE_TIMEOUT时间内，向其他nodes发送ping。比如有100个nodes，<code>NODE_TIMEOUT</code>为60秒，那么每个node在30秒内向其他99各nodes发送ping，平均每秒3.3个消息，那么整个集群全局就是每秒330个消息。这些消息量，并不会对集群的带宽带来不良问题。</p>
<h3 id="心跳数据包的内容"><a href="#心跳数据包的内容" class="headerlink" title="心跳数据包的内容"></a>心跳数据包的内容</h3><p>1）node ID<br>2）currentEpoch和configEpoch<br>3）node flags：比如表示此node是maste、slave等<br>4）hash slots：发送者持有的slots<br>5）如果发送者是slave，那么其master的ID<br>6）其他..</p>
<p>ping和pong数据包中也包含gossip部分，这部分信息包含sender持有的集群视图，不过它只包含sender已知的随机几个nodes，nodes的数量根据集群规模的大小按比例计算。gossip部分包含了nodes的ID、ip+port、flags，那么接收者将根据sender的视图，来判定节点的状态，这对故障检测、节点自动发现非常有用。</p>
<h3 id="失效检测"><a href="#失效检测" class="headerlink" title="失效检测"></a>失效检测</h3><p>集群失效检测就是，当某个master或者slave不能被大多数nodes可达时，用于故障迁移并将合适的<code>slave</code>提升为master。当slave提升未能有效实施时，集群将处于error状态且停止接收Client端查询。<br>如上所述，每个node有持有其已知nodes的列表包括flags，有2个flag状态：PFAIL和FAIL；PFAIL表示“可能失效”，是一种尚未完全确认的失效状态（即某个节点或者少数masters认为其不可达）。FAIL表示此node已经被集群大多数masters判定为失效（大多数master已认定为不可达，且不可达时间已达到设定值，需要failover）。</p>
<h3 id="PFAIL："><a href="#PFAIL：" class="headerlink" title="PFAIL："></a>PFAIL：</h3><p>一个被标记为PFAIL的节点，表示此node不可达的时间超过NODE_TIMEOUT，master和slave有可以被标记为PFAIL。所谓不可达，就是当“active ping”（发送ping且能受到pong）尚未成功的时间超过<code>NODE_TIMEOUT</code>，因此我们设定的NODE_TIMEOUT的值应该比网络交互往返的时间延迟要大一些（通常要大的多，以至于交互往返时间可以忽略）。为了避免误判，当一个node在半个NODE_TIMEOUT时间内仍未能pong，那么当前node将会尽力尝试重新建立连接进行重试，以排除pong未能接收是因为当前链接故障的问题。</p>
<h3 id="FAIL："><a href="#FAIL：" class="headerlink" title="FAIL："></a>FAIL：</h3><p>PFAIL只是当前node有关于其他nodes的本地视图，可能每个node对其他nodes的本地视图都不一样，所以PFAIL还不足以触发Failover。处于PFAIL状态下的node可以被提升到FAIL状态。如上所述，每个node在向其他nodes发送gossip消息时，都会包含本地视图中几个随机nodes的状态信息；每个node最终都会从其他nodes发送的消息中获得一组nodes的flags。因此，每个node都可以通过这种机制来通知其他nodes，它检测到的故障情况。</p>
<h3 id="PFAIL被上升为FAIL的集中情况："><a href="#PFAIL被上升为FAIL的集中情况：" class="headerlink" title="PFAIL被上升为FAIL的集中情况："></a>PFAIL被上升为FAIL的集中情况：</h3><p>1）比如A节点，认为B为PFAIL<br>2）那么A通过gossip信息，收集集群中大多数masters关于B的状态视图。<br>3）多数master都认为B为PFAIL，或者PFAIL情况持续时间为NODE_TIMEOUT * FAIL_REPORT_VALIDITY_MULT（此值当前为2）</p>
<p>如果上述条件成立，那么A将会：<br>1）将B节点设定为FAIL<br>2）将FAIL信息发送给其所有能到达的所有节点。</p>
<p>每个接收到FAIL消息的节点都会强制将此node标记为FAIL状态，不管此节点在本地视图中是否为PFAIL。FAIL状态是单向的，即PFAIL可以转换为FAIL，但是FAIL状态只能清除，不能回转为PFAIL：</p>
<p>1）当此node已经变的可达，且为slave，这种情况下FAIL状态将会被清除，因为没有发生failover。<br>2）此node已经可达，且是一个没有服务任何slots的master（空的master）；这种情况下，FAIL将会被清除，因为master没有持有slots，所以它并没有真正参与到集群中，需要等到重新配置以便它加入集群。<br>3）此node已经可达，且是master，且在较长时间内（N倍的NODE_TIMEOUT）没有检测到slave的提升，即没有slave发生failover（比如此master下没有slave），那么它只能重新加入集群且仍为master。</p>
<p>需要注意的是PFAIL-&gt;FAIL的转变，使用了“协议”（agreement）的形式：<br>1）nodes会间歇性的收集其他nodes的视图，即使大多数masters都“agree”，事实上这个状态，仅仅是我们从不同的nodes、不同的时间收集到的，我们无法确认（也不需要）在特定时刻大多数masters是否“agree”。我们丢弃较旧的故障报告，所以此故障（FAIL）是有大多数masters在一段时间内的信号。<br>2）虽然每个node在检测到FAIL情况时，都会通过FAIL消息发送给其他nodes，但是无法保证消息一定会到达所有的nodes，比如可能当前节点（发送消息的node）因为网络分区与其他部分nodes隔离了。</p>
<p>如果只有少数master认为某个node为FAIL，并不会触发相应的slave提升，即failover，因为可能是因为网络分区导致。FAIL标记只是用来触发slave 提升；在原理上，当master不可达时将会触发slave提升，不过当master仍然被大多数可达时，它会拒绝提供相应的确认。</p>
<h2 id="五、Failover相关的配置"><a href="#五、Failover相关的配置" class="headerlink" title="五、Failover相关的配置"></a>五、Failover相关的配置</h2><h3 id="集群currentEpoch"><a href="#集群currentEpoch" class="headerlink" title="集群currentEpoch"></a>集群currentEpoch</h3><p>Redis Cluster使用了类似于Raft算法“term”（任期）的概念，那么在redis Cluster中term称为epoch，用来给events增量版本号。当多个nodes提供了信息有冲突时，它可以作为node来知道哪个状态是最新的。currentEpoch为一个64位无签名数字。<br>在集群node创建时，master和slave都会将各自的currentEpoch设置为0，每次从其他node接收到数据包时，如果发现发送者的epoch值比自己的大，那么当前node将自己的currentEpoch设置为发送者的epoch。由此，最终所有的nodes都会认同集群中最大的epoch值；当集群的状态变更，或者node为了执行某个行为需求agreement时，都将需要epoch（传递或者比较）。</p>
<p>当前来说，只有在slave提升期间发生；currentEpoch为集群的逻辑时钟（logical clock），指使持有较大值的获胜。（currentEpoch，当前集群已达成认同的epoch值，通常所有的nodes应该一样）</p>
<h3 id="configEpoch"><a href="#configEpoch" class="headerlink" title="configEpoch"></a>configEpoch</h3><p>每个master总会在ping、pong数据包中携带自己的configEpoch以及它持有的slots列表。新创建的node，其configEpoch为0，slaves通过递增它们的configEpoch来替代失效的master，并尝试获得其他大多数master的授权（认同）。当slave被授权，一个新的configEpoch被生成，slave提升为master且使用此configEpoch。<br>接下来介绍configEpoch帮助解决冲突，当不同的nodes宣称有分歧的配置时。<br>slaves在ping、pong数据包中也会携带自己的configEpoch信息，不过这个epoch为它与master在最近一次数据交换时，master的configEpoch。<br>每当节点发现configEpoch值变更时，都会将新值写入nodes.conf文件，当然currentEpoch也也是如此。这两个变量在写入文件后会伴随磁盘的fsync，持久写入。严格来说，集群中所有的master都持有唯一的configEpoch值。同一组master-slaves持有相同的configEpoch。</p>
<h3 id="slave选举与提升"><a href="#slave选举与提升" class="headerlink" title="slave选举与提升"></a>slave选举与提升</h3><p>在slaves节点中进行选举，在其他masters的帮助下进行投票，选举出一个slave并提升为master。当master处于FAIL状态时，将会触发slave的选举。slaves都希望将自己提升为master，此master的所有slaves都可以开启选举，不过最终只有一个slave获胜。当如下情况满足时，slave将会开始选举：<br>1）当此slave的master处于FAIL状态<br>2）此master持有非零个slots<br>3）此slave的replication链接与master断开时间没有超过设定值，为了确保此被提升的slave的数据是新鲜的，这个时间用户可以配置。</p>
<p>为了选举，第一步，就是slave自增它的currentEpoch值，然后向其他masters请求投票（需求支持，votes）。slave通过向其他masters传播“FAILOVER_AUTH_REQUEST”数据包，然后最长等待2倍的NODE_TIMEOUT时间，来接收反馈。一旦一个master向此slave投票，将会响应“FAILOVER_AUTH_ACK”，此后在2 <em> NODE_TIMOUT时间内，它将不会向同一个master的slaves投票；虽然这对保证安全上没有必要，但是对避免多个slaves同时选举时有帮助的。slave将会丢弃那些epoch值小于自己的currentEpoch的AUTH_ACK反馈，即不会对上一次选举的投票计数（只对当前轮次的投票计数）。一旦此slave获取了大多数master的ACKs，它将在此次选举中获胜；否则如果大多数master不可达（在2 </em> NODE_TIMEOUT）或者投票额不足，那么它的选举将会被中断，那么其他的slave将会继续尝试。</p>
<h3 id="slave-rank（次序）"><a href="#slave-rank（次序）" class="headerlink" title="slave rank（次序）"></a>slave rank（次序）</h3><p>当master处于FAIL状态时，slave将会随机等待一段时间，然后才尝试选举，等待的时间：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">DELAY = 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000ms</div></pre></td></tr></table></figure></p>
<p>一定的延迟确保我们等待FAIL状态在集群中传播，否则slave立即尝试选举（不进行等待的话），不过此时其他masters或许尚未意识到FAIL状态，可能会拒绝投票。</p>
<p>延迟的时间是随机的，这用来“去同步”（desynchronize），避免slaves同时开始选举。SLAVE_RANK表示此slave已经从master复制数据的总量的rank。当master失效时，slaves之间交换消息以尽可能的构建rank，持有replication offset最新的rank为0，第二最新的为1，依次轮推。这种方式下，持有最新数据的slave将会首先发起选举（理论上）。当然rank顺序也不是严格执行的，如果一个持有较小rank的slave选举失败，其他slaves将会稍后继续。</p>
<p>一旦，slave选举成功，它将获取一个新的、唯一的、自增的configEpoch值，此值比集群中任何masters持有的都要大，它开始宣称自己是master，并通过ping、pong数据包传播，并提供自己的新的configEpoch以及持有的slots列表。为了加快其他nodes的重新配置，pong数据包将会在集群中广播。当前node不可达的那些节点，它们可以从其他节点的ping或者pong中获知信息（gossip），并重新配置。</p>
<p>其他节点也会检测到这个新的master和旧master持有相同的slots，且持有更高的configEpoch，此时也会更新自己的配置（epoch，以及master）；旧master的slaves不仅仅更新配置信息，也会重新配置并与新的master跟进（slave of）。</p>
<h3 id="Masters响应slave的投票请求"><a href="#Masters响应slave的投票请求" class="headerlink" title="Masters响应slave的投票请求"></a>Masters响应slave的投票请求</h3><p>当Master接收到slave的“FAILOVER_AUTH_REQUEST”请求后，开始投票，不过需要满足如下条件：<br>1）此master只会对指定的epoch投票一次，并且拒绝对旧的epoch投票：每个master都持有一个lastVoteEpoch，将会拒绝AUTH_REQUEST中currentEpoch比lastVoteEpoch小的请求。当master响应投票时，将会把lastVoteEpoch保存在磁盘中。<br>2）此slave的master处于FAIL状态时，master才会投票。<br>3）如果slave的currentEpoch比此master的currentEpoch小，那么AUTH_REQUEST将会被忽略。因为master只会响应那些与自己的currentEpoch相等的请求。如果同一个slave再此请求投票，持有已经增加的currentEpoch，它（slave）将保证旧的投票响应不能参与计票。</p>
<p>比如master的currentEpoch为5，lastVoteEpoch为1：<br>1）slave的currentEpoch为3<br>2）slave在选举开始时，使用epoch为4（先自增），因为小于master的epoch，所以投票响应被延缓。<br>3）slave在一段时间后将重新选举，使用epoch为5（4 + 1，再次自增），此时master上延缓的响应发给slave，接收后视为有效。</p>
<p>1）master在2 * NODE_TIMEOUT超时之前，不会对同一个master的slave再次投票。这并不是严格需要，因为也不太可能两个slave在相同的epoch下同时赢得选举。不过，它确保当一个slave选举成功后，它（slave）有一段缓冲时间来通知其他的slaves，避免另一个slave赢得了新的一轮的选择，避免不必要的二次failover。<br>2）master并不会尽力选举最合适的slave。当slave的master处于FAIL状态，此master在当前任期（term）内并不投票，只是批准主动投票者（即master不发起选举，只批准别人的投票）。最合适的slave应该在其他slaves之前，首先发起选举。<br>3）当master拒绝一个slave投票，并不会发出一个“否决”响应，而是简单的忽略。<br>4）slave发送的configEpoch是其master的，还包括其master持有的slots；master不会向持有相同slots、但configEpoch只较低的slave投票。</p>
<h3 id="Hash-Slots配置传播"><a href="#Hash-Slots配置传播" class="headerlink" title="Hash Slots配置传播"></a>Hash Slots配置传播</h3><p>Redis Cluster中重要的一部分就是传播集群中哪些节点上持有的哪些hash slots信息；无论是启动一个新的集群，还是当master失效其slave提升后更新配置，这对它们都至关重要。有2种方式用于hash slot配置的传播：<br>1）heartbeat 消息：发送者的ping、pong消息中，总是携带自己目前持有的slots信息，不管自己是master还是slave。<br>2）UPDATE 消息：因为每个心跳消息中会包含发送者的configEpoch和其持有的slots，如果接收者发现发送者的信息已经stale（比如发送者的configEpoch值小于持有相同slots的master的值），它会向发送者反馈新的配置信息（UPDATE），强制stale节点更新它。</p>
<p>当一个新的节点加入集群，其本地的hash slots映射表将初始为NULL，即每个hash slot都没有与任何节点绑定。<br>Rule 1：如果此node本地视图中一个hash slot尚未分配（设置为NULL），并且有一个已知的node声明持有它，那么此node将会修改本地hash slot的映射表，将此slot与那个node关联。slave的failover操作、reshard操作都会导致hash slots映射的变更，新的配置信息将会通过心跳在集群中传播。<br>Rule 2：如果此node的本地视图中一个hash slot已经分配，并且一个已知的node也声明持有它，且此node的configEpoch比当前slot关联的master的configEpoch值更大，那么此node将会把slot重新绑定到新的node上。根据此规则，最终集群中所有的nodes都赞同那个持有声明持有slot、且configEpoch最大值的nodes为slot的持有者。</p>
<h3 id="nodes如何重新加入集群"><a href="#nodes如何重新加入集群" class="headerlink" title="nodes如何重新加入集群"></a>nodes如何重新加入集群</h3><p>node A被告知slot 1、2现在由node B接管，假如这两个slots目前由A持有，且A只持有这两个slots，那么此后A将放弃这2个slots，成为空的节点；此后A将会被重新配置，成为其他新master的slave。这个规则可能有些复杂，A离群一段时间后重新加入集群，此时A发现此前自己持有的slots已经被其他多个nodes接管，比如slot 1被B接管，slot 2被C接管。<br>在重新配置时，最终此节点上的slots将会被清空，那个窃取自己最后一个slot的node，将成为它的新master。<br>节点重新加入集群，通常发生在failover之后，旧的master（也可以为slave）离群，然后重新加入集群。</p>
<h3 id="Replica迁移"><a href="#Replica迁移" class="headerlink" title="Replica迁移"></a>Replica迁移</h3><p>Redis Cluster实现了一个成为“Replica migration”的概念，用来提升集群的可用性。比如集群中每个master都有一个slave，当集群中有一个master或者slave失效时，而不是master与它的slave同时失效，集群仍然可以继续提供服务。<br>1）master A，有一个slave A1<br>2）master A失效，A1被提升为master<br>3）一段时间后，A1也失效了，那么此时集群中没有其他的slave可以接管服务，集群将不能继续服务。</p>
<p>如果masters与slaves之间的映射关系是固定的（fixed），提高集群抗灾能力的唯一方式，就是给每个master增加更多的slaves，不过这种方式开支很大，需要更多的redis实例。<br>解决这个问题的方案，我们可以将集群非对称，且在运行时可以动态调整master-slaves的布局（而不是固定master-slaves的映射），比如集群中有三个master A、B、C，它们对应的slave为A1、B1、C1、C2，即C节点有2个slaves。“Replica迁移”可以自动的重新配置slave，将其迁移到某个没有slave的master下。<br>1）A失效，A1被提升为master<br>2）此时A1没有任何slave，但是C仍然有2个slave，此时C2被迁移到A1下，成为A1的slave<br>3）此后某刻，A1失效，那么C2将被提升为master。集群可以继续提供服务。</p>
<h3 id="Replica迁移算法"><a href="#Replica迁移算法" class="headerlink" title="Replica迁移算法"></a>Replica迁移算法</h3><p>迁移算法并没有使用“agree”形式，而是使用一种算法来避免大规模迁移，这个算法确保最终每个master至少有一个slave即可。起初，我们先定义哪个slave是良好的：一个良好的slave不能处于FAIL状态。触发时机为，任何一个slave检测到某个master没有一个良好slave时。参与迁移的slave必须为，持有最多slaves的master的其中一个slave，且不处于FAIL状态，且持有最小的node ID。<br>比如有10个masters都持有一个slave，有2个masters各持有5个slaves，那么迁移将会发生在持有5个slaves的masters中，且node ID最小的slave node上。我们不再使用“agreement”，不过也有可能当集群的配置不够稳定时，有一种竞争情况的发生，即多个slaves都认为它们自己的ID最小；如果这种情况发生，结果就是可能多个slaves会迁移到同一个master下，不过这并没有什么害处，但是最坏的结果是导致原来的master迁出了所有的slaves，让自己变得单一。但是迁移算法（进程）会在迁移完毕之后重新判断，如果尚未平衡，那么将会重新迁移。<br>最终，每个master最少持有一个slave；这个算法由用户配置的“cluster-migration-barrier”，此配置参数表示一个master至少保留多少个slaves，其他多余的slaves可以被迁出。此值通常为1，如果设置为2，表示一个master持有的slaves个数大于2时，多余的slaves才可以迁移到持有更少slaves的master下。</p>
<h3 id="configEpoch冲突解决算法"><a href="#configEpoch冲突解决算法" class="headerlink" title="configEpoch冲突解决算法"></a>configEpoch冲突解决算法</h3><p>在slave failover期间，会生成新的configEpoch值，需要保证唯一性。不过有2种不同的event会导致configEpoch的创建是不安全的：仅仅自增本地的currentEpoch并希望它不会发生冲突。这两个事件有系统管理员触发：<br>1）CLUSTER FAILOVER：这个指令，就是人为的将某个slave提升为master，而不需要要求大多数masters的投票参与。<br>2）slots的迁移，用于平衡集群的数据分布（reshard）；此时本地的configEpoch也会修改，因为性能的考虑，这个过程也不需要“agreement”。</p>
<p>在手动reshard期间，当一个hash slot从A迁移到B，resharding程序将强制B更新自己的配置信息、epoch值也修改为集群的最大值 + 1（除非B的configEpoch已经是最大值），这种变更则不需要其他nodes的agreement（注意与failover的原理不同）。通常每次resharding都会迁移多个slots，且有多个nodes参与，如果每个slots迁移都需要agreement，才能生成新的epoch，这种性能是很差的，也不可取。我们在首个slots迁移开始时，只会生成一个新的configEpoch，在迁移完毕后，将新的配置传播给集群即可，这种方式在生产环境中更加高效。</p>
<p>因为上述两个情况，有可能（虽然概率极小）最终多个nodes产生了相同的configEpoch；比如管理员正在进行resharding，但是此时failover发生了…无论是failover还是resharding都是将currentEpoch自增，而且resharding不使用agreement形式（即其他nodes或许不知道，而且网络传播可能延迟），这就会发生epoch值的冲突问题。</p>
<p>当持有不同slots的masters持有相同的configEpoch，这并不会有什么问题。比较遗憾的是，人工干预或者resharding会以不同的方式修改了集群的配置，Cluster要求所有的slots都应该被nodes覆盖，所以在任何情况下，我们都希望所有的master都持有不同的configEpoch。避免冲突的算法，就是用来解决当2个nodes持有相同的configEpoch：<br>1）如果一个master节点发现其他master持有相同的configEpoch。<br>2）并且此master逻辑上持有较小的node ID（字典顺序）<br>3）然后此master将自己的currentEpoch加1，并作为自己新的configEpoch。</p>
<p>如果有多个nodes持有相同的congfigEpoch，那么除了持有最大ID的节点外，其他的nodes都将往前推进（+1，直到冲突解决），最终保证每个master都持有唯一的configEpoch（slave的configEpoch与master一样）。对于新创建的cluster也是同理，所有的nodes都初始为不同的configEpoch。</p>
<h3 id="Node-resets"><a href="#Node-resets" class="headerlink" title="Node resets"></a>Node resets</h3><p>所有的nodes都可以进行软件级的reset（不需要重启、重新部署它们），reset为了重用集群（重新设定集群），必须需要将某个（些）节点重置后添加到其他集群。我们可以使用“CLUSTER RESET”指令：<br>1）CLUSTER RESET SOFT<br>2）CLUSTER RESET HARD</p>
<p>指令必须直接发给需要reset的节点，如果没有指定reset类型，默认为SOFT。<br>1）soft和hard：如果节点为slave，那么节点将会转换为master，并清空其持有的数据，成为一个空的master。如果此节点为master，且持有slots数据，那么reset操作将被中断。<br>2）soft和hard：其上持有的slots将会被释放<br>3）soft和hard：此节点上的nodes映射表将会被清除，此后此node将不会知道其他节点的存在与状态。<br>4）hard：currentEpoch、configEpoch、lastVoteEpoch值将被重置为0。<br>5）hard：此nodeID将会重新生成。</p>
<p>持有数据的（slot映射不为空的）master不能被reset（除非现将此master上的slot手动迁移到其他nodes上，或者手动failover，将其切换成slave）；在某些特定的场景下，在执行reset之前，或许需要执行FLUSHALL来清空原有的数据。</p>
<h3 id="集群中移除节点"><a href="#集群中移除节点" class="headerlink" title="集群中移除节点"></a>集群中移除节点</h3><p>我们已经知道，将node移除集群之前，首先将其上的slots迁移到其他nodes上（reshard），然后关闭它。不过这似乎还并未结束，因为其他nodes仍然记住了它的ID，仍然会尝试与它建立连接。因此，当我们确定将节点移除集群时，可以使用“CLUSTER FORGET <node-id>”指令：<br>1）将此node从nodes映射表中移除。<br>2）然后设定一个60秒的隔离时间，阻止持有相同ID的node再次加入集群。</node-id></p>
<p>之所以2）规则，因为FORGET指令将会通过gossip协议传播给其他nodes，集群中所有的节点都收到消息是需要一定的时间延迟。</p>
]]></content>
    
    <summary type="html">
    
      Redis Cluster实现原理
    
    </summary>
    
      <category term="Redis" scheme="http://jishusuishouji.github.io/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://jishusuishouji.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>全面剖析Redis Cluster原理和应用</title>
    <link href="http://jishusuishouji.github.io/2017/04/02/redis/%E5%85%A8%E9%9D%A2%E5%89%96%E6%9E%90Redis_Cluster%E5%8E%9F%E7%90%86%E5%92%8C%E5%BA%94%E7%94%A8/"/>
    <id>http://jishusuishouji.github.io/2017/04/02/redis/全面剖析Redis_Cluster原理和应用/</id>
    <published>2017-04-02T15:57:30.000Z</published>
    <updated>2017-04-02T16:04:03.246Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Redis-Cluster总览"><a href="#1-Redis-Cluster总览" class="headerlink" title="1.Redis Cluster总览"></a>1.Redis Cluster总览</h2><h3 id="1-1-设计原则和初衷"><a href="#1-1-设计原则和初衷" class="headerlink" title="1.1 设计原则和初衷"></a>1.1 设计原则和初衷</h3><p>在官方文档ClusterSpec中，作者详细介绍了Redis集群为什么要设计成现在的样子。最核心的目标有三个：</p>
<ul>
<li>性能：这是Redis赖以生存的看家本领，增加集群功能后当然不能对性能产生太大影响，所以Redis采取了P2P而非Proxy方式、异步复制、客户端重定向等设计，而牺牲了部分的一致性、使用性。</li>
<li>水平扩展：集群的最重要能力当然是扩展，文档中称可以线性扩展到1000结点。</li>
<li>可用性：在Cluster推出之前，可用性要靠Sentinel保证。有了集群之后也自动具有了Sentinel的监控和自动Failover能力。</li>
</ul>
<h3 id="1-2-架构变化与CAP理论"><a href="#1-2-架构变化与CAP理论" class="headerlink" title="1.2 架构变化与CAP理论"></a>1.2 架构变化与CAP理论</h3><p>Redis Cluster集群功能推出已经有一段时间了。在单机版的Redis中，每个Master之间是没有任何通信的，所以我们一般在Jedis客户端或者Codis这样的代理中做Pre-sharding。按照CAP理论来说，单机版的Redis属于保证CP(Consistency &amp; Partition-Tolerancy)而牺牲A(Availability)，也就说Redis能够保证所有用户看到相同的数据（一致性，因为Redis不自动冗余数据）和网络通信出问题时，暂时隔离开的子系统能继续运行（分区容忍性，因为Master之间没有直接关系，不需要通信），但是不保证某些结点故障时，所有请求都能被响应（可用性，某个Master结点挂了的话，那么它上面分片的数据就无法访问了）。</p>
<p>有了Cluster功能后，Redis从一个单纯的NoSQL内存数据库变成了分布式NoSQL数据库，CAP模型也从CP变成了AP。也就是说，通过自动分片和冗余数据，Redis具有了真正的分布式能力，某个结点挂了的话，因为数据在其他结点上有备份，所以其他结点顶上来就可以继续提供服务，保证了Availability。然而，也正因为这一点，Redis无法保证曾经的强一致性了。这也是CAP理论要求的，三者只能取其二。</p>
<p>简单分析了Redis在架构上的变化后，咱们就一起来体验一下Redis Cluster功能吧！</p>
<p>2.Redis集群初探</p>
<p>Redis的安装很简单，以前已经介绍过，就不详细说了。关于Redis Cluster的基础知识之前也有过整理，请参考《Redis集群功能预览》。如果需要全面的了解，那一定要看官方文档Cluster Tutorial，只看这一个就够了！</p>
<p>2.1 集群配置</p>
<p>要想开启Redis Cluster模式，有几项配置是必须的。此外为了方便使用和后续的测试，我还额外做了一些配置：</p>
<p>绑定地址：bind 192.168.XXX.XXX。不能绑定到127.0.0.1或localhost，否则指导客户端重定向时会报”Connection refused”的错误。<br>开启Cluster：cluster-enabled yes<br>集群配置文件：cluster-config-file nodes-7000.conf。这个配置文件不是要我们去配的，而是Redis运行时保存配置的文件，所以我们也不可以修改这个文件。<br>集群超时时间：cluster-node-timeout 15000。结点超时多久则认为它宕机了。<br>槽是否全覆盖：cluster-require-full-coverage no。默认是yes，只要有结点宕机导致16384个槽没全被覆盖，整个集群就全部停止服务，所以一定要改为no<br>后台运行：daemonize yes<br>输出日志：logfile “./redis.log”<br>监听端口：port 7000<br>配置好后，根据我们的集群规模，拷贝出来几份同样的配置文件，唯一不同的就是监听端口，可以依次改为7001、7002… 因为Redis Cluster如果数据冗余是1的话，至少要3个Master和3个Slave，所以我们拷贝出6个实例的配置文件。为了避免相互影响，为6个实例的配置文件建立独立的文件夹。</p>
<p>[root@8gVm redis-3.0.4]# pwd<br>/root/Software/redis-3.0.4<br>[root@8gVm redis-3.0.4]# tree -I “<em>log|nodes</em>“ cfg-cluster/<br>cfg-cluster/<br>├── 7000<br>│   └── redis.conf.7000<br>├── 7001<br>│   └── redis.conf.7001<br>├── 7002<br>│   └── redis.conf.7002<br>├── 7003<br>│   └── redis.conf.7003<br>├── 7004<br>│   └── redis.conf.7004<br>└── 7005<br>    └── redis.conf.7005</p>
<p>6 directories, 6 files<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>2.2 redis-trib管理器</p>
<p>Redis作者应该是个Ruby爱好者，Ruby客户端就是他开发的。这次集群的管理功能没有嵌入到Redis代码中，于是作者又顺手写了个叫做redis-trib的管理脚本。redis-trib依赖Ruby和RubyGems，以及redis扩展。可以先用which命令查看是否已安装ruby和rubygems，用gem list –local查看本地是否已安装redis扩展。</p>
<p>最简便的方法就是用apt或yum包管理器安装RubyGems后执行gem install redis。如果网络或环境受限的话，可以手动安装RubyGems和redis扩展（国外链接可能无法下载，可以从CSDN下载）：</p>
<p>[root@8gVm Software]# wget <a href="https://github.com/rubygems/rubygems/releases/download/v2.2.3/rubygems-2.2.3.tgz" target="_blank" rel="external">https://github.com/rubygems/rubygems/releases/download/v2.2.3/rubygems-2.2.3.tgz</a><br>[root@8gVm Software]# tar xzvf rubygems-2.2.3.tgz<br>[root@8gVm Software]# cd rubygems-2.2.3<br>[root@8gVm rubygems-2.2.3]# ruby setup.rb –no-rdoc –no-ri</p>
<p>[root@8gVm Software]# wget <a href="https://rubygems.org/downloads/redis-3.2.1.gem" target="_blank" rel="external">https://rubygems.org/downloads/redis-3.2.1.gem</a><br>[root@8gVm Software]# gem install redis-3.2.1.gem –local –no-rdoc –no-ri<br>Successfully installed redis-3.2.1<br>1 gem installed<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>2.3 集群建立</p>
<p>首先，启动我们配置好的6个Redis实例。</p>
<p>[root@8gVm redis-3.0.4]# for ((i=0; i&lt;6; ++i))</p>
<blockquote>
<p>do<br>cd cfg-cluster/700$i &amp;&amp; ../../src/redis-server redis.conf.700$i &amp;&amp; cd -<br>done<br>1<br>2<br>3<br>4<br>1<br>2<br>3<br>4<br>此时6个实例还没有形成集群，现在用redis-trb.rb管理脚本建立起集群。可以看到，redis-trib默认用前3个实例作为Master，后3个作为Slave。因为Redis基于Master-Slave做数据备份，而非像Cassandra或Hazelcast一样不区分结点角色，自动复制并分配Slot的位置到各个结点。</p>
</blockquote>
<p>[root@8gVm redis-3.0.4]# src/redis-trib.rb create –replicas 1 192.168.1.100:7000 192.168.1.100:7001 192.168.1.100:7002 192.168.1.100:7003 192.168.1.100:7004 192.168.1.100:7005</p>
<blockquote>
<blockquote>
<blockquote>
<p>Creating cluster<br>Connecting to node 192.168.1.100:7000: OK<br>Connecting to node 192.168.1.100:7001: OK<br>Connecting to node 192.168.1.100:7002: OK<br>Connecting to node 192.168.1.100:7003: OK<br>Connecting to node 192.168.1.100:7004: OK<br>Connecting to node 192.168.1.100:7005: OK<br>Performing hash slots allocation on 6 nodes…<br>Using 3 masters:<br>192.168.1.100:7000<br>192.168.1.100:7001<br>192.168.1.100:7002<br>Adding replica 192.168.1.100:7003 to 192.168.1.100:7000<br>Adding replica 192.168.1.100:7004 to 192.168.1.100:7001<br>Adding replica 192.168.1.100:7005 to 192.168.1.100:7002<br>    …<br>Can I set the above configuration? (type ‘yes’ to accept): yes<br>Nodes configuration updated<br>Assign a different config epoch to each node<br>Sending CLUSTER MEET messages to join the cluster<br>Waiting for the cluster to join….<br>Performing Cluster Check (using node 192.168.1.100:7000)<br>    …<br>[OK] All nodes agree about slots configuration.<br>Check for open slots…<br>Check slots coverage…<br>[OK] All 16384 slots covered.<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>至此，集群就已经建立成功了！“贴心”的Redis还在utils/create-cluster下提供了一个create-cluster脚本，能够创建出一个集群，类似我们上面建立起的3主3从的集群。</p>
</blockquote>
</blockquote>
</blockquote>
<p>2.4 简单测试</p>
<p>我们连接到集群中的任意一个结点，启动redis-cli时要加-c选项，存取两个Key-Value感受一下Redis久违的集群功能。</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000<br>192.168.1.100:7000&gt; set foo bar<br>-&gt; Redirected to slot [12182] located at 192.168.1.100:7002<br>OK<br>192.168.1.100:7002&gt; set hello world<br>-&gt; Redirected to slot [866] located at 192.168.1.100:7000<br>OK<br>192.168.1.100:7000&gt; get foo<br>-&gt; Redirected to slot [12182] located at 192.168.1.100:7002<br>“bar”<br>192.168.1.100:7002&gt; get hello<br>-&gt; Redirected to slot [866] located at 192.168.1.100:7000<br>“world”<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>仔细观察能够注意到，redis-cli根据指示，不断在7000和7002结点之前重定向跳转。如果启动时不加-c选项的话，就能看到以错误形式显示出的MOVED重定向消息。</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -h 192.168.1.100 -p 7000<br>192.168.1.100:7000&gt; get foo<br>(error) MOVED 12182 192.168.1.100:7002<br>1<br>2<br>3<br>1<br>2<br>3<br>2.5 集群重启</p>
<p>目前redis-trib的功能还比较弱，需要重启集群的话先手动kill掉各个进程，然后重新启动就可以了。这也有点太… 网上有人重启后会碰到问题，我还比较幸运，这种“土鳖”的方式重启试了两次还没发现问题。</p>
<p>[root@8gVm redis-3.0.4]# ps -ef | grep redis | awk ‘{print $2}’ | xargs kill<br>1<br>1<br>3.高级功能尝鲜</p>
<p>说是“高级功能”，其实在其他分布式系统中早就都有实现了，只不过在Redis世界里是比较新鲜的。本部分主要试验一下Redis Cluster中的数据迁移(Resharding)和故障转移功能。</p>
<p>3.1 数据迁移</p>
<p>本小节我们体验一下Redis集群的Resharding功能！</p>
<p>3.1.1 创建测试数据</p>
<p>首先保存foo1~10共10个Key-Value作为测试数据。</p>
<p>[root@8gVm redis-3.0.4]# for ((i=0; i&lt;10; ++i))</p>
<blockquote>
<p>do<br>src/redis-cli -c -h 192.168.1.100 -p 7000 set foo$i bar<br>done</p>
</blockquote>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000<br>192.168.1.100:7000&gt; keys <em><br>1) “foo6”<br>2) “foo7”<br>3) “foo3”<br>4) “foo2”<br>192.168.1.100:7000&gt; get foo4<br>-&gt; Redirected to slot [9426] located at 192.168.1.100:7001<br>“bar”<br>192.168.1.100:7001&gt; keys </em><br>1) “foo4”<br>2) “foo8”<br>192.168.1.100:7001&gt; get foo5<br>-&gt; Redirected to slot [13555] located at 192.168.1.100:7002<br>“bar”<br>192.168.1.100:7002&gt; keys *<br>1) “foo5”<br>2) “foo1”<br>3) “foo10”<br>4) “foo9”<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>3.1.2 启动新结点</p>
<p>参照之前的方法新拷贝出两份redis.conf配置文件redis.conf.7010和7011，与之前结点的配置文件做一下区分。启动新的两个Redis实例之后，通过redis-trib.rb脚本添加新的Master和Slave到集群中。</p>
<p>[root@8gVm redis-3.0.4]# cd cfg-cluster/7010 &amp;&amp; ../../src/redis-server redis.conf.7010 &amp;&amp; cd -<br>[root@8gVm redis-3.0.4]# cd cfg-cluster/7011 &amp;&amp; ../../src/redis-server redis.conf.7011 &amp;&amp; cd -<br>1<br>2<br>1<br>2<br>3.1.3 添加到集群</p>
<p>使用redis-trib.rb add-node分别将两个新结点添加到集群中，一个作为Master，一个作为其Slave。</p>
<p>[root@8gVm redis-3.0.4]# src/redis-trib.rb add-node 192.168.1.100:7010 192.168.1.100:7000</p>
<blockquote>
<blockquote>
<blockquote>
<p>Adding node 192.168.1.100:7010 to cluster 192.168.1.100:7000<br>Connecting to node 192.168.1.100:7000: OK<br>Connecting to node 192.168.1.100:7001: OK<br>Connecting to node 192.168.1.100:7002: OK<br>Connecting to node 192.168.1.100:7005: OK<br>Connecting to node 192.168.1.100:7003: OK<br>Connecting to node 192.168.1.100:7004: OK<br>Performing Cluster Check (using node 192.168.1.100:7000)<br>    …<br>[OK] All nodes agree about slots configuration.<br>Check for open slots…<br>Check slots coverage…<br>[OK] All 16384 slots covered.<br>Connecting to node 192.168.1.100:7010: OK<br>Send CLUSTER MEET to node 192.168.1.100:7010 to make it join the cluster.<br>[OK] New node added correctly.</p>
</blockquote>
</blockquote>
</blockquote>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes<br>0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9 192.168.1.100:7010 master - 0 1442452249525 0 connected<br>    …</p>
<p>[root@8gVm redis-3.0.4]# src/redis-trib.rb add-node –slave –master-id 0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9 192.168.1.100:7011 192.168.1.100:7000</p>
<blockquote>
<blockquote>
<blockquote>
<p>Adding node 192.168.1.100:7011 to cluster 192.168.1.100:7000<br>Connecting to node 192.168.1.100:7000: OK<br>Connecting to node 192.168.1.100:7010: OK<br>Connecting to node 192.168.1.100:7001: OK<br>Connecting to node 192.168.1.100:7002: OK<br>Connecting to node 192.168.1.100:7005: OK<br>Connecting to node 192.168.1.100:7003: OK<br>Connecting to node 192.168.1.100:7004: OK<br>Performing Cluster Check (using node 192.168.1.100:7000)<br>    …<br>[OK] All nodes agree about slots configuration.<br>Check for open slots…<br>Check slots coverage…<br>[OK] All 16384 slots covered.<br>Connecting to node 192.168.1.100:7011: OK<br>Send CLUSTER MEET to node 192.168.1.100:7011 to make it join the cluster.<br>Waiting for the cluster to join.<br>Configure node as replica of 192.168.1.100:7010.<br>[OK] New node added correctly.<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>3.1.4 Resharding</p>
</blockquote>
</blockquote>
</blockquote>
<p>通过redis-trib.rb reshard可以交互式地迁移Slot。下面的例子将5000个Slot从7000~7002迁移到7010上。也可以通过./redis-trib.rb reshard <host>:<port> –from <node-id> –to <node-id> –slots –yes在程序中自动完成迁移。</node-id></node-id></port></host></p>
<p>[root@8gVm redis-3.0.4]# src/redis-trib.rb reshard 192.168.1.100:7000<br>Connecting to node 192.168.1.100:7000: OK<br>Connecting to node 192.168.1.100:7010: OK<br>Connecting to node 192.168.1.100:7001: OK<br>Connecting to node 192.168.1.100:7002: OK<br>Connecting to node 192.168.1.100:7005: OK<br>Connecting to node 192.168.1.100:7011: OK<br>Connecting to node 192.168.1.100:7003: OK<br>Connecting to node 192.168.1.100:7004: OK</p>
<blockquote>
<blockquote>
<blockquote>
<p>Performing Cluster Check (using node 192.168.1.100:7000)<br>M: b2036adda128b2eeffa36c3a2056444d23b548a8 192.168.1.100:7000<br>   slots:0-5460 (4128 slots) master<br>   1 additional replica(s)<br>M: 0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9 192.168.1.100:7010<br>   slots:0 (4000 slots) master<br>   1 additional replica(s)<br>   …<br>[OK] All nodes agree about slots configuration.<br>Check for open slots…<br>Check slots coverage…<br>[OK] All 16384 slots covered.<br>How many slots do you want to move (from 1 to 16384)? 5000<br>What is the receiving node ID? 0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9<br>Please enter all the source node IDs.<br>  Type ‘all’ to use all the nodes as source nodes for the hash slots.<br>  Type ‘done’ once you entered all the source nodes IDs.<br>Source node #1:all</p>
</blockquote>
</blockquote>
</blockquote>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes<br>0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9 192.168.1.100:7010 master - 0 1442455872019 7 connected 0-1332 5461-6794 10923-12255<br>b2036adda128b2eeffa36c3a2056444d23b548a8 192.168.1.100:7000 myself,master - 0 0 1 connected 1333-5460<br>b5ab302f5c2395e3c8194c354a85d02f89bace62 192.168.1.100:7001 master - 0 1442455875022 2 connected 6795-10922<br>0c565e207ce3118470fd5ed3c806eb78f1fdfc01 192.168.1.100:7002 master - 0 1442455874521 3 connected 12256-16383<br>    …<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>迁移完成后，查看之前保存的foo1~10的分布情况，可以看到部分Key已经迁移到了新的结点7010上。</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 keys “<em>“<br>1) “foo3”<br>2) “foo7”<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7001 keys “</em>“<br>1) “foo4”<br>2) “foo8”<br>3) “foo0”<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7002 keys “<em>“<br>1) “foo1”<br>2) “foo9”<br>3) “foo5”<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7010 keys “</em>“<br>1) “foo6”<br>2) “foo2”<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>3.2 故障转移</p>
<p>在高可用性方面，Redis可算是能够”Auto”一把了！Redis Cluster重用了Sentinel的代码逻辑，不需要单独启动一个Sentinel集群，Redis Cluster本身就能自动进行Master选举和Failover切换。</p>
<p>下面我们故意kill掉7010结点，之后可以看到结点状态变成了fail，而Slave 7011被选举为新的Master。</p>
<p>[root@8gVm redis-3.0.4]# kill 43637</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes<br>0d1f9c979684e0bffc8230c7bb6c7c0d37d8a5a9 192.168.1.100:7010 master,fail - 1442456829380 1442456825674 7 disconnected<br>b2036adda128b2eeffa36c3a2056444d23b548a8 192.168.1.100:7000 myself,master - 0 0 1 connected 1333-5460<br>b5ab302f5c2395e3c8194c354a85d02f89bace62 192.168.1.100:7001 master - 0 1442456848722 2 connected 6795-10922<br>0c565e207ce3118470fd5ed3c806eb78f1fdfc01 192.168.1.100:7002 master - 0 1442456846717 3 connected 12256-16383<br>5a3c67248b1df554fbf2c93112ba429f31b1d3d1 192.168.1.100:7005 slave 0c565e207ce3118470fd5ed3c806eb78f1fdfc01 0 1442456847720 6 connected<br>99bff22b97119cf158d225c2b450732a1c0d3c44 192.168.1.100:7011 master - 0 1442456849725 8 connected 0-1332 5461-6794 10923-12255<br>cd305d509c34842a8047e19239b64df94c13cb96 192.168.1.100:7003 slave b2036adda128b2eeffa36c3a2056444d23b548a8 0 1442456848220 4 connected<br>64b544cdd75c1ce395fb9d0af024b7f2b77213a3 192.168.1.100:7004 slave b5ab302f5c2395e3c8194c354a85d02f89bace62 0 1442456845715 5 connected<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>尝试查询之前保存在7010上的Key，可以看到7011顶替上来继续提供服务，整个集群没有受到影响。</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 get foo6<br>“bar”<br>[root@8gVm redis-3.0.4]#<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 get foo2<br>“bar”<br>1<br>2<br>3<br>4<br>5<br>1<br>2<br>3<br>4<br>5<br>4.内部原理剖析</p>
<p>前面我们已经学习过，用Redis提供的redis-trib或create-cluster脚本能几步甚至一步就建立起一个Redis集群。这一部分我们为了深入学习，所以要暂时抛开这些方便的工具，完全手动建立一遍上面的3主3从集群。</p>
<p>4.1 集群发现：MEET</p>
<p>最开始时，每个Redis实例自己是一个集群，我们通过cluster meet让各个结点互相“握手”。这也是Redis Cluster目前的一个欠缺之处：缺少结点的自动发现功能。</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes<br>33c0bd93d7c7403ef0239ff01eb79bfa15d2a32c :7000 myself,master - 0 0 0 connected</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster meet 192.168.1.100 7001<br>OK<br>    …<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster meet 192.168.1.100 7005<br>OK</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes<br>7b953ec26bbdbf67179e5d37e3cf91626774e96f 192.168.1.100:7003 master - 0 1442466369259 4 connected<br>5d9f14cec1f731b6477c1e1055cecd6eff3812d4 192.168.1.100:7005 master - 0 1442466368659 4 connected<br>33c0bd93d7c7403ef0239ff01eb79bfa15d2a32c 192.168.1.100:7000 myself,master - 0 0 1 connected<br>63162ed000db9d5309e622ec319a1dcb29a3304e 192.168.1.100:7001 master - 0 1442466371262 3 connected<br>45baa2cb45435398ba5d559cdb574cfae4083893 192.168.1.100:7002 master - 0 1442466372264 2 connected<br>cdd5b3a244761023f653e08cb14721f70c399b82 192.168.1.100:7004 master - 0 1442466370261 0 connecte<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>4.2 角色设置：REPLICATE</p>
<p>结点全部“握手”成功后，就可以用cluster replicate命令为结点指定角色了，默认每个结点都是Master。</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7003 cluster replicate 33c0bd93d7c7403ef0239ff01eb79bfa15d2a32c<br>OK<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7004 cluster replicate 63162ed000db9d5309e622ec319a1dcb29a3304e<br>OK<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7005 cluster replicate 45baa2cb45435398ba5d559cdb574cfae4083893<br>OK</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster nodes<br>7b953ec26bbdbf67179e5d37e3cf91626774e96f 192.168.1.100:7003 slave 33c0bd93d7c7403ef0239ff01eb79bfa15d2a32c 0 1442466812984 4 connected<br>5d9f14cec1f731b6477c1e1055cecd6eff3812d4 192.168.1.100:7005 slave 45baa2cb45435398ba5d559cdb574cfae4083893 0 1442466813986 5 connected<br>33c0bd93d7c7403ef0239ff01eb79bfa15d2a32c 192.168.1.100:7000 myself,master - 0 0 1 connected<br>63162ed000db9d5309e622ec319a1dcb29a3304e 192.168.1.100:7001 master - 0 1442466814987 3 connected<br>45baa2cb45435398ba5d559cdb574cfae4083893 192.168.1.100:7002 master - 0 1442466811982 2 connected<br>cdd5b3a244761023f653e08cb14721f70c399b82 192.168.1.100:7004 slave 63162ed000db9d5309e622ec319a1dcb29a3304e 0 1442466812483 3 connected<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>4.3 槽指派：ADDSLOTS</p>
<p>设置好主从关系之后，就可以用cluster addslots命令指派16384个槽的位置了。有点恶心的是，ADDSLOTS命令需要在参数中一个个指明槽的ID，而不能指定范围。这里用Bash 3.0的特性简化了，不然就得用Bash的循环来完成了：</p>
<p>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7000 cluster addslots {0..5000}<br>OK<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7001 cluster addslots {5001..10000}<br>OK<br>[root@8gVm redis-3.0.4]# src/redis-cli -c -h 192.168.1.100 -p 7001 cluster addslots {10001..16383}<br>OK</p>
<p>[root@8gVm redis-3.0.4]# src/redis-trib.rb check 192.168.1.100:7000<br>Connecting to node 192.168.1.100:7000: OK<br>  …</p>
<blockquote>
<blockquote>
<blockquote>
<p>Performing Cluster Check (using node 192.168.1.100:7000)<br>  …<br>[OK] All nodes agree about slots configuration.<br>Check for open slots…<br>Check slots coverage…<br>[OK] All 16384 slots covered.<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>这样我们就通过手动执行命令得到了与之前一样的集群。</p>
</blockquote>
</blockquote>
</blockquote>
<p>4.4 数据迁移：MIGRATE</p>
<p>真正开始Resharding之前，redis-trib会先在源结点和目的结点上执行cluster setslot <slot> importing和cluster setslot <slot> migrating命令，将要迁移的槽分别标记为迁出中和导入中的状态。然后，执行cluster getkeysinslot获得Slot中的所有Key。最后就可以对每个Key执行migrate命令进行迁移了。槽迁移完成后，执行cluster setslot命令通知整个集群槽的指派已经发生变化。</slot></slot></p>
<p>关于迁移过程中的数据访问，客户端访问源结点时，如果Key还在源结点上就直接操作。如果已经不在源结点了，就向客户端返回一个ASK错误，将客户端重定向到目的结点。</p>
<p>4.5 内部数据结构</p>
<p>Redis Cluster功能涉及三个核心的数据结构clusterState、clusterNode、clusterLink都在cluster.h中定义。这三个数据结构中最重要的属性就是：clusterState.slots、clusterState.slots_to_keys和clusterNode.slots了，它们保存了三种映射关系：</p>
<p>clusterState：集群状态<br>nodes：所有结点<br>migrating_slots_to：迁出中的槽<br>importing_slots_from：导入中的槽<br>slots_to_keys：槽中包含的所有Key，用于迁移Slot时获得其包含的Key<br>slots：Slot所属的结点，用于处理请求时判断Key所在Slot是否自己负责<br>clusterNode：结点信息<br>slots：结点负责的所有Slot，用于发送Gossip消息通知其他结点自己负责的Slot。通过位图方式保存节省空间，16384/8恰好是2048字节，所以槽总数16384不是随意定的。<br>clusterLink：与其他结点通信的连接<br>// 集群状态，每个节点都保存着一个这样的状态，记录了它们眼中的集群的样子。<br>// 另外，虽然这个结构主要用于记录集群的属性，但是为了节约资源，<br>// 有些与节点有关的属性，比如 slots_to_keys 、 failover_auth_count<br>// 也被放到了这个结构里面。<br>typedef struct clusterState {<br>    …<br>    // 指向当前节点的指针<br>    clusterNode <em>myself;  /</em> This node */</p>
<pre><code>// 集群当前的状态：是在线还是下线
int state;            /* REDIS_CLUSTER_OK, REDIS_CLUSTER_FAIL, ... */

// 集群节点名单（包括 myself 节点）
// 字典的键为节点的名字，字典的值为 clusterNode 结构
dict *nodes;          /* Hash table of name -&gt; clusterNode structures */

// 记录要从当前节点迁移到目标节点的槽，以及迁移的目标节点
// migrating_slots_to[i] = NULL 表示槽 i 未被迁移
// migrating_slots_to[i] = clusterNode_A 表示槽 i 要从本节点迁移至节点 A
clusterNode *migrating_slots_to[REDIS_CLUSTER_SLOTS];

// 记录要从源节点迁移到本节点的槽，以及进行迁移的源节点
// importing_slots_from[i] = NULL 表示槽 i 未进行导入
// importing_slots_from[i] = clusterNode_A 表示正从节点 A 中导入槽 i
clusterNode *importing_slots_from[REDIS_CLUSTER_SLOTS];

// 负责处理各个槽的节点
// 例如 slots[i] = clusterNode_A 表示槽 i 由节点 A 处理
clusterNode *slots[REDIS_CLUSTER_SLOTS];

// 跳跃表，表中以槽作为分值，键作为成员，对槽进行有序排序
// 当需要对某些槽进行区间（range）操作时，这个跳跃表可以提供方便
// 具体操作定义在 db.c 里面
zskiplist *slots_to_keys;
...
</code></pre><p>} clusterState;</p>
<p>// 节点状态<br>struct clusterNode {<br>    …<br>    // 节点标识<br>    // 使用各种不同的标识值记录节点的角色（比如主节点或者从节点），<br>    // 以及节点目前所处的状态（比如在线或者下线）。<br>    int flags;      /<em> REDIS<em>NODE</em>… </em>/</p>
<pre><code>// 由这个节点负责处理的槽
// 一共有 REDIS_CLUSTER_SLOTS / 8 个字节长
// 每个字节的每个位记录了一个槽的保存状态
// 位的值为 1 表示槽正由本节点处理，值为 0 则表示槽并非本节点处理
// 比如 slots[0] 的第一个位保存了槽 0 的保存情况
// slots[0] 的第二个位保存了槽 1 的保存情况，以此类推
unsigned char slots[REDIS_CLUSTER_SLOTS/8]; /* slots handled by this node */

// 指针数组，指向各个从节点
struct clusterNode **slaves; /* pointers to slave nodes */

// 如果这是一个从节点，那么指向主节点
struct clusterNode *slaveof; /* pointer to the master node */
...
</code></pre><p>};</p>
<p>/<em> clusterLink encapsulates everything needed to talk with a remote node. </em>/<br>// clusterLink 包含了与其他节点进行通讯所需的全部信息<br>typedef struct clusterLink {<br>    …<br>    // TCP 套接字描述符<br>    int fd;                     /<em> TCP socket file descriptor </em>/</p>
<pre><code>// 与这个连接相关联的节点，如果没有的话就为 NULL
struct clusterNode *node;   /* Node related to this link if any, or NULL */
...
</code></pre><p>} clusterLink;<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58<br>59<br>60<br>61<br>62<br>63<br>64<br>65<br>66<br>67<br>68<br>69<br>70<br>71<br>72<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58<br>59<br>60<br>61<br>62<br>63<br>64<br>65<br>66<br>67<br>68<br>69<br>70<br>71<br>72<br>4.6 处理流程全梳理</p>
<p>在单机模式下，Redis对请求的处理很简单。Key存在的话，就执行请求中的操作；Key不存在的话，就告诉客户端Key不存在。然而在集群模式下，因为涉及到请求重定向和Slot迁移，所以对请求的处理变得很复杂，流程如下：</p>
<p>检查Key所在Slot是否属于当前Node？<br>2.1 计算crc16(key) % 16384得到Slot<br>2.2 查询clusterState.slots负责Slot的结点指针<br>2.3 与myself指针比较<br>若不属于，则响应MOVED错误重定向客户端<br>若属于且Key存在，则直接操作，返回结果给客户端<br>若Key不存在，检查该Slot是否迁出中？(clusterState.migrating_slots_to)<br>若Slot迁出中，返回ASK错误重定向客户端到迁移的目的服务器上<br>若Slot未迁出，检查Slot是否导入中？(clusterState.importing_slots_from)<br>若Slot导入中且有ASKING标记，则直接操作<br>否则响应MOVED错误重定向客户端<br>5.应用案例收集</p>
<p>5.1 有道：Redis Cluster使用经验</p>
<p>详情请参见原文，关键内容摘录如下：</p>
<p>5.1.1 两个缺点</p>
<p>“redis cluster的设计在这块有点奇葩，跟集群相关的操作需要一个外部的ruby脚本来协助（当然可能是为了让主程序的代码足够简洁？），然后那个脚本还只支持填实例的ip不支持host，还不告诉你不支持让你用host之后各种莫名其妙。”</p>
<p>“第一个缺点就是严格依赖客户端driver的成熟度。如果把redis cluster设计成类似Cassandra，请求集群中任何一个节点都可以负责转发请求，client会好写一些。”</p>
<p>“第二个缺点完全是设计问题了，就是一个redis进程既负责读写数据又负责集群交互，虽然设计者已经尽可能简化了代码和逻辑，但还是让redis从一个内存NoSQL变成了一个分布式NoSQL。分布式系统很容易有坑，一旦有坑必须升级redis。”</p>
<p>5.1.2 去中心化 vs. Proxy</p>
<p>“关于redis cluster的设计，Gossip/P2P的去中心化架构本身不是问题，但一旦有了中心节点，能做的事情就多了，比如sharding不均匀是很容易自动rebalance的，而无中心的只能靠外界来搞。然后redis cluster又是slot的形式而非C*式的一致性哈希，新节点分slot又不自动，依赖外界（ruby脚本）来分配显得不方便更不优美和谐。而且因为是master-slave的系统而非W+R&gt;N的那种，master挂掉之后尽快发现是比较重要的，gossip对于节点挂掉的发现终究没有中心节点/zookeeper方便快速。”</p>
<p>“基于proxy做转发意味着屏蔽了下层存储，完全可以根据前缀/tag/冷热程度，来把部分甚至大多数数据放在磁盘从而节约成本又保证一致性，这都是有中心节点所带来的好处。”</p>
<p>5.2 奇虎360：Redis Cluster浅析和Bada对比</p>
<p>详情请参见原文，关键内容摘录如下：</p>
<p>5.2.1 负载均衡问题</p>
<p>“redis cluster的主备是以节点为单位，而bada则是以partition为单位，这样，同样是3个节点，1024个partition的情况下，redis cluster的主节点负责整个1024个partition的服务，而两个从节点则只负责异步备份，导致集群负载不均，再看bada，将1024个partition的主均分到3个节点中，每个节点各有主备，主对外提供服务，这样均分了访问压力，有效的利用了资源。”</p>
<p>5.2.2 一致性的保证</p>
<p>“redis cluster与bada一样，最终一致性，读写都只请求主节点，当一条写请求在对应的主节点写成功后，会立刻返回给客户端成功，然后主节点通过异步的方式将新的数据同步到对应的从节点，这样的方式减少了客户端多个节点写成功等待的时间，不过在某些情况下会造成写丢失：</p>
<p>1）当主节点接受一条写请求，写入并返回给客户端成功后不幸宕掉，此时刚才的写还未同步给其对应的从节点，而从节点在发现主节点挂掉并重新选主后，新的主节点则永久丢失了之前老的主节点向用户确认的写</p>
<p>2）当网络发生割裂，将集群分裂成少数派与多数派，这样在客户端不知情的情况下，会将写继续写入到少数派中的某些主节点中，而当割裂超过一定时长后，集群感知到异常，此时少数派中的所有主节点会停止响应所有的写请求，多数派的其对应的从节点则会发起选举成为新的主节点，假设过了一会后割裂恢复，老的主节点发现有更新的主存在，自动变成其从节点，而新的主节点中则会永久丢失掉网络割裂至集群感知异常进行切主这个阶段老主节点确认的所有写</p>
<p>相对于redis cluster的永久丢失，bada通过binlog merge有效的解决了这一问题。所有partition的主节点在响应客户端的写请求时，都会在本地记录binlog，binlog实质就是带有时间戳的KV对。当老主以从节点的身份重新加入集群时，会触发binlog merge操作，新主会比较并且合并二者的binlog，这样就可以将之前丢失掉得写再补回来。”</p>
<p>5.2.3 请求重定向问题</p>
<p>“bada服务端节点在收到本不该由自己负责的Partition请求后，不会向客户端返回重定向信息，而是通过代理的方式，直接在集群内部向正确节点转发客户端的请求，并将结果同meta信息再转发回客户端。”</p>
<p>“再看multi key操作，redis cluster为了追求高性能，支持multi key的前提是所有的key必须在同一个节点中, 不过这样的处理需要交给用户，对需要进行multi key操作的所有key，在写入前人为的加上hash tags。当redis cluster进行resharding的时候，也就是将某些slot从一个节点迁移到另一个节点时，此时的multi key操作可能会失败，因为在迁移的slot中的key此时存在于两个节点。</p>
<p>bada怎么做呢？用户如果对multi key操作性能很在乎时，可以采用与redis cluster同样的方式，给这些key加上hash tags来让它们落在同一个节点，如果可以接受性能的稍微损耗而解放用户的处理逻辑，则可以像single key操作一样，请求任一bada节点，它会代理所有的key请求并将结果返回给用户。并且在multi key操作在任何时候都可以，即使在进行partition的迁移，bada也会提前进行切主，保证服务的正常提供。”</p>
<p>5.3 芒果TV：Redis服务解决方案</p>
<p>详情请参见原文，关键内容摘录如下：</p>
<p>芒果TV在Redis Cluster基础上进行开发，主要增加了两个组件：</p>
<p>监控管理：以Python为主要开发框架的Web应用程序Redis-ctl<br>请求代理：以C++11为开发语言的轻量数据代理程序cerberus。其作用和优点为：<br>集群代理程序的自动请求分发/重试机制使得应用不必修改自身代码或更新Redis库<br>代理节点为所有Redis节点加上统一管理和状态监测, 可以查阅历史数据, 或在发生任何问题之后快速响应修复<br>代理进程的无状态性使之可在故障后快速恢复, 不影响后端集群数据完整性<br>这两个组件都已开源到GitHub上，大家可以关注一下！</p>
<p>6.Pros &amp; Cons总结</p>
<p>关于Redis Cluster带来的种种优势就不说了，在这里主要是“鸡蛋里挑骨头”，总结一下现阶段集群功能的欠缺之处和可能的“坑”。</p>
<p>6.1 无中心化架构</p>
<p>6.1.1 Gossip消息</p>
<p>Gossip消息的网络开销和时延是决定Redis Cluster能够线性扩展的因素之一。关于这个问题，在《redis cluster百万QPS的挑战》一文中有所提及。</p>
<p>6.1.2 结点粒度备份</p>
<p>此外，Redis Cluster也许是为了简化设计采用了Master-Slave复制的数据备份方案，并没有采取如Cassandra或IMDG等对等分布式系统中常见的Slot粒度（或叫Partition/Bucket等）的自动冗余和指派。</p>
<p>这种设计虽然避免比较复杂的分布式技术，但也带来了一些问题：</p>
<p>Slave完全闲置：即便是读请求也不会被重定向到Slave结点上，Slave属于“冷备”<br>写压力无法分摊：Slave闲置导致的另一个问题就是写压力也都在Master上<br>6.2 客户端的挑战</p>
<p>由于Redis Cluster的设计，客户端要担负起一部分责任：</p>
<p>Cluster协议支持：不管Dummy还是Smart模式，都要具备解析Cluster协议的能力<br>网络开销：Dummy客户端不断重定向的网络开销<br>连接维护：Smart客户端对连接到集群中每个结点Socket的维护<br>缓存路由表：Smart客户端Slot路由表的缓存和更新<br>内存消耗：Smart客户端上述维护的信息都是有内存消耗的<br>MultiOp有限支持：对于MultiOp，由客户端通过KeyTag保证所有Key都在同一Slot。而即便如此，迁移时也会导致MultiOp失败。同理，对Pipeline和Transaction的支持也受限于必须操作同一Slot内的Key。<br>6.3 Redis实现问题</p>
<p>尽管属于无中心化架构一类的分布式系统，但不同产品的细节实现和代码质量还是有不少差异的，就比如Redis Cluster有些地方的设计看起来就有一些“奇葩”和简陋：</p>
<p>不能自动发现：无Auto Discovery功能。集群建立时以及运行中新增结点时，都要通过手动执行MEET命令或redis-trib.rb脚本添加到集群中<br>不能自动Resharding：不仅不自动，连Resharding算法都没有，要自己计算从哪些结点上迁移多少Slot，然后还是得通过redis-trib.rb操作<br>严重依赖外部redis-trib：如上所述，像集群健康状况检查、结点加入、Resharding等等功能全都抽离到一个Ruby脚本中了。还不清楚上面提到的缺失功能未来是要继续加到这个脚本里还是会集成到集群结点中？redis-trib也许要变成Codis中Dashboard的角色<br>无监控管理UI：即便未来加了UI，像迁移进度这种信息在无中心化设计中很难得到<br>只保证最终一致性：写Master成功后立即返回，如需强一致性，自行通过WAIT命令实现。但对于“脑裂”问题，目前Redis没提供网络恢复后的Merge功能，“脑裂”期间的更新可能丢失<br>6.4 性能损耗</p>
<p>由于之前手头没有空闲的物理机资源，所以只在虚拟机上做了简单的单机测试，在单独的一台压力机使用YCSB测试框架向虚拟机产生读写负载。虚拟机的配置为8核Intel Xeon CPU X5650@2.67GHz，16GB内存，分别搭建了4结点的单机版Redis和集群版Redis，测试一下Redis Cluster的性能损耗。由于不是最近做的测试，所以Jedis用的2.6.2版本。注：当然Redis Cluster可以通过多机部署获得水平扩展带来的性能提升，这里只是由于环境有限所以做的简单单机测试。</p>
<p>由于YCSB本身仅支持Redis单机版，所以需要我们自己增加扩展插件，具体方法请参照《YCSB性能测试工具使用》。通过YCSB产生2000w随机数据，Value大约100Byte左右。然后通过YCSB测试Read-Mostly(90% Read)和Read-Write-Mixed(50% Read)两种情况：</p>
<p>数据加载：吞吐量上有约18%的下降。<br>Read-Mostly：吞吐量上有约3.5%~7.9%的下降。<br>Read-Write-Mixed：吞吐量上有约3.3%~5.5%下降。<br>内存占用：Jedis客户端多占用380MB内存。<br>6.5 最后的总结</p>
<p>从现阶段看来，相比Sentinel或Codis等方案，Redis Cluster的优势还真是有限，个人觉得最大的优点有两个：</p>
<p>官方提供的Slot实现而不用像Codis那样去改源码了；<br>不用额外的Sentinel集群或类似的代码实现了。<br>同其他分布式系统，如Cassandra，或内存型的IMDG如Hazelcast和GridGain，除了性能方面外，从功能上Redis Cluster简直被爆得体无完肤… 看看我之前总结过的GridGain介绍《开源IMDG之GridGain》：</p>
<p>结点自动发现和Rebalance<br>分区粒度的备份<br>故障时分区角色自动调整<br>结果聚合（不会重定向客户端）<br>“脑裂”恢复后的Merge（Hazelcast支持多种合并策略）<br>多Primary分区写操作（见Replicated模式）<br>这些都是Redis Cluster没有或者要手动完成的。当然这也不足为奇，因为这与Redis的设计初衷有关，毕竟作者都已经说了，最核心的设计目标就是性能、水平伸缩和可用性。</p>
<p>从Redis Cluster的环境搭建使用到高级功能和内部原理剖析，再到应用案例收集和优缺点的分析罗列，讲了这么多，关于Redis集群到底如何，相信大家根据自己切身和项目的具体情况一定有了自己的结论。不管是评估测试也好，二次开发也好，还是直接上线使用也好，相信随着官方的不断迭代更新和大家的力量，Redis Cluster一定会逐渐完善成熟的！</p>
<p>顶<br>13</p>
<p>踩<br>0</p>
<p>上一篇操作系统内核Hack：(一)实验环境搭建<br>下一篇Redis Cluster架构优化<br>我的同类文章<br>Redis（13）<br>•Redis Cluster架构优化2015-09-25阅读11969<br>•Redis监控工具,命令和调优2015-08-16阅读15729<br>•豌豆夹Redis解决方案Codis安装使用2015-07-25阅读17653<br>•用Netty解析Redis网络协议2015-06-19阅读4886<br>•Redis源码学习：Lua脚本2015-05-22阅读2327<br>•Jedis分片Sentinel连接池实验2015-08-29阅读6353<br>•豌豆夹Redis解决方案Codis源码剖析：Dashboard2015-08-08阅读4675<br>•豌豆夹Redis解决方案Codis源码剖析：Proxy代理2015-07-03阅读8979<br>•Redis源码学习：字符串2015-05-30阅读1772<br>•Redis集群功能预览2015-02-28阅读4059<br>更多文章<br>参考知识库<br>img<br>Python知识库<br>22194关注|1364收录<br>img<br>C++知识库<br>9249关注|1393收录<br>img<br>Redis知识库<br>5139关注|738收录<br>img<br>软件测试知识库<br>4272关注|318收录<br>img<br>MySQL知识库<br>21472关注|1448收录<br>img<br>算法与数据结构知识库<br>15138关注|2320收录<br>img<br>大型网站架构知识库<br>8321关注|708收录<br>猜你在找</p>
]]></content>
    
    <summary type="html">
    
      全面剖析Redis Cluster原理和应用
    
    </summary>
    
      <category term="redis" scheme="http://jishusuishouji.github.io/categories/redis/"/>
    
    
      <category term="redis" scheme="http://jishusuishouji.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>Hibernate缓存 查询缓存</title>
    <link href="http://jishusuishouji.github.io/2017/03/30/hibernate/Hibernate%E7%BC%93%E5%AD%98_%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98/"/>
    <id>http://jishusuishouji.github.io/2017/03/30/hibernate/Hibernate缓存_查询缓存/</id>
    <published>2017-03-30T05:58:14.000Z</published>
    <updated>2017-03-30T05:59:23.196Z</updated>
    
    <content type="html"><![CDATA[<p>网上说<code>query.setCacheable(true)</code>或<code>criteria.setCacheable(true)`` 这两种方式的缓存命中率低，个人认为谈论这个“无卵用”；
我在测试的时候发现，上面的操作会受配置的限制，必须在配置文件中打开</code>hibernate.cache.use_query_cache=true<code>，之后</code>setCacheable`才起作用；</p>
<p>查询缓存可以解决二级缓存的不足；它的作用范围也是<code>SessionFactory</code>；</p>
<p>可以缓存hql语句查询，也可以缓存query和criteria查询；</p>
<p>下面针对query和criteria进行测试：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">/**</div><div class="line"> * 对查询缓存测试 &lt;br&gt;</div><div class="line"> * 1. 只有B处起作用，作用于session; &lt;br&gt;</div><div class="line"> * 2. 配置文件中打开query_cache的前提下，setCacheable 是起作用的</div><div class="line"> */</div><div class="line">@Test</div><div class="line">public void testCriteriaInCache() &#123;</div><div class="line"> System.out.println(&quot;=============&quot;);</div><div class="line"> Session session = hibernateTemplate.getSessionFactory().openSession();</div><div class="line"> Criteria criteria = session.createCriteria(UserModel.class);</div><div class="line"> criteria.setCacheable(true); // 这里仅对B处起作用</div><div class="line"> criteria.add(Restrictions.eq(&quot;name&quot;, &quot;Sucre&quot;));</div><div class="line"> System.out.println(&quot;=============A&quot; + criteria.list());</div><div class="line"> System.out.println(&quot;=============B&quot; + criteria.list()); // B</div><div class="line"> criteria.add(Restrictions.eq(&quot;id&quot;, 1));</div><div class="line"> System.out.println(&quot;=============C&quot; + criteria.list());</div><div class="line"> criteria = session.createCriteria(UserModel.class);</div><div class="line"> criteria.setCacheable(true);</div><div class="line"> criteria.add(Restrictions.eq(&quot;id&quot;, 1));</div><div class="line"> System.out.println(&quot;=============D&quot; + criteria.list());</div><div class="line"> session = hibernateTemplate.getSessionFactory().openSession();</div><div class="line"> criteria = session.createCriteria(UserModel.class);</div><div class="line"> criteria.setCacheable(true);</div><div class="line"> criteria.add(Restrictions.eq(&quot;id&quot;, 1));</div><div class="line"> System.out.println(&quot;=============E&quot; + criteria.list());</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">/**</div><div class="line"> * 测试查询缓存 &lt;br&gt;</div><div class="line"> * 1. BC两处都是使用的A产生的缓存，作用于SessionFactory &lt;br&gt;</div><div class="line"> * 2. 配置文件中打开query_cache的前提下，setCacheable 是起作用的</div><div class="line"> */</div><div class="line">@Test</div><div class="line">public void testQueryInCache() &#123;</div><div class="line"> System.out.println(&quot;=============&quot;);</div><div class="line"> Session session = hibernateTemplate.getSessionFactory().openSession();</div><div class="line"> Query query = session</div><div class="line">   .createQuery(&quot;select u.name from UserModel as u where u.id=?&quot;);</div><div class="line"> query.setParameter(0, 1);</div><div class="line"> query.setCacheable(true);</div><div class="line"> String name = (String) query.list().get(0);</div><div class="line"> System.out.println(&quot;=============A&quot; + name); // A</div><div class="line"> query = session</div><div class="line">   .createQuery(&quot;select u.name from UserModel as u where u.id=?&quot;);</div><div class="line"> query.setParameter(0, 1);</div><div class="line"> query.setCacheable(true);</div><div class="line"> name = (String) query.list().get(0);</div><div class="line"> System.out.println(&quot;=============B&quot; + name); // B</div><div class="line"> session = hibernateTemplate.getSessionFactory().openSession();</div><div class="line"> query = session</div><div class="line">   .createQuery(&quot;select u.name from UserModel as u where u.id=?&quot;);</div><div class="line"> query.setParameter(0, 1);</div><div class="line"> query.setCacheable(true);</div><div class="line"> name = (String) query.list().get(0);</div><div class="line"> System.out.println(&quot;=============C&quot; + name); // C</div><div class="line">&#125;</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      Hibernate缓存 查询缓存
    
    </summary>
    
      <category term="hibernate" scheme="http://jishusuishouji.github.io/categories/hibernate/"/>
    
    
      <category term="hibernate" scheme="http://jishusuishouji.github.io/tags/hibernate/"/>
    
  </entry>
  
  <entry>
    <title>hibernate的查询缓存</title>
    <link href="http://jishusuishouji.github.io/2017/03/30/hibernate/hibernate%E7%9A%84%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98/"/>
    <id>http://jishusuishouji.github.io/2017/03/30/hibernate/hibernate的查询缓存/</id>
    <published>2017-03-30T05:47:52.000Z</published>
    <updated>2017-03-30T05:56:50.612Z</updated>
    
    <content type="html"><![CDATA[<p>hibernate的查询缓存主要是针对普通属性结果集的缓存，而对于实体对象的结果集只缓存id。在一级缓存,二级缓存和查询缓存都打开的情况下做查询操作时这样的：查询普通属性，会先到查询缓存中取，如果没有，则查询数据库；查询实体，会先到查询缓存中取id，如果有，则根据id到缓存(一级/二级)中取实体，如果缓存中取不到实体，再查询数据库。<br> 和一级/二级缓存不同，查询缓存的生命周期是不确定的，当前关联的表发生改变时，查询缓存的生命周期结束。<br><a id="more"></a><br>查询缓存的配置和使用也是很简单的：<br>1&gt;查询缓存的启用不但要在配置文件中进行配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;property name=&quot;hibernate.cache.use_query_cache&quot;&gt;true&lt;/property&gt;</div></pre></td></tr></table></figure></p>
<p>2&gt;还要在程序中显示的进行启用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">query.setCacheable(true);</div></pre></td></tr></table></figure></p>
<p>1&gt;查询缓存的启用不但要在配置文件中进行配置 ——-换成spring配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line">&lt;bean id=&quot;propertyConfigurer&quot; class=&quot;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer&quot;&gt;</div><div class="line">    &lt;property name=&quot;locations&quot;&gt;</div><div class="line">        &lt;list&gt;</div><div class="line">            &lt;value&gt;/WEB-INF/config/jdbc.properties&lt;/value&gt;</div><div class="line">        &lt;/list&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/bean&gt;</div><div class="line">&lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt;</div><div class="line">    &lt;property name=&quot;driverClass&quot; value=&quot;$&#123;jdbc.driverClassName&#125;&quot; /&gt;</div><div class="line">    &lt;property name=&quot;jdbcUrl&quot; value=&quot;$&#123;jdbc.url&#125;&quot; /&gt;</div><div class="line">    &lt;property name=&quot;user&quot; value=&quot;$&#123;jdbc.username&#125;&quot; /&gt;</div><div class="line">    &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot; /&gt;</div><div class="line">    &lt;property name=&quot;autoCommitOnClose&quot; value=&quot;true&quot;/&gt;</div><div class="line">    &lt;property name=&quot;checkoutTimeout&quot; value=&quot;$&#123;cpool.checkoutTimeout&#125;&quot;/&gt;</div><div class="line">    &lt;property name=&quot;initialPoolSize&quot; value=&quot;$&#123;cpool.minPoolSize&#125;&quot;/&gt;</div><div class="line">    &lt;property name=&quot;minPoolSize&quot; value=&quot;$&#123;cpool.minPoolSize&#125;&quot;/&gt;</div><div class="line">    &lt;property name=&quot;maxPoolSize&quot; value=&quot;$&#123;cpool.maxPoolSize&#125;&quot;/&gt;</div><div class="line">    &lt;property name=&quot;maxIdleTime&quot; value=&quot;$&#123;cpool.maxIdleTime&#125;&quot;/&gt;</div><div class="line">    &lt;property name=&quot;acquireIncrement&quot; value=&quot;$&#123;cpool.acquireIncrement&#125;&quot;/&gt;</div><div class="line">    &lt;property name=&quot;maxIdleTimeExcessConnections&quot; value=&quot;$&#123;cpool.maxIdleTimeExcessConnections&#125;&quot;/&gt;</div><div class="line">&lt;/bean&gt;</div><div class="line">&lt;bean id=&quot;sessionFactory&quot; class=&quot;org.springframework.orm.hibernate3.LocalSessionFactoryBean&quot;&gt;</div><div class="line">    &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;    </div><div class="line">    &lt;property name=&quot;mappingLocations&quot;&gt;</div><div class="line">        &lt;list&gt;</div><div class="line">            &lt;value&gt;classpath*:/com/jeecms/core/entity/hbm/*.hbm.xml&lt;/value&gt;</div><div class="line">            &lt;value&gt;classpath*:/com/jeecms/cms/entity/main/hbm/*.hbm.xml&lt;/value&gt;</div><div class="line">            &lt;value&gt;classpath*:/com/jeecms/cms/entity/assist/hbm/*.hbm.xml&lt;/value&gt;</div><div class="line">        &lt;/list&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property name=&quot;hibernateProperties&quot;&gt;</div><div class="line">        &lt;value&gt;</div><div class="line">        hibernate.dialect=org.hibernate.dialect.MySQLInnoDBDialect</div><div class="line">        hibernate.show_sql=false</div><div class="line">        hibernate.format_sql=false</div><div class="line">        hibernate.query.substitutions=true 1, false 0</div><div class="line">        hibernate.jdbc.batch_size=20</div><div class="line">        //查询缓存配置</div><div class="line">        hibernate.cache.use_query_cache=true</div><div class="line">        &lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property name=&quot;entityInterceptor&quot;&gt;   </div><div class="line">        &lt;ref local=&quot;treeInterceptor&quot;/&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property name=&quot;cacheProvider&quot;&gt;</div><div class="line">        &lt;ref local=&quot;cacheProvider&quot;/&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property name=&quot;lobHandler&quot;&gt;</div><div class="line">        &lt;ref bean=&quot;lobHandler&quot; /&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/bean&gt;</div></pre></td></tr></table></figure></p>
<p>2&gt;还要在程序中显示的进行启用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">public List&lt;CmsSite&gt; getList(boolean cacheable) &#123;</div><div class="line">        String hql = &quot;from CmsSite bean order by bean.id asc&quot;;</div><div class="line">        return getSession().createQuery(hql).setCacheable(cacheable).list();</div><div class="line">    &#125;</div></pre></td></tr></table></figure></p>
<h2 id="1-实体类："><a href="#1-实体类：" class="headerlink" title="1.实体类："></a>1.实体类：</h2><pre><code>public class Student { 
  private Integer id; 
  private String name; 
  //一系列的setter.getter方法 
}
</code></pre><p>##2.映射文件</p>
<p>Student.hbm.xml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&lt;class name=&quot;com.sxt.hibernate.cache.entity.Student&quot; table=&quot;sxt_hibernate_student&quot;&gt; </div><div class="line">       </div><div class="line">  &lt;!-- 指定本类的对象使用二级缓存(这也可以放在hibernate.cfg.xml中统一指定) --&gt; </div><div class="line">  &lt;!-- </div><div class="line">  &lt;cache usage=&quot;read-only&quot;/&gt; </div><div class="line">   --&gt; </div><div class="line">  &lt;id name=&quot;id&quot; length=&quot;4&quot;&gt; </div><div class="line">    &lt;generator class=&quot;native&quot;&gt;&lt;/generator&gt; </div><div class="line">  &lt;/id&gt; </div><div class="line">  &lt;property name=&quot;name&quot; length=&quot;10&quot;&gt;&lt;/property&gt; </div><div class="line">&lt;/class&gt;</div></pre></td></tr></table></figure></p>
<h2 id="3-hibernate配置文件："><a href="#3-hibernate配置文件：" class="headerlink" title="3.hibernate配置文件："></a>3.hibernate配置文件：</h2><p>hibernate.cfg.xml</p>
<pre><code>&lt;hibernate-configuration&gt; 
  &lt;session-factory&gt; 
    &lt;property name=&quot;hibernate.connection.url&quot;&gt;jdbc:oracle:thin:@localhost:1521:ORCL10&lt;/property&gt;
    &lt;property name=&quot;hibernate.connection.driver_class&quot;&gt;oracle.jdbc.driver.OracleDriver&lt;/property&gt; 
    &lt;property name=&quot;hibernate.connection.username&quot;&gt;scott&lt;/property&gt; 
    &lt;property name=&quot;hibernate.connection.password&quot;&gt;yf123&lt;/property&gt; 
    &lt;property name=&quot;hibernate.dialect&quot;&gt;org.hibernate.dialect.Oracle9Dialect&lt;/property&gt; 
    &lt;property name=&quot;hibernate.show_sql&quot;&gt;true&lt;/property&gt; 

    &lt;!-- 开启二级缓存,其实hibernate默认就是开启的,这里显示的指定一下 --&gt; 
    &lt;property name=&quot;hibernate.cache.use_second_level_cache&quot;&gt;true&lt;/property&gt; 
    &lt;!-- 指定二级缓存产品的提供商 --&gt; 
    &lt;property name=&quot;hibernate.cache.provider_class&quot;&gt;org.hibernate.cache.EhCacheProvider&lt;/property&gt; 

    &lt;!-- 启用查询缓存 --&gt; 
    &lt;property name=&quot;hibernate.cache.use_query_cache&quot;&gt;true&lt;/property&gt; 

    &lt;mapping resource=&quot;com/sxt/hibernate/cache/entity/Student.hbm.xml&quot;/&gt; 

    &lt;!-- 指定那些类使用二级缓存 --&gt; 
    &lt;class-cache usage=&quot;read-only&quot; class=&quot;com.sxt.hibernate.cache.entity.Student&quot;/&gt; 
  &lt;/session-factory&gt; 
&lt;/hibernate-configuration&gt;
</code></pre><h2 id="4-测试方法："><a href="#4-测试方法：" class="headerlink" title="4.测试方法："></a>4.测试方法：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">public static void main(String[] args) &#123; </div><div class="line">  Session session = null; </div><div class="line">  Transaction t = null; </div><div class="line"></div><div class="line">  *//** </div><div class="line">   * 开启查询缓存,关闭二级缓存, 开启一个session,分别调用query.list </div><div class="line">   */ </div><div class="line">//如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. </div><div class="line">/* </div><div class="line">  try &#123; </div><div class="line">    session = HibernateUtils.getSession(); </div><div class="line">    t = session.beginTransaction(); </div><div class="line">    Query query = session.createQuery(&quot;select s.name from Student s&quot;); </div><div class="line">    //启用查询缓存    </div><div class="line">    query.setCacheable(true); </div><div class="line">    List&lt;String&gt; names = query.list(); </div><div class="line">    for (Iterator&lt;String&gt; it = names.iterator(); it.hasNext();) &#123; </div><div class="line">      String name = it.next(); </div><div class="line">      System.out.println(name); </div><div class="line">    &#125; </div><div class="line">    System.out.println(&quot;================================&quot;); </div><div class="line">    query = session.createQuery(&quot;select s.name from Student s&quot;); </div><div class="line">    //启用查询缓存 </div><div class="line">    query.setCacheable(true); </div><div class="line">    //没有发出查询语句,因为这里使用的查询缓存 </div><div class="line">    names = query.list(); </div><div class="line">    for (Iterator&lt;String&gt; it = names.iterator(); it.hasNext();) &#123; </div><div class="line">      String name = it.next(); </div><div class="line">      System.out.println(name); </div><div class="line">    &#125; </div><div class="line">    t.commit(); </div><div class="line">  &#125; catch (Exception e) &#123; </div><div class="line">    e.printStackTrace(); </div><div class="line">    t.rollback(); </div><div class="line">  &#125; finally &#123; </div><div class="line">    HibernateUtils.closeSession(session); </div><div class="line">  &#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line">@SuppressWarnings(&quot;unchecked&quot;) </div><div class="line">public static void main(String[] args) &#123; </div><div class="line">  Session session = null; </div><div class="line">  Transaction t = null; </div><div class="line"></div><div class="line">  *//** </div><div class="line">   * 开启查询缓存,关闭二级缓存, 开启两个session,分别调用query.list </div><div class="line">   *//* </div><div class="line">  //如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. </div><div class="line">  try &#123; </div><div class="line">    session = HibernateUtils.getSession(); </div><div class="line">    t = session.beginTransaction(); </div><div class="line">    Query query = session.createQuery(&quot;select s.name from Student s&quot;); </div><div class="line">    //启用查询缓存    </div><div class="line">    //query.setCacheable(true); </div><div class="line">    List&lt;String&gt; names = query.list(); </div><div class="line">    for (Iterator&lt;String&gt; it = names.iterator(); it.hasNext();) &#123; </div><div class="line">      String name = it.next(); </div><div class="line">      System.out.println(name); </div><div class="line">    &#125; </div><div class="line"></div><div class="line">    t.commit(); </div><div class="line">  &#125; catch (Exception e) &#123; </div><div class="line">    e.printStackTrace(); </div><div class="line">    t.rollback(); </div><div class="line">  &#125; finally &#123; </div><div class="line">    HibernateUtils.closeSession(session); </div><div class="line">  &#125; </div><div class="line">   </div><div class="line">  System.out.println(&quot;================================&quot;); </div><div class="line">   </div><div class="line">  try &#123; </div><div class="line">    session = HibernateUtils.getSession(); </div><div class="line">    t = session.beginTransaction(); </div><div class="line">    Query query = session.createQuery(&quot;select s.name from Student s&quot;); </div><div class="line">    //启用查询缓存    </div><div class="line">    //query.setCacheable(true); </div><div class="line">    //不会发出查询语句,因为查询缓存和session无关. </div><div class="line">    List&lt;String&gt; names = query.list(); </div><div class="line">    for (Iterator&lt;String&gt; it = names.iterator(); it.hasNext();) &#123; </div><div class="line">      String name = it.next(); </div><div class="line">      System.out.println(name); </div><div class="line">    &#125; </div><div class="line">    t.commit(); </div><div class="line">  &#125; catch (Exception e) &#123; </div><div class="line">    e.printStackTrace(); </div><div class="line">    t.rollback(); </div><div class="line">  &#125; finally &#123; </div><div class="line">    HibernateUtils.closeSession(session); </div><div class="line">  &#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line">@SuppressWarnings(&quot;unchecked&quot;) </div><div class="line">public static void main(String[] args) &#123; </div><div class="line">  Session session = null; </div><div class="line">  Transaction t = null; </div><div class="line"></div><div class="line">  *//** </div><div class="line">   * 开启查询缓存,关闭二级缓存, 开启两个session,分别调用query.iterate </div><div class="line">   *//* </div><div class="line">  //如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. </div><div class="line">  try &#123; </div><div class="line">    session = HibernateUtils.getSession(); </div><div class="line">    t = session.beginTransaction(); </div><div class="line">    Query query = session.createQuery(&quot;select s.name from Student s&quot;); </div><div class="line">    //启用查询缓存    </div><div class="line">    query.setCacheable(true); </div><div class="line">    for (Iterator&lt;String&gt; it = query.iterate(); it.hasNext();) &#123; </div><div class="line">      String name = it.next(); </div><div class="line">      System.out.println(name); </div><div class="line">    &#125; </div><div class="line">    t.commit(); </div><div class="line">  &#125; catch (Exception e) &#123; </div><div class="line">    e.printStackTrace(); </div><div class="line">    t.rollback(); </div><div class="line">  &#125; finally &#123; </div><div class="line">    HibernateUtils.closeSession(session); </div><div class="line">  &#125; </div><div class="line">   </div><div class="line">  System.out.println(&quot;================================&quot;); </div><div class="line">   </div><div class="line">  try &#123; </div><div class="line">    session = HibernateUtils.getSession(); </div><div class="line">    t = session.beginTransaction(); </div><div class="line">    Query query = session.createQuery(&quot;select s.name from Student s&quot;); </div><div class="line">    //启用查询缓存    </div><div class="line">    query.setCacheable(true); </div><div class="line">    //会发出查询语句,因为query.iterate不使用查询缓存 </div><div class="line">    for (Iterator&lt;String&gt; it = query.iterate(); it.hasNext();) &#123; </div><div class="line">      String name = it.next(); </div><div class="line">      System.out.println(name); </div><div class="line">    &#125; </div><div class="line">    t.commit(); </div><div class="line">  &#125; catch (Exception e) &#123; </div><div class="line">    e.printStackTrace(); </div><div class="line">    t.rollback(); </div><div class="line">  &#125; finally &#123; </div><div class="line">    HibernateUtils.closeSession(session); </div><div class="line">  &#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>```<br>  @SuppressWarnings(“unchecked”)<br>  public static void main(String[] args) {<br>    Session session = null;<br>    Transaction t = null; </p>
<pre><code>*//** 
 * 关闭查询缓存,关闭二级缓存, 开启两个session,分别调用query.list查询实体对象 
 *//* 
//如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. 
try { 
  session = HibernateUtils.getSession(); 
  t = session.beginTransaction(); 
  Query query = session.createQuery(&quot;select s from Student s&quot;); 
  //启用查询缓存    
  //query.setCacheable(true); 
  List&lt;Student&gt; students = query.list(); 
  for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { 
    Student s = it.next(); 
    System.out.println(s.getName()); 
  } 
  t.commit(); 
} catch (Exception e) { 
  e.printStackTrace(); 
  t.rollback(); 
} finally { 
  HibernateUtils.closeSession(session); 
} 

System.out.println(&quot;================================&quot;); 

try { 
  session = HibernateUtils.getSession(); 
  t = session.beginTransaction(); 
  Query query = session.createQuery(&quot;select s from Student s&quot;); 
  //启用查询缓存    
  //query.setCacheable(true); 
  //会发出查询语句,因为list默认每次都会发出sql语句 
  List&lt;Student&gt; students = query.list(); 
  for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { 
    Student s = it.next(); 
    System.out.println(s.getName()); 
  } 
  t.commit(); 
} catch (Exception e) { 
  e.printStackTrace(); 
  t.rollback(); 
} finally { 
  HibernateUtils.closeSession(session); 
} 
</code></pre><p>  }*/ </p>
<p>/*  @SuppressWarnings(“unchecked”)<br>  public static void main(String[] args) {<br>    Session session = null;<br>    Transaction t = null; </p>
<pre><code>*//** 
 * 开启查询缓存,关闭二级缓存, 开启两个session,分别调用query.list查询实体对象 
 *//* 
//如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. 
try { 
  session = HibernateUtils.getSession(); 
  t = session.beginTransaction(); 
  Query query = session.createQuery(&quot;select s from Student s&quot;); 
  //启用查询缓存    
  query.setCacheable(true); 
  List&lt;Student&gt; students = query.list(); 
  for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { 
    Student s = it.next(); 
    System.out.println(s.getName()); 
  } 
  t.commit(); 
} catch (Exception e) { 
  e.printStackTrace(); 
  t.rollback(); 
} finally { 
  HibernateUtils.closeSession(session); 
} 

System.out.println(&quot;================================&quot;); 

try { 
  session = HibernateUtils.getSession(); 
  t = session.beginTransaction(); 
  Query query = session.createQuery(&quot;select s from Student s&quot;); 
  //启用查询缓存    
  query.setCacheable(true); 
  //会发出根据id查询实体的n条查询语句,因为这种情况下,查询过程是这样的： 
  // 在第一次执行list时,会把查询对象的id缓存到查询缓存里 
  // 第二次执行list时, 会遍历查询缓存里的id到缓存里去找实体对象,由于这里没找到实体对象, 
  //所以就发出n条查询语句到数据库中查询. 
  List&lt;Student&gt; students = query.list(); 
  for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { 
    Student s = it.next(); 
    System.out.println(s.getName()); 
  } 
  t.commit(); 
} catch (Exception e) { 
  e.printStackTrace(); 
  t.rollback(); 
} finally { 
  HibernateUtils.closeSession(session); 
} 
</code></pre><p>  }*/ </p>
<p>  @SuppressWarnings(“unchecked”)<br>  public static void main(String[] args) {<br>    Session session = null;<br>    Transaction t = null; </p>
<pre><code>/** 
 * 开启查询缓存,开启二级缓存, 开启两个session,分别调用query.list查询实体对象 
 */ 
//如果不用查询缓存的话,那两个都发出查询语句,这也是默认的情况. 
try { 
  session = HibernateUtils.getSession(); 
  t = session.beginTransaction(); 
  Query query = session.createQuery(&quot;select s from Student s&quot;); 
  //启用查询缓存    
  query.setCacheable(true); 
  List&lt;Student&gt; students = query.list(); 
  for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { 
    Student s = it.next(); 
    System.out.println(s.getName()); 
  } 
  t.commit(); 
} catch (Exception e) { 
  e.printStackTrace(); 
  t.rollback(); 
} finally { 
  HibernateUtils.closeSession(session); 
} 

System.out.println(&quot;================================&quot;); 

try { 
  session = HibernateUtils.getSession(); 
  t = session.beginTransaction(); 
  Query query = session.createQuery(&quot;select s from Student s&quot;); 
  //启用查询缓存    
  query.setCacheable(true); 
  //不会发出查询语句,因为这种情况下,查询过程是这样的： 
  // 在第一次执行list时,会把查询对象的id缓存到查询缓存里 
  // 第二次执行list时, 会遍历查询缓存里的id到缓存里去找实体对象,由于这里开启了二级缓存,可以找到目标实体对象, 
  //所以就不会再发出n条查询语句. 
  List&lt;Student&gt; students = query.list(); 
  for (Iterator&lt;Student&gt; it = students.iterator(); it.hasNext();) { 
    Student s = it.next(); 
    System.out.println(s.getName()); 
  } 
  t.commit(); 
} catch (Exception e) { 
  e.printStackTrace(); 
  t.rollback(); 
} finally { 
  HibernateUtils.closeSession(session); 
} 
</code></pre><p>  }</p>
]]></content>
    
    <summary type="html">
    
      hibernate的查询缓存
    
    </summary>
    
      <category term="hibernate" scheme="http://jishusuishouji.github.io/categories/hibernate/"/>
    
    
      <category term="hibernate" scheme="http://jishusuishouji.github.io/tags/hibernate/"/>
    
  </entry>
  
  <entry>
    <title>Layout of Log4j</title>
    <link href="http://jishusuishouji.github.io/2017/03/28/Log4j/Layout_of_Log4j/"/>
    <id>http://jishusuishouji.github.io/2017/03/28/Log4j/Layout_of_Log4j/</id>
    <published>2017-03-28T07:02:00.000Z</published>
    <updated>2017-03-28T07:03:46.667Z</updated>
    
    <content type="html"><![CDATA[<p>本文档使用Log4j版本为1.2.17</p>
<h2 id="1-Layout介绍"><a href="#1-Layout介绍" class="headerlink" title="1. Layout介绍"></a>1. Layout介绍</h2><p>Log4j Layout主要用来控制日志的序列化格式，比如时间、线程号、日志消息对齐方式等，是log4j体系结构中的核心组成部分之一。</p>
<p>Layout抽象类声明为:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">public abstract class Layout implements OptionHandler</div></pre></td></tr></table></figure></p>
<p><code>Layout</code>实现了<code>OptionHandler</code>接口，<code>OptionHandler</code>仅包含一个方法<code>activateOptions()</code>。对实现了<code>OptionHandler</code>接口的模块，调用属性<code>setter</code>方法后，log4j的配置器类会调用此模块的<code>activateOptions</code>实现以激活配置。<code>OptionHandler</code>存在的原因是有些属性彼此依赖，在它们在全部加载完成之前是无法激活的，这个方法用于在模块变为激活和就绪之前用来执行任何必要任务的机制。比如：</p>
<p>某模块有字符串属性fileName属性，表示log4j用户配置的写出日志文件名，使用前需要创建File对象获取文件写出IO流，具体则是由activateOptions完成文件的打开等，具体可见log4j的FileAppender实现中对文件名和文件IO的操作。</p>
<p>Layout类的方法或接口如下，abstract修饰的需要具体子类实现:</p>
<p>//abstract修饰需要具体子类实现，将日志事件渲染为待打印的日志文本字符串，可写出到Appender<br>abstract  public  String format(LoggingEvent event )<br>//format函数返回的格式化文本类型，默认返回为”text/plain”<br>public String getContentType()<br>//针对HTMLLayout类的格式化输出，html字符串的头部，默认null<br>public String getHeader()<br>//针对HTMLLayout类的格式化输出，html字符串的尾部，默认null<br>public String getFooter()<br>//对于LayoutEvent中异常的处理模式，true表示忽略异常，异常会到达Appender，由Appender负责渲染为打印持久化字符串信息；false表示由Layout负责渲染异常信息。SimpleLayout、TTCCLayout、PatternLayout实现返回true;XMLLayout实现返回false，由Appender处理渲染异常消息。<br>abstract public boolean ignoresThrowable()<br>Layout是对序列化每一次LoggingEvent的抽象，核心是format方法，format作为抽象方法，由具体子类实现具体的序列化方式。具体子类有：</p>
<p>SimpleLayout<br>TTCCLayout<br>PatternLayout<br>XMLLayout<br>HTMLLayout<br>DateLayout<br>Layout继承体系</p>
<ol>
<li>XMLLayout</li>
</ol>
<p>XMLLayout实现了根据log4j.dtd序列化输出xml格式的日志文本，默认的log4j.dtd文件在/org/apache/log4j/xml/log4j.dtd目录下，注意，XMLLayout打印输出的并非完整XML文件，并不包括&lt;?xml version=”1.0” ?&gt;等XML头部，XMLLayout的目的是输出XML的部分片段，应用可将此片段整合嵌入到其它XML文件中。XMLLayout有成员属性：<br>locationInfo表示是否打印位置信息，即日志事件发生的代码文件名、日志记录点代码行号等信息，log4j配置文件中需要配置为LocationInfo<br>properties表示是否打印MDC中的Key-Value信息，默认为false，log4j配置文件中需要配置为Properties</p>
<p>注意：log4j的各个模块涉及的成员属性时，如果属性有set方法，一般表示此属性可通过log4j.properties进行配置，具体配置属性值为属性的setXXX方法去掉set前缀。</p>
<p>示例如上面的locationInfo和properties配置:</p>
<p>log4j.appender.Console.layout.LocationInfo=true<br>log4j.appender.Console.layout.Properties=true</p>
<p>XMLLayout继承自Layout的方法实现有：</p>
<p>//配置激活的接口实现，来自于OptionHandler interface，方法体为空<br>public void activateOptions()<br>//返回false，表示XMLLayout自己处理异常信息<br>public boolean ignoresThrowable()<br>public String format( final LoggingEvent event)<br>2.1 format实现</p>
<p>format按照日志message、NDC、getThrowableStrRep、日志位置信息、MDC的顺序，并按照XML格式序列化LoggingEvent。log4j实现时使用StringBuffer避免字符串拼接的开销（JAVA中String是不可变类），具体使用时设置了StringBuffer的默认长度即DEFAULT_SIZE = 256，最大长度UPPER_LIMIT = 2048。每次format函数调用时，如果当前StringBuffer容量未超过上限，则复用已有的StringBuffer并清空已有内容；如果当前StringBuffer容量超过UPPER_LIMIT上限，则创建一个新的StringBuffer将当前LoggingEvent 序列化到其中，目的是尽量减少内存的占用量。</p>
<p>if(buf.capacity() &gt; UPPER_LIMIT) {<br>  buf = new StringBuffer(DEFAULT_SIZE);<br>} else {<br>  buf.setLength(0);<br>}<br>xml序列化中，对于属性如 timestamp=”1452874282177” level=“INFO”，为了保持生成的文本符合XML语法，需要对特殊字符进行转义处理。对于属性使用org.apache.log4j.helpers.Transform.escapeTags做转义。对于文本子元素如 <log4j:message>&lt;![CDATA[123]]&gt;</log4j:message>，使用org.apache.log4j.helpers.Transform.appendEscapingCDATA做转义，将message放在 &lt;![CDATA[ 和 ]] 之间，避免文本破坏XML语法。</p>
<p>处理的XML特殊字符有（简单字符串替换）:</p>
<blockquote>
<p>-&gt; &gt;<br>&lt; -&gt; &lt;<br>&amp; -&gt; &amp;<br>“ -&gt; &quot;<br>2.2 demo</p>
</blockquote>
<p>demo java code:</p>
<p>Logger logger = Logger.getLogger(LayoutTest.class);<br>NDC.push(“ndc message”);<br>logger.info(“info:123”);<br>logger.warn(“warn:abc”);<br>logger.info(“exception”, new RuntimeException(“run time exception”));<br>demo log4j config:</p>
<p>log4j.rootLogger=INFO,Console<br>log4j.appender.Console=org.apache.log4j.ConsoleAppender<br>log4j.appender.Console.target=System.out<br>log4j.appender.Console.layout=org.apache.log4j.xml.XMLLayout<br>log4j.appender.Console.layout.LocationInfo=true<br>log4j.appender.Console.layout.Properties=true</p>
<p>demo 日志输出:</p>
<p><log4j:event logger="com.luohw.log4j.LayoutTest" timestamp="1459227960659" level="INFO" thread="main"></log4j:event></p>
<p><log4j:message>&lt;![CDATA[info:123]]&gt;</log4j:message></p>
<p><log4j:ndc>&lt;![CDATA[ndc message]]&gt;</log4j:ndc></p>
<p><log4j:locationinfo class="com.luohw.log4j.LayoutTest" method="test" file="LayoutTest.java" line="13"><br></log4j:locationinfo></p>
<p><log4j:event logger="com.luohw.log4j.LayoutTest" timestamp="1459227960670" level="WARN" thread="main"></log4j:event></p>
<p><log4j:message>&lt;![CDATA[warn:abc]]&gt;</log4j:message></p>
<p><log4j:ndc>&lt;![CDATA[ndc message]]&gt;</log4j:ndc></p>
<p><log4j:locationinfo class="com.luohw.log4j.LayoutTest" method="test" file="LayoutTest.java" line="14"><br></log4j:locationinfo></p>
<p><log4j:event logger="com.luohw.log4j.LayoutTest" timestamp="1459227960670" level="ERROR" thread="main"></log4j:event></p>
<p><log4j:message>&lt;![CDATA[error:xyz]]&gt;</log4j:message></p>
<p><log4j:ndc>&lt;![CDATA[ndc message]]&gt;</log4j:ndc></p>
<p><log4j:locationinfo class="com.luohw.log4j.LayoutTest" method="test" file="LayoutTest.java" line="15"><br></log4j:locationinfo></p>
<p><log4j:event logger="com.luohw.log4j.LayoutTest" timestamp="1459227960671" level="INFO" thread="main"></log4j:event></p>
<p><log4j:message>&lt;![CDATA[exception]]&gt;</log4j:message></p>
<p><log4j:ndc>&lt;![CDATA[ndc message]]&gt;</log4j:ndc></p>
<p><log4j:throwable>&lt;![CDATA[java.lang.RuntimeException: run time exception<br>at com.luohw.log4j.LayoutTest.test(LayoutTest.java:16)<br>at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<br>at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)<br>… …<br>at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)<br>at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)<br>]]&gt;</log4j:throwable></p>
<p><log4j:locationinfo class="com.luohw.log4j.LayoutTest" method="test" file="LayoutTest.java" line="16"><br></log4j:locationinfo></p>
<ol>
<li>HTMLLayout</li>
</ol>
<p>HTMLLayout用于将每次的LoggingEvent序列化为HTML格式字符串，具体的内容组织为html的表格。生成的HTML文本为完整的一份HTML格式代码（不同于XMLLayout的部分片段），包含html、head、body、具体table信息等。一份HTML日志文档可以包含多条LoggingEvent序列化输出，但header和footer只会输出一次（具体是有Appender打开和关闭相关流时输出）。</p>
<p>注意：如果有Appender使用HTMLLayout，需要设置Appender的字符编码为UTF-8 或者 UTF-16，否则非ASCII字符会产生乱码。</p>
<p>locationInfo表示是否打印位置信息，即日志事件发生的代码文件名、代码行号，log4j配置文件中需要配置为LocationInfo</p>
<p>title输出html文档head的title部分，默认为Log4J Log Messages，log4j配置文件中需要配置为Title</p>
<p>XMLLayout继承自Layout的方法实现有：</p>
<p>//默认返回”text/html”<br>public String getContentType()<br>//配置加载完成后操作，实现为空<br>public void activateOptions()<br>//返回相应HTML头部部分，具体是html、head、title以及body、table的开始部分<br>public String getHeader()<br>//返回相应html尾部，具体是table、body、html的html闭合标签<br>public String getFooter()<br>//返回false，即由HTMLLayout本身处理异常信息格式化，HTMLLayout有成员函数appendThrowableAsHTML，具体是将Throwable对应的字符串做相关转移和替换处理，以符合html语法<br>public boolean ignoresThrowable()<br>//具体序列化LoggingEvent为字符串<br>public String format(LoggingEvent event)<br>3.1 format实现</p>
<p>a.  缓冲StringBuffer更新，判断容量是否超过HTMLLayout的MAX_CAPACITY(1024)，如果超过则创建新的StringBuffer，否则复用原有的StringBuffer，避免内存浪费，具体和XMLLayout原理一致。<br>b.  输出时间、线程、Level等上下文信息，根据locationInfo（如果locationInfo为true）、Level等具体字符串拼接和格式化</p>
<tr><br><td>0</td><br><td title="main thread">main</td><br><td title="Level">INFO</td><br><td title="com.luohw.log4j.LayoutTest category">com.luohw.log4j.LayoutTest</td><br><td>LayoutTest.java:12</td><br><td title="Message">info:123</td><br></tr>

<p>c. 输出NDC信息</p>
<tr><td bgcolor="#EEEEEE" style="font-size : xx-small;" colspan="6" title="Nested Diagnostic Context">NDC: ndc message</td></tr>

<p>d. 如果有则输出异常栈信息，一般Logger的日志函数info、warn、error等都有带Throwable型参的重载<br>e. 没有MDC相关信息的格式化输出</p>
<p>3.2 demo</p>
<p>demo java code:</p>
<p>Logger logger = Logger.getLogger(LayoutTest.class);<br>NDC.push(“ndc message”);<br>logger.info(“info:123”);<br>logger.warn(“warn:abc”);<br>logger.error(“error:xyz”);<br>logger.info(“exception”, new RuntimeException(“run time exception”));<br>demo log4j config:</p>
<p>log4j.rootLogger=INFO,Console<br>log4j.appender.Console=org.apache.log4j.ConsoleAppender<br>log4j.appender.Console.target=System.out<br>log4j.appender.Console.layout=org.apache.log4j.HTMLLayout<br>log4j.appender.Console.layout.LocationInfo=true<br>log4j.appender.Console.layout.Title=luohw@log4j</p>
<p>demo浏览器打开日志输出html:</p>
<p>html</p>
<p>see more …</p>
]]></content>
    
    <summary type="html">
    
      Layout of Log4j
    
    </summary>
    
      <category term="Log4j" scheme="http://jishusuishouji.github.io/categories/Log4j/"/>
    
    
      <category term="Log4j" scheme="http://jishusuishouji.github.io/tags/Log4j/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB两阶段提交实现事务</title>
    <link href="http://jishusuishouji.github.io/2017/03/27/mongodb/MongoDB%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E5%AE%9E%E7%8E%B0%E4%BA%8B%E5%8A%A1/"/>
    <id>http://jishusuishouji.github.io/2017/03/27/mongodb/MongoDB两阶段提交实现事务/</id>
    <published>2017-03-27T13:12:46.000Z</published>
    <updated>2017-03-29T10:15:06.559Z</updated>
    
    <content type="html"><![CDATA[<p> MongoDB数据库中操作单个文档总是原子性的，然而，涉及多个文档的操作，通常被作为一个“事务”，而不是原子性的。因为文档可以是相当复杂并且包含多个嵌套文档，单文档的原子性对许多实际用例提供了支持。尽管单文档操作是原子性的，在某些情况下，需要多文档事务。在这些情况下，使用两阶段提交，提供这些类型的多文档更新支持。因为文档可以表示为<code>Pending</code>数据和状态，可以使用一个两阶段提交确保数据是一致的，在一个错误的情况下，事务前的状态是可恢复的。</p>
<p>事务最常见的例子是以可靠的方式从A账户转账到B账户，在关系型数据库中，此操作将从A账户减掉金额和给B账户增加金额的操作封装在单个原子事务中。在MongoDB中，可以使用两阶段提交达到相同的效果。本文中的所有示例使用mongo shell与数据库进行交互,并假设有两个集合：首先，一个名为<code>accounts</code>的集合存储每个账户的文档数据，另一个名为<code>transactions</code>的集合存储事务本身。</p>
<p>首先创建两个名为A和B的账户，使用下面的命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">db.accounts.save(&#123;name: &quot;A&quot;, balance: 1000, pendingTransactions: []&#125;)</div><div class="line">db.accounts.save(&#123;name: &quot;B&quot;, balance: 1000, pendingTransactions: []&#125;)</div></pre></td></tr></table></figure></p>
<p>使用<code>find()</code>方法验证这两个操作已经成功：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.accounts.find()</div></pre></td></tr></table></figure></p>
<p>mongo会返回两个类似下面的文档：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc66cb8a04f512696151f&quot;), &quot;name&quot; : &quot;A&quot;, &quot;balance&quot; : 1000, &quot;pendingTransactions&quot; : [ ] &#125;</div><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc67bb8a04f5126961520&quot;), &quot;name&quot; : &quot;B&quot;, &quot;balance&quot; : 1000, &quot;pendingTransactions&quot; : [ ] &#125;</div></pre></td></tr></table></figure></p>
<h2 id="事务过程："><a href="#事务过程：" class="headerlink" title="事务过程："></a>事务过程：</h2><p>设置事务初始状态<code>initial</code>：</p>
<p>通过插入下面的文档创建transaction集合，transaction文档持有源(source)和目标(destination)，它们引用自<code>accounts</code>集合文档的字段名，以及<code>value</code>字段表示改变<code>balance</code>字段数量的数据。最后，<code>state</code>字段反映事务的当前状态。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.transactions.save(&#123;source: &quot;A&quot;, destination: &quot;B&quot;, value: 100, state: &quot;initial&quot;&#125;)</div></pre></td></tr></table></figure></p>
<p>验证这个操作已经成功，使用<code>find()</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.transactions.find()</div></pre></td></tr></table></figure></p>
<p>这个操作会返回一个类似下面的文档：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;), &quot;source&quot; : &quot;A&quot;, &quot;destination&quot; : &quot;B&quot;, &quot;value&quot; : 100, &quot;state&quot; : &quot;initial&quot; &#125;</div></pre></td></tr></table></figure></p>
<p>切换事务到Pending状态：<br>在修改accounts集合记录之前，将事务状态从initial设置为pending。使用<code>findOne()</code>方法将transaction文档赋值给shell会话中的局部变量t：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">t = db.transactions.findOne(&#123;state: &quot;initial&quot;&#125;)</div></pre></td></tr></table></figure></p>
<p>变量t创建后，shell将返回它的值，将会看到如下的输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;), &quot;source&quot; : &quot;A&quot;, &quot;destination&quot; : &quot;B&quot;, &quot;value&quot; : 100, &quot;state&quot; : &quot;initial&quot; &#125;</div></pre></td></tr></table></figure></p>
<p>使用<code>update()</code>改变<code>state</code>的值为<code>pending</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">db.transactions.update(&#123;_id: t._id&#125;, &#123;$set: &#123;state: &quot;pending&quot;&#125;&#125;)</div><div class="line">db.transactions.find()</div></pre></td></tr></table></figure></p>
<p><code>find()</code>操作将返回<code>transaction</code>集合的内容，类似下面：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;), &quot;source&quot; : &quot;A&quot;, &quot;destination&quot; : &quot;B&quot;, &quot;value&quot; : 100, &quot;state&quot; : &quot;pending&quot; &#125;</div></pre></td></tr></table></figure></p>
<h3 id="将事务应用到两个账户："><a href="#将事务应用到两个账户：" class="headerlink" title="将事务应用到两个账户："></a>将事务应用到两个账户：</h3><p>使用<code>update()</code>方法应用事务到两个账户。在<code>update()</code>查询中，条件<code>pendingTransactions:{$ne:t._id}</code>阻止事务更新账户，如果账户的pendingTransaction字段包含事务t的<code>_id</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">db.accounts.update(</div><div class="line">    &#123; name: t.source, pendingTransactions: &#123; $ne: t._id &#125; &#125;,</div><div class="line">    &#123; $inc: &#123; balance: -t.value &#125;, $push: &#123; pendingTransactions: t._id &#125; &#125;</div><div class="line">)</div><div class="line">db.accounts.update(</div><div class="line">    &#123; name: t.destination, pendingTransactions: &#123; $ne: t._id &#125; &#125;,</div><div class="line">    &#123; $inc: &#123; balance: t.value &#125;, $push: &#123; pendingTransactions: t._id &#125; &#125;</div><div class="line">)</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.accounts.find()</div></pre></td></tr></table></figure>
<p><code>find()</code>操作将返回accounts集合的内容，现在应该类似于下面的内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc97fb8a04f5126961523&quot;), &quot;balance&quot; : 900, &quot;name&quot; : &quot;A&quot;, &quot;pendingTransactions&quot; : [ ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;) ] &#125;</div><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc984b8a04f5126961524&quot;), &quot;balance&quot; : 1100, &quot;name&quot; : &quot;B&quot;, &quot;pendingTransactions&quot; : [ ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;) ] &#125;</div></pre></td></tr></table></figure></p>
<h3 id="设置事务状态为committed："><a href="#设置事务状态为committed：" class="headerlink" title="设置事务状态为committed："></a>设置事务状态为<code>committed</code>：</h3><p>使用下面的<code>update()</code>操作设置事务的状态为<code>committed</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">db.transactions.update(&#123;_id: t._id&#125;, &#123;$set: &#123;state: &quot;committed&quot;&#125;&#125;)</div><div class="line">db.transactions.find()</div></pre></td></tr></table></figure></p>
<p><code>find()</code>操作发回transactions集合的内容，现在应该类似下面的内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;), &quot;destination&quot; : &quot;B&quot;, &quot;source&quot; : &quot;A&quot;, &quot;state&quot; : &quot;committed&quot;, &quot;value&quot; : 100 &#125;</div></pre></td></tr></table></figure></p>
<h3 id="移除pending事务："><a href="#移除pending事务：" class="headerlink" title="移除pending事务："></a>移除pending事务：</h3><p>使用下面的<code>update()</code>操作从<code>accounts</code>集合中移除<code>pending</code>事务：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">db.accounts.update(&#123;name: t.source&#125;, &#123;$pull: &#123;pendingTransactions: t._id&#125;&#125;)</div><div class="line">db.accounts.update(&#123;name: t.destination&#125;, &#123;$pull: &#123;pendingTransactions: t._id&#125;&#125;)</div><div class="line">db.accounts.find()</div></pre></td></tr></table></figure></p>
<p><code>find()</code>操作返回accounts集合内容，现在应该类似下面内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc97fb8a04f5126961523&quot;), &quot;balance&quot; : 900, &quot;name&quot; : &quot;A&quot;, &quot;pendingTransactions&quot; : [ ] &#125;</div><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc984b8a04f5126961524&quot;), &quot;balance&quot; : 1100, &quot;name&quot; : &quot;B&quot;, &quot;pendingTransactions&quot; : [ ] &#125;</div></pre></td></tr></table></figure>
<h3 id="设置事务状态为done："><a href="#设置事务状态为done：" class="headerlink" title="设置事务状态为done："></a>设置事务状态为done：</h3><p>通过设置transaction文档的<code>state</code>为<code>done</code>完成事务：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">db.transactions.update(&#123;_id: t._id&#125;, &#123;$set: &#123;state: &quot;done&quot;&#125;&#125;)</div><div class="line">db.transactions.find()</div></pre></td></tr></table></figure></p>
<p><code>find()</code>操作返回transaction集合的内容，此时应该类似下面：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc7a8b8a04f5126961522&quot;), &quot;destination&quot; : &quot;B&quot;, &quot;source&quot; : &quot;A&quot;, &quot;state&quot; : &quot;done&quot;, &quot;value&quot; : 100 &#125;</div></pre></td></tr></table></figure></p>
<h3 id="从失败场景中恢复："><a href="#从失败场景中恢复：" class="headerlink" title="从失败场景中恢复："></a>从失败场景中恢复：</h3><p>最重要的部分不是上面的典型例子，而是从各种失败场景中恢复未完成的事务的可能性。这部分将概述可能的失败，并提供方法从这些事件中恢复事务。这里有两种类型的失败：</p>
<p>1、所有发生在第一步（即设置事务的初始状态<code>initial</code>）之后，但在第三步（即应用事务到两个账户）之前的失败。为了还原事务，应用应该获取一个<code>pending</code>状态的<code>transaction</code>列表并且从第二步（即切换事务到<code>pending</code>状态）中恢复。</p>
<p>2、所有发生在第三步之后（即应用事务到两个账户）但在第五步(即设置事务状态为<code>done</code>)之前的失败。为了还原事务，应用需要获取一个<code>committed</code>状态的事务列表，并且从第四步（即移除<code>pending</code>事务）恢复。</p>
<p>因此应用程序总是能够恢复事务，最终达到一个一致的状态。应用程序开始捕获到每个未完成的事务时运行下面的恢复操作。你可能还希望定期运行恢复操作，以确保数据处于一致状态。达成一致状态所需要的时间取决于应用程序需要多长时间恢复每个事务。</p>
<h3 id="回滚："><a href="#回滚：" class="headerlink" title="回滚："></a>回滚：</h3><p>在某些情况下可能需要“回滚”或“撤消”事务，当应用程序需要“取消”该事务时，或者是因为它永远需要恢复当其中一个帐户不存在的情况下，或停止现有的事务。这里有两种可能的回滚操作：</p>
<p>1、应用事务（即第三步）之后，你已经完全提交事务，你不应该回滚事务。相反，创建一个新的事务，切换源(源)和目标(destination)的值。</p>
<p>2、创建事务（即第一步）之后，在应用事务（即第三步）之前，使用下面的处理过程：</p>
<h3 id="设置事务状态为canceling："><a href="#设置事务状态为canceling：" class="headerlink" title="设置事务状态为canceling："></a>设置事务状态为canceling：</h3><pre><code>首先设置事务状态为canceling，使用下面的update()操作：
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.transactions.update(&#123;_id: t._id&#125;, &#123;$set: &#123;state: &quot;canceling&quot;&#125;&#125;)</div></pre></td></tr></table></figure>
<p>###撤销事务：</p>
<p>使用下面的操作顺序从两个账户中撤销事务：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">db.accounts.update(&#123;name: t.source, pendingTransactions: t._id&#125;, &#123;$inc: &#123;balance: t.value&#125;, $pull: &#123;pendingTransactions: t._id&#125;&#125;)</div><div class="line">db.accounts.update(&#123;name: t.destination, pendingTransactions: t._id&#125;, &#123;$inc: &#123;balance: -t.value&#125;, $pull: &#123;pendingTransactions: t._id&#125;&#125;)</div><div class="line">db.accounts.find()</div></pre></td></tr></table></figure>
<p><code>find()</code>操作返回acounts集合的内容，应该类似下面：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc97fb8a04f5126961523&quot;), &quot;balance&quot; : 1000, &quot;name&quot; : &quot;A&quot;, &quot;pendingTransactions&quot; : [ ] &#125;</div><div class="line">&#123; &quot;_id&quot; : ObjectId(&quot;4d7bc984b8a04f5126961524&quot;), &quot;balance&quot; : 1000, &quot;name&quot; : &quot;B&quot;, &quot;pendingTransactions&quot; : [ ] &#125;</div></pre></td></tr></table></figure></p>
<h3 id="设置事务状态为canceled："><a href="#设置事务状态为canceled：" class="headerlink" title="设置事务状态为canceled："></a>设置事务状态为<code>canceled</code>：</h3><p>最后，使用下面的update()状态将事务状态设置为canceled：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.transactions.update(&#123;_id: t._id&#125;, &#123;$set: &#123;state: &quot;canceled&quot;&#125;&#125;)</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      MongoDB两阶段提交实现事务
    
    </summary>
    
      <category term="MongoDB" scheme="http://jishusuishouji.github.io/categories/MongoDB/"/>
    
    
      <category term="MongoDB" scheme="http://jishusuishouji.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>mysql-Innodb事务隔离级别-repeatable read详解</title>
    <link href="http://jishusuishouji.github.io/2017/03/27/mysql/mysql-Innodb%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB-repeatable_read%E8%AF%A6%E8%A7%A3/"/>
    <id>http://jishusuishouji.github.io/2017/03/27/mysql/mysql-Innodb事务隔离级别-repeatable_read详解/</id>
    <published>2017-03-27T11:04:08.000Z</published>
    <updated>2017-03-27T11:37:29.144Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、事务隔离级别"><a href="#一、事务隔离级别" class="headerlink" title="一、事务隔离级别"></a>一、事务隔离级别</h2><p>ANSI/ISO SQL标准定义了4中事务隔离级别：未提交读（read uncommitted），提交读（read committed），重复读（repeatable read），串行读（serializable）。</p>
<p>对于不同的事务，采用不同的隔离级别分别有不同的结果。不同的隔离级别有不同的现象。主要有下面3种现在：</p>
<p>1、脏读（dirty read）：一个事务可以读取另一个尚未提交事务的修改数据。</p>
<p>2、非重复读（nonrepeatable read）：在同一个事务中，同一个查询在T1时间读取某一行，在T2时间重新读取这一行时候，这一行的数据已经发生修改(T1和T2都在同一个事务里面)，可能被更新了（update），也可能被删除了（delete）。</p>
<p>3、幻像读（phantom read）：在同一事务中，同一查询多次进行时候，由于其他插入操作（insert）的事务提交，导致每次返回不同的结果集。</p>
<p>不同的隔离级别有不同的现象，并有不同的锁定/并发机制，隔离级别越高，数据库的并发性就越差，4种事务隔离级别分别表现的现象如下表：</p>
<table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读</th>
<th>非重复读</th>
<th>幻像读</th>
</tr>
</thead>
<tbody>
<tr>
<td>read uncommitted</td>
<td>允许</td>
<td>允许</td>
<td>允许</td>
</tr>
<tr>
<td>read committed</td>
<td></td>
<td>允许</td>
<td>允许</td>
</tr>
<tr>
<td>repeatable read</td>
<td></td>
<td></td>
<td>允许</td>
</tr>
<tr>
<td>serializable</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="二、数据库中的默认事务隔离级别"><a href="#二、数据库中的默认事务隔离级别" class="headerlink" title="二、数据库中的默认事务隔离级别"></a>二、数据库中的默认事务隔离级别</h2><p>在Oracle中默认的事务隔离级别是提交读（read committed）。<br>对于MySQL的Innodb的默认事务隔离级别是重复读（repeatable read）。可以通过下面的命令查看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">mysql&gt; SELECT @@GLOBAL.tx_isolation, @@tx_isolation;</div><div class="line"></div><div class="line">+———————–+—————–+</div><div class="line"></div><div class="line">| @@GLOBAL.tx_isolation | @@tx_isolation  |</div><div class="line"></div><div class="line">+———————–+—————–+</div><div class="line"></div><div class="line">| REPEATABLE-READ | REPEATABLE-READ |</div><div class="line"></div><div class="line">+———————–+—————–+</div><div class="line"></div><div class="line">1 row in set (0.00 sec)</div></pre></td></tr></table></figure>
<p>下面进行一下测试：</p>
<p><img src="/img/mysql Innodb repeatable read测试.png" alt=""><br>【说明】<br>事务提交，看到最新数据。</p>
<p>上面的结果可以看到Innodb的重复读（repeatable read）不允许脏读，不允许非重复读（即可以重复读，Innodb使用多版本一致性读来实现）和不允许幻象读（这点和ANSI/ISO SQL标准定义的有所区别）。</p>
<p>另外，同样的测试：</p>
<p>1、当session 2进行truncate表的时候，这个时候session 1再次查询就看不到数据。</p>
<p>2、当session 2进行alter表的时候，这个时候session 1再次查询就看不到数据。</p>
<p>造成以上的原因是因为 mysql的持续非锁定读，在repeatable read级别下，读采用的是持续非锁定读。相关介绍见下面：</p>
<p>持续读意味着InnoDB使用它的多版本化来给一个查询展示某个时间点处数据库的快照。查询看到在那个时间点之前被提交的那些确切事务做的更改，并且没有其后的事务或未提交事务做的改变。这个规则的例外是，查询看到发布该查询的事务本身所做的改变。</p>
<p>如果你运行在默认的REPEATABLE READ隔离级别，则在同一事务内的所有持续读读取由该事务中第一个这样的读所确立的快照。你可以通过提交当前事务并在发布新查询的事务之后，为你的查询获得一个更新鲜的快照。</p>
<p>持续读是默认模式，在其中InnoDBzai在READ COMMITTED和REPEATABLE READ隔离级别处理SELECT语句。持续读不在任何它访问的表上设置锁定，因此，其它用户可自由地在持续读在一个表上执行的同一时间修改这些表。</p>
<p>注意，持续读不在DROP TABLE和ALTER TABLE上作用。持续读不在DROP TABLE上作用，因为MySQL不能使用已经被移除的表，并且InnoDB 破坏了该表。持续读不在ALTER TABLE上作用，因为它在某事务内执行，该事务创建一个新表，并且从旧表往新表中插入行。现在，当你重新发出持续读之时，它不能在新表中看见任何行，因为它们被插入到一个在持续读读取的快照中不可见的事务 里。</p>
<p>MySQL官方文档中的多版本一致性读中说明了原因：Consistent read does not work over certain DDL statements。</p>
]]></content>
    
    <summary type="html">
    
      mysql-Innodb事务隔离级别-repeatable read详解
    
    </summary>
    
      <category term="mysql" scheme="http://jishusuishouji.github.io/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://jishusuishouji.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>说说MySQL中的事务</title>
    <link href="http://jishusuishouji.github.io/2017/03/27/mysql/%E8%AF%B4%E8%AF%B4MySQL%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1/"/>
    <id>http://jishusuishouji.github.io/2017/03/27/mysql/说说MySQL中的事务/</id>
    <published>2017-03-27T10:27:04.000Z</published>
    <updated>2017-03-27T10:58:26.740Z</updated>
    
    <content type="html"><![CDATA[<h2 id="从一个问题开始"><a href="#从一个问题开始" class="headerlink" title="从一个问题开始"></a>从一个问题开始</h2><p>从ATM机取钱分为以下几个步骤：</p>
<p>1.登陆ATM机，输入密码；<br>2.连接数据库，验证密码；<br>3.验证成功，获得用户信息，比如存款余额等；<br>4.用户输入需要取款的金额，按下确认键；<br>5.从后台数据库中减掉用户账户上的对应金额；<br>6.ATM吐出钱；<br>7.用户把钱拿走。</p>
<p>一个简单的取钱，主要分为以上几步。不知道大家有没有“天真”的想过，如果在第5步中，后台数据库中已经把钱减掉了，但是ATM还就是没有吐出钱（虽然实际也发生过，但是毕竟是低概率事件），这该怎么办？</p>
<p>关于这个问题，银行系统的开发人员早就想过了，那么他们是怎么来搞定这个问题的呢？这就要说到今天总结的事务这个概念了。</p>
<h2 id="简单说说事务"><a href="#简单说说事务" class="headerlink" title="简单说说事务"></a>简单说说事务</h2><p>对于上面的取钱这个事情，如果有一步出现了错误，那么就取消整个取钱的动作；简单来说，就是取钱这7步，要么都完成，要么就啥也不做。在数据库中，事务也是这个道理。</p>
<p>事务由一条或者多条sql语句组成，在事务中的操作，这些sql语句要么都执行，要么都不执行，这就是事务的目的。</p>
<p>对于事务而言，它需要满足ACID特性，下面就简要的说说事务的ACID特性。</p>
<p>A，表示原子性；原子性指整个数据库事务是不可分割的工作单位。只有使事务中所有的数据库操作都执行成功，整个事务的执行才算成功。事务中任何一个sql语句执行失败，那么已经执行成功的sql语句也必须撤销，数据库状态应该退回到执行事务前的状态；<br>C，表示一致性；也就是说一致性指事务将数据库从一种状态转变为另一种一致的状态，在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏；<br>I，表示隔离性；隔离性也叫做并发控制、可串行化或者锁。事务的隔离性要求每个读写事务的对象与其它事务的操作对象能相互分离，即该事务提交前对其它事务都不可见，这通常使用锁来实现；<br>D，持久性，表示事务一旦提交了，其结果就是永久性的，也就是数据就已经写入到数据库了，如果发生了宕机等事故，数据库也能将数据恢复。</p>
<p>总结了一些事务的基本概念，在MySQL中，事务还是分为很多中的，下面就来看看到底有哪些事务。</p>
<h2 id="有哪些事务"><a href="#有哪些事务" class="headerlink" title="有哪些事务"></a>有哪些事务</h2><p>你能想象到吗？就这么个破事务还会分以下这么多种：</p>
<ul>
<li>扁平事务；</li>
<li>带有保存点的扁平事务；</li>
<li>链事务；</li>
<li>嵌套事务；</li>
<li>分布式事务。</li>
</ul>
<p>现在就来对这些事务从概念的层面上进行简单的总结一下。</p>
<h3 id="扁平事务"><a href="#扁平事务" class="headerlink" title="扁平事务"></a>扁平事务</h3><p>扁平事务是最简单的一种，也是实际开发中使用的最多的一种事务。在这种事务中，所有操作都处于同一层次，最常见的方式如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">BEGIN WORK</div><div class="line">    Operation 1</div><div class="line">    Operation 2</div><div class="line">    Operation 3</div><div class="line">    ...</div><div class="line">    Operation N</div><div class="line">COMMIT WORK</div></pre></td></tr></table></figure></p>
<p>或者是这种：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">BEGIN WORK</div><div class="line">    Operation 1</div><div class="line">    Operation 2</div><div class="line">    Operation 3</div><div class="line">    ...</div><div class="line">    Operation N</div><div class="line">    (Error Occured)</div><div class="line">ROLLBACK WORK</div></pre></td></tr></table></figure></p>
<p>扁平事务的主要缺点是不能提交或回滚事务的某一部分，或者分几个独立的步骤去提交。比如有这样的一个例子，我从呼和浩特去深圳，为了便宜，我可能这么干：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">BEGIN WORK</div><div class="line">    Operation1:呼和浩特---火车---&gt;北京</div><div class="line">    Operation2:北京---飞机---&gt;深圳</div><div class="line">ROLLBACK WORK</div></pre></td></tr></table></figure></p>
<p>但是，如果Operation1，从呼和浩特到北京的火车晚点了，错过了航班，怎么办？感觉扁平事务的特性，那我就需要回滚，我再回到呼和浩特，那么这样成本是不是也太高了啊，所以就有了下面的第二种事务——带有保存点的扁平事务。</p>
<h3 id="带有保存点的扁平事务"><a href="#带有保存点的扁平事务" class="headerlink" title="带有保存点的扁平事务"></a>带有保存点的扁平事务</h3><p>这种事务除了支持扁平事务支持的操作外，允许在事务执行过程中回滚到同一事务中较早的一个状态，这是因为可能某些事务在执行过程中出现的错误并不会对所有的操作都无效，放弃整个事务不合乎要求，开销也太大。保存点用来通知系统应该记住事务当前的状态，以便以后发生错误时，事务能回到该状态。</p>
<h3 id="链事务"><a href="#链事务" class="headerlink" title="链事务"></a>链事务</h3><p>链事务，就是指回滚时，只能恢复到最近一个保存点；而带有保存点的扁平事务则可以回滚到任意正确的保存点。</p>
<h3 id="嵌套事务"><a href="#嵌套事务" class="headerlink" title="嵌套事务"></a>嵌套事务</h3><p>看下面这个，你就能明白了，啥是嵌套事务：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">BEGIN WORK</div><div class="line">    SubTransaction1:</div><div class="line">            BEGIN WORK</div><div class="line">                SubOperationX</div><div class="line">            COMMIT WORK</div><div class="line">    SubTransaction2:</div><div class="line">            BEGIN WORK</div><div class="line">                SubOperationY</div><div class="line">            COMMIT WORK</div><div class="line">    ...</div><div class="line">    SubTransactionN:</div><div class="line">            BEGIN WORK</div><div class="line">                SubOperationN</div><div class="line">            COMMIT WORK</div><div class="line">COMMIT WORK</div></pre></td></tr></table></figure></p>
<p>这就是嵌套事务，在事务中再嵌套事务，位于根节点的事务称为顶层事务。事务的前驱称为父事务，其它事务称为子事务。事务的前驱称为父事务，事务的下一层称为子事务。</p>
<p>子事务既可以提交也可以回滚，但是它的提交操作并不马上生效，除非由其父事务提交。因此就可以确定，任何子事务都在顶层事务提交后才真正的被提交了。同理，任意一个事务的回滚都会引起它的所有子事务一同回滚。</p>
<h3 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h3><p>分布式事务通常是指在一个分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点，比如：通过建设银行向招商银行转账，建设银行和招商银行肯定用的不是同一个数据库，同时二者的数据库也不在一个网络节点上，那么当用户跨行转账，就是通过分布式事务来保证数据的ACID的。</p>
<h2 id="MySQL中使用事务"><a href="#MySQL中使用事务" class="headerlink" title="MySQL中使用事务"></a>MySQL中使用事务</h2><p>理论总结的再好，终归都要通过实践来进行理解。下面就来说说MySQL中是如何使用事务的。</p>
<p>在MySQL命令行的默认设置下，事务都是自动提交的，即执行SQL语句后就会马上执行COMMIT操作。因此要显示地开启一个事务须使用命令BEGIN或START TRANSACTION，或者执行命令<code>SET AUTOCOMMIT=0</code>，用来禁止使用当前会话的自动提交。</p>
<p>来看看我们可以使用哪些事务控制语句。</p>
<ul>
<li><code>BEGIN</code>或<code>START TRANSACTION</code>；显示地开启一个事务；</li>
<li><code>COMMIT</code>；也可以使用<code>COMMIT WORK</code>，不过二者是等价的。COMMIT会提交事务，并使已对数据库进行的所有修改称为永久性的；</li>
<li>ROLLBACK；有可以使用ROLLBACK WORK，不过二者是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改；</li>
<li><code>SAVEPOINT identifier</code>；SAVEPOINT允许在事务中创建一个保存点，一个事务中可以有多个SAVEPOINT；</li>
<li>RELEASE SAVEPOINT identifier；删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常；</li>
<li><code>ROLLBACK TO identifier</code>；把事务回滚到标记点；</li>
<li><code>SET RANSACTION</code>；用来设置事务的隔离级别。InnoDB存储引擎提供事务的隔离级别有<code>READ UNCOMMITTED</code>、<code>READ COMMITTED</code>、<code>REPEATABLE READ</code>和<code>SERIALIZABLE</code>。</li>
</ul>
<h2 id="这些不用你“管”"><a href="#这些不用你“管”" class="headerlink" title="这些不用你“管”"></a>这些不用你“管”</h2><p>有的时候有些SQL语句会产生一个隐式的提交操作，即执行完成这些语句后，会有一个隐式的<code>COMMIT</code>操作。有以下SQL语句，不用你去“管”：</p>
<ul>
<li>DDL语句，ALTER DATABASE、ALTER EVENT、ALTER PROCEDURE、ALTER TABLE、ALTER VIEW、CREATE TABLE、DROP TABLE、RENAME TABLE、TRUNCATE TABLE等；</li>
<li>修改MYSQL架构的语句，CREATE USER、DROP USER、GRANT、RENAME USER、REVOKE、SET PASSWORD；</li>
<li>管理语句，ANALYZE TABLE、CACHE INDEX、CHECK TABLE、LOAD INDEX INTO CACHE、OPTIMIZE TABLE、REPAIR TABLE等。</li>
</ul>
<p>以上的这些SQL操作都是隐式的提交操作，不需要手动显式提交。</p>
<h2 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h2><p>上面也说到了<code>SET TRANSACTION</code>用来设置事务的隔离级别。那事务的隔离级别是什么东东？</p>
<p>在数据库操作中，为了有效保证并发读取数据的正确性，提出的事务隔离级别。</p>
<p>InnoDB存储引擎提供事务的隔离级别有READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ和SERIALIZABLE。这些隔离级别之间的区别如下：</p>
<table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读（Dirty Read）</th>
<th>不可重复读（NonRepeatable Read）</th>
<th>幻读（Phantom Read）</th>
</tr>
</thead>
<tbody>
<tr>
<td>未提交读（Read uncommitted）</td>
<td>可能</td>
<td>可能</td>
<td>可能</td>
</tr>
<tr>
<td>已提交读（Read committed）</td>
<td>不可能</td>
<td>可能</td>
<td>可能</td>
</tr>
<tr>
<td>可重复读（Repeatable read）</td>
<td>不可能</td>
<td>不可能</td>
<td>可能</td>
</tr>
<tr>
<td>可串行化（Serializable ）</td>
<td>不可能</td>
<td>不可能</td>
<td>不可能</td>
</tr>
</tbody>
</table>
<p>脏读：一个事务读取到了另外一个事务没有提交的数据；比如：事务T1更新了一行记录的内容，但是并没有提交所做的修改。事务T2读取到了T1更新后的行，然后T1执行回滚操作，取消了刚才所做的修改。现在T2所读取的行就无效了；<br>不可重复读：在同一事务中，两次读取同一数据，得到内容不同；比如：事务T1读取一行记录，紧接着事务T2修改了T1刚才读取的那一行记录(T2的事务已经提交了)。然后T1又再次读取这行记录，发现与刚才读取的结果不同。这就称为“不可重复”读，因为T1原来读取的那行记录已经发生了变化；<br>幻读：同一事务中，用同样的操作读取两次，得到的记录数不相同；比如：事务T1读取一条指定的WHERE子句所返回的结果集。然后事务T2新插入一行记录，这行记录恰好可以满足T1所使用的查询条件中的WHERE子句的条件。然后T1又使用相同的查询再次对表进行检索，但是此时却看到了事务T2刚才插入的新行。这个新行就称为“幻像”，因为对T1来说这一行就像突然出现的一样。</p>
<p>隔离级别越低，事务请求的锁越少或保持锁的时间就越短。InnoDB存储引擎默认的支持隔离级别是<code>REPEATABLE READ</code>；在这种默认的事务隔离级别下已经能完全保证事务的隔离性要求，即达到SQL标准的SERIALIZABLE级别隔离。</p>
<p>我们可以可以用<code>SET TRANSACTION</code>语句改变单个会话或者所有新进连接的隔离级别。它的语法如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">SET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL &#123;READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE&#125;</div></pre></td></tr></table></figure></p>
<p>注意：默认的行为（不带session和global）是为下一个（未开始）事务设置隔离级别。如果使用GLOBAL关键字，语句在全局对从那点开始创建的所有新连接（除了不存在的连接）设置默认事务级别。你需要SUPER权限来做这个。使用SESSION 关键字为将来在当前连接上执行的事务设置默认事务级别。 任何客户端都能自由改变会话隔离级别（甚至在事务的中间），或者为下一个事务设置隔离级别。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">mysql&gt; set session transaction isolation level repeatable read;</div><div class="line">Query OK, 0 rows affected (0.00 sec)</div><div class="line"></div><div class="line">mysql&gt; select @@tx_isolation;</div><div class="line">+-----------------+</div><div class="line">| @@tx_isolation  |</div><div class="line">+-----------------+</div><div class="line">| REPEATABLE-READ |</div><div class="line">+-----------------+</div><div class="line">1 row in set (0.00 sec)</div></pre></td></tr></table></figure></p>
<h2 id="数据库的默认隔离级别"><a href="#数据库的默认隔离级别" class="headerlink" title="数据库的默认隔离级别"></a>数据库的默认隔离级别</h2><h3 id="mysql的默认隔离级别是可重复读："><a href="#mysql的默认隔离级别是可重复读：" class="headerlink" title="mysql的默认隔离级别是可重复读："></a>mysql的默认隔离级别是可重复读：</h3><p>要是读为主的业务场景，建议RC模式；若是非读为主的业务场景，则建议RR模式，考虑到MySQL5.1及以上版本二进制日志登记格式，建议优先考虑RR模式。</p>
<h3 id="Oracle采用的也是-read-committed"><a href="#Oracle采用的也是-read-committed" class="headerlink" title="Oracle采用的也是 read committed"></a>Oracle采用的也是 read committed</h3><p>Oracle的RC 跟InnoDB存储引擎的RC不是一样的，属于综合了 RC + RR的折中版本。</p>
]]></content>
    
    <summary type="html">
    
      说说MySQL中的事务
    
    </summary>
    
      <category term="mysql" scheme="http://jishusuishouji.github.io/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://jishusuishouji.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>ORM到底是用还是不用？</title>
    <link href="http://jishusuishouji.github.io/2017/03/27/ORM/ORM%E5%88%B0%E5%BA%95%E6%98%AF%E7%94%A8%E8%BF%98%E6%98%AF%E4%B8%8D%E7%94%A8%EF%BC%9F/"/>
    <id>http://jishusuishouji.github.io/2017/03/27/ORM/ORM到底是用还是不用？/</id>
    <published>2017-03-27T05:22:54.000Z</published>
    <updated>2017-03-27T05:26:18.258Z</updated>
    
    <content type="html"><![CDATA[<p>ORM即Object/Relation Mapping的简写，一般称作“对象关系映射”，在Web开发中最常出没于和关系型数据库交互的地方。接口、中间件、库、包，你都可以这么称呼它。<br><a id="more"></a><br>我们可以结合PHP和MySQL，从ORM的四个核心理念来认识它：</p>
<ul>
<li>简单：ORM以最基本的形式建模数据。比如ORM会将MySQL的一张表映射成一个PHP类（模型），表的字段就是这个类的成员变量</li>
<li>精确：ORM使所有的MySQL数据表都按照统一的标准精确地映射成PHP类，使系统在代码层面保持准确统一</li>
<li>易懂：ORM使数据库结构文档化。比如MySQL数据库就被ORM转换为了PHP程序员可以读懂的PHP类，PHP程序员可以只把注意力放在他擅长的PHP层面（当然能够熟练掌握MySQL更好）</li>
<li>易用：ORM的避免了不规范、冗余、风格不统一的SQL语句，可以避免很多人为Bug，方便编码风格的统一和后期维护</li>
</ul>
<p>接下来再通过一个很基本的例子来说明一下ORM的使用，还以PHP和MySQL为例。</p>
<p>user这个数据模型是再普遍不过的了。假设我们有一张user数据表。</p>
<p>在OOP中通常我们需要写一个对应的class User来作为user数据表的数据模型:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">// 声明class User</div><div class="line">class User&#123;</div><div class="line">    $id;</div><div class="line">    $name;</div><div class="line"></div><div class="line">    function create()&#123;/*...*/&#125;</div><div class="line">    function load($id)&#123;/*...*/&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">// 使用class User</div><div class="line">$user = new User();</div><div class="line">$user-&gt;name = &apos;fancy&apos;;</div><div class="line">$user-&gt;create();</div></pre></td></tr></table></figure>
<p>但是通过ORM，我们可以不用去声明class User，可以直接继承ORM提供的工厂类，比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">// 直接使用！对于熟悉MVC的亲知道这个意义之所在！</div><div class="line">$user = new ORM(&apos;user&apos;);  // ORM都有自己的规则，这里直接使用了MySQL的表名</div><div class="line">$user-&gt;name = &apos;fancy&apos;;    // MySQL的表的字段就是$user对象的成员变量</div><div class="line">$user-&gt;save();            // 掉用ORM提供的接口函数</div></pre></td></tr></table></figure></p>
<p>ORM一般都针对数据模型提供了一下常见的接口函数，比如：<code>create()</code>, <code>update()</code>, <code>save()</code>, <code>load()</code>, <code>find()</code>, <code>find_all()</code>, <code>where()</code>等，也就是讲sql查询全部封装成了编程语言中的函数，通过函数的链式组合生成最终的SQL语句。</p>
<p>所以由这些来看，ORM对于敏捷开发和团队合作开发来说，好处是非常非常大的。这里就罗列一下我想到的ORM显著的优点：</p>
<ul>
<li>大大缩短了程序员的编码时间，减少甚至免除了对Model的编码</li>
<li>良好的数据库操作接口，使编码难度降低，使团队成员的代码变得简洁易读、风格统一</li>
<li>动态的数据表映射，在数据表结构甚至数据库发生改变时，减少了相应的代码修改</li>
<li>减少了程序员对数据库的学习成本</li>
<li>可以很方便地引入数据缓存之类的附加功能</li>
</ul>
<p>但是ORM并不是一个完美的东西，它同时也有其自身不可避免的缺点：</p>
<ul>
<li>自动化进行关系数据库的映射需要消耗系统性能。其实这里的性能消耗还好啦，一般来说都可以忽略之，特别是有cacha存在的时候</li>
<li>在处理多表联查、where条件复杂之类的查询时，ORM的语法会变得复杂且猥琐</li>
<li>越是功能强大的ORM越是消耗内存，因为一个ORM Object会带有很多成员变量和成员函数。有一次修复bug时就遇见，使用ORM查询的时候会占用12MB的内存，而使用SQL的查询时只占用了1.7MB……</li>
</ul>
<p>ORM就是这么一个让人又爱又恨的东西。回到我们开始的问题：“ORM到底是用还是不用？”</p>
<p>Fancy个人的观点是：ORM要用！但关键部位不能用！<br>因为对于一般的Web应用开发来说，使用ORM确实能带来上述的诸多好处，而且在大部分情况下涉及不到ORM的不好的地方。但是在系统里面有大数据量、大运算量、复杂查询的地方，就不要用ORM。ORM的性能问题将给你带来灾难。在这些地方就可以使用纯SQL或者其他简单轻量的DB Helper库了。在详细了解ORM之后，你就可以扬长避短让ORM发挥其最大效用了。</p>
]]></content>
    
    <summary type="html">
    
      ORM到底是用还是不用？
    
    </summary>
    
      <category term="ORM" scheme="http://jishusuishouji.github.io/categories/ORM/"/>
    
    
      <category term="ORM" scheme="http://jishusuishouji.github.io/tags/ORM/"/>
    
  </entry>
  
  <entry>
    <title>maven 多模块项目</title>
    <link href="http://jishusuishouji.github.io/2017/03/27/maven/maven_%E5%A4%9A%E6%A8%A1%E5%9D%97%E9%A1%B9%E7%9B%AE/"/>
    <id>http://jishusuishouji.github.io/2017/03/27/maven/maven_多模块项目/</id>
    <published>2017-03-27T02:16:27.000Z</published>
    <updated>2017-03-27T02:16:27.306Z</updated>
    
    <summary type="html">
    
      maven 多模块项目
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Maven最佳实践：划分模块</title>
    <link href="http://jishusuishouji.github.io/2017/03/27/maven/Maven%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%EF%BC%9A%E5%88%92%E5%88%86%E6%A8%A1%E5%9D%97/"/>
    <id>http://jishusuishouji.github.io/2017/03/27/maven/Maven最佳实践：划分模块/</id>
    <published>2017-03-27T02:00:50.000Z</published>
    <updated>2017-03-27T02:15:42.058Z</updated>
    
    <content type="html"><![CDATA[<p>“分天下为三十六郡，郡置守，尉，监” —— 《史记·秦始皇本纪》</p>
<p>所有用Maven管理的真实的项目都应该是分模块的，每个模块都对应着一个<code>pom.xml</code>。它们之间通过继承和聚合（也称作多模块，multi-module）相互关联。那么，为什么要这么做呢？我们明明在开发一个项目，划分模块后，导入Eclipse变成了N个项目，这会带来复杂度，给开发带来不便。<br><a id="more"></a><br>为了解释原因，假设有这样一个项目，很常见的Java Web应用。在这个应用中，我们分了几层：</p>
<ul>
<li>Dao层负责数据库交互，封装了Hibernate交互的类。</li>
<li>Service层处理业务逻辑，放一些Service接口和实现相关的Bean。</li>
<li>Web层负责与客户端交互，主要有一些Structs的Action类。</li>
</ul>
<p>对应的，在一个项目中，我们会看到一些包名：</p>
<ul>
<li><code>org.myorg.app.dao</code></li>
<li><code>org.myorg.app.service</code></li>
<li><code>org.myorg.app.web</code></li>
<li><code>org.myorg.app.util</code></li>
</ul>
<p>这样整个项目的框架就清晰了，但随着项目的进行，你可能会遇到如下问题：<br>这个应用可能需要有一个前台和一个后台管理端（web或者swing），你发现大部分dao，一些service，和大部分util是在两个应用中可用的。这样的问题，你一周内遇到了好几次。<br><code>pom.xml</code>中的依赖列表越来越长以重用的，但是，由于目前只有一个项目（WAR），你不得不新建一个项目依赖这个WAR，这变得非常的恶心，因为在Maven中配置对WAR的依赖远不如依赖JAR那样简单明了，而且你根本不需要<code>org.myorg.app.web</code>。有人修改了dao，提交到svn并且不小心导致build失败了，你在编写service的代码，发现编译不过，只能等那人把dao修复了，你才能继续进行，很多人都在修改，到后来你根本就不清楚哪个依赖是谁需要的，渐渐的，很多不必要的依赖被引入。甚至出现了一个依赖有多个版本存在。<br>build整个项目的时间越来越长，尽管你只是一直在web层工作，但你不得不build整个项目。<br>某个模块，比如util，你只想让一些经验丰富的人来维护，可是，现在这种情况，每个开发者都能修改，这导致关键模块的代码质量不能达到你的要求。<br>我们会发现，其实这里实际上没有遵守一个设计模式原则：“高内聚，低耦合”。虽然我们通过包名划分了层次，并且你还会说，这些包的依赖都是单向的，没有包的环依赖。这很好，但还不够，因为就构建层次来说，所有东西都被耦合在一起了。因此我们需要使用Maven划分模块。</p>
<p>一个简单的Maven模块结构是这样的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">---- app-parent</div><div class="line">             |-- pom.xml (pom)</div><div class="line">             |</div><div class="line">             |-- app-util</div><div class="line">             |        |-- pom.xml (jar)</div><div class="line">             |</div><div class="line">             |-- app-dao</div><div class="line">             |        |-- pom.xml (jar)</div><div class="line">             |</div><div class="line">             |-- app-service</div><div class="line">             |        |-- pom.xml (jar)</div><div class="line">             |</div><div class="line">             |-- app-web</div><div class="line">                      |-- pom.xml (war)</div></pre></td></tr></table></figure></p>
<p>上述简单示意图中，有一个父项目(app-parent)聚合很多子项目（app-util, app-dao, app-service, app-web）。每个项目，不管是父子，都含有一个<code>pom.xml</code>文件。而且要注意的是，小括号中标出了每个项目的打包类型。父项目是pom,也只能是pom。子项目有jar，或者war。根据它包含的内容具体考虑。</p>
<p>这些模块的依赖关系如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">app-dao      --&gt; app-util</div><div class="line">app-service --&gt; app-dao</div><div class="line">app-web     --&gt; app-service</div></pre></td></tr></table></figure></p>
<p>注意依赖的传递性（大部分情况是传递的，除非你配置了特殊的依赖scope），app-dao依赖于app-util，app-service依赖于app-dao，于是app-service也依赖于app-util。同理，app-web依赖于app-dao,app-util。</p>
<p>用<strong>项目层次的划分</strong>替<strong>代包层次的划分</strong>能给我们带来如下好处：</p>
<ul>
<li>方便重用，如果你有一个新的swing项目需要用到app-dao和app-service，添加对它们的依赖即可，你不再需要去依赖一个WAR。而有些模块，如app-util，完全可以渐渐进化成公司的一份基础工具类库，供所有项目使用。这是模块化最重要的一个目的。</li>
<li>由于你现在划分了模块，每个模块的配置都在各自的<code>pom.xml</code>里，不用再到一个混乱的纷繁复杂的总的POM中寻找自己的配置。</li>
<li>如果你只是在app-dao上工作，你不再需要build整个项目，只要在app-dao目录运行<code>mvn</code>命令进行build即可，这样可以节省时间，尤其是当项目越来越复杂，build越来越耗时后。</li>
<li>某些模块，如app-util被所有人依赖，但你不想给所有人修改，现在你完全可以从这个项目结构出来，做成另外一个项目，svn只给特定的人访问，但仍提供jar给别人使用。</li>
<li>多模块的Maven项目结构支持一些Maven的更有趣的特性（如<code>DepencencyManagement</code>），这留作以后讨论。</li>
<li>接下来讨论一下POM配置细节，实际上非常简单，先看app-parent的<code>pom.xml</code>：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  </div><div class="line">    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;  </div><div class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  </div><div class="line">    &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt;  </div><div class="line">    &lt;artifactId&gt;app-parent&lt;/artifactId&gt;  </div><div class="line">    &lt;packaging&gt;pom&lt;/packaging&gt;  </div><div class="line">    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  </div><div class="line">    &lt;modules&gt;  </div><div class="line">        &lt;module&gt;app-util&lt;/module&gt;  </div><div class="line">        &lt;module&gt;app-dao&lt;/module&gt;  </div><div class="line">        &lt;module&gt;app-service&lt;/module&gt;  </div><div class="line">        &lt;module&gt;app-web&lt;/module&gt;  </div><div class="line">    &lt;/modules&gt;  </div><div class="line">&lt;/project&gt;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>Maven的坐标GAV（<code>groupId</code>, <code>artifactId</code>, <code>version</code>）在这里进行配置，这些都是必须的。特殊的地方在于，这里的<code>packaging</code>为<code>pom</code>。所有带有子模块的项目的<code>packaging</code>都为<code>pom</code>。<code>packaging</code>如果不进行配置，它的默认值是<code>jar</code>，代表Maven会将项目打成一个jar包。<br>该配置重要的地方在于modules，例子中包含的子模块有app-util, app-dao, app-service, app-war。在Maven build app-parent的时候，它会根据子模块的相互依赖关系整理一个build顺序，然后依次build。<br>这就是一个父模块大概需要的配置，接下来看一下子模块符合配置继承父模块。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  </div><div class="line">    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;  </div><div class="line">    &lt;parent&gt;  </div><div class="line">        &lt;artifactId&gt;app-parent&lt;/artifactId&gt;  </div><div class="line">        &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt;  </div><div class="line">        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  </div><div class="line">    &lt;/parent&gt;  </div><div class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  </div><div class="line">    &lt;artifactId&gt;app-util&lt;/artifactId&gt;  </div><div class="line">    &lt;dependencies&gt;  </div><div class="line">        &lt;dependency&gt;  </div><div class="line">            &lt;groupId&gt;commons-lang&lt;/groupId&gt;  </div><div class="line">            &lt;artifactId&gt;commons-lang&lt;/artifactId&gt;  </div><div class="line">            &lt;version&gt;2.4&lt;/version&gt;  </div><div class="line">        &lt;/dependency&gt;  </div><div class="line">    &lt;/dependencies&gt;  </div><div class="line">&lt;/project&gt;</div></pre></td></tr></table></figure></p>
<p>app-util模块继承了app-parent父模块，因此这个POM的一开始就声明了对app-parent的引用，该引用是通过Maven坐标GAV实现的。而关于项目app-util本身，它却没有声明完整GAV，这里我们只看到了artifactId。这个POM并没有错，groupId和version默认从父模块继承了。实际上子模块从父模块继承一切东西，包括依赖，插件配置等等。<br>此外app-util配置了一个对于commons-lang的简单依赖，这是最简单的依赖配置形式。大部分情况，也是通过GAV引用的。<br>再看一下app-dao，它也是继承于app-parent，同时依赖于app-util：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  </div><div class="line">    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;  </div><div class="line">    &lt;parent&gt;  </div><div class="line">        &lt;artifactId&gt;app-parent&lt;/artifactId&gt;  </div><div class="line">        &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt;  </div><div class="line">        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  </div><div class="line">    &lt;/parent&gt;  </div><div class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  </div><div class="line">    &lt;artifactId&gt;app-dao&lt;/artifactId&gt;  </div><div class="line">    &lt;dependencies&gt;  </div><div class="line">        &lt;dependency&gt;  </div><div class="line">            &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt;  </div><div class="line">            &lt;artifactId&gt;app-util&lt;/artifactId&gt;  </div><div class="line">            &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt;  </div><div class="line">        &lt;/dependency&gt;  </div><div class="line">    &lt;/dependencies&gt;  </div><div class="line">&lt;/project&gt;</div></pre></td></tr></table></figure></p>
<p>该配置和app-util的配置几乎没什么差别，不同的地方在于，依赖变化了，app-dao依赖于app-util。这里要注意的是version的值为<code>${project.version}</code>，这个值是一个属性引用，指向了POM的project/version的值，也就是这个POM对应的version。由于app-dao的version继承于app-parent，因此它的值就是<code>1.0-SNAPSHOT</code>。而<code>app-util</code>也继承了这个值，因此在所有这些项目中，我们做到了保持版本一致。<br>这里还需要注意的是，app-dao依赖于app-util，而app-util又依赖于commons-lang，根据传递性，app-dao也拥有了对于commons-lang的依赖。<br>app-service我们跳过不谈，它依赖于app-dao。我们最后看一下app-web：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  </div><div class="line">    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;  </div><div class="line">    &lt;parent&gt;  </div><div class="line">        &lt;artifactId&gt;app-parent&lt;/artifactId&gt;  </div><div class="line">        &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt;  </div><div class="line">        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  </div><div class="line">    &lt;/parent&gt;  </div><div class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  </div><div class="line">    &lt;artifactId&gt;app-web&lt;/artifactId&gt;  </div><div class="line">    &lt;packaging&gt;war&lt;/packaging&gt;  </div><div class="line">    &lt;dependencies&gt;  </div><div class="line">        &lt;dependency&gt;  </div><div class="line">            &lt;groupId&gt;org.myorg.myapp&lt;/groupId&gt;  </div><div class="line">            &lt;artifactId&gt;app-service&lt;/artifactId&gt;  </div><div class="line">            &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt;  </div><div class="line">        &lt;/dependency&gt;  </div><div class="line">    &lt;/dependencies&gt;  </div><div class="line">&lt;/project&gt;</div></pre></td></tr></table></figure></p>
<p>app-web依赖于app-service，因此配置了对其的依赖。<br>由于app-web是我们最终要部署的应用，因此它的packaging是war。为此，你需要有一个目录<code>src/main/webapp</code>。并在这个目录下拥有web应用需要的文件，如<code>/WEB-INF/web.xml</code>。没有web.xml，Maven会报告build失败，此外你可能还会有这样一些子目录：/js, /img, /css … 。</p>
<p>看看Maven是如何build整个项目的，我们在 app-parent 根目录中运行 <code>mvn clean install</code> ，输出的末尾会有大致这样的内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line">...</div><div class="line">[INFO] [war:war]</div><div class="line">[INFO] Packaging webapp</div><div class="line">[INFO] Assembling webapp[app-web] in [/home/juven/workspaces/ws-others/myapp/app-web/target/app-web-1.0-SNAPSHOT]</div><div class="line">[INFO] Processing war project</div><div class="line">[INFO] Webapp assembled in[50 msecs]</div><div class="line">[INFO] Building war: /home/juven/workspaces/ws-others/myapp/app-web/target/app-web-1.0-SNAPSHOT.war</div><div class="line">[INFO] [install:install]</div><div class="line">[INFO] Installing /home/juven/workspaces/ws-others/myapp/app-web/target/app-web-1.0-SNAPSHOT.war to /home/juven/.m2/repository/org/myorg/myapp/app-web/1.0-SNAPSHOT/app-web-1.0-SNAPSHOT.war</div><div class="line">[INFO] </div><div class="line">[INFO] </div><div class="line">[INFO] ------------------------------------------------------------------------</div><div class="line">[INFO] Reactor Summary:</div><div class="line">[INFO] ------------------------------------------------------------------------</div><div class="line">[INFO] app-parent ............................................ SUCCESS [1.191s]</div><div class="line">[INFO] app-util .............................................. SUCCESS [1.274s]</div><div class="line">[INFO] app-dao ............................................... SUCCESS [0.583s]</div><div class="line">[INFO] app-service ........................................... SUCCESS [0.593s]</div><div class="line">[INFO] app-web ............................................... SUCCESS [0.976s]</div><div class="line">[INFO] ------------------------------------------------------------------------</div><div class="line">[INFO] ------------------------------------------------------------------------</div><div class="line">[INFO] BUILD SUCCESSFUL</div><div class="line">[INFO] ------------------------------------------------------------------------</div><div class="line">[INFO] Total time: 4 seconds</div><div class="line">[INFO] Finished at: Sat Dec 27 08:20:18 PST 2008</div><div class="line">[INFO] Final Memory: 3M/17M</div><div class="line">[INFO] ------------------------------------------------------------------------</div></pre></td></tr></table></figure></p>
<p>注意Reactor Summary，整个项目根据我们希望的顺序进行build。Maven根据我们的依赖配置，智能的安排了顺序，app-util, app-dao, app-service, app-web。</p>
<p>最后，你可以在 <code>app-web/target</code> 目录下找到文件 <code>app-web-1.0-SNAPSHOT.war</code> ，打开这个war包，在 <code>/WEB-INF/lib</code> 目录看到了 commons-lang-2.4.jar，以及对应的app-util, app-dao, app-service 的jar包。Maven自动帮你处理了打包的事情，并且根据你的依赖配置帮你引入了相应的jar文件。</p>
<p>使用多模块的Maven配置，可以帮助项目划分模块，鼓励重用，防止POM变得过于庞大，方便某个模块的构建，而不用每次都构建整个项目，并且使得针对某个模块的特殊控制更为方便。本文同时给出了一个实际的配置样例，展示了如何使用Maven配置多模块项目。</p>
]]></content>
    
    <summary type="html">
    
      Maven最佳实践：划分模块
    
    </summary>
    
      <category term="maven" scheme="http://jishusuishouji.github.io/categories/maven/"/>
    
    
      <category term="maven" scheme="http://jishusuishouji.github.io/tags/maven/"/>
    
  </entry>
  
  <entry>
    <title>mongodb最大连接数修改</title>
    <link href="http://jishusuishouji.github.io/2017/03/26/mongodb/mongodb%E6%9C%80%E5%A4%A7%E8%BF%9E%E6%8E%A5%E6%95%B0%E4%BF%AE%E6%94%B9/"/>
    <id>http://jishusuishouji.github.io/2017/03/26/mongodb/mongodb最大连接数修改/</id>
    <published>2017-03-26T11:22:25.000Z</published>
    <updated>2017-03-26T11:29:33.693Z</updated>
    
    <content type="html"><![CDATA[<p>在nodejs启动时一次性开了200个Mongodb连接，目的是为了高并发时减少数据库连接耗时。如果做cluster开10个实例就有2000个连接了，这样就有些节点连接不到数据库的情况。</p>
<p>原因是Mongodb默认最大连接数只有819个，于是通过在启动里面加参数<code>--maxConns=3000</code>来提高最大连接数。然后重启服务，但悲剧的是通过<code>db.serverStatus().connections;</code>查看到最大连接数还是<code>819</code>。原因是linux系统的限制，Linux系统默认一个进程最大文件打开数目为1024。需要在Mongodb开启前修改这个限制。在运行数据前运行<code>ulimit -n</code>命令 。如果已经加入开机脚本，就要在脚本中启动前增加这行了。比如：</p>
<pre><code>ulimit -n 20000
/usr/mongodb/bin/mongod --dbpath=/usr/mongodb/data/ --logpath=/usr/mongodb/log/mongodb.log  --maxConns=3000  --fork
</code></pre><p>再查看就可以看到最大连接数增加了。</p>
<h2 id="重启机器后仍有问题"><a href="#重启机器后仍有问题" class="headerlink" title="重启机器后仍有问题"></a>重启机器后仍有问题</h2><p>解决问题：<code>Invariant failure: ret resulted in status UnknownError 24: Too many open files at src/mongo/db/storage/wiredtiger/wiredtiger_session_cache.cpp 73</code></p>
<p>按照官方的建议<a href="https://docs.mongodb.com/manual/reference/ulimit/#recommended-ulimit-settings，" target="_blank" rel="external">https://docs.mongodb.com/manual/reference/ulimit/#recommended-ulimit-settings，</a> 由于centos 6的最大进程连接数为1024，我们就增加一个限制设定的配置</p>
<blockquote>
<p>Red Hat Enterprise Linux and CentOS 6 place a max process limitation of 1024 which overridesulimit settings. Create a file named /etc/security/limits.d/99-mongodb-nproc.conf with new soft nproc and hard nproc values to increase the process limit. See /etc/security/limits.d/90-nproc.conf file as an example.</p>
</blockquote>
<p>按照官方推荐的设置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">-f (file size): unlimited</div><div class="line">-t (cpu time): unlimited</div><div class="line">-v (virtual memory): unlimited [1]</div><div class="line">-n (open files): 64000</div><div class="line">-m (memory size): unlimited [1] [2]</div><div class="line">-u (processes/threads): 64000</div></pre></td></tr></table></figure></p>
<p>由于服务器只有openfiles不匹配且比推荐的小，另外process/threads比较大， 所以其中99-mongodb-nproc.conf的内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># Default limit for number of user&apos;s processes to prevent</div><div class="line"># accidental fork bombs.</div><div class="line"># See rhbz #432903 for reasoning.</div><div class="line"> </div><div class="line">root       soft    nproc     unlimited</div><div class="line">root       hard    nproc     unlimited</div><div class="line">root       soft    nofile    64000</div><div class="line">root       hard    nofile    64000</div></pre></td></tr></table></figure></p>
<p>设计后重启机器，可用<code>ulimit -a</code>看到值已经更改，问题解决。</p>
]]></content>
    
    <summary type="html">
    
      mongodb最大连接数修改
    
    </summary>
    
      <category term="mongodb" scheme="http://jishusuishouji.github.io/categories/mongodb/"/>
    
    
      <category term="mongodb" scheme="http://jishusuishouji.github.io/tags/mongodb/"/>
    
  </entry>
  
  <entry>
    <title>Spring Cloud Netflix构建微服务入门实践</title>
    <link href="http://jishusuishouji.github.io/2017/03/26/spring/Spring_Cloud_Netflix%E6%9E%84%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"/>
    <id>http://jishusuishouji.github.io/2017/03/26/spring/Spring_Cloud_Netflix构建微服务入门实践/</id>
    <published>2017-03-26T09:57:46.000Z</published>
    <updated>2017-03-27T02:15:42.669Z</updated>
    
    <content type="html"><![CDATA[<p>在使用Spring Cloud Netflix构建微服务之前，我们先了解一下Spring Cloud集成的Netflix OSS的基础组件Eureka，对于Netflix的其他微服务组件，像Hystrix、Zuul、Ribbon等等本文暂不涉及，感兴趣可以参考官网文档。这里，我们用最基础的Eureka来构建一个最基础的微服务应用，来演示如何构建微服务，了解微服务的基本特点。</p>
<h2 id="Eureka"><a href="#Eureka" class="headerlink" title="Eureka"></a>Eureka</h2><p>Eureka是Netflix开源的一个微服务注册组件，提供服务发现特性，它是一个基于REST的服务，主要具有如下功能：</p>
<ul>
<li>支持服务注册和发现</li>
<li>具有Load Balance和Failover的功能</li>
<li>在进行服务调用过程中，无需知道目标服务的主机（IP）和端口，只要知道服务名就可以实现调用</li>
</ul>
<p>通过Netfix在Github上的文档，我们看一下Eureka的基本架构，如下图所示：<br><img src="/img/Eureka的基本架构.png" alt="eureka_architecture"><br>Eureka主要包含如下两个核心组件：</p>
<h3 id="Eureka-Server"><a href="#Eureka-Server" class="headerlink" title="Eureka Server"></a>Eureka Server</h3><p>Eureka Server是服务注册的服务端组件，负责管理Eureka Client注册的服务，提供服务发现的功能。它支持集群模式部署，集群部署模式中，多个Eureka Server之间会同步服务注册数据，能够保证某一个Eureka Server因为故障挂掉，仍能对外提供注册服务的能力。因为最初在Netflix，Eureka主要用在AWS Cloud上，用作定位服务、Load Balance和Failover，在AWS Cloud上，Eureka支持在多个Region中部署Eureka Server而构建一个注册中心集群，从而实现了服务注册中心的高可用性。</p>
<h3 id="Eureka-Client"><a href="#Eureka-Client" class="headerlink" title="Eureka Client"></a>Eureka Client</h3><p>Eureka Client是Eureka Server客户端组件库，可以基于它向Eureka Server注册服务，供服务调用方调用；也可以是一个服务调用方，通过检索服务并调用已经注册的服务。如上图所示，Application Service和Application Client都是基于Eureka Client开发的使用Eureka Server的服务。另外，Eureka Client提供了内置的Load Balancer，实现了基本的Round-robin模式的负载均衡。</p>
<h2 id="Spring-Cloud-Netflix"><a href="#Spring-Cloud-Netflix" class="headerlink" title="Spring Cloud Netflix"></a>Spring Cloud Netflix</h2><p>Spring Cloud Netflix提供了对Netflix OSS的集成，同时还使用了Spring Boot，能够极大地简化微服务程序的开发。使用Spring Cloud提供的基本注解，就能非常方便的使用Netfix OSS基本组件。<br>要想使用Spring Cloud Eureka，只需要在Maven POM文件中加入如下依赖管理配置即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&lt;dependencyManagement&gt;</div><div class="line">    &lt;dependencies&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spring-cloud-netflix&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;1.0.7.RELEASE&lt;/version&gt;</div><div class="line">            &lt;type&gt;pom&lt;/type&gt;</div><div class="line">            &lt;scope&gt;import&lt;/scope&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">    &lt;/dependencies&gt;</div><div class="line">&lt;/dependencyManagement&gt;</div></pre></td></tr></table></figure></p>
<p>关于如何使用注解，我们会在下面的实践中，详细说明。</p>
<h2 id="构建微服务实践"><a href="#构建微服务实践" class="headerlink" title="构建微服务实践"></a>构建微服务实践</h2><p>我们构建一个简单的微服务应用，能够实现服务注册，服务调用的基本功能。计划实现的微服务应用，交互流程如下图所示：<br><img src="/img/eureka-service-interaction.png" alt="eureka-service-interaction"><br>上图中，我们假设Eureka Client并没有缓存Eureka Server中注册的服务，而是每次都需要通过Eureka Server来查找并映射目标服务。上图所示的微服务应用，具有如下服务组件：</p>
<p>两个Eureka Server实例组成的服务发现集群<br>通过Spring Cloud实现，只需要使用注解配置即可，代码如下所示：</p>
<p>01<br>package org.shirdrn.springcloud.eureka.server;<br>02</p>
<p>03<br>import org.springframework.boot.autoconfigure.SpringBootApplication;<br>04<br>import org.springframework.boot.builder.SpringApplicationBuilder;<br>05<br>import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;<br>06</p>
<p>07<br>@EnableEurekaServer<br>08<br>@SpringBootApplication<br>09<br>public class MyEurekaServer {<br>10</p>
<p>11<br>    public static void main(String[] args) {<br>12<br>        new SpringApplicationBuilder(MyEurekaServer.class).web(true).run(args);<br>13<br>    }<br>14<br>}<br>部署两个Eureka Server的代码是相同的，其中，对应的配置文件application.yml内容不同，示例如下所示：</p>
<p>01<br>server:<br>02<br>  port: 3300<br>03<br>spring:<br>04<br>  application:<br>05<br>    name: my-eureka-server<br>06<br>eureka:<br>07<br>  client:<br>08<br>    serviceUrl:<br>09<br>      defaultZone: <a href="http://localhost:3300/eureka/,http://localhost:3301/eureka/" target="_blank" rel="external">http://localhost:3300/eureka/,http://localhost:3301/eureka/</a><br>10<br>  instance:<br>11<br>    metadataMap:<br>12<br>      instanceId: ${spring.application.name}:${spring.application.instance_id:${random.value}}<br>另一个只需要改一下server.port为3301即可。</p>
<p>具有两个实例的Greeting Service服务<br>该示例服务，只是提供一个接口，能够给调用方返回调用结果，实现代码，如下所示：</p>
<p>01<br>package org.shirdrn.springcloud.eureka.applicationservice.greeting;<br>02</p>
<p>03<br>import org.springframework.boot.autoconfigure.EnableAutoConfiguration;<br>04<br>import org.springframework.boot.autoconfigure.SpringBootApplication;<br>05<br>import org.springframework.boot.builder.SpringApplicationBuilder;<br>06<br>import org.springframework.cloud.netflix.eureka.EnableEurekaClient;<br>07<br>import org.springframework.web.bind.annotation.PathVariable;<br>08<br>import org.springframework.web.bind.annotation.RequestMapping;<br>09<br>import org.springframework.web.bind.annotation.RequestMethod;<br>10<br>import org.springframework.web.bind.annotation.RestController;<br>11</p>
<p>12<br>@SpringBootApplication<br>13<br>@EnableEurekaClient<br>14<br>@RestController<br>15<br>@EnableAutoConfiguration<br>16<br>public class GreeingService {<br>17</p>
<p>18<br>    @RequestMapping(method = RequestMethod.GET, value = “/greeting/{name}”)<br>19<br>    public String greet(@PathVariable(“name”) String name) {<br>20<br>        return “::01:: Hello, “ + name + “!”;<br>21<br>    }<br>22</p>
<p>23<br>    public static void main(String[] args) {<br>24<br>        new SpringApplicationBuilder(GreeingService.class).web(true).run(args);<br>25<br>    }<br>26<br>}<br>为了能够观察，Greeting Service的两个实例，能够在调用的时候实现Round-robin风格的负载均衡，特别在返回的结果中增加了标识来区分。<br>对应的配置文件application.properties内容，除了对应的端口和服务实例名称不同，其它都相同，示例如下所示：</p>
<p>1<br>server.port=9901<br>2<br>spring.application.name = greeting.service<br>3<br>eureka.instance.metadataMap.instanceId = ${spring.application.name}:instance-9901<br>4<br>eureka.client.serviceUrl.defaultZone = <a href="http://localhost:3300/eureka/,http://localhost:3301/eureka/" target="_blank" rel="external">http://localhost:3300/eureka/,http://localhost:3301/eureka/</a><br>这样就可以在启动时注册到Eureka Server中。</p>
<p>一个名称为Application Caller的服务，需要调用Greeting Service服务<br>该服务和上面的服务类似，只是在其内部实现了对远程服务的调用，我们的实现代码如下所示：</p>
<p>01<br>package org.shirdrn.springcloud.eureka.applicationclient.caller;<br>02</p>
<p>03<br>import org.springframework.beans.factory.annotation.Autowired;<br>04<br>import org.springframework.boot.CommandLineRunner;<br>05<br>import org.springframework.boot.autoconfigure.SpringBootApplication;<br>06<br>import org.springframework.boot.builder.SpringApplicationBuilder;<br>07<br>import org.springframework.cloud.netflix.eureka.EnableEurekaClient;<br>08<br>import org.springframework.cloud.netflix.feign.EnableFeignClients;<br>09<br>import org.springframework.stereotype.Component;<br>10<br>import org.springframework.web.client.RestTemplate;<br>11</p>
<p>12<br>@SpringBootApplication<br>13<br>@EnableEurekaClient<br>14<br>@EnableFeignClients<br>15<br>public class Application {<br>16</p>
<p>17<br>    public static void main(String[] args) {<br>18<br>        new SpringApplicationBuilder(Application.class)<br>19<br>                .web(false)<br>20<br>                .run(args);<br>21<br>    }<br>22<br>}<br>23</p>
<p>24<br>@Component<br>25<br>class RestTemplateExample implements CommandLineRunner {<br>26</p>
<p>27<br>    @Autowired<br>28<br>    private RestTemplate restTemplate;<br>29<br>    private static final String GREETING_SERVICE_URI = “<a href="http://greeting.service/greeting/{name}" target="_blank" rel="external">http://greeting.service/greeting/{name}</a>“;  // 通过服务名称来调用，而不需要知道目标服务的IP和端口<br>30</p>
<p>31<br>    @Override<br>32<br>    public void run(String… strings) throws Exception {<br>33<br>        while(true) {<br>34<br>            String greetingSentence = this.restTemplate.getForObject(<br>35<br>                    GREETING_SERVICE_URI,<br>36<br>                    String.class,<br>37<br>                    “Dean Shi”); // 透明调用远程服务<br>38<br>            System.out.println(“Response result: “ + greetingSentence);<br>39</p>
<p>40<br>            Thread.sleep(5000);<br>41<br>        }<br>42<br>    }<br>43<br>}<br>对应的配置文件application.properties内容，如下所示：</p>
<p>1<br>server.port=9999<br>2<br>spring.application.name = application.client.caller<br>3<br>eureka.instance.metadataMap.instanceId = ${spring.application.name}:instance-9999<br>4<br>eureka.client.serviceUrl.defaultZone = <a href="http://localhost:3300/eureka/,http://localhost:3301/eureka/" target="_blank" rel="external">http://localhost:3300/eureka/,http://localhost:3301/eureka/</a><br>启动并验证微服务应用</p>
<p>上面已经实现了该示例微服务应用的全部组件，先可以启动各个服务组件了。启动顺序如下所示：</p>
<p>启动两个Eureka Server<br>启动两个Greeting Service<br>启动服务消费应用Application Call<br>可以通过Web页面查看Eureka Server控制台，如下图所示：<br>eureka-web-console<br>多次启动Application Call应用，就可以通过查看Greeting Service服务的日志，可以看到服务被调用，而且实现了基础的Round-robin负载均衡，日志如下所示：</p>
<p>1<br>Response result: ::02:: Hello, Dean Shi!<br>2<br>Response result: ::01:: Hello, Dean Shi!<br>3<br>Response result: ::02:: Hello, Dean Shi!<br>4<br>Response result: ::01:: Hello, Dean Shi!<br>5<br>Response result: ::02:: Hello, Dean Shi!<br>6<br>Response result: ::01:: Hello, Dean Shi!<br>我们实现示例微服务应用，验证后符合我们的期望。<br>上面微服务应用的实现代码及其配置，可以查看我的Github：<a href="https://github.com/shirdrn/springcloud-eureka-demo.git" target="_blank" rel="external">https://github.com/shirdrn/springcloud-eureka-demo.git</a></p>
<p>参考链接</p>
<p><a href="https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance" target="_blank" rel="external">https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance</a><br><a href="http://cloud.spring.io/spring-cloud-netflix/" target="_blank" rel="external">http://cloud.spring.io/spring-cloud-netflix/</a><br><a href="http://cloud.spring.io/spring-cloud-netflix/1.0.x/" target="_blank" rel="external">http://cloud.spring.io/spring-cloud-netflix/1.0.x/</a><br><a href="https://spring.io/blog/2015/01/20/microservice-registration-and-discovery-with-spring-cloud-and-netflix-s-eureka" target="_blank" rel="external">https://spring.io/blog/2015/01/20/microservice-registration-and-discovery-with-spring-cloud-and-netflix-s-eureka</a><br><a href="http://itmuch.com/spring-cloud-sum-eureka/" target="_blank" rel="external">http://itmuch.com/spring-cloud-sum-eureka/</a><br><a href="http://blog.abhijitsarkar.org/technical/netflix-eureka/" target="_blank" rel="external">http://blog.abhijitsarkar.org/technical/netflix-eureka/</a><br>Creative Commons License<br>本文基于署名-非商业性使用-相同方式共享 4.0许可协议发布，欢迎转载、使用、重新发布，但务必保留文章署名时延军（包含链接：<a href="http://shiyanjun.cn），不得用于商业目的，基于本文修改后的作品务必以相同的许可发布。如有任何疑问，请与我联系。" target="_blank" rel="external">http://shiyanjun.cn），不得用于商业目的，基于本文修改后的作品务必以相同的许可发布。如有任何疑问，请与我联系。</a></p>
]]></content>
    
    <summary type="html">
    
      Spring Cloud Netflix构建微服务入门实践
    
    </summary>
    
      <category term="spring" scheme="http://jishusuishouji.github.io/categories/spring/"/>
    
    
      <category term="spring" scheme="http://jishusuishouji.github.io/tags/spring/"/>
    
  </entry>
  
  <entry>
    <title>ZooKeeper 基础知识、部署和应用程序</title>
    <link href="http://jishusuishouji.github.io/2017/03/26/zookeeper/ZooKeeper_%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E3%80%81%E9%83%A8%E7%BD%B2%E5%92%8C%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F/"/>
    <id>http://jishusuishouji.github.io/2017/03/26/zookeeper/ZooKeeper_基础知识、部署和应用程序/</id>
    <published>2017-03-25T16:07:53.000Z</published>
    <updated>2017-03-25T16:25:00.412Z</updated>
    
    <content type="html"><![CDATA[<p>Apache ZooKeeper 是一个面向分布式应用程序的高性能<strong>协调服务器</strong>。它使用一个简单的接口暴露公共服务（比如命名和配置管理、同步和组服务），让用户不必从头开始编程。它为实现共识、组管理、领导者选举和到场协议（presence protocol）配备了现成的支持。 的示例。</p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>ZooKeeper 是一个面向分布式系统的构建块。当设计一个分布式系统时，一般需要设计和开发一些协调服务：</p>
<ul>
<li><p>名称服务— 名称服务是将一个名称映射到与该名称有关联的一些信息的服务。电话目录是将人的名字映射到其电话号码的一个名称服务。同样，DNS服务也是一个名称服务，它将一个域名映射到一个 IP 地址。在分布式系统中，您可能想跟踪哪些服务器或服务在运行，并通过名称查看其状态。ZooKeeper暴露了一个简单的接口来完成此工作。也可以将名称服务扩展到组成员服务，这样就可以获得与正在查找其名称的实体有关联的组的信息。</p>
</li>
<li><p>锁定— 为了允许在分布式系统中对共享资源进行有序的访问，可能需要实现分布式互斥（distributed mutexes）。ZooKeeper 提供一种简单的方式来实现它们。</p>
</li>
<li>同步— 与互斥同时出现的是同步访问共享资源的需求。无论是实现一个生产者-消费者队列，还是实现一个障碍，ZooKeeper 都提供一个简单的接口来实现该操作。</li>
<li>配置管理— 您可以使用 ZooKeeper 集中存储和管理分布式系统的配置。这意味着，所有新加入的节点都将在加入系统后就可以立即使用来自ZooKeeper的最新集中式配置。这还允许您通过其中一个 ZooKeeper 客户端更改集中式配置，集中地更改分布式系统的状态。</li>
<li>领导者选举— 分布式系统可能必须处理节点停机的问题，您可能想实现一个自动故障转移策略。ZooKeeper 通过领导者选举对此提供现成的支持。</li>
</ul>
<p>虽然可以从头开始设计和实现所有这些服务，但调试任何问题、竞争条件或死锁都需要执行额外的工作，并且很难实现。就像您不会在代码中随处编写自己的随机数发生器或哈希函数一样，这里有一个要求：人们不应该在每次有需要时就到处从头编写自己的名称服务或领导者选举服务。此外，您可以相对容易地一起解决一个非常简单的组成员服务，但是，要编写它们来提供可靠性、复制和可扩展性，可能需要做更多的工作。这导致了Apache ZooKeeper 的开发和开源，Apache ZooKeeper是一个针对分布式系统的、开箱即用的、可靠的、可扩展的、高性能的协调服务。</p>
<p>ZooKeeper虽然是一个针对分布式系统的协调服务，但它本身也是一个分布式应用程序。ZooKeeper 遵循一个简单的客户端-服务器模型，其中客户端是使用服务的节点（即机器），而服务器是提供服务的节点。ZooKeeper 服务器的集合形成了一个ZooKeeper集合体（ensemble）。在任何给定的时间内，一个 ZooKeeper 客户端可连接到一个 ZooKeeper 服务器。每个 ZooKeeper服务器都可以同时处理大量客户端连接。每个客户端定期发送 ping 到它所连接的 ZooKeeper 服务器，让服务器知道它处于活动和连接状态。被询问的ZooKeeper 服务器通过 ping 确认进行响应，表示服务器也处于活动状态。如果客户端在指定时间内没有收到服务器的确认，那么客户端会连接到集合体中的另一台服务器，而且客户端会话会被透明地转移到新的 ZooKeeper 服务器。</p>
<p><img src="/img/ZooKeeper 的客户端-服务器架构.png" alt="图 1 描述了 ZooKeeper 的客户端-服务器架构。"></p>
<p> ZooKeeper 有一个类似于文件系统的数据模型，由znodes组成。可以将 znodes（ZooKeeper 数据节点）视为类似 UNIX 的传统系统中的文件，但它们可以有子节点。另一种方式是将它们视为目录，它们可以有与其相关的数据。每个这些目录都被称为一个 znode。图 2 显示的图代表与两个城市中的运动队相同的层次结构。</p>
<p><img src="/img/两个城市中的运动队的层次结构.png" alt="图 2. 该图表示了两个城市中的运动队的层次结构"></p>
<p>znode层次结构被存储在每个 ZooKeeper服务器的内存中。这实现了对来自客户端的读取操作的可扩展的快速响应。每个 ZooKeeper服务器还在磁盘上维护了一个事务日志，记录所有的写入请求。因为ZooKeeper 服务器在返回一个成功的响应之前必须将事务同步到磁盘，所以事务日志也是ZooKeeper 中对性能最重要的组成部分。可以存储在 znode 中的数据的默认最大大小为 1 MB。因此，即使 ZooKeeper 的层次结构看起来与文件系统相似，也不应该将它用作一个通用的文件系统。相反，应该只将它用作少量数据的存储机制，以便为分布式应用程序提供可靠性、可用性和协调。<br>当客户端请求读取特定 znode 的内容时，读取操作是在客户端所连接的服务器上进行的。因此，由于只涉及集合体中的一个服务器，所以读取是快速和可扩展的。然而，为了成功完成写入操作，要求 ZooKeeper 集合体的严格意义上的多数节点都是可用的。在启动 ZooKeeper 服务时，集合体中的某个节点被选举为领导者。当客户端发出一个写入请求时，所连接的服务器会将请求传递给领导者。此领导者对集合体的所有节点发出相同的写入请求。如果严格意义上的多数节点（也被称为法定数量（quorum））成功响应该写入请求，那么写入请求被视为已成功完成。然后，一个成功的返回代码会返回给发起写入请求的客户端。如果集合体中的可用节点数量未达到法定数量，那么ZooKeeper服务将不起作用。</p>
<p>法定数量是通过严格意义上的多数节点来表示的。在集合体中，可以包含一个节点，但它不是一个高可用和可靠的系统。如果在集合体中有两个节点，那么这两个节点都必须已经启动并让服务正常运行，因为两个节点中的一个并不是严格意义上的多数。如果在集合体中有三个节点，即使其中一个停机了，您仍然可以获得正常运行的服务（三个中的两个是严格意义上的多数）。出于这个原因，ZooKeeper 的集合体中通常包含奇数数量的节点，因为就容错而言，与三个节点相比，四个节点并不占优势，因为只要有两个节点停机，ZooKeeper 服务就会停止。在有五个节点的集群上，需要三个节点停机才会导致 ZooKeeper 服务停止运作。</p>
<p>现在，我们已经清楚地了解到，节点数量应该是奇数，让我们再来思考一下 ZooKeeper 集合体中需要有多少个节点。读取操作始终从连接到客户端的 ZooKeeper 服务器读取数据，所以它们的性能不会随着集合体中的服务器数量额变化而变化。但是，仅在写入法定数量的节点时，写入操作才是成功的。这意味着，随着在集合体中的节点数量的增加，写入性能会下降，因为必须将写入内容写入到更多的服务器中，并在更多服务器之间进行协调。</p>
<p>ZooKeeper的美妙之处在于，想运行多少服务器完全由您自己决定。如果想运行一台服务器，从 ZooKeeper的角度来看是没问题的；只是您的系统不再是高度可靠或高度可用的。三个节点的 ZooKeeper 集合体支持在一个节点故障的情况下不丢失服务，这对于大多数用户而言，这可能是没问题的，也可以说是最常见的部署拓扑。不过，为了安全起见，可以在您的集合体中使用五个节点。五个节点的集合体让您可以拿出一台服务器进行维护或滚动升级，并能够在不中断服务的情况下承受第二台服务器的意外故障。</p>
<p>因此，在 ZooKeeper 集合体中，三、五或七是最典型的节点数量。请记住，ZooKeeper 集合体的大小与分布式系统中的节点大小没有什么关系。分布式系统中的节点将是 ZooKeeper 集合体的客户端，每个 ZooKeeper服务器都能够以可扩展的方式处理大量客户端。例如，HBase（Hadoop 上的分布式数据库）依赖​​于 ZooKeeper 实现区域服务器的领导者选举和租赁管理。您可以利用一个相对较少（比如说，五个）节点的 ZooKeeper 集合体运行有 50 个节点的大型 HBase 集群。</p>
<h2 id="设置并部署-ZooKeeper-集合体"><a href="#设置并部署-ZooKeeper-集合体" class="headerlink" title="设置并部署 ZooKeeper 集合体"></a>设置并部署 ZooKeeper 集合体</h2><p>现在让我们设置并部署有三个节点的 ZooKeeper集合体。在这里，我们将使用撰写本文时的最新版的 ZooKeeper：3.4.5。我们用于此演示的节点被命名为zkserver1.mybiz.com、zkserver2.mybiz.com和zk3server3.mybiz.com。必须在每个节点上遵循下面的步骤来启动 ZooKeeper 服务器：</p>
<p>1.如果尚未安装 JDK，请下载安装它。这是必需的，因为 ZooKeeper 服务器在 JVM 上运行。<br>2.下载 ZooKeeper 3.4.5. tar.gz tarball 并将它解压缩到适当的位置。<br>清单 1. 下载 ZooKeeper tarball 并将它解压缩到适当的位置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"> wget</div><div class="line">http://www.bizdirusa.com/mirrors/apache/ZooKeeper/stable/zookeeper3.4.5.</div><div class="line">tar.gz tar xzvf zookeeper3.4.5.tar.gz</div></pre></td></tr></table></figure></p>
<p>3.创建一个目录，用它来存储与 ZooKeeper 服务器有关联的一些状态：<code>mkdir /var/lib/zookeeper</code>。您可能需要将这个目录创建为根目录，并在以后将这个目录的所有者更改为您希望运行ZooKeeper服务器的用户。<br>4.设置配置。创建或编辑<code>zookeeper3.4.5/conf/zoo.cfg</code>文件，使其与 清单 2 相似。<br>清单 2. 设置配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">tickTime=2000</div><div class="line">dataDir=/var/lib/zookeeper </div><div class="line">clientPort=2181</div><div class="line">initLimit=5 </div><div class="line">syncLimit=2</div><div class="line">server.1=zkserver1.mybiz.com:2888:3888</div><div class="line">server.2=zkserver2.mybiz.com:2888:3888</div><div class="line">server.3=zkserver3.mybiz.com:2888:3888</div></pre></td></tr></table></figure></p>
<p>值得重点注意的一点是，所有三个机器都应该打开端口 2181、2888 和 3888。在本例中，端口 2181 由 ZooKeeper 客户端使用，用于连接到 ZooKeeper 服务器；端口 2888 由对等 ZooKeeper 服务器使用，用于互相通信；而端口 3888 用于领导者选举。您可以选择自己喜欢的任何端口。通常建议在所有 ZooKeeper 服务器上使用相同的端口。</p>
<p>5.创建一个 <code>/var/lib/zookeeper/myid</code>文件。此文件的内容将只包含 zkserver1.mybiz.com 上的数字 1、zkserver2.mybiz.com 上的数字 2 和 zkserver3.mybiz.com 上的数字 3。清单 3 显示了来自 zkserver1.mybiz.com 的此文件的 cat 输出。<br>清单 3. cat 输出<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mark@zkserver1.mybiz.com:~# cat</div><div class="line">/var/lib/zookeeper/myid 1</div></pre></td></tr></table></figure></p>
<p>现在，您已经做好了在每台机器上启动 ZooKeeper 服务器的准备。</p>
<p>清单 4. 启动 ZooKeeper 服务器</p>
<pre><code>bin/zkServer.sh start
</code></pre><p>现在，您可以从其中一台正在运行 ZooKeeper 服务器的机器上启动一个 CLI 客户端。</p>
<p>清单 5. 启动 CLI 客户端<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">zookeeper3.4.5/ bin/zkCli.sh server</div><div class="line">zkserver1.mybiz.com:2181,zkserver2.mybiz.com:2181,zkserver3.mybiz.com:2181</div></pre></td></tr></table></figure></p>
<p>客户端提供一个服务器列表，可以任意选中一个进行连接。如果在连接过程中失去与该服务器的连接，则会选中列表中的另一台服务器，而且客户端会话也会转移到该服务器。一旦启动了客户端，您就可以创建、编辑和删除 znode。让我们在 <code>/mynode</code> 创建一个znode，使用helloworld作为关联的数据。</p>
<p>清单 6. 在 <code>/mynode</code> 上创建一个 znode<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[zk:127.0.0.1:2181(CONNECTED) 2] create /mynode</div><div class="line">helloworld Created /mynode</div></pre></td></tr></table></figure></p>
<p>现在，让我们在 /mynode 验证和检索数据。</p>
<p>清单 7. 在 /mynode 验证和检索数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[zk:127.0.0.1:2181(CONNECTED) 6] get /mynode</div><div class="line">helloworld cZxid = 0x200000005 ctime = Sat Jul 20</div><div class="line">19:53:52 PDT 2013 mZxid = 0x200000005 mtime = Sat</div><div class="line">Jul 20 19:53:52 PDT 2013 pZxid = 0x200000005</div><div class="line">cversion = 0 dataVersion = 0 aclVersion = 0</div><div class="line">ephemeralOwner = 0x0 dataLength = 11 numChildren =</div><div class="line">0</div></pre></td></tr></table></figure></p>
<p>您会发现，在获取一个 znode 数据时，客户端也返回了一些与 znode 有关的元数据。此元数据中的一些重要字段包括，与创建和最后修改 znode 的时间有关的阶段时间戳（ctime 和 mtime）、每次修改数据都会更改的数据版本（dataVersion）、数据长度（dataLength）、这个 znode 的子节点的数量（numChildren）。我们现在可以删除 znode。</p>
<p>清单 8. 删除 znode<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"> [zk:127.0.0.1:2181(CONNECTED) 7]</div><div class="line">rmr /mynode</div></pre></td></tr></table></figure></p>
<p>让我们在 /mysecondnode 创建另一个 znode。</p>
<p>清单 9. 创建另一个 znode<br>```<br>[zk:127.0.0.1:2181(CONNECTED) 10] create<br>/mysecondnode hello Created /mysecondnode<br>现在，让我们在 /mysecondnode 验证和检索数据。这一次，我们在最后提供了一个可选参数 1。此参数为 /mysecondnode 上的数据设置了一个一次性的触发器（名称为 watch）。如果另一个客户端在 /mysecondnode 上修改数据，该客户端将会获得一个异步通知。请注意，该通知只发送一次，除非 watch 被重新设置，否则不会因数据发生改变而再次发送通知。</p>
<p>清单 10. 在 /mysecondnode 上验证和检索数据</p>
<p>[zk:127.0.0.1:2181(CONNECTED) 12] get<br>/mysecondnode 1 hello cZxid = 0x200000007 ctime =<br>Sat Jul 20 19:58:27 PDT 2013 mZxid = 0x200000007<br>mtime = Sat Jul 20 19:58:27 PDT 2013 pZxid =<br>0x200000007 cversion = 0 dataVersion = 0<br>aclVersion = 0 ephemeralOwner = 0x0 dataLength = 5<br>numChildren = 0<br>现在，从不同的客户端（比如，从不同的机器）更改与 /mysecondnode 有关联的数据的值。</p>
<p>清单 11. 更改与 /mysecondnode 有关联的数据的值</p>
<p> [zk: localhost:2181(CONNECTED)<br>1] set /mysecondnode hello2 cZxid = 0x200000007<br>ctime = Sat Jul 20 19:58:27 PDT 2013 mZxid =<br>0x200000009 mtime = Sat Jul 20 20:02:37 PDT 2013<br>pZxid = 0x200000007 cversion = 0 dataVersion = 1<br>aclVersion = 0 ephemeralOwner = 0x0 dataLength = 6<br>numChildren = 0<br>您会发现，在第一个客户端上获得了一个 watch 通知。</p>
<p>清单 12. 在第一个客户端上获得了一个 watch 通知</p>
<p>[zk:127.0.0.1:2181(CONNECTED) 13] WATCHER::<br>WatchedEvent state:SyncConnected<br>type:NodeDataChanged path:/mysecondnode<br>继续下去，因为 znode 形成了一个分层命名空间，所以您还可以创建子节点。</p>
<p>清单 13. 创建子节点</p>
<p> [zk:<br>localhost:2181(CONNECTED) 2] create /mysecondnode/<br>subnode 123 Created /mysecondnode/ subnode<br>您可以获得关于某个 znode 的其他统计元数据。</p>
<p>清单 14. 获得关于某个 znode 的其他统计元数据</p>
<p> [zk:127.0.0.1:2181(CONNECTED)<br>14] stat /mysecondnode cZxid = 0x200000007 ctime =<br>Sat Jul 20 19:58:27 PDT 2013 mZxid = 0x200000009<br>mtime = Sat Jul 20 20:02:37 PDT 2013 pZxid =<br>0x20000000a cversion = 1 dataVersion = 1<br>aclVersion = 0 ephemeralOwner = 0x0 dataLength = 6<br>numChildren = 1<br>在上面的示例中，我们使用了 ZooKeeper 的 CLI 客户端与 ZooKeeper 服务器进行交互。ZooKeeper 提供了 Java™、C、Python 和其他绑定。您可以通过这些绑定调用客户端 API，将 Java、C 或 Python 应用程序转换为 ZooKeeper 客户端。</p>
<p>ZooKeeper 的应用程序</p>
<p>由于 ZooKeeper 在分布式系统中提供了一些多功能的用例，ZooKeeper 有一组不同的实用应用程序。我们将在这里列出部分这些应用程序。这些应用程序大多取自 Apache ZooKeeper 维基，那里还提供了一个更完整的最新列表。请参阅 参考资料，获得这些技术的链接：</p>
<p>Apache Hadoop 依靠 ZooKeeper 来实现 Hadoop HDFS NameNode 的自动故障转移，以及 YARN ResourceManager 的高可用性。</p>
<p>Apache HBase 是构建于 Hadoop 之上的分布式数据库，它使用 ZooKeeper 来实现区域服务器的主选举（master election）、租赁管理以及区域服务器之间的其他通信。</p>
<p>Apache Accumulo 是构建于 Apache ZooKeeper（和 Apache Hadoop）之上的另一个排序分布式键/值存储。</p>
<p>Apache Solr 使用 ZooKeeper 实现领导者选举和集中式配置。</p>
<p>Apache Mesos 是一个集群管理器，提供了分布式应用程序之间高效的资源隔离和共享。Mesos 使用 ZooKeeper 实现了容错的、复制的主选举。</p>
<p>Neo4j 是一个分布式图形数据库，它使用 ZooKeeper 写入主选择和读取从协调（read slave coordination）。</p>
<p>Cloudera Search 使用 ZooKeeper（通过 Apache Solr）集成了搜索功能与 Apache Hadoop，以实现集中式配置管理。</p>
<p>结束语</p>
<p>实现您自己的协议来协调分布式系统，这可能是一个令人感到沮丧的费时的过程。这正是 ZooKeeper 发挥其作用的地方。ZooKeeper 是一个稳定的、简单的、高性能的协调服务，为您提供编写正确的分布式应用程序所需的工具，而无需担心竞争条件、死锁和不一致。在下一次编写分布式应用程序时，您就可以利用 ZooKeeper 支持所有协调需求。</p>
]]></content>
    
    <summary type="html">
    
      ZooKeeper 基础知识、部署和应用程序
    
    </summary>
    
      <category term="ZooKeeper" scheme="http://jishusuishouji.github.io/categories/ZooKeeper/"/>
    
    
      <category term="ZooKeeper" scheme="http://jishusuishouji.github.io/tags/ZooKeeper/"/>
    
  </entry>
  
</feed>
